---
title: 消费者
date: 2024-09-18 12:42:00
permalink: /pages/ca141b/
---

## 前言

![image-20240918130848740](https://echo798.oss-cn-shenzhen.aliyuncs.com/img/202409181308806.png)

## 初始化

### 参数配置

在 Kafka 消费者的初始化过程中，需要配置多个关键参数，以保证消费者能够稳定、高效地从 Kafka 集群中读取消息。以下是一些常用的消费者参数：

- `bootstrap.servers`：Kafka 集群地址，用于连接到 Kafka 集群。
- `group.id`：消费者组 ID，Kafka 消费者必须属于某一个组，Kafka 使用消费者组来实现消息的分发和负载均衡。
- `enable.auto.commit`：是否自动提交位移，默认值为 `true`。若设置为 `false`，则需要手动控制位移提交。
- `auto.offset.reset`：当没有初始位移或位移超出范围时，如何处理。常见的选项有 `earliest`（从最早的消息开始消费）和 `latest`（从最新的消息开始消费）。
- `key.deserializer` 和 `value.deserializer`：指定用于反序列化消息键和值的类。常见的反序列化器包括 `StringDeserializer` 和 `ByteArrayDeserializer`。

### 订阅主题与分区

Kafka 消费者必须订阅一个或多个主题以开始消费消息。Kafka 提供了两种订阅模式：

1. **主题订阅**：消费者可以通过 `subscribe()` 方法订阅一个或多个主题，并让 Kafka 自动分配分区。
2. **分区分配**：消费者可以使用 `assign()` 方法直接指定消费的分区。这种方式常用于精细化控制，特别是在消息顺序性要求较高的场景。

## 消费过程

### 反序列化

Kafka 消费者从 Kafka 服务器拉取的消息是字节数组，因此需要使用反序列化器将字节数组转换为可读的 Java 对象。`key.deserializer` 和 `value.deserializer` 分别用于处理消息的键和值。

Kafka 内置了多种常见的反序列化器，开发者也可以根据业务需求自定义反序列化逻辑，需实现 `Deserializer` 接口。例如：

```Java
public class CustomDeserializer implements Deserializer<MyObject> {
    @Override
    public MyObject deserialize(String topic, byte[] data) {
        // 自定义反序列化逻辑
        return SerializationUtils.deserialize(data);
    }
}
```

### 消息消费

消息消费的核心是从 Kafka 中拉取消息并处理它们。Kafka 提供了 `poll()` 方法来拉取消息，这个方法会返回一个 `ConsumerRecords` 对象，其中包含多个 `ConsumerRecord`，每个 `ConsumerRecord` 代表一条消息。

```Java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        // 处理消息
        System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
    }
}
```

### 位移提交

Kafka 消费者需要定期提交位移（offset），以标识已经成功处理的消息。Kafka 提供了两种位移提交方式：

1. **自动提交**：由 `enable.auto.commit` 参数控制，Kafka 会在 `poll()` 之后自动提交当前位移。但这种方式可能导致消息丢失或重复消费。
2. **手动提交**：通过调用 `commitSync()` 或 `commitAsync()` 方法手动提交位移。手动提交可以更精确地控制消息的处理，但需要开发者在适当的时间点提交位移。

### 控制或关闭消费

在某些情况下，需要暂停或恢复消费，Kafka 提供了 `pause()` 和 `resume()` 方法用于控制指定分区的消费。例如，消费者可以在处理慢速批量任务时暂停消费，待任务完成后恢复消费。

```c
consumer.pause(Collections.singletonList(new TopicPartition("my-topic", 0)));
// 处理完慢速任务后恢复
consumer.resume(Collections.singletonList(new TopicPartition("my-topic", 0)));
```



### 指定位移消费

除了自动消费最新的消息外，Kafka 也允许消费者从指定的位移位置开始消费消息。通过 `seek()` 方法，可以精确地控制消费的开始位置，常用于故障恢复或特定时间点的数据回溯。

```Java
TopicPartition partition = new TopicPartition("my-topic", 0);
consumer.assign(Collections.singletonList(partition));
consumer.seek(partition, 1234L); // 从 offset 1234 开始消费
```

## 再均衡

Kafka 消费者组中的多个消费者会共同消费一个或多个主题的分区。Kafka 通过再均衡（rebalance）机制来动态调整分区分配，以确保每个消费者处理相应的分区。在以下情况下，Kafka 会触发再均衡：

- 有新的消费者加入或已有消费者离开。
- 消费者组中的某个消费者长时间未发送心跳。

再均衡对消费过程有一定影响，可能导致分区的临时不可用，或使正在处理的消息丢失。因此，在设计高可用消费应用时，需要考虑再均衡的处理。可以通过实现 `ConsumerRebalanceListener` 来控制再均衡的逻辑，特别是保存和恢复位移。

```Java
consumer.subscribe(Arrays.asList("my-topic"), new ConsumerRebalanceListener() {
    @Override
    public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
        // 再均衡之前，保存当前位移
        consumer.commitSync();
    }

    @Override
    public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
        // 再均衡之后，恢复位移
        for (TopicPartition partition : partitions) {
            consumer.seek(partition, getOffset(partition));
        }
    }
});
```

## 总结

