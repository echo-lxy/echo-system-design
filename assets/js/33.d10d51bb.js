(window.webpackJsonp=window.webpackJsonp||[]).push([[33],{371:function(a,t,e){"use strict";e.r(t);var r=e(4),s=Object(r.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h2",{attrs:{id:"前言"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[a._v("#")]),a._v(" 前言")]),a._v(" "),t("h2",{attrs:{id:"kafka高性能探究"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka高性能探究"}},[a._v("#")]),a._v(" "),t("strong",[a._v("Kafka高性能探究")])]),a._v(" "),t("p",[a._v("Kafka 高性能的核心是保障系统低延迟、高吞吐地处理消息，为此，Kafaka 采用了许多精妙的设计：")]),a._v(" "),t("ul",[t("li",[a._v("异步发送")]),a._v(" "),t("li",[a._v("批量发送")]),a._v(" "),t("li",[a._v("压缩技术")]),a._v(" "),t("li",[a._v("Pagecache 机制&顺序追加落盘")]),a._v(" "),t("li",[a._v("零拷贝")]),a._v(" "),t("li",[a._v("稀疏索引")]),a._v(" "),t("li",[a._v("Broker & 数据分区")]),a._v(" "),t("li",[a._v("多 Reactor 多线程网络模型")])]),a._v(" "),t("h3",{attrs:{id:"异步发送"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#异步发送"}},[a._v("#")]),a._v(" "),t("strong",[a._v("异步发送")])]),a._v(" "),t("p",[a._v("如上文所述，Kafka 提供了异步和同步两种消息发送方式。在异步发送中，整个流程都是异步的。调用异步发送方法后，消息会被写入 Channel，然后立即返回成功。Dispatcher 协程会从 Channel 轮询消息，将其发送到 Broker，同时会有另一个异步协程负责处理 Broker 返回的结果。同步发送本质上也是异步的，但是在处理结果时，同步发送通过 WaitGroup 将异步操作转换为同步。使用异步发送可以最大化提高消息发送的吞吐能力。")]),a._v(" "),t("h3",{attrs:{id:"批量发送"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#批量发送"}},[a._v("#")]),a._v(" "),t("strong",[a._v("批量发送")])]),a._v(" "),t("p",[a._v("Kafka 支持批量发送消息，将多个消息打包成一个批次进行发送，从而减少网络传输的开销，提高网络传输的效率和吞吐量。")]),a._v(" "),t("p",[a._v("Kafka 的批量发送消息是通过以下两个参数来控制的：")]),a._v(" "),t("p",[a._v("\\1. "),t("strong",[a._v("Batch.size")]),a._v("：控制批量发送消息的大小，默认值为 16KB，可适当增加 Batch.size 参数值提升吞吐。但是，需要注意的是，"),t("strong",[a._v("如果批量发送的大小设置得过大，可能会导致消息发送的延迟增加，因此需要根据实际情况进行调整")]),a._v("。")]),a._v(" "),t("p",[a._v("\\2. "),t("strong",[a._v("linger.ms")]),a._v("：控制消息在批量发送前的等待时间，默认值为0。当 Linger.ms 大于0时，如果有消息发送，Kafka 会等待指定的时间，如果等待时间到达或者批量大小达到 Batch.size，就会将消息打包成一个批次进行发送。可适当增加 Linger.ms 参数值提升吞吐，比如10～100。")]),a._v(" "),t("p",[a._v("在 Kafka 的生产者客户端中，当发送消息时，如果启用了批量发送，Kafka 会将消息缓存到缓冲区中。当缓冲区中的消息大小达到 Batch.size 或者等待时间到达 Linger.ms 时，Kafka 会将缓冲区中的消息打包成一个批次进行发送。如果在等待时间内没有达到 Batch.size，Kafka 也会将缓冲区中的消息发送出去，从而避免消息积压。")]),a._v(" "),t("h3",{attrs:{id:"压缩技术"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#压缩技术"}},[a._v("#")]),a._v(" "),t("strong",[a._v("压缩技术")])]),a._v(" "),t("p",[a._v("Kafka 支持压缩技术，通过将消息进行压缩后再进行传输，从而减少网络传输的开销(压缩和解压缩的过程会消耗一定的 CPU 资源，因此需要根据实际情况进行调整。)，提高网络传输的效率和吞吐量。Kafka 支持多种压缩算法，在 Kafka 2.1.0版本之前，仅支持 GZIP，Snappy 和 LZ4，2.1.0 后还支持 Zstandard 算法（Facebook 开源，能够提供超高压缩比）。这些压缩算法性能对比（两指标都是越高越好）如下：")]),a._v(" "),t("ul",[t("li",[a._v("吞吐量：LZ4>Snappy>zstd 和 GZIP，压缩比：zstd>LZ4>GZIP>Snappy。")])]),a._v(" "),t("p",[a._v("在 Kafka 中，压缩技术是通过以下两个参数来控制的：")]),a._v(" "),t("p",[a._v("\\1. Compression.type：控制压缩算法的类型，默认值为None，表示不进行压缩。")]),a._v(" "),t("p",[a._v("\\2. Compression.level：控制压缩的级别，取值范围为0-9，默认值为-1。当值为-1时，表示使用默认的压缩级别。")]),a._v(" "),t("p",[a._v("在 Kafka 的生产者客户端中，当发送消息时，如果启用了压缩技术，Kafka 会将消息进行压缩后再进行传输。在消费者客户端中，如果消息进行了压缩，Kafka 会在消费消息时将其解压缩。注意：Broker 如果设置了和生产者不通的压缩算法，接收消息后会解压后重新压缩保存。Broker 如果存在消息版本兼容也会触发解压后再压缩。")]),a._v(" "),t("h3",{attrs:{id:"pagecache-机制-顺序追加落盘"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pagecache-机制-顺序追加落盘"}},[a._v("#")]),a._v(" "),t("strong",[a._v("Pagecache 机制&顺序追加落盘")])]),a._v(" "),t("p",[a._v("Kafka 为了提升系统吞吐、降低时延，Broker 接收到消息后只是将数据写入"),t("strong",[a._v("PageCache")]),a._v("后便认为消息已写入成功，而 PageCache 中的数据通过 Linux 的 Flusher 程序进行异步刷盘（避免了同步刷盘的巨大系统开销），将数据"),t("strong",[a._v("顺序追加写")]),a._v("到磁盘日志文件中。由于 Pagecache 是在内存中进行缓存，因此读写速度非常快，可以大大提高读写效率。顺序追加写充分利用顺序 I/O 写操作，避免了缓慢的随机 I/O 操作，可有效提升 Kafka 吞吐。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://developer.qcloudimg.com/http-save/yehe-1009808/9098de0390c55e91e3db3a9ff43fd43a.png",alt:"img"}})]),a._v(" "),t("p",[a._v("如上图所示，消息被顺序追加到每个分区日志文件的尾部。")]),a._v(" "),t("h3",{attrs:{id:"零拷贝"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#零拷贝"}},[a._v("#")]),a._v(" "),t("strong",[a._v("零拷贝")])]),a._v(" "),t("p",[a._v("Kafka 中存在大量的网络数据持久化到磁盘（Producer 到 Broker）和磁盘文件通过网络发送（Broker 到 Consumer）的过程，这一过程的性能直接影响 Kafka 的整体吞吐量。传统的 IO 操作存在多次数据拷贝和上下文切换，性能比较低。Kafka 利用零拷贝技术提升上述过程性能，其中网络数据持久化磁盘主要用 mmap 技术，网络数据传输环节主要使用 Sendfile 技术。")]),a._v(" "),t("p",[t("strong",[a._v("网络数据持久化磁盘之mmap")])]),a._v(" "),t("p",[a._v("传统模式下，数据从网络传输到文件需要 4 次数据拷贝、4 次上下文切换和两次系统调用。如下图所示：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://developer.qcloudimg.com/http-save/yehe-1009808/a1ff596a61e06f6c140306d02d45f668.png",alt:"img"}})]),a._v(" "),t("p",[a._v("为了减少上下文切换以及数据拷贝带来的性能开销，Broker 在对 Producer 传来的网络数据进行持久化时使用了 mmap 技术。通过这种技术手段， Broker 读取到 Socket Buffer 的网络数据，可以直接在内核空间完成落盘，没有必要将 Socket Buffer 的网络数据读取到应用进程缓冲区。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://echo798.oss-cn-shenzhen.aliyuncs.com/img/202409181844201.png",alt:"img"}})]),a._v(" "),t("p",[t("strong",[a._v("网络数据传输之 Sendfile")])]),a._v(" "),t("p",[a._v("传统方式实现：先读取磁盘、再用 Socket 发送，实际也是进过四次 Copy。如下图所示")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://echo798.oss-cn-shenzhen.aliyuncs.com/img/202409181844327.png",alt:"img"}})]),a._v(" "),t("p",[a._v("为了减少上下文切换以及数据拷贝带来的性能开销，Kafka 在 Consumer 从 Broker 读数据过程中使用了 Sendfile 技术。具体在这里采用的方案是通过 NIO 的 "),t("code",[a._v("transferTo/transferFrom")]),a._v(" 调用操作系统的 Sendfile 实现零拷贝。总共发生 2 次内核数据拷贝、2 次上下文切换和一次系统调用，消除了 CPU 数据拷贝，如下：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://echo798.oss-cn-shenzhen.aliyuncs.com/img/202409181844555.png",alt:"img"}})]),a._v(" "),t("h3",{attrs:{id:"稀疏索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#稀疏索引"}},[a._v("#")]),a._v(" "),t("strong",[a._v("稀疏索引")])]),a._v(" "),t("p",[a._v("为了方便对日志进行检索和过期清理，Kafka 日志文件除了有用于存储日志的.log文件，还有一个"),t("strong",[a._v("位移索引文件.index")]),a._v(" 和一个"),t("strong",[a._v("时间戳索引文件.timeindex 文件")]),a._v("，并且三文件的名字完全相同，如下：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://echo798.oss-cn-shenzhen.aliyuncs.com/img/202409181844675.png",alt:"img"}})]),a._v(" "),t("p",[a._v("Kafka 的索引文件是按照稀疏索引的思想进行设计的。"),t("strong",[a._v("稀疏索引的核心是不会为每个记录都保存索引，而是写入一定的记录之后才会增加一个索引值")]),a._v("，具体这个间隔有多大则通过 log.index.interval.bytes 参数进行控制，默认大小为 4 KB，意味着 Kafka 至少写入 4KB 消息数据之后，才会在索引文件中增加一个索引项。可见，单条消息大小会影响 Kakfa 索引的插入频率，因此 log.index.interval.bytes 也是 Kafka 调优一个重要参数值。由于索引文件也是按照消息的顺序性进行增加索引项的，因此 Kafka 可以利用二分查找算法来搜索目标索引项，把时间复杂度降到了 O(lgN)，大大减少了查找的时间。")]),a._v(" "),t("p",[t("strong",[a._v("位移索引文件.index")])]),a._v(" "),t("p",[a._v("位移索引文件的索引项结构如下：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://echo798.oss-cn-shenzhen.aliyuncs.com/img/202409181844246.png",alt:"img"}})]),a._v(" "),t("p",[t("strong",[a._v("相对位移")]),a._v("：保存于索引文件名字上面的起始位移的差值，假设一个索引文件为：00000000000000000100.index，那么起始位移值即 100，当存储位移为 150 的消息索引时，在索引文件中的相对位移则为 150 - 100 = 50，这么做的好处是使用 4 字节保存位移即可，"),t("strong",[a._v("可以节省非常多的磁盘空间")]),a._v("。")]),a._v(" "),t("p",[t("strong",[a._v("文件物理位置")]),a._v("：消息在 log 文件中保存的位置，也就是说 Kafka 可根据消息位移，通过位移索引文件快速找到消息在 Log 文件中的物理位置，有了该物理位置的值，我们就可以快速地从 Log 文件中找到对应的消息了。")]),a._v(" "),t("p",[a._v("下面我用图来表示 Kafka 是如何快速检索消息：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://echo798.oss-cn-shenzhen.aliyuncs.com/img/202409181843745.png",alt:"img"}})]),a._v(" "),t("p",[a._v("假设 Kafka 需要找出位移为 3550 的消息，那么 Kafka 首先会使用二分查找算法找到小于 3550 的最大索引项：[3528, 2310272]，得到索引项之后，Kafka 会根据该索引项的文件物理位置在 Log 文件中从位置 2310272 开始顺序查找，直至找到位移为 3550 的消息记录为止。")]),a._v(" "),t("p",[t("strong",[a._v("时间戳索引文件.timeindex")])]),a._v(" "),t("p",[a._v("Kafka 在 0.10.0.0 以后的版本当中，消息中增加了时间戳信息，为了满足用户需要根据时间戳查询消息记录，Kafka 增加了时间戳索引文件，时间戳索引文件的索引项结构如下：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://echo798.oss-cn-shenzhen.aliyuncs.com/img/202409181843795.png",alt:"img"}})]),a._v(" "),t("p",[a._v("时间戳索引文件的检索与位移索引文件类似，如下快速检索消息示意图：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://developer.qcloudimg.com/http-save/yehe-1009808/b9280f82501f4392f8297be91aca7c8f.png",alt:"img"}})]),a._v(" "),t("h3",{attrs:{id:"broker-数据分区"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#broker-数据分区"}},[a._v("#")]),a._v(" "),t("strong",[a._v("Broker & 数据分区")])]),a._v(" "),t("p",[a._v("Kafka 集群包含多个 Broker。一个 Topic下通常有多个 Partition，Partition 分布在不同的 Broker 上，用于存储 Topic 的消息，这使 Kafka 可以在多台机器上处理、存储消息，给 Kafka 提供给了并行的消息处理能力和横向扩容能力。")]),a._v(" "),t("h3",{attrs:{id:"多-reactor-多线程网络模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#多-reactor-多线程网络模型"}},[a._v("#")]),a._v(" "),t("strong",[a._v("多 Reactor 多线程网络模型")])]),a._v(" "),t("p",[a._v("多 Reactor 多线程网络模型 是一种高效的网络通信模型，可以充分利用多核 CPU 的性能，提高系统的吞吐量和响应速度。Kafka 为了提升系统的吞吐，在 Broker 端处理消息时采用了该模型，示意如下：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://developer.qcloudimg.com/http-save/yehe-1009808/f8baddcd38c2ec51f9bb417adda45cc1.png",alt:"img"}})]),a._v(" "),t("p",[t("strong",[a._v("SocketServer")]),a._v(" 和 "),t("strong",[a._v("KafkaRequestHandlerPool")]),a._v(" 是其中最重要的两个组件：")]),a._v(" "),t("ul",[t("li",[t("strong",[a._v("SocketServer")]),a._v("：实现 Reactor 模式，用于处理多个 Client（包括客户端和其他 Broker 节点）的并发请求，并将处理结果返回给 Client。")]),a._v(" "),t("li",[t("strong",[a._v("KafkaRequestHandlerPool")]),a._v("：Reactor 模式中的 Worker 线程池，里面定义了多个工作线程，用于处理实际的 I/O 请求逻辑。")])]),a._v(" "),t("h2",{attrs:{id:"总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[a._v("#")]),a._v(" 总结")]),a._v(" "),t("h2",{attrs:{id:"参考资料"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[a._v("#")]),a._v(" 参考资料")])])}),[],!1,null,null,null);t.default=s.exports}}]);