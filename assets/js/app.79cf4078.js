(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,a,s=e[0],l=e[1],c=e[2],d=0,h=[];d<s.length;d++)a=s[d],Object.prototype.hasOwnProperty.call(i,a)&&i[a]&&h.push(i[a][0]),i[a]=0;for(r in l)Object.prototype.hasOwnProperty.call(l,r)&&(n[r]=l[r]);for(u&&u(e);h.length;)h.shift()();return o.push.apply(o,c||[]),t()}function t(){for(var n,e=0;e<o.length;e++){for(var t=o[e],r=!0,s=1;s<t.length;s++){var l=t[s];0!==i[l]&&(r=!1)}r&&(o.splice(e--,1),n=a(a.s=t[0]))}return n}var r={},i={1:0},o=[];function a(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,a),t.l=!0,t.exports}a.e=function(n){var e=[],t=i[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=i[n]=[e,r]}));e.push(t[2]=r);var o,s=document.createElement("script");s.charset="utf-8",s.timeout=120,a.nc&&s.setAttribute("nonce",a.nc),s.src=function(n){return a.p+"assets/js/"+({}[n]||n)+"."+{2:"81691b95",3:"9d64ee0b",4:"d012670c",5:"ae7e13e5",6:"f85123d8",7:"efb9ad0b",8:"97867ec5",9:"b684ab04",10:"61813b49",11:"0011448e",12:"952650dc",13:"3e99a433",14:"52d1b954",15:"6ff4ba84",16:"a97a420c",17:"b5662076",18:"6e9842f6",19:"8e5967f7",20:"08c78ff8",21:"897de245",22:"97fc482d",23:"0c9d476d",24:"cc0d80e2",25:"08b91bc4",26:"a9a7f77a",27:"256f80a1",28:"29525c25",29:"86d0baf8",30:"236210ed",31:"96b0a20d",32:"c59f82a9",33:"097c1ce9",34:"6fe8c5ab",35:"c2bc60c2",36:"badf36be",37:"c3415129"}[n]+".js"}(n);var l=new Error;o=function(e){s.onerror=s.onload=null,clearTimeout(c);var t=i[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),o=e&&e.target&&e.target.src;l.message="Loading chunk "+n+" failed.\n("+r+": "+o+")",l.name="ChunkLoadError",l.type=r,l.request=o,t[1](l)}i[n]=void 0}};var c=setTimeout((function(){o({type:"timeout",target:s})}),12e4);s.onerror=s.onload=o,document.head.appendChild(s)}return Promise.all(e)},a.m=n,a.c=r,a.d=function(n,e,t){a.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},a.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},a.t=function(n,e){if(1&e&&(n=a(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(a.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)a.d(t,r,function(e){return n[e]}.bind(null,r));return t},a.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return a.d(e,"a",e),e},a.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},a.p="/",a.oe=function(n){throw console.error(n),n};var s=window.webpackJsonp=window.webpackJsonp||[],l=s.push.bind(s);s.push=e,s=s.slice();for(var c=0;c<s.length;c++)e(s[c]);var u=l;o.push([106,0]),t()}([function(n,e,t){"use strict";var r=function(n){return n&&n.Math===Math&&n};n.exports=r("object"==typeof globalThis&&globalThis)||r("object"==typeof window&&window)||r("object"==typeof self&&self)||r("object"==typeof global&&global)||r("object"==typeof this&&this)||function(){return this}()||Function("return this")()},function(n,e,t){"use strict";var r="object"==typeof document&&document.all;n.exports=void 0===r&&void 0!==r?function(n){return"function"==typeof n||n===r}:function(n){return"function"==typeof n}},function(n,e,t){"use strict";var r=t(26),i=Function.prototype,o=i.call,a=r&&i.bind.bind(o,o);n.exports=r?a:function(n){return function(){return o.apply(n,arguments)}}},function(n,e,t){"use strict";n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e,t){"use strict";function r(n,e,t,r,i,o,a,s){var l,c="function"==typeof n?n.options:n;if(e&&(c.render=e,c.staticRenderFns=t,c._compiled=!0),r&&(c.functional=!0),o&&(c._scopeId="data-v-"+o),a?(l=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),i&&i.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(a)},c._ssrRegister=l):i&&(l=s?function(){i.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:i),l)if(c.functional){c._injectStyles=l;var u=c.render;c.render=function(n,e){return l.call(e),u(n,e)}}else{var d=c.beforeCreate;c.beforeCreate=d?[].concat(d,l):[l]}return{exports:n,options:c}}t.d(e,"a",(function(){return r}))},function(n,e,t){"use strict";var r=t(3);n.exports=!r((function(){return 7!==Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){"use strict";var r=t(1);n.exports=function(n){return"object"==typeof n?null!==n:r(n)}},function(n,e,t){var r=t(69),i="object"==typeof self&&self&&self.Object===Object&&self,o=r||i||Function("return this")();n.exports=o},function(n,e,t){"use strict";var r=t(2),i=t(31),o=r({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return o(i(n),e)}},function(n,e,t){var r=t(165),i=t(168);n.exports=function(n,e){var t=i(n,e);return r(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return r})),t.d(e,"b",(function(){return o})),t.d(e,"j",(function(){return a})),t.d(e,"g",(function(){return l})),t.d(e,"h",(function(){return c})),t.d(e,"i",(function(){return u})),t.d(e,"c",(function(){return d})),t.d(e,"f",(function(){return h})),t.d(e,"l",(function(){return p})),t.d(e,"m",(function(){return f})),t.d(e,"d",(function(){return v})),t.d(e,"k",(function(){return g})),t.d(e,"n",(function(){return y})),t.d(e,"a",(function(){return k}));t(16);const r=/#.*$/,i=/\.(md|html)$/,o=/\/$/,a=/^[a-z]+:/i;function s(n){return decodeURI(n).replace(r,"").replace(i,"")}function l(n){return a.test(n)}function c(n){return/^mailto:/.test(n)}function u(n){return/^tel:/.test(n)}function d(n){if(l(n))return n;if(!n)return"404";const e=n.match(r),t=e?e[0]:"",i=s(n);return o.test(i)?n:i+".html"+t}function h(n,e){const t=n.hash,i=function(n){const e=n&&n.match(r);if(e)return e[0]}(e);if(i&&t!==i)return!1;return s(n.path)===s(e)}function p(n,e,t){if(l(e))return{type:"external",path:e};t&&(e=function(n,e,t){const r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;const i=e.split("/");t&&i[i.length-1]||i.pop();const o=n.replace(/^\//,"").split("/");for(let n=0;n<o.length;n++){const e=o[n];".."===e?i.pop():"."!==e&&i.push(e)}""!==i[0]&&i.unshift("");return i.join("/")}(e,t));const r=s(e);for(let e=0;e<n.length;e++)if(s(n[e].regularPath)===r)return Object.assign({},n[e],{type:"page",path:d(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function f(n,e,t,r){const{pages:i,themeConfig:o}=t,a=r&&o.locales&&o.locales[r]||o;if("auto"===(n.frontmatter.sidebar||a.sidebar||o.sidebar))return m(n);const s=a.sidebar||o.sidebar;if(s){const{base:t,config:r}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const r in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(r)))return{base:r,config:e[r]};var t;return{}}(e,s);return"auto"===r?m(n):r?r.map(n=>function n(e,t,r,i=1){if("string"==typeof e)return p(t,e,r);if(Array.isArray(e))return Object.assign(p(t,e[0],r),{title:e[1]});{i>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const o=e.children||[];return 0===o.length&&e.path?Object.assign(p(t,e.path,r),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:o.map(e=>n(e,t,r,i+1)),collapsable:!1!==e.collapsable}}}(n,i,t)):[]}return[]}function m(n){const e=v(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function v(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function g(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function y(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function b(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function k(n,e){return b(e)-b(n)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){var r=t(15),i=t(150),o=t(151),a=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":a&&a in Object(n)?i(n):o(n)}},function(n,e,t){"use strict";var r=t(5),i=t(17),o=t(34);n.exports=r?function(n,e,t){return i.f(n,e,o(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var r=t(8).Symbol;n.exports=r},function(n,e,t){"use strict";var r=t(25),i=t(31),o=t(32),a=t(144),s=t(146);r({target:"Array",proto:!0,arity:1,forced:t(3)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(n){return n instanceof TypeError}}()},{push:function(n){var e=i(this),t=o(e),r=arguments.length;s(t+r);for(var l=0;l<r;l++)e[t]=arguments[l],t++;return a(e,t),t}})},function(n,e,t){"use strict";var r=t(5),i=t(64),o=t(101),a=t(47),s=t(54),l=TypeError,c=Object.defineProperty,u=Object.getOwnPropertyDescriptor;e.f=r?o?function(n,e,t){if(a(n),e=s(e),a(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var r=u(n,e);r&&r.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:r.configurable,enumerable:"enumerable"in t?t.enumerable:r.enumerable,writable:!1})}return c(n,e,t)}:c:function(n,e,t){if(a(n),e=s(e),a(t),i)try{return c(n,e,t)}catch(n){}if("get"in t||"set"in t)throw new l("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){"use strict";var r=t(2),i=r({}.toString),o=r("".slice);n.exports=function(n){return o(i(n),8,-1)}},function(n,e,t){var r=t(155),i=t(156),o=t(157),a=t(158),s=t(159);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=i,l.prototype.get=o,l.prototype.has=a,l.prototype.set=s,n.exports=l},function(n,e,t){var r=t(71);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(10)(Object,"create");n.exports=r},function(n,e,t){var r=t(177);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(45);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var r,i;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(i="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function i(n,e,t){return n<e?e:n>t?t:n}function o(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=i(n,r.minimum,1),t.status=1===n?null:n;var l=t.render(!e),c=l.querySelector(r.barSelector),u=r.speed,d=r.easing;return l.offsetWidth,a((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),s(c,function(n,e,t){var i;return(i="translate3d"===r.positionUsing?{transform:"translate3d("+o(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+o(n)+"%,0)"}:{"margin-left":o(n)+"%"}).transition="all "+e+"ms "+t,i}(n,u,d)),1===n?(s(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){s(l,{transition:"all "+u+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),u)}),u)):setTimeout(e,u)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*i(Math.random()*e,.1,.95)),e=i(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var i,a=e.querySelector(r.barSelector),l=n?"-100":o(t.status||0),u=document.querySelector(r.parent);return s(a,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),r.showSpinner||(i=e.querySelector(r.spinnerSelector))&&h(i),u!=document.body&&c(u,"nprogress-custom-parent"),u.appendChild(e),e},t.remove=function(){u(document.documentElement,"nprogress-busy"),u(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&h(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var a=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),s=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,i=n.length,o=e.charAt(0).toUpperCase()+e.slice(1);i--;)if((r=n[i]+o)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,i,o=arguments;if(2==o.length)for(t in e)void 0!==(i=e[t])&&e.hasOwnProperty(t)&&r(n,t,i);else r(n,o[1],o[2])}}();function l(n,e){return("string"==typeof n?n:d(n)).indexOf(" "+e+" ")>=0}function c(n,e){var t=d(n),r=t+e;l(t,e)||(n.className=r.substring(1))}function u(n,e){var t,r=d(n);l(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function d(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function h(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=i)},function(n,e,t){"use strict";var r=t(0),i=t(52).f,o=t(14),a=t(97),s=t(37),l=t(65),c=t(124);n.exports=function(n,e){var t,u,d,h,p,f=n.target,m=n.global,v=n.stat;if(t=m?r:v?r[f]||s(f,{}):r[f]&&r[f].prototype)for(u in e){if(h=e[u],d=n.dontCallGetSet?(p=i(t,u))&&p.value:t[u],!c(m?u:f+(v?".":"#")+u,n.forced)&&void 0!==d){if(typeof h==typeof d)continue;l(h,d)}(n.sham||d&&d.sham)&&o(h,"sham",!0),a(t,u,h,n)}}},function(n,e,t){"use strict";var r=t(3);n.exports=!r((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){"use strict";var r=t(48),i=t(35);n.exports=function(n){return r(i(n))}},function(n,e,t){"use strict";var r=t(0),i=t(1),o=function(n){return i(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?o(r[n]):r[n]&&r[n][e]}},function(n,e,t){"use strict";var r=t(1),i=t(111),o=TypeError;n.exports=function(n){if(r(n))return n;throw new o(i(n)+" is not a function")}},function(n,e,t){"use strict";var r=t(0),i=t(61),o=t(9),a=t(63),s=t(58),l=t(57),c=r.Symbol,u=i("wks"),d=l?c.for||c:c&&c.withoutSetter||a;n.exports=function(n){return o(u,n)||(u[n]=s&&o(c,n)?c[n]:d("Symbol."+n)),u[n]}},function(n,e,t){"use strict";var r=t(35),i=Object;n.exports=function(n){return i(r(n))}},function(n,e,t){"use strict";var r=t(122);n.exports=function(n){return r(n.length)}},function(n,e,t){"use strict";var r=t(26),i=Function.prototype.call;n.exports=r?i.bind(i):function(){return i.apply(i,arguments)}},function(n,e,t){"use strict";n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){"use strict";var r=t(53),i=TypeError;n.exports=function(n){if(r(n))throw new i("Can't call method on "+n);return n}},function(n,e,t){"use strict";var r=t(62),i=t(0),o=t(37),a=n.exports=i["__core-js_shared__"]||o("__core-js_shared__",{});(a.versions||(a.versions=[])).push({version:"3.38.1",mode:r?"pure":"global",copyright:"© 2014-2024 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.38.1/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e,t){"use strict";var r=t(0),i=Object.defineProperty;n.exports=function(n,e){try{i(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){var r=t(149),i=t(12),o=Object.prototype,a=o.hasOwnProperty,s=o.propertyIsEnumerable,l=r(function(){return arguments}())?r:function(n){return i(n)&&a.call(n,"callee")&&!s.call(n,"callee")};n.exports=l},function(n,e,t){var r=t(10)(t(8),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(169),i=t(176),o=t(178),a=t(179),s=t(180);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=i,l.prototype.get=o,l.prototype.has=a,l.prototype.set=s,n.exports=l},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(6),i=t(45),o=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,a=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!i(n))||(a.test(n)||!o.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(13),i=t(12);n.exports=function(n){return"symbol"==typeof n||i(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){"use strict";var r=t(7),i=String,o=TypeError;n.exports=function(n){if(r(n))return n;throw new o(i(n)+" is not an object")}},function(n,e,t){"use strict";var r=t(2),i=t(3),o=t(18),a=Object,s=r("".split);n.exports=i((function(){return!a("z").propertyIsEnumerable(0)}))?function(n){return"String"===o(n)?s(n,""):a(n)}:a},function(n,e,t){"use strict";n.exports={}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,i=/^0b[01]+$/i,o=/^0o[0-7]+$/i,a=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=s||l||Function("return this")(),u=Object.prototype.toString,d=Math.max,h=Math.min,p=function(){return c.Date.now()};function f(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function m(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==u.call(n)}(n))return NaN;if(f(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=f(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var s=i.test(n);return s||o.test(n)?a(n.slice(2),s?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,i,o,a,s,l,c=0,u=!1,v=!1,g=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function y(e){var t=r,o=i;return r=i=void 0,c=e,a=n.apply(o,t)}function b(n){return c=n,s=setTimeout(_,e),u?y(n):a}function k(n){var t=n-l;return void 0===l||t>=e||t<0||v&&n-c>=o}function _(){var n=p();if(k(n))return x(n);s=setTimeout(_,function(n){var t=e-(n-l);return v?h(t,o-(n-c)):t}(n))}function x(n){return s=void 0,g&&r?y(n):(r=i=void 0,a)}function E(){var n=p(),t=k(n);if(r=arguments,i=this,l=n,t){if(void 0===s)return b(l);if(v)return s=setTimeout(_,e),y(l)}return void 0===s&&(s=setTimeout(_,e)),a}return e=m(e)||0,f(t)&&(u=!!t.leading,o=(v="maxWait"in t)?d(m(t.maxWait)||0,e):o,g="trailing"in t?!!t.trailing:g),E.cancel=function(){void 0!==s&&clearTimeout(s),c=0,r=l=i=s=void 0},E.flush=function(){return void 0===s?a:x(p())},E}},function(n,e,t){"use strict";var r=t(5),i=t(33),o=t(108),a=t(34),s=t(27),l=t(54),c=t(9),u=t(64),d=Object.getOwnPropertyDescriptor;e.f=r?d:function(n,e){if(n=s(n),e=l(e),u)try{return d(n,e)}catch(n){}if(c(n,e))return a(!i(o.f,n,e),n[e])}},function(n,e,t){"use strict";n.exports=function(n){return null==n}},function(n,e,t){"use strict";var r=t(109),i=t(55);n.exports=function(n){var e=r(n,"string");return i(e)?e:e+""}},function(n,e,t){"use strict";var r=t(28),i=t(1),o=t(56),a=t(57),s=Object;n.exports=a?function(n){return"symbol"==typeof n}:function(n){var e=r("Symbol");return i(e)&&o(e.prototype,s(n))}},function(n,e,t){"use strict";var r=t(2);n.exports=r({}.isPrototypeOf)},function(n,e,t){"use strict";var r=t(58);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){"use strict";var r=t(59),i=t(3),o=t(0).String;n.exports=!!Object.getOwnPropertySymbols&&!i((function(){var n=Symbol("symbol detection");return!o(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){"use strict";var r,i,o=t(0),a=t(60),s=o.process,l=o.Deno,c=s&&s.versions||l&&l.version,u=c&&c.v8;u&&(i=(r=u.split("."))[0]>0&&r[0]<4?1:+(r[0]+r[1])),!i&&a&&(!(r=a.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=a.match(/Chrome\/(\d+)/))&&(i=+r[1]),n.exports=i},function(n,e,t){"use strict";var r=t(0).navigator,i=r&&r.userAgent;n.exports=i?String(i):""},function(n,e,t){"use strict";var r=t(36);n.exports=function(n,e){return r[n]||(r[n]=e||{})}},function(n,e,t){"use strict";n.exports=!1},function(n,e,t){"use strict";var r=t(2),i=0,o=Math.random(),a=r(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+a(++i+o,36)}},function(n,e,t){"use strict";var r=t(5),i=t(3),o=t(100);n.exports=!r&&!i((function(){return 7!==Object.defineProperty(o("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){"use strict";var r=t(9),i=t(117),o=t(52),a=t(17);n.exports=function(n,e,t){for(var s=i(e),l=a.f,c=o.f,u=0;u<s.length;u++){var d=s[u];r(n,d)||t&&r(t,d)||l(n,d,c(e,d))}}},function(n,e,t){"use strict";var r=t(121);n.exports=function(n){var e=+n;return e!=e||0===e?0:r(e)}},function(n,e,t){"use strict";var r=t(132),i=t(7),o=t(35),a=t(133);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=r(Object.prototype,"__proto__","set"))(t,[]),e=t instanceof Array}catch(n){}return function(t,r){return o(t),a(r),i(t)?(e?n(t,r):t.__proto__=r,t):t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,i=n.length;++t<r;)n[i+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(19),i=t(160),o=t(161),a=t(162),s=t(163),l=t(164);function c(n){var e=this.__data__=new r(n);this.size=e.size}c.prototype.clear=i,c.prototype.delete=o,c.prototype.get=a,c.prototype.has=s,c.prototype.set=l,n.exports=c},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(13),i=t(40);n.exports=function(n){if(!i(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(181),i=t(12);n.exports=function n(e,t,o,a,s){return e===t||(null==e||null==t||!i(e)&&!i(t)?e!=e&&t!=t:r(e,t,o,a,n,s))}},function(n,e,t){var r=t(76),i=t(184),o=t(77);n.exports=function(n,e,t,a,s,l){var c=1&t,u=n.length,d=e.length;if(u!=d&&!(c&&d>u))return!1;var h=l.get(n),p=l.get(e);if(h&&p)return h==e&&p==n;var f=-1,m=!0,v=2&t?new r:void 0;for(l.set(n,e),l.set(e,n);++f<u;){var g=n[f],y=e[f];if(a)var b=c?a(y,g,f,e,n,l):a(g,y,f,n,e,l);if(void 0!==b){if(b)continue;m=!1;break}if(v){if(!i(e,(function(n,e){if(!o(v,e)&&(g===n||s(g,n,t,a,l)))return v.push(e)}))){m=!1;break}}else if(g!==y&&!s(g,y,t,a,l)){m=!1;break}}return l.delete(n),l.delete(e),m}},function(n,e,t){var r=t(41),i=t(182),o=t(183);function a(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}a.prototype.add=a.prototype.push=i,a.prototype.has=o,n.exports=a},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(194),i=t(200),o=t(82);n.exports=function(n){return o(n)?r(n):i(n)}},function(n,e,t){(function(n){var r=t(8),i=t(196),o=e&&!e.nodeType&&e,a=o&&"object"==typeof n&&n&&!n.nodeType&&n,s=a&&a.exports===o?r.Buffer:void 0,l=(s?s.isBuffer:void 0)||i;n.exports=l}).call(this,t(50)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(197),i=t(198),o=t(199),a=o&&o.isTypedArray,s=a?i(a):r;n.exports=s},function(n,e,t){var r=t(72),i=t(43);n.exports=function(n){return null!=n&&i(n.length)&&!r(n)}},function(n,e,t){var r=t(10)(t(8),"Set");n.exports=r},function(n,e,t){var r=t(40);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(87),i=t(23);n.exports=function(n,e){for(var t=0,o=(e=r(e,n)).length;null!=n&&t<o;)n=n[i(e[t++])];return t&&t==o?n:void 0}},function(n,e,t){var r=t(6),i=t(44),o=t(211),a=t(214);n.exports=function(n,e){return r(n)?n:i(n,e)?[n]:o(a(n))}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(147),i=t(152),o=t(223),a=t(231),s=t(240),l=t(105),c=o((function(n){var e=l(n);return s(e)&&(e=void 0),a(r(n,1,s,!0),i(e,2))}));n.exports=c},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var r=/["'&<>]/;n.exports=function(n){var e,t=""+n,i=r.exec(t);if(!i)return t;var o="",a=0,s=0;for(a=i.index;a<t.length;a++){switch(t.charCodeAt(a)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}s!==a&&(o+=t.substring(s,a)),s=a+1,o+=e}return s!==a?o+t.substring(s,a):o}},function(n){n.exports=JSON.parse('{"en-US":{"author":"author","beforeAuthor":"Copyright © ","afterAuthor":"\\nLink: "},"zh-CN":{"author":"作者","beforeAuthor":"著作权归","afterAuthor":"所有。\\n链接："}}')},function(n,e,t){"use strict";t.r(e);var r={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},i=(t(243),t(4)),o=Object(i.a)(r,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=o.exports},function(n,e,t){"use strict";t.r(e);var r={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},i=(t(244),t(4)),o=Object(i.a)(r,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"theme-code-group"},[e("div",{staticClass:"theme-code-group__nav"},[e("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(t,r){return e("li",{key:t.title,staticClass:"theme-code-group__li"},[e("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":r===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(r)}}},[n._v("\n            "+n._s(t.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?e("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=o.exports},function(n,e,t){"use strict";var r=t(1),i=t(17),o=t(102),a=t(37);n.exports=function(n,e,t,s){s||(s={});var l=s.enumerable,c=void 0!==s.name?s.name:e;if(r(t)&&o(t,c,s),s.global)l?n[e]=t:a(e,t);else{try{s.unsafe?n[e]&&(l=!0):delete n[e]}catch(n){}l?n[e]=t:i.f(n,e,{value:t,enumerable:!1,configurable:!s.nonConfigurable,writable:!s.nonWritable})}return n}},function(n,e,t){"use strict";n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){"use strict";var r=t(138),i=String;n.exports=function(n){if("Symbol"===r(n))throw new TypeError("Cannot convert a Symbol value to a string");return i(n)}},function(n,e,t){"use strict";var r=t(0),i=t(7),o=r.document,a=i(o)&&i(o.createElement);n.exports=function(n){return a?o.createElement(n):{}}},function(n,e,t){"use strict";var r=t(5),i=t(3);n.exports=r&&i((function(){return 42!==Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){"use strict";var r=t(2),i=t(3),o=t(1),a=t(9),s=t(5),l=t(113).CONFIGURABLE,c=t(114),u=t(115),d=u.enforce,h=u.get,p=String,f=Object.defineProperty,m=r("".slice),v=r("".replace),g=r([].join),y=s&&!i((function(){return 8!==f((function(){}),"length",{value:8}).length})),b=String(String).split("String"),k=n.exports=function(n,e,t){"Symbol("===m(p(e),0,7)&&(e="["+v(p(e),/^Symbol\(([^)]*)\).*$/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!a(n,"name")||l&&n.name!==e)&&(s?f(n,"name",{value:e,configurable:!0}):n.name=e),y&&t&&a(t,"arity")&&n.length!==t.arity&&f(n,"length",{value:t.arity});try{t&&a(t,"constructor")&&t.constructor?s&&f(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var r=d(n);return a(r,"source")||(r.source=g(b,"string"==typeof e?e:"")),n};Function.prototype.toString=k((function(){return o(this)&&h(this).source||c(this)}),"toString")},function(n,e,t){"use strict";var r=t(61),i=t(63),o=r("keys");n.exports=function(n){return o[n]||(o[n]=i(n))}},function(n,e,t){"use strict";var r=t(2),i=t(9),o=t(27),a=t(119).indexOf,s=t(49),l=r([].push);n.exports=function(n,e){var t,r=o(n),c=0,u=[];for(t in r)!i(s,t)&&i(r,t)&&l(u,t);for(;e.length>c;)i(r,t=e[c++])&&(~a(u,t)||l(u,t));return u}},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){n.exports=t(249)},function(n,e,t){"use strict";var r=t(25),i=t(125).left,o=t(126),a=t(59);r({target:"Array",proto:!0,forced:!t(127)&&a>79&&a<83||!o("reduce")},{reduce:function(n){var e=arguments.length;return i(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,i=Object.getOwnPropertyDescriptor,o=i&&!r.call({1:2},1);e.f=o?function(n){var e=i(this,n);return!!e&&e.enumerable}:r},function(n,e,t){"use strict";var r=t(33),i=t(7),o=t(55),a=t(110),s=t(112),l=t(30),c=TypeError,u=l("toPrimitive");n.exports=function(n,e){if(!i(n)||o(n))return n;var t,l=a(n,u);if(l){if(void 0===e&&(e="default"),t=r(l,n,e),!i(t)||o(t))return t;throw new c("Can't convert object to primitive value")}return void 0===e&&(e="number"),s(n,e)}},function(n,e,t){"use strict";var r=t(29),i=t(53);n.exports=function(n,e){var t=n[e];return i(t)?void 0:r(t)}},function(n,e,t){"use strict";var r=String;n.exports=function(n){try{return r(n)}catch(n){return"Object"}}},function(n,e,t){"use strict";var r=t(33),i=t(1),o=t(7),a=TypeError;n.exports=function(n,e){var t,s;if("string"===e&&i(t=n.toString)&&!o(s=r(t,n)))return s;if(i(t=n.valueOf)&&!o(s=r(t,n)))return s;if("string"!==e&&i(t=n.toString)&&!o(s=r(t,n)))return s;throw new a("Can't convert object to primitive value")}},function(n,e,t){"use strict";var r=t(5),i=t(9),o=Function.prototype,a=r&&Object.getOwnPropertyDescriptor,s=i(o,"name"),l=s&&"something"===function(){}.name,c=s&&(!r||r&&a(o,"name").configurable);n.exports={EXISTS:s,PROPER:l,CONFIGURABLE:c}},function(n,e,t){"use strict";var r=t(2),i=t(1),o=t(36),a=r(Function.toString);i(o.inspectSource)||(o.inspectSource=function(n){return a(n)}),n.exports=o.inspectSource},function(n,e,t){"use strict";var r,i,o,a=t(116),s=t(0),l=t(7),c=t(14),u=t(9),d=t(36),h=t(103),p=t(49),f=s.TypeError,m=s.WeakMap;if(a||d.state){var v=d.state||(d.state=new m);v.get=v.get,v.has=v.has,v.set=v.set,r=function(n,e){if(v.has(n))throw new f("Object already initialized");return e.facade=n,v.set(n,e),e},i=function(n){return v.get(n)||{}},o=function(n){return v.has(n)}}else{var g=h("state");p[g]=!0,r=function(n,e){if(u(n,g))throw new f("Object already initialized");return e.facade=n,c(n,g,e),e},i=function(n){return u(n,g)?n[g]:{}},o=function(n){return u(n,g)}}n.exports={set:r,get:i,has:o,enforce:function(n){return o(n)?i(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!l(e)||(t=i(e)).type!==n)throw new f("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){"use strict";var r=t(0),i=t(1),o=r.WeakMap;n.exports=i(o)&&/native code/.test(String(o))},function(n,e,t){"use strict";var r=t(28),i=t(2),o=t(118),a=t(123),s=t(47),l=i([].concat);n.exports=r("Reflect","ownKeys")||function(n){var e=o.f(s(n)),t=a.f;return t?l(e,t(n)):e}},function(n,e,t){"use strict";var r=t(104),i=t(98).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,i)}},function(n,e,t){"use strict";var r=t(27),i=t(120),o=t(32),a=function(n){return function(e,t,a){var s=r(e),l=o(s);if(0===l)return!n&&-1;var c,u=i(a,l);if(n&&t!=t){for(;l>u;)if((c=s[u++])!=c)return!0}else for(;l>u;u++)if((n||u in s)&&s[u]===t)return n||u||0;return!n&&-1}};n.exports={includes:a(!0),indexOf:a(!1)}},function(n,e,t){"use strict";var r=t(66),i=Math.max,o=Math.min;n.exports=function(n,e){var t=r(n);return t<0?i(t+e,0):o(t,e)}},function(n,e,t){"use strict";var r=Math.ceil,i=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?i:r)(e)}},function(n,e,t){"use strict";var r=t(66),i=Math.min;n.exports=function(n){var e=r(n);return e>0?i(e,9007199254740991):0}},function(n,e,t){"use strict";e.f=Object.getOwnPropertySymbols},function(n,e,t){"use strict";var r=t(3),i=t(1),o=/#|\.prototype\./,a=function(n,e){var t=l[s(n)];return t===u||t!==c&&(i(e)?r(e):!!e)},s=a.normalize=function(n){return String(n).replace(o,".").toLowerCase()},l=a.data={},c=a.NATIVE="N",u=a.POLYFILL="P";n.exports=a},function(n,e,t){"use strict";var r=t(29),i=t(31),o=t(48),a=t(32),s=TypeError,l="Reduce of empty array with no initial value",c=function(n){return function(e,t,c,u){var d=i(e),h=o(d),p=a(d);if(r(t),0===p&&c<2)throw new s(l);var f=n?p-1:0,m=n?-1:1;if(c<2)for(;;){if(f in h){u=h[f],f+=m;break}if(f+=m,n?f<0:p<=f)throw new s(l)}for(;n?f>=0:p>f;f+=m)f in h&&(u=t(u,h[f],f,d));return u}};n.exports={left:c(!1),right:c(!0)}},function(n,e,t){"use strict";var r=t(3);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){"use strict";var r=t(128);n.exports="NODE"===r},function(n,e,t){"use strict";var r=t(0),i=t(60),o=t(18),a=function(n){return i.slice(0,n.length)===n};n.exports=a("Bun/")?"BUN":a("Cloudflare-Workers")?"CLOUDFLARE":a("Deno/")?"DENO":a("Node.js/")?"NODE":r.Bun&&"string"==typeof Bun.version?"BUN":r.Deno&&"object"==typeof Deno.version?"DENO":"process"===o(r.process)?"NODE":r.window&&r.document?"BROWSER":"REST"},function(n,e,t){"use strict";var r=t(25),i=t(0),o=t(130),a=t(131),s=i.WebAssembly,l=7!==new Error("e",{cause:7}).cause,c=function(n,e){var t={};t[n]=a(n,e,l),r({global:!0,constructor:!0,arity:1,forced:l},t)},u=function(n,e){if(s&&s[n]){var t={};t[n]=a("WebAssembly."+n,e,l),r({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:l},t)}};c("Error",(function(n){return function(e){return o(n,this,arguments)}})),c("EvalError",(function(n){return function(e){return o(n,this,arguments)}})),c("RangeError",(function(n){return function(e){return o(n,this,arguments)}})),c("ReferenceError",(function(n){return function(e){return o(n,this,arguments)}})),c("SyntaxError",(function(n){return function(e){return o(n,this,arguments)}})),c("TypeError",(function(n){return function(e){return o(n,this,arguments)}})),c("URIError",(function(n){return function(e){return o(n,this,arguments)}})),u("CompileError",(function(n){return function(e){return o(n,this,arguments)}})),u("LinkError",(function(n){return function(e){return o(n,this,arguments)}})),u("RuntimeError",(function(n){return function(e){return o(n,this,arguments)}}))},function(n,e,t){"use strict";var r=t(26),i=Function.prototype,o=i.apply,a=i.call;n.exports="object"==typeof Reflect&&Reflect.apply||(r?a.bind(o):function(){return a.apply(o,arguments)})},function(n,e,t){"use strict";var r=t(28),i=t(9),o=t(14),a=t(56),s=t(67),l=t(65),c=t(135),u=t(136),d=t(137),h=t(140),p=t(141),f=t(5),m=t(62);n.exports=function(n,e,t,v){var g=v?2:1,y=n.split("."),b=y[y.length-1],k=r.apply(null,y);if(k){var _=k.prototype;if(!m&&i(_,"cause")&&delete _.cause,!t)return k;var x=r("Error"),E=e((function(n,e){var t=d(v?e:n,void 0),r=v?new k(n):new k;return void 0!==t&&o(r,"message",t),p(r,E,r.stack,2),this&&a(_,this)&&u(r,this,E),arguments.length>g&&h(r,arguments[g]),r}));if(E.prototype=_,"Error"!==b?s?s(E,x):l(E,x,{name:!0}):f&&"stackTraceLimit"in k&&(c(E,k,"stackTraceLimit"),c(E,k,"prepareStackTrace")),l(E,k),!m)try{_.name!==b&&o(_,"name",b),_.constructor=E}catch(n){}return E}}},function(n,e,t){"use strict";var r=t(2),i=t(29);n.exports=function(n,e,t){try{return r(i(Object.getOwnPropertyDescriptor(n,e)[t]))}catch(n){}}},function(n,e,t){"use strict";var r=t(134),i=String,o=TypeError;n.exports=function(n){if(r(n))return n;throw new o("Can't set "+i(n)+" as a prototype")}},function(n,e,t){"use strict";var r=t(7);n.exports=function(n){return r(n)||null===n}},function(n,e,t){"use strict";var r=t(17).f;n.exports=function(n,e,t){t in n||r(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){"use strict";var r=t(1),i=t(7),o=t(67);n.exports=function(n,e,t){var a,s;return o&&r(a=e.constructor)&&a!==t&&i(s=a.prototype)&&s!==t.prototype&&o(n,s),n}},function(n,e,t){"use strict";var r=t(99);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:r(n)}},function(n,e,t){"use strict";var r=t(139),i=t(1),o=t(18),a=t(30)("toStringTag"),s=Object,l="Arguments"===o(function(){return arguments}());n.exports=r?o:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=s(n),a))?t:l?o(e):"Object"===(r=o(e))&&i(e.callee)?"Arguments":r}},function(n,e,t){"use strict";var r={};r[t(30)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){"use strict";var r=t(7),i=t(14);n.exports=function(n,e){r(e)&&"cause"in e&&i(n,"cause",e.cause)}},function(n,e,t){"use strict";var r=t(14),i=t(142),o=t(143),a=Error.captureStackTrace;n.exports=function(n,e,t,s){o&&(a?a(n,e):r(n,"stack",i(t,s)))}},function(n,e,t){"use strict";var r=t(2),i=Error,o=r("".replace),a=String(new i("zxcasd").stack),s=/\n\s*at [^:]*:[^\n]*/,l=s.test(a);n.exports=function(n,e){if(l&&"string"==typeof n&&!i.prepareStackTrace)for(;e--;)n=o(n,s,"");return n}},function(n,e,t){"use strict";var r=t(3),i=t(34);n.exports=!r((function(){var n=new Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",i(1,7)),7!==n.stack)}))},function(n,e,t){"use strict";var r=t(5),i=t(145),o=TypeError,a=Object.getOwnPropertyDescriptor,s=r&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(n){return n instanceof TypeError}}();n.exports=s?function(n,e){if(i(n)&&!a(n,"length").writable)throw new o("Cannot set read only .length");return n.length=e}:function(n,e){return n.length=e}},function(n,e,t){"use strict";var r=t(18);n.exports=Array.isArray||function(n){return"Array"===r(n)}},function(n,e,t){"use strict";var r=TypeError;n.exports=function(n){if(n>9007199254740991)throw r("Maximum allowed index exceeded");return n}},function(n,e,t){var r=t(68),i=t(148);n.exports=function n(e,t,o,a,s){var l=-1,c=e.length;for(o||(o=i),s||(s=[]);++l<c;){var u=e[l];t>0&&o(u)?t>1?n(u,t-1,o,a,s):r(s,u):a||(s[s.length]=u)}return s}},function(n,e,t){var r=t(15),i=t(38),o=t(6),a=r?r.isConcatSpreadable:void 0;n.exports=function(n){return o(n)||i(n)||!!(a&&n&&n[a])}},function(n,e,t){var r=t(13),i=t(12);n.exports=function(n){return i(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(15),i=Object.prototype,o=i.hasOwnProperty,a=i.toString,s=r?r.toStringTag:void 0;n.exports=function(n){var e=o.call(n,s),t=n[s];try{n[s]=void 0;var r=!0}catch(n){}var i=a.call(n);return r&&(e?n[s]=t:delete n[s]),i}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(153),i=t(209),o=t(46),a=t(6),s=t(220);n.exports=function(n){return"function"==typeof n?n:null==n?o:"object"==typeof n?a(n)?i(n[0],n[1]):r(n):s(n)}},function(n,e,t){var r=t(154),i=t(208),o=t(85);n.exports=function(n){var e=i(n);return 1==e.length&&e[0][2]?o(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(70),i=t(74);n.exports=function(n,e,t,o){var a=t.length,s=a,l=!o;if(null==n)return!s;for(n=Object(n);a--;){var c=t[a];if(l&&c[2]?c[1]!==n[c[0]]:!(c[0]in n))return!1}for(;++a<s;){var u=(c=t[a])[0],d=n[u],h=c[1];if(l&&c[2]){if(void 0===d&&!(u in n))return!1}else{var p=new r;if(o)var f=o(d,h,u,n,e,p);if(!(void 0===f?i(h,d,3,o,p):f))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(20),i=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():i.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(20);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(20);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(20);n.exports=function(n,e){var t=this.__data__,i=r(t,n);return i<0?(++this.size,t.push([n,e])):t[i][1]=e,this}},function(n,e,t){var r=t(19);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(19),i=t(39),o=t(41);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var a=t.__data__;if(!i||a.length<199)return a.push([n,e]),this.size=++t.size,this;t=this.__data__=new o(a)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(72),i=t(166),o=t(40),a=t(73),s=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,u=l.toString,d=c.hasOwnProperty,h=RegExp("^"+u.call(d).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!o(n)||i(n))&&(r(n)?h:s).test(a(n))}},function(n,e,t){var r,i=t(167),o=(r=/[^.]+$/.exec(i&&i.keys&&i.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!o&&o in n}},function(n,e,t){var r=t(8)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(170),i=t(19),o=t(39);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(o||i),string:new r}}},function(n,e,t){var r=t(171),i=t(172),o=t(173),a=t(174),s=t(175);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=i,l.prototype.get=o,l.prototype.has=a,l.prototype.set=s,n.exports=l},function(n,e,t){var r=t(21);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(21),i=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return i.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(21),i=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:i.call(e,n)}},function(n,e,t){var r=t(21);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(22);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(22);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(22);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(22);n.exports=function(n,e){var t=r(this,n),i=t.size;return t.set(n,e),this.size+=t.size==i?0:1,this}},function(n,e,t){var r=t(70),i=t(75),o=t(185),a=t(188),s=t(204),l=t(6),c=t(79),u=t(81),d="[object Object]",h=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,p,f,m){var v=l(n),g=l(e),y=v?"[object Array]":s(n),b=g?"[object Array]":s(e),k=(y="[object Arguments]"==y?d:y)==d,_=(b="[object Arguments]"==b?d:b)==d,x=y==b;if(x&&c(n)){if(!c(e))return!1;v=!0,k=!1}if(x&&!k)return m||(m=new r),v||u(n)?i(n,e,t,p,f,m):o(n,e,y,t,p,f,m);if(!(1&t)){var E=k&&h.call(n,"__wrapped__"),w=_&&h.call(e,"__wrapped__");if(E||w){var T=E?n.value():n,A=w?e.value():e;return m||(m=new r),f(T,A,t,p,m)}}return!!x&&(m||(m=new r),a(n,e,t,p,f,m))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(15),i=t(186),o=t(71),a=t(75),s=t(187),l=t(42),c=r?r.prototype:void 0,u=c?c.valueOf:void 0;n.exports=function(n,e,t,r,c,d,h){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!d(new i(n),new i(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return o(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var p=s;case"[object Set]":var f=1&r;if(p||(p=l),n.size!=e.size&&!f)return!1;var m=h.get(n);if(m)return m==e;r|=2,h.set(n,e);var v=a(p(n),p(e),r,c,d,h);return h.delete(n),v;case"[object Symbol]":if(u)return u.call(n)==u.call(e)}return!1}},function(n,e,t){var r=t(8).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(189),i=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,o,a,s){var l=1&t,c=r(n),u=c.length;if(u!=r(e).length&&!l)return!1;for(var d=u;d--;){var h=c[d];if(!(l?h in e:i.call(e,h)))return!1}var p=s.get(n),f=s.get(e);if(p&&f)return p==e&&f==n;var m=!0;s.set(n,e),s.set(e,n);for(var v=l;++d<u;){var g=n[h=c[d]],y=e[h];if(o)var b=l?o(y,g,h,e,n,s):o(g,y,h,n,e,s);if(!(void 0===b?g===y||a(g,y,t,o,s):b)){m=!1;break}v||(v="constructor"==h)}if(m&&!v){var k=n.constructor,_=e.constructor;k==_||!("constructor"in n)||!("constructor"in e)||"function"==typeof k&&k instanceof k&&"function"==typeof _&&_ instanceof _||(m=!1)}return s.delete(n),s.delete(e),m}},function(n,e,t){var r=t(190),i=t(191),o=t(78);n.exports=function(n){return r(n,o,i)}},function(n,e,t){var r=t(68),i=t(6);n.exports=function(n,e,t){var o=e(n);return i(n)?o:r(o,t(n))}},function(n,e,t){var r=t(192),i=t(193),o=Object.prototype.propertyIsEnumerable,a=Object.getOwnPropertySymbols,s=a?function(n){return null==n?[]:(n=Object(n),r(a(n),(function(e){return o.call(n,e)})))}:i;n.exports=s},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,i=0,o=[];++t<r;){var a=n[t];e(a,t,n)&&(o[i++]=a)}return o}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(195),i=t(38),o=t(6),a=t(79),s=t(80),l=t(81),c=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=o(n),u=!t&&i(n),d=!t&&!u&&a(n),h=!t&&!u&&!d&&l(n),p=t||u||d||h,f=p?r(n.length,String):[],m=f.length;for(var v in n)!e&&!c.call(n,v)||p&&("length"==v||d&&("offset"==v||"parent"==v)||h&&("buffer"==v||"byteLength"==v||"byteOffset"==v)||s(v,m))||f.push(v);return f}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(13),i=t(43),o=t(12),a={};a["[object Float32Array]"]=a["[object Float64Array]"]=a["[object Int8Array]"]=a["[object Int16Array]"]=a["[object Int32Array]"]=a["[object Uint8Array]"]=a["[object Uint8ClampedArray]"]=a["[object Uint16Array]"]=a["[object Uint32Array]"]=!0,a["[object Arguments]"]=a["[object Array]"]=a["[object ArrayBuffer]"]=a["[object Boolean]"]=a["[object DataView]"]=a["[object Date]"]=a["[object Error]"]=a["[object Function]"]=a["[object Map]"]=a["[object Number]"]=a["[object Object]"]=a["[object RegExp]"]=a["[object Set]"]=a["[object String]"]=a["[object WeakMap]"]=!1,n.exports=function(n){return o(n)&&i(n.length)&&!!a[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(69),i=e&&!e.nodeType&&e,o=i&&"object"==typeof n&&n&&!n.nodeType&&n,a=o&&o.exports===i&&r.process,s=function(){try{var n=o&&o.require&&o.require("util").types;return n||a&&a.binding&&a.binding("util")}catch(n){}}();n.exports=s}).call(this,t(50)(n))},function(n,e,t){var r=t(201),i=t(202),o=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return i(n);var e=[];for(var t in Object(n))o.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(203)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(205),i=t(39),o=t(206),a=t(83),s=t(207),l=t(13),c=t(73),u=c(r),d=c(i),h=c(o),p=c(a),f=c(s),m=l;(r&&"[object DataView]"!=m(new r(new ArrayBuffer(1)))||i&&"[object Map]"!=m(new i)||o&&"[object Promise]"!=m(o.resolve())||a&&"[object Set]"!=m(new a)||s&&"[object WeakMap]"!=m(new s))&&(m=function(n){var e=l(n),t="[object Object]"==e?n.constructor:void 0,r=t?c(t):"";if(r)switch(r){case u:return"[object DataView]";case d:return"[object Map]";case h:return"[object Promise]";case p:return"[object Set]";case f:return"[object WeakMap]"}return e}),n.exports=m},function(n,e,t){var r=t(10)(t(8),"DataView");n.exports=r},function(n,e,t){var r=t(10)(t(8),"Promise");n.exports=r},function(n,e,t){var r=t(10)(t(8),"WeakMap");n.exports=r},function(n,e,t){var r=t(84),i=t(78);n.exports=function(n){for(var e=i(n),t=e.length;t--;){var o=e[t],a=n[o];e[t]=[o,a,r(a)]}return e}},function(n,e,t){var r=t(74),i=t(210),o=t(217),a=t(44),s=t(84),l=t(85),c=t(23);n.exports=function(n,e){return a(n)&&s(e)?l(c(n),e):function(t){var a=i(t,n);return void 0===a&&a===e?o(t,n):r(e,a,3)}}},function(n,e,t){var r=t(86);n.exports=function(n,e,t){var i=null==n?void 0:r(n,e);return void 0===i?t:i}},function(n,e,t){var r=t(212),i=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,o=/\\(\\)?/g,a=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(i,(function(n,t,r,i){e.push(r?i.replace(o,"$1"):t||n)})),e}));n.exports=a},function(n,e,t){var r=t(213);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(41);function i(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,i=e?e.apply(this,r):r[0],o=t.cache;if(o.has(i))return o.get(i);var a=n.apply(this,r);return t.cache=o.set(i,a)||o,a};return t.cache=new(i.Cache||r),t}i.Cache=r,n.exports=i},function(n,e,t){var r=t(215);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(15),i=t(216),o=t(6),a=t(45),s=r?r.prototype:void 0,l=s?s.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(o(e))return i(e,n)+"";if(a(e))return l?l.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,i=Array(r);++t<r;)i[t]=e(n[t],t,n);return i}},function(n,e,t){var r=t(218),i=t(219);n.exports=function(n,e){return null!=n&&i(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(87),i=t(38),o=t(6),a=t(80),s=t(43),l=t(23);n.exports=function(n,e,t){for(var c=-1,u=(e=r(e,n)).length,d=!1;++c<u;){var h=l(e[c]);if(!(d=null!=n&&t(n,h)))break;n=n[h]}return d||++c!=u?d:!!(u=null==n?0:n.length)&&s(u)&&a(h,u)&&(o(n)||i(n))}},function(n,e,t){var r=t(221),i=t(222),o=t(44),a=t(23);n.exports=function(n){return o(n)?r(a(n)):i(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(86);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(46),i=t(224),o=t(226);n.exports=function(n,e){return o(i(n,e,r),n+"")}},function(n,e,t){var r=t(225),i=Math.max;n.exports=function(n,e,t){return e=i(void 0===e?n.length-1:e,0),function(){for(var o=arguments,a=-1,s=i(o.length-e,0),l=Array(s);++a<s;)l[a]=o[e+a];a=-1;for(var c=Array(e+1);++a<e;)c[a]=o[a];return c[e]=t(l),r(n,this,c)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(227),i=t(230)(r);n.exports=i},function(n,e,t){var r=t(228),i=t(229),o=t(46),a=i?function(n,e){return i(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:o;n.exports=a},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(10),i=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=i},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var i=t(),o=16-(i-r);if(r=i,o>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(76),i=t(232),o=t(237),a=t(77),s=t(238),l=t(42);n.exports=function(n,e,t){var c=-1,u=i,d=n.length,h=!0,p=[],f=p;if(t)h=!1,u=o;else if(d>=200){var m=e?null:s(n);if(m)return l(m);h=!1,u=a,f=new r}else f=e?[]:p;n:for(;++c<d;){var v=n[c],g=e?e(v):v;if(v=t||0!==v?v:0,h&&g==g){for(var y=f.length;y--;)if(f[y]===g)continue n;e&&f.push(g),p.push(v)}else u(f,g,t)||(f!==p&&f.push(g),p.push(v))}return p}},function(n,e,t){var r=t(233);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(234),i=t(235),o=t(236);n.exports=function(n,e,t){return e==e?o(n,e,t):r(n,i,t)}},function(n,e){n.exports=function(n,e,t,r){for(var i=n.length,o=t+(r?1:-1);r?o--:++o<i;)if(e(n[o],o,n))return o;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,i=n.length;++r<i;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,i=null==n?0:n.length;++r<i;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(83),i=t(239),o=t(42),a=r&&1/o(new r([,-0]))[1]==1/0?function(n){return new r(n)}:i;n.exports=a},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(82),i=t(12);n.exports=function(n){return i(n)&&r(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(88)},function(n,e,t){"use strict";t(89)},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(90)},function(n,e,t){"use strict";t(91)},function(n,e,t){"use strict";t.r(e);
/*!
 * Vue.js v2.7.16
 * (c) 2014-2023 Evan You
 * Released under the MIT License.
 */
var r=Object.freeze({}),i=Array.isArray;function o(n){return null==n}function a(n){return null!=n}function s(n){return!0===n}function l(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function c(n){return"function"==typeof n}function u(n){return null!==n&&"object"==typeof n}var d=Object.prototype.toString;function p(n){return"[object Object]"===d.call(n)}function f(n){return"[object RegExp]"===d.call(n)}function m(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function v(n){return a(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function g(n){return null==n?"":Array.isArray(n)||p(n)&&n.toString===d?JSON.stringify(n,y,2):String(n)}function y(n,e){return e&&e.__v_isRef?e.value:e}function b(n){var e=parseFloat(n);return isNaN(e)?n:e}function k(n,e){for(var t=Object.create(null),r=n.split(","),i=0;i<r.length;i++)t[r[i]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}k("slot,component",!0);var _=k("key,ref,slot,slot-scope,is");function x(n,e){var t=n.length;if(t){if(e===n[t-1])return void(n.length=t-1);var r=n.indexOf(e);if(r>-1)return n.splice(r,1)}}var E=Object.prototype.hasOwnProperty;function w(n,e){return E.call(n,e)}function T(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var A=/-(\w)/g,C=T((function(n){return n.replace(A,(function(n,e){return e?e.toUpperCase():""}))})),L=T((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),S=/\B([A-Z])/g,R=T((function(n){return n.replace(S,"-$1").toLowerCase()}));var I=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function z(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function B(n,e){for(var t in e)n[t]=e[t];return n}function O(n){for(var e={},t=0;t<n.length;t++)n[t]&&B(e,n[t]);return e}function j(n,e,t){}var U=function(n,e,t){return!1},P=function(n){return n};function D(n,e){if(n===e)return!0;var t=u(n),r=u(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var i=Array.isArray(n),o=Array.isArray(e);if(i&&o)return n.length===e.length&&n.every((function(n,t){return D(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(i||o)return!1;var a=Object.keys(n),s=Object.keys(e);return a.length===s.length&&a.every((function(t){return D(n[t],e[t])}))}catch(n){return!1}}function M(n,e){for(var t=0;t<n.length;t++)if(D(n[t],e))return t;return-1}function N(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function F(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var $=["component","directive","filter"],q=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],H={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:U,isReservedAttr:U,isUnknownElement:U,getTagNamespace:j,parsePlatformTagName:P,mustUseProp:U,async:!0,_lifecycleHooks:q},K=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function V(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function G(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var W=new RegExp("[^".concat(K.source,".$_\\d]"));var X="__proto__"in{},Q="undefined"!=typeof window,Z=Q&&window.navigator.userAgent.toLowerCase(),Y=Z&&/msie|trident/.test(Z),J=Z&&Z.indexOf("msie 9.0")>0,nn=Z&&Z.indexOf("edge/")>0;Z&&Z.indexOf("android");var en=Z&&/iphone|ipad|ipod|ios/.test(Z);Z&&/chrome\/\d+/.test(Z),Z&&/phantomjs/.test(Z);var tn,rn=Z&&Z.match(/firefox\/(\d+)/),on={}.watch,an=!1;if(Q)try{var sn={};Object.defineProperty(sn,"passive",{get:function(){an=!0}}),window.addEventListener("test-passive",null,sn)}catch(n){}var ln=function(){return void 0===tn&&(tn=!Q&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),tn},cn=Q&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function un(n){return"function"==typeof n&&/native code/.test(n.toString())}var dn,hn="undefined"!=typeof Symbol&&un(Symbol)&&"undefined"!=typeof Reflect&&un(Reflect.ownKeys);dn="undefined"!=typeof Set&&un(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var pn=null;function fn(n){void 0===n&&(n=null),n||pn&&pn._scope.off(),pn=n,n&&n._scope.on()}var mn=function(){function n(n,e,t,r,i,o,a,s){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=i,this.ns=void 0,this.context=o,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=a,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),vn=function(n){void 0===n&&(n="");var e=new mn;return e.text=n,e.isComment=!0,e};function gn(n){return new mn(void 0,void 0,void 0,String(n))}function yn(n){var e=new mn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}"function"==typeof SuppressedError&&SuppressedError;var bn=0,kn=[],_n=function(){function n(){this._pending=!1,this.id=bn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){this.subs[this.subs.indexOf(n)]=null,this._pending||(this._pending=!0,kn.push(this))},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.filter((function(n){return n}));for(var t=0,r=e.length;t<r;t++){0,e[t].update()}},n}();_n.target=null;var xn=[];function En(n){xn.push(n),_n.target=n}function wn(){xn.pop(),_n.target=xn[xn.length-1]}var Tn=Array.prototype,An=Object.create(Tn);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=Tn[n];G(An,n,(function(){for(var t=[],r=0;r<arguments.length;r++)t[r]=arguments[r];var i,o=e.apply(this,t),a=this.__ob__;switch(n){case"push":case"unshift":i=t;break;case"splice":i=t.slice(2)}return i&&a.observeArray(i),a.dep.notify(),o}))}));var Cn=Object.getOwnPropertyNames(An),Ln={},Sn=!0;function Rn(n){Sn=n}var In={notify:j,depend:j,addSub:j,removeSub:j},zn=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?In:new _n,this.vmCount=0,G(n,"__ob__",this),i(n)){if(!t)if(X)n.__proto__=An;else for(var r=0,o=Cn.length;r<o;r++){G(n,s=Cn[r],An[s])}e||this.observeArray(n)}else{var a=Object.keys(n);for(r=0;r<a.length;r++){var s;On(n,s=a[r],Ln,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)Bn(n[e],!1,this.mock)},n}();function Bn(n,e,t){return n&&w(n,"__ob__")&&n.__ob__ instanceof zn?n.__ob__:!Sn||!t&&ln()||!i(n)&&!p(n)||!Object.isExtensible(n)||n.__v_skip||Fn(n)||n instanceof mn?void 0:new zn(n,e,t)}function On(n,e,t,r,o,a,s){void 0===s&&(s=!1);var l=new _n,c=Object.getOwnPropertyDescriptor(n,e);if(!c||!1!==c.configurable){var u=c&&c.get,d=c&&c.set;u&&!d||t!==Ln&&2!==arguments.length||(t=n[e]);var h=o?t&&t.__ob__:Bn(t,!1,a);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=u?u.call(n):t;return _n.target&&(l.depend(),h&&(h.dep.depend(),i(e)&&Pn(e))),Fn(e)&&!o?e.value:e},set:function(e){var r=u?u.call(n):t;if(F(r,e)){if(d)d.call(n,e);else{if(u)return;if(!o&&Fn(r)&&!Fn(e))return void(r.value=e);t=e}h=o?e&&e.__ob__:Bn(e,!1,a),l.notify()}}}),l}}function jn(n,e,t){if(!Nn(n)){var r=n.__ob__;return i(n)&&m(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),r&&!r.shallow&&r.mock&&Bn(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||r&&r.vmCount?t:r?(On(r.value,e,t,void 0,r.shallow,r.mock),r.dep.notify(),t):(n[e]=t,t)}}function Un(n,e){if(i(n)&&m(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||Nn(n)||w(n,e)&&(delete n[e],t&&t.dep.notify())}}function Pn(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),i(e)&&Pn(e)}function Dn(n){return Mn(n,!0),G(n,"__v_isShallow",!0),n}function Mn(n,e){if(!Nn(n)){Bn(n,e,ln());0}}function Nn(n){return!(!n||!n.__v_isReadonly)}function Fn(n){return!(!n||!0!==n.__v_isRef)}function $n(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){var n=e[t];if(Fn(n))return n.value;var r=n&&n.__ob__;return r&&r.dep.depend(),n},set:function(n){var r=e[t];Fn(r)&&!Fn(n)?r.value=n:e[t]=n}})}"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");var qn;var Hn=function(){function n(n){void 0===n&&(n=!1),this.detached=n,this.active=!0,this.effects=[],this.cleanups=[],this.parent=qn,!n&&qn&&(this.index=(qn.scopes||(qn.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=qn;try{return qn=this,n()}finally{qn=e}}else 0},n.prototype.on=function(){qn=this},n.prototype.off=function(){qn=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(!this.detached&&this.parent&&!n){var r=this.parent.scopes.pop();r&&r!==this&&(this.parent.scopes[this.index]=r,r.index=this.index)}this.parent=void 0,this.active=!1}},n}();function Kn(n){var e=n._provided,t=n.$parent&&n.$parent._provided;return t===e?n._provided=Object.create(t):e}var Vn=T((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function Gn(n,e){function t(){var n=t.fns;if(!i(n))return Se(n,null,arguments,e,"v-on handler");for(var r=n.slice(),o=0;o<r.length;o++)Se(r[o],null,arguments,e,"v-on handler")}return t.fns=n,t}function Wn(n,e,t,r,i,a){var l,c,u,d;for(l in n)c=n[l],u=e[l],d=Vn(l),o(c)||(o(u)?(o(c.fns)&&(c=n[l]=Gn(c,a)),s(d.once)&&(c=n[l]=i(d.name,c,d.capture)),t(d.name,c,d.capture,d.passive,d.params)):c!==u&&(u.fns=c,n[l]=u));for(l in e)o(n[l])&&r((d=Vn(l)).name,e[l],d.capture)}function Xn(n,e,t){var r;n instanceof mn&&(n=n.data.hook||(n.data.hook={}));var i=n[e];function l(){t.apply(this,arguments),x(r.fns,l)}o(i)?r=Gn([l]):a(i.fns)&&s(i.merged)?(r=i).fns.push(l):r=Gn([i,l]),r.merged=!0,n[e]=r}function Qn(n,e,t,r,i){if(a(e)){if(w(e,t))return n[t]=e[t],i||delete e[t],!0;if(w(e,r))return n[t]=e[r],i||delete e[r],!0}return!1}function Zn(n){return l(n)?[gn(n)]:i(n)?function n(e,t){var r,c,u,d,h=[];for(r=0;r<e.length;r++)o(c=e[r])||"boolean"==typeof c||(u=h.length-1,d=h[u],i(c)?c.length>0&&(Yn((c=n(c,"".concat(t||"","_").concat(r)))[0])&&Yn(d)&&(h[u]=gn(d.text+c[0].text),c.shift()),h.push.apply(h,c)):l(c)?Yn(d)?h[u]=gn(d.text+c):""!==c&&h.push(gn(c)):Yn(c)&&Yn(d)?h[u]=gn(d.text+c.text):(s(e._isVList)&&a(c.tag)&&o(c.key)&&a(t)&&(c.key="__vlist".concat(t,"_").concat(r,"__")),h.push(c)));return h}(n):void 0}function Yn(n){return a(n)&&a(n.text)&&!1===n.isComment}function Jn(n,e){var t,r,o,s,l=null;if(i(n)||"string"==typeof n)for(l=new Array(n.length),t=0,r=n.length;t<r;t++)l[t]=e(n[t],t);else if("number"==typeof n)for(l=new Array(n),t=0;t<n;t++)l[t]=e(t+1,t);else if(u(n))if(hn&&n[Symbol.iterator]){l=[];for(var c=n[Symbol.iterator](),d=c.next();!d.done;)l.push(e(d.value,l.length)),d=c.next()}else for(o=Object.keys(n),l=new Array(o.length),t=0,r=o.length;t<r;t++)s=o[t],l[t]=e(n[s],s,t);return a(l)||(l=[]),l._isVList=!0,l}function ne(n,e,t,r){var i,o=this.$scopedSlots[n];o?(t=t||{},r&&(t=B(B({},r),t)),i=o(t)||(c(e)?e():e)):i=this.$slots[n]||(c(e)?e():e);var a=t&&t.slot;return a?this.$createElement("template",{slot:a},i):i}function ee(n){return zt(this.$options,"filters",n,!0)||P}function te(n,e){return i(n)?-1===n.indexOf(e):n!==e}function re(n,e,t,r,i){var o=H.keyCodes[e]||t;return i&&r&&!H.keyCodes[e]?te(i,r):o?te(o,n):r?R(r)!==e:void 0===n}function ie(n,e,t,r,o){if(t)if(u(t)){i(t)&&(t=O(t));var a=void 0,s=function(i){if("class"===i||"style"===i||_(i))a=n;else{var s=n.attrs&&n.attrs.type;a=r||H.mustUseProp(e,s,i)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var l=C(i),c=R(i);l in a||c in a||(a[i]=t[i],o&&((n.on||(n.on={}))["update:".concat(i)]=function(n){t[i]=n}))};for(var l in t)s(l)}else;return n}function oe(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||se(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),r}function ae(n,e,t){return se(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function se(n,e,t){if(i(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&le(n[r],"".concat(e,"_").concat(r),t);else le(n,e,t)}function le(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function ce(n,e){if(e)if(p(e)){var t=n.on=n.on?B({},n.on):{};for(var r in e){var i=t[r],o=e[r];t[r]=i?[].concat(i,o):o}}else;return n}function ue(n,e,t,r){e=e||{$stable:!t};for(var o=0;o<n.length;o++){var a=n[o];i(a)?ue(a,e,t):a&&(a.proxy&&(a.fn.proxy=!0),e[a.key]=a.fn)}return r&&(e.$key=r),e}function de(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function he(n,e){return"string"==typeof n?e+n:n}function pe(n){n._o=ae,n._n=b,n._s=g,n._l=Jn,n._t=ne,n._q=D,n._i=M,n._m=oe,n._f=ee,n._k=re,n._b=ie,n._v=gn,n._e=vn,n._u=ue,n._g=ce,n._d=de,n._p=he}function fe(n,e){if(!n||!n.length)return{};for(var t={},r=0,i=n.length;r<i;r++){var o=n[r],a=o.data;if(a&&a.attrs&&a.attrs.slot&&delete a.attrs.slot,o.context!==e&&o.fnContext!==e||!a||null==a.slot)(t.default||(t.default=[])).push(o);else{var s=a.slot,l=t[s]||(t[s]=[]);"template"===o.tag?l.push.apply(l,o.children||[]):l.push(o)}}for(var c in t)t[c].every(me)&&delete t[c];return t}function me(n){return n.isComment&&!n.asyncFactory||" "===n.text}function ve(n){return n.isComment&&n.asyncFactory}function ge(n,e,t,i){var o,a=Object.keys(t).length>0,s=e?!!e.$stable:!a,l=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(s&&i&&i!==r&&l===i.$key&&!a&&!i.$hasNormal)return i;for(var c in o={},e)e[c]&&"$"!==c[0]&&(o[c]=ye(n,t,c,e[c]))}else o={};for(var u in t)u in o||(o[u]=be(t,u));return e&&Object.isExtensible(e)&&(e._normalized=o),G(o,"$stable",s),G(o,"$key",l),G(o,"$hasNormal",a),o}function ye(n,e,t,r){var o=function(){var e=pn;fn(n);var t=arguments.length?r.apply(null,arguments):r({}),o=(t=t&&"object"==typeof t&&!i(t)?[t]:Zn(t))&&t[0];return fn(e),t&&(!o||1===t.length&&o.isComment&&!ve(o))?void 0:t};return r.proxy&&Object.defineProperty(e,t,{get:o,enumerable:!0,configurable:!0}),o}function be(n,e){return function(){return n[e]}}function ke(n){return{get attrs(){if(!n._attrsProxy){var e=n._attrsProxy={};G(e,"_v_attr_proxy",!0),_e(e,n.$attrs,r,n,"$attrs")}return n._attrsProxy},get listeners(){n._listenersProxy||_e(n._listenersProxy={},n.$listeners,r,n,"$listeners");return n._listenersProxy},get slots(){return function(n){n._slotsProxy||Ee(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:I(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return $n(n,e,t)}))}}}function _e(n,e,t,r,i){var o=!1;for(var a in e)a in n?e[a]!==t[a]&&(o=!0):(o=!0,xe(n,a,r,i));for(var a in n)a in e||(o=!0,delete n[a]);return o}function xe(n,e,t,r){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t[r][e]}})}function Ee(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var we=null;function Te(n,e){return(n.__esModule||hn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),u(n)?e.extend(n):n}function Ae(n){if(i(n))for(var e=0;e<n.length;e++){var t=n[e];if(a(t)&&(a(t.componentOptions)||ve(t)))return t}}function Ce(n,e,t,r,d,h){return(i(t)||l(t))&&(d=r,r=t,t=void 0),s(h)&&(d=2),function(n,e,t,r,l){if(a(t)&&a(t.__ob__))return vn();a(t)&&a(t.is)&&(e=t.is);if(!e)return vn();0;i(r)&&c(r[0])&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===l?r=Zn(r):1===l&&(r=function(n){for(var e=0;e<n.length;e++)if(i(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var d,h;if("string"==typeof e){var p=void 0;h=n.$vnode&&n.$vnode.ns||H.getTagNamespace(e),d=H.isReservedTag(e)?new mn(H.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!a(p=zt(n.$options,"components",e))?new mn(e,t,r,void 0,void 0,n):xt(p,t,n,r,e)}else d=xt(e,t,n,r);return i(d)?d:a(d)?(a(h)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(a(e.children))for(var i=0,l=e.children.length;i<l;i++){var c=e.children[i];a(c.tag)&&(o(c.ns)||s(r)&&"svg"!==c.tag)&&n(c,t,r)}}(d,h),a(t)&&function(n){u(n.style)&&He(n.style);u(n.class)&&He(n.class)}(t),d):vn()}(n,e,t,r,d)}function Le(n,e,t){En();try{if(e)for(var r=e;r=r.$parent;){var i=r.$options.errorCaptured;if(i)for(var o=0;o<i.length;o++)try{if(!1===i[o].call(r,n,e,t))return}catch(n){Re(n,r,"errorCaptured hook")}}Re(n,e,t)}finally{wn()}}function Se(n,e,t,r,i){var o;try{(o=t?n.apply(e,t):n.call(e))&&!o._isVue&&v(o)&&!o._handled&&(o.catch((function(n){return Le(n,r,i+" (Promise/async)")})),o._handled=!0)}catch(n){Le(n,r,i)}return o}function Re(n,e,t){if(H.errorHandler)try{return H.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Ie(e,null,"config.errorHandler")}Ie(n,e,t)}function Ie(n,e,t){if(!Q||"undefined"==typeof console)throw n;console.error(n)}var ze,Be=!1,Oe=[],je=!1;function Ue(){je=!1;var n=Oe.slice(0);Oe.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&un(Promise)){var Pe=Promise.resolve();ze=function(){Pe.then(Ue),en&&setTimeout(j)},Be=!0}else if(Y||"undefined"==typeof MutationObserver||!un(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())ze="undefined"!=typeof setImmediate&&un(setImmediate)?function(){setImmediate(Ue)}:function(){setTimeout(Ue,0)};else{var De=1,Me=new MutationObserver(Ue),Ne=document.createTextNode(String(De));Me.observe(Ne,{characterData:!0}),ze=function(){De=(De+1)%2,Ne.data=String(De)},Be=!0}function Fe(n,e){var t;if(Oe.push((function(){if(n)try{n.call(e)}catch(n){Le(n,e,"nextTick")}else t&&t(e)})),je||(je=!0,ze()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function $e(n){return function(e,t){if(void 0===t&&(t=pn),t)return function(n,e,t){var r=n.$options;r[e]=Lt(r[e],t)}(t,n,e)}}$e("beforeMount"),$e("mounted"),$e("beforeUpdate"),$e("updated"),$e("beforeDestroy"),$e("destroyed"),$e("activated"),$e("deactivated"),$e("serverPrefetch"),$e("renderTracked"),$e("renderTriggered"),$e("errorCaptured");var qe=new dn;function He(n){return function n(e,t){var r,o,a=i(e);if(!a&&!u(e)||e.__v_skip||Object.isFrozen(e)||e instanceof mn)return;if(e.__ob__){var s=e.__ob__.dep.id;if(t.has(s))return;t.add(s)}if(a)for(r=e.length;r--;)n(e[r],t);else if(Fn(e))n(e.value,t);else for(o=Object.keys(e),r=o.length;r--;)n(e[o[r]],t)}(n,qe),qe.clear(),n}var Ke,Ve=0,Ge=function(){function n(n,e,t,r,i){var o,a;o=this,void 0===(a=qn&&!qn._vm?qn:n?n._scope:void 0)&&(a=qn),a&&a.active&&a.effects.push(o),(this.vm=n)&&i&&(n._watcher=this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++Ve,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new dn,this.newDepIds=new dn,this.expression="",c(e)?this.getter=e:(this.getter=function(n){if(!W.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=j)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;En(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Le(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&He(n),wn(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():ft(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||u(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');Se(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&x(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();function We(n,e){Ke.$on(n,e)}function Xe(n,e){Ke.$off(n,e)}function Qe(n,e){var t=Ke;return function r(){var i=e.apply(null,arguments);null!==i&&t.$off(n,r)}}function Ze(n,e,t){Ke=n,Wn(e,t||{},We,Xe,Qe,n),Ke=void 0}var Ye=null;function Je(n){var e=Ye;return Ye=n,function(){Ye=e}}function nt(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function et(n,e){if(e){if(n._directInactive=!1,nt(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)et(n.$children[t]);tt(n,"activated")}}function tt(n,e,t,r){void 0===r&&(r=!0),En();var i=pn,o=qn;r&&fn(n);var a=n.$options[e],s="".concat(e," hook");if(a)for(var l=0,c=a.length;l<c;l++)Se(a[l],n,t||null,n,s);n._hasHookEvent&&n.$emit("hook:"+e),r&&(fn(i),o&&o.on()),wn()}var rt=[],it=[],ot={},at=!1,st=!1,lt=0;var ct=0,ut=Date.now;if(Q&&!Y){var dt=window.performance;dt&&"function"==typeof dt.now&&ut()>document.createEvent("Event").timeStamp&&(ut=function(){return dt.now()})}var ht=function(n,e){if(n.post){if(!e.post)return 1}else if(e.post)return-1;return n.id-e.id};function pt(){var n,e;for(ct=ut(),st=!0,rt.sort(ht),lt=0;lt<rt.length;lt++)(n=rt[lt]).before&&n.before(),e=n.id,ot[e]=null,n.run();var t=it.slice(),r=rt.slice();lt=rt.length=it.length=0,ot={},at=st=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,et(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r&&r._watcher===t&&r._isMounted&&!r._isDestroyed&&tt(r,"updated")}}(r),function(){for(var n=0;n<kn.length;n++){var e=kn[n];e.subs=e.subs.filter((function(n){return n})),e._pending=!1}kn.length=0}(),cn&&H.devtools&&cn.emit("flush")}function ft(n){var e=n.id;if(null==ot[e]&&(n!==_n.target||!n.noRecurse)){if(ot[e]=!0,st){for(var t=rt.length-1;t>lt&&rt[t].id>n.id;)t--;rt.splice(t+1,0,n)}else rt.push(n);at||(at=!0,Fe(pt))}}function mt(n,e){if(n){for(var t=Object.create(null),r=hn?Reflect.ownKeys(n):Object.keys(n),i=0;i<r.length;i++){var o=r[i];if("__ob__"!==o){var a=n[o].from;if(a in e._provided)t[o]=e._provided[a];else if("default"in n[o]){var s=n[o].default;t[o]=c(s)?s.call(e):s}else 0}}return t}}function vt(n,e,t,o,a){var l,c=this,u=a.options;w(o,"_uid")?(l=Object.create(o))._original=o:(l=o,o=o._original);var d=s(u._compiled),h=!d;this.data=n,this.props=e,this.children=t,this.parent=o,this.listeners=n.on||r,this.injections=mt(u.inject,o),this.slots=function(){return c.$slots||ge(o,n.scopedSlots,c.$slots=fe(t,o)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return ge(o,n.scopedSlots,this.slots())}}),d&&(this.$options=u,this.$slots=this.slots(),this.$scopedSlots=ge(o,n.scopedSlots,this.$slots)),u._scopeId?this._c=function(n,e,t,r){var a=Ce(l,n,e,t,r,h);return a&&!i(a)&&(a.fnScopeId=u._scopeId,a.fnContext=o),a}:this._c=function(n,e,t,r){return Ce(l,n,e,t,r,h)}}function gt(n,e,t,r,i){var o=yn(n);return o.fnContext=t,o.fnOptions=r,e.slot&&((o.data||(o.data={})).slot=e.slot),o}function yt(n,e){for(var t in e)n[C(t)]=e[t]}function bt(n){return n.name||n.__name||n._componentTag}pe(vt.prototype);var kt={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;kt.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;a(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Ye)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,i,o){var a=i.data.scopedSlots,s=n.$scopedSlots,l=!!(a&&!a.$stable||s!==r&&!s.$stable||a&&n.$scopedSlots.$key!==a.$key||!a&&n.$scopedSlots.$key),c=!!(o||n.$options._renderChildren||l),u=n.$vnode;n.$options._parentVnode=i,n.$vnode=i,n._vnode&&(n._vnode.parent=i),n.$options._renderChildren=o;var d=i.data.attrs||r;n._attrsProxy&&_e(n._attrsProxy,d,u.data&&u.data.attrs||r,n,"$attrs")&&(c=!0),n.$attrs=d,t=t||r;var h=n.$options._parentListeners;if(n._listenersProxy&&_e(n._listenersProxy,t,h||r,n,"$listeners"),n.$listeners=n.$options._parentListeners=t,Ze(n,t,h),e&&n.$options.props){Rn(!1);for(var p=n._props,f=n.$options._propKeys||[],m=0;m<f.length;m++){var v=f[m],g=n.$options.props;p[v]=Bt(v,g,e,n)}Rn(!0),n.$options.propsData=e}c&&(n.$slots=fe(o,i.context),n.$forceUpdate())}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,tt(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,it.push(e)):et(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(!(t&&(e._directInactive=!0,nt(e))||e._inactive)){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);tt(e,"deactivated")}}(e,!0):e.$destroy())}},_t=Object.keys(kt);function xt(n,e,t,l,c){if(!o(n)){var d=t.$options._base;if(u(n)&&(n=d.extend(n)),"function"==typeof n){var h;if(o(n.cid)&&void 0===(n=function(n,e){if(s(n.error)&&a(n.errorComp))return n.errorComp;if(a(n.resolved))return n.resolved;var t=we;if(t&&a(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t),s(n.loading)&&a(n.loadingComp))return n.loadingComp;if(t&&!a(n.owners)){var r=n.owners=[t],i=!0,l=null,c=null;t.$on("hook:destroyed",(function(){return x(r,t)}));var d=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==l&&(clearTimeout(l),l=null),null!==c&&(clearTimeout(c),c=null))},h=N((function(t){n.resolved=Te(t,e),i?r.length=0:d(!0)})),p=N((function(e){a(n.errorComp)&&(n.error=!0,d(!0))})),f=n(h,p);return u(f)&&(v(f)?o(n.resolved)&&f.then(h,p):v(f.component)&&(f.component.then(h,p),a(f.error)&&(n.errorComp=Te(f.error,e)),a(f.loading)&&(n.loadingComp=Te(f.loading,e),0===f.delay?n.loading=!0:l=setTimeout((function(){l=null,o(n.resolved)&&o(n.error)&&(n.loading=!0,d(!1))}),f.delay||200)),a(f.timeout)&&(c=setTimeout((function(){c=null,o(n.resolved)&&p(null)}),f.timeout)))),i=!1,n.loading?n.loadingComp:n.resolved}}(h=n,d)))return function(n,e,t,r,i){var o=vn();return o.asyncFactory=n,o.asyncMeta={data:e,context:t,children:r,tag:i},o}(h,e,t,l,c);e=e||{},Gt(n),a(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var o=e.on||(e.on={}),s=o[r],l=e.model.callback;a(s)?(i(s)?-1===s.indexOf(l):s!==l)&&(o[r]=[l].concat(s)):o[r]=l}(n.options,e);var p=function(n,e,t){var r=e.options.props;if(!o(r)){var i={},s=n.attrs,l=n.props;if(a(s)||a(l))for(var c in r){var u=R(c);Qn(i,l,c,u,!0)||Qn(i,s,c,u,!1)}return i}}(e,n);if(s(n.options.functional))return function(n,e,t,o,s){var l=n.options,c={},u=l.props;if(a(u))for(var d in u)c[d]=Bt(d,u,e||r);else a(t.attrs)&&yt(c,t.attrs),a(t.props)&&yt(c,t.props);var h=new vt(t,c,s,o,n),p=l.render.call(null,h._c,h);if(p instanceof mn)return gt(p,t,h.parent,l,h);if(i(p)){for(var f=Zn(p)||[],m=new Array(f.length),v=0;v<f.length;v++)m[v]=gt(f[v],t,h.parent,l,h);return m}}(n,p,e,t,l);var f=e.on;if(e.on=e.nativeOn,s(n.options.abstract)){var m=e.slot;e={},m&&(e.slot=m)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<_t.length;t++){var r=_t[t],i=e[r],o=kt[r];i===o||i&&i._merged||(e[r]=i?Et(o,i):o)}}(e);var g=bt(n.options)||c;return new mn("vue-component-".concat(n.cid).concat(g?"-".concat(g):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:p,listeners:f,tag:c,children:l},h)}}}function Et(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}var wt=j,Tt=H.optionMergeStrategies;function At(n,e,t){if(void 0===t&&(t=!0),!e)return n;for(var r,i,o,a=hn?Reflect.ownKeys(e):Object.keys(e),s=0;s<a.length;s++)"__ob__"!==(r=a[s])&&(i=n[r],o=e[r],t&&w(n,r)?i!==o&&p(i)&&p(o)&&At(i,o):jn(n,r,o));return n}function Ct(n,e,t){return t?function(){var r=c(e)?e.call(t,t):e,i=c(n)?n.call(t,t):n;return r?At(r,i):i}:e?n?function(){return At(c(e)?e.call(this,this):e,c(n)?n.call(this,this):n)}:e:n}function Lt(n,e){var t=e?n?n.concat(e):i(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function St(n,e,t,r){var i=Object.create(n||null);return e?B(i,e):i}Tt.data=function(n,e,t){return t?Ct(n,e,t):e&&"function"!=typeof e?n:Ct(n,e)},q.forEach((function(n){Tt[n]=Lt})),$.forEach((function(n){Tt[n+"s"]=St})),Tt.watch=function(n,e,t,r){if(n===on&&(n=void 0),e===on&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var o={};for(var a in B(o,n),e){var s=o[a],l=e[a];s&&!i(s)&&(s=[s]),o[a]=s?s.concat(l):i(l)?l:[l]}return o},Tt.props=Tt.methods=Tt.inject=Tt.computed=function(n,e,t,r){if(!n)return e;var i=Object.create(null);return B(i,n),e&&B(i,e),i},Tt.provide=function(n,e){return n?function(){var t=Object.create(null);return At(t,c(n)?n.call(this):n),e&&At(t,c(e)?e.call(this):e,!1),t}:e};var Rt=function(n,e){return void 0===e?n:e};function It(n,e,t){if(c(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var r,o,a={};if(i(t))for(r=t.length;r--;)"string"==typeof(o=t[r])&&(a[C(o)]={type:null});else if(p(t))for(var s in t)o=t[s],a[C(s)]=p(o)?o:{type:o};else 0;n.props=a}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(i(t))for(var o=0;o<t.length;o++)r[t[o]]={from:t[o]};else if(p(t))for(var a in t){var s=t[a];r[a]=p(s)?B({from:a},s):{from:s}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];c(r)&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=It(n,e.extends,t)),e.mixins))for(var r=0,o=e.mixins.length;r<o;r++)n=It(n,e.mixins[r],t);var a,s={};for(a in n)l(a);for(a in e)w(n,a)||l(a);function l(r){var i=Tt[r]||Rt;s[r]=i(n[r],e[r],t,r)}return s}function zt(n,e,t,r){if("string"==typeof t){var i=n[e];if(w(i,t))return i[t];var o=C(t);if(w(i,o))return i[o];var a=L(o);return w(i,a)?i[a]:i[t]||i[o]||i[a]}}function Bt(n,e,t,r){var i=e[n],o=!w(t,n),a=t[n],s=Pt(Boolean,i.type);if(s>-1)if(o&&!w(i,"default"))a=!1;else if(""===a||a===R(n)){var l=Pt(String,i.type);(l<0||s<l)&&(a=!0)}if(void 0===a){a=function(n,e,t){if(!w(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return c(r)&&"Function"!==jt(e.type)?r.call(n):r}(r,i,n);var u=Sn;Rn(!0),Bn(a),Rn(u)}return a}var Ot=/^\s*function (\w+)/;function jt(n){var e=n&&n.toString().match(Ot);return e?e[1]:""}function Ut(n,e){return jt(n)===jt(e)}function Pt(n,e){if(!i(e))return Ut(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Ut(e[t],n))return t;return-1}var Dt={enumerable:!0,configurable:!0,get:j,set:j};function Mt(n,e,t){Dt.get=function(){return this[e][t]},Dt.set=function(n){this[e][t]=n},Object.defineProperty(n,t,Dt)}function Nt(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props=Dn({}),i=n.$options._propKeys=[];n.$parent&&Rn(!1);var o=function(o){i.push(o);var a=Bt(o,e,t,n);On(r,o,a,void 0,!0),o in n||Mt(n,"_props",o)};for(var a in e)o(a);Rn(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var r=n._setupContext=ke(n);fn(n),En();var i=Se(t,null,[n._props||Dn({}),r],n,"setup");if(wn(),fn(),c(i))e.render=i;else if(u(i))if(n._setupState=i,i.__sfc){var o=n._setupProxy={};for(var a in i)"__sfc"!==a&&$n(o,i,a)}else for(var a in i)V(a)||$n(n,i,a);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?j:I(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;p(e=n._data=c(e)?function(n,e){En();try{return n.call(e,e)}catch(n){return Le(n,e,"data()"),{}}finally{wn()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,i=(n.$options.methods,t.length);for(;i--;){var o=t[i];0,r&&w(r,o)||V(o)||Mt(n,"_data",o)}var a=Bn(e);a&&a.vmCount++}(n);else{var t=Bn(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=ln();for(var i in e){var o=e[i],a=c(o)?o:o.get;0,r||(t[i]=new Ge(n,a||j,j,Ft)),i in n||$t(n,i,o)}}(n,e.computed),e.watch&&e.watch!==on&&function(n,e){for(var t in e){var r=e[t];if(i(r))for(var o=0;o<r.length;o++)Kt(n,t,r[o]);else Kt(n,t,r)}}(n,e.watch)}var Ft={lazy:!0};function $t(n,e,t){var r=!ln();c(t)?(Dt.get=r?qt(e):Ht(t),Dt.set=j):(Dt.get=t.get?r&&!1!==t.cache?qt(e):Ht(t.get):j,Dt.set=t.set||j),Object.defineProperty(n,e,Dt)}function qt(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),_n.target&&e.depend(),e.value}}function Ht(n){return function(){return n.call(this,this)}}function Kt(n,e,t,r){return p(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var Vt=0;function Gt(n){var e=n.options;if(n.super){var t=Gt(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var i in t)t[i]!==r[i]&&(e||(e={}),e[i]=t[i]);return e}(n);r&&B(n.extendOptions,r),(e=n.options=It(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Wt(n){this._init(n)}function Xt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,i=n._Ctor||(n._Ctor={});if(i[r])return i[r];var o=bt(n)||bt(t.options);var a=function(n){this._init(n)};return(a.prototype=Object.create(t.prototype)).constructor=a,a.cid=e++,a.options=It(t.options,n),a.super=t,a.options.props&&function(n){var e=n.options.props;for(var t in e)Mt(n.prototype,"_props",t)}(a),a.options.computed&&function(n){var e=n.options.computed;for(var t in e)$t(n.prototype,t,e[t])}(a),a.extend=t.extend,a.mixin=t.mixin,a.use=t.use,$.forEach((function(n){a[n]=t[n]})),o&&(a.options.components[o]=a),a.superOptions=t.options,a.extendOptions=n,a.sealedOptions=B({},a.options),i[r]=a,a}}function Qt(n){return n&&(bt(n.Ctor.options)||n.tag)}function Zt(n,e){return i(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!f(n)&&n.test(e)}function Yt(n,e){var t=n.cache,r=n.keys,i=n._vnode,o=n.$vnode;for(var a in t){var s=t[a];if(s){var l=s.name;l&&!e(l)&&Jt(t,a,r,i)}}o.componentOptions.children=void 0}function Jt(n,e,t,r){var i=n[e];!i||r&&i.tag===r.tag||i.componentInstance.$destroy(),n[e]=null,x(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=Vt++,e._isVue=!0,e.__v_skip=!0,e._scope=new Hn(!0),e._scope.parent=void 0,e._scope._vm=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var i=r.componentOptions;t.propsData=i.propsData,t._parentListeners=i.listeners,t._renderChildren=i.children,t._componentTag=i.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=It(Gt(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Ze(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,i=t&&t.context;n.$slots=fe(e._renderChildren,i),n.$scopedSlots=t?ge(n.$parent,t.data.scopedSlots,n.$slots):r,n._c=function(e,t,r,i){return Ce(n,e,t,r,i,!1)},n.$createElement=function(e,t,r,i){return Ce(n,e,t,r,i,!0)};var o=t&&t.data;On(n,"$attrs",o&&o.attrs||r,null,!0),On(n,"$listeners",e._parentListeners||r,null,!0)}(e),tt(e,"beforeCreate",void 0,!1),function(n){var e=mt(n.$options.inject,n);e&&(Rn(!1),Object.keys(e).forEach((function(t){On(n,t,e[t])})),Rn(!0))}(e),Nt(e),function(n){var e=n.$options.provide;if(e){var t=c(e)?e.call(n):e;if(!u(t))return;for(var r=Kn(n),i=hn?Reflect.ownKeys(t):Object.keys(t),o=0;o<i.length;o++){var a=i[o];Object.defineProperty(r,a,Object.getOwnPropertyDescriptor(t,a))}}}(e),tt(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}(Wt),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=jn,n.prototype.$delete=Un,n.prototype.$watch=function(n,e,t){if(p(e))return Kt(this,n,e,t);(t=t||{}).user=!0;var r=new Ge(this,n,e,t);if(t.immediate){var i='callback for immediate watcher "'.concat(r.expression,'"');En(),Se(e,this,[r.value],this,i),wn()}return function(){r.teardown()}}}(Wt),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(i(n))for(var o=0,a=n.length;o<a;o++)r.$on(n[o],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(i(n)){for(var r=0,o=n.length;r<o;r++)t.$off(n[r],e);return t}var a,s=t._events[n];if(!s)return t;if(!e)return t._events[n]=null,t;for(var l=s.length;l--;)if((a=s[l])===e||a.fn===e){s.splice(l,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?z(t):t;for(var r=z(arguments,1),i='event handler for "'.concat(n,'"'),o=0,a=t.length;o<a;o++)Se(t[o],e,r,e,i)}return e}}(Wt),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,i=t._vnode,o=Je(t);t._vnode=n,t.$el=i?t.__patch__(i,n):t.__patch__(t.$el,n,e,!1),o(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t);for(var a=t;a&&a.$vnode&&a.$parent&&a.$vnode===a.$parent._vnode;)a.$parent.$el=a.$el,a=a.$parent},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){tt(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||x(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),tt(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Wt),function(n){pe(n.prototype),n.prototype.$nextTick=function(n){return Fe(n,this)},n.prototype._render=function(){var n=this,e=n.$options,t=e.render,r=e._parentVnode;r&&n._isMounted&&(n.$scopedSlots=ge(n.$parent,r.data.scopedSlots,n.$slots,n.$scopedSlots),n._slotsProxy&&Ee(n._slotsProxy,n.$scopedSlots)),n.$vnode=r;var o,a=pn,s=we;try{fn(n),we=n,o=t.call(n._renderProxy,n.$createElement)}catch(e){Le(e,n,"render"),o=n._vnode}finally{we=s,fn(a)}return i(o)&&1===o.length&&(o=o[0]),o instanceof mn||(o=vn()),o.parent=r,o}}(Wt);var nr=[String,RegExp,Array],er={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:nr,exclude:nr,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var i=t.tag,o=t.componentInstance,a=t.componentOptions;n[r]={name:Qt(a),tag:i,componentInstance:o},e.push(r),this.max&&e.length>parseInt(this.max)&&Jt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Jt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Yt(n,(function(n){return Zt(e,n)}))})),this.$watch("exclude",(function(e){Yt(n,(function(n){return!Zt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Ae(n),t=e&&e.componentOptions;if(t){var r=Qt(t),i=this.include,o=this.exclude;if(i&&(!r||!Zt(i,r))||o&&r&&Zt(o,r))return e;var a=this.cache,s=this.keys,l=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;a[l]?(e.componentInstance=a[l].componentInstance,x(s,l),s.push(l)):(this.vnodeToCache=e,this.keyToCache=l),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return H}};Object.defineProperty(n,"config",e),n.util={warn:wt,extend:B,mergeOptions:It,defineReactive:On},n.set=jn,n.delete=Un,n.nextTick=Fe,n.observable=function(n){return Bn(n),n},n.options=Object.create(null),$.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,B(n.options.components,er),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=z(arguments,1);return t.unshift(this),c(n.install)?n.install.apply(n,t):c(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=It(this.options,n),this}}(n),Xt(n),function(n){$.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&p(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&c(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Wt),Object.defineProperty(Wt.prototype,"$isServer",{get:ln}),Object.defineProperty(Wt.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Wt,"FunctionalRenderContext",{value:vt}),Wt.version="2.7.16";var tr=k("style,class"),rr=k("input,textarea,option,select,progress"),ir=k("contenteditable,draggable,spellcheck"),or=k("events,caret,typing,plaintext-only"),ar=k("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),sr="http://www.w3.org/1999/xlink",lr=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},cr=function(n){return lr(n)?n.slice(6,n.length):""},ur=function(n){return null==n||!1===n};function dr(n){for(var e=n.data,t=n,r=n;a(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=hr(r.data,e));for(;a(t=t.parent);)t&&t.data&&(e=hr(e,t.data));return function(n,e){if(a(n)||a(e))return pr(n,fr(e));return""}(e.staticClass,e.class)}function hr(n,e){return{staticClass:pr(n.staticClass,e.staticClass),class:a(n.class)?[n.class,e.class]:e.class}}function pr(n,e){return n?e?n+" "+e:n:e||""}function fr(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,i=n.length;r<i;r++)a(e=fr(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):u(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var mr={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},vr=k("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),gr=k("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),yr=function(n){return vr(n)||gr(n)};var br=Object.create(null);var kr=k("text,number,password,search,email,tel,url");var _r=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(mr[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),xr={create:function(n,e){Er(e)},update:function(n,e){n.data.ref!==e.data.ref&&(Er(n,!0),Er(e))},destroy:function(n){Er(n,!0)}};function Er(n,e){var t=n.data.ref;if(a(t)){var r=n.context,o=n.componentInstance||n.elm,s=e?null:o,l=e?void 0:o;if(c(t))Se(t,r,[s],r,"template ref function");else{var u=n.data.refInFor,d="string"==typeof t||"number"==typeof t,h=Fn(t),p=r.$refs;if(d||h)if(u){var f=d?p[t]:t.value;e?i(f)&&x(f,o):i(f)?f.includes(o)||f.push(o):d?(p[t]=[o],wr(r,t,p[t])):t.value=[o]}else if(d){if(e&&p[t]!==o)return;p[t]=l,wr(r,t,s)}else if(h){if(e&&t.value!==o)return;t.value=s}else 0}}}function wr(n,e,t){var r=n._setupState;r&&w(r,e)&&(Fn(r[e])?r[e].value=t:r[e]=t)}var Tr=new mn("",{},[]),Ar=["create","activate","update","remove","destroy"];function Cr(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&a(n.data)===a(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=a(t=n.data)&&a(t=t.attrs)&&t.type,i=a(t=e.data)&&a(t=t.attrs)&&t.type;return r===i||kr(r)&&kr(i)}(n,e)||s(n.isAsyncPlaceholder)&&o(e.asyncFactory.error))}function Lr(n,e,t){var r,i,o={};for(r=e;r<=t;++r)a(i=n[r].key)&&(o[i]=r);return o}var Sr={create:Rr,update:Rr,destroy:function(n){Rr(n,Tr)}};function Rr(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,i,o=n===Tr,a=e===Tr,s=zr(n.data.directives,n.context),l=zr(e.data.directives,e.context),c=[],u=[];for(t in l)r=s[t],i=l[t],r?(i.oldValue=r.value,i.oldArg=r.arg,Or(i,"update",e,n),i.def&&i.def.componentUpdated&&u.push(i)):(Or(i,"bind",e,n),i.def&&i.def.inserted&&c.push(i));if(c.length){var d=function(){for(var t=0;t<c.length;t++)Or(c[t],"inserted",e,n)};o?Xn(e,"insert",d):d()}u.length&&Xn(e,"postpatch",(function(){for(var t=0;t<u.length;t++)Or(u[t],"componentUpdated",e,n)}));if(!o)for(t in s)l[t]||Or(s[t],"unbind",n,n,a)}(n,e)}var Ir=Object.create(null);function zr(n,e){var t,r,i=Object.create(null);if(!n)return i;for(t=0;t<n.length;t++){if((r=n[t]).modifiers||(r.modifiers=Ir),i[Br(r)]=r,e._setupState&&e._setupState.__sfc){var o=r.def||zt(e,"_setupState","v-"+r.name);r.def="function"==typeof o?{bind:o,update:o}:o}r.def=r.def||zt(e.$options,"directives",r.name)}return i}function Br(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function Or(n,e,t,r,i){var o=n.def&&n.def[e];if(o)try{o(t.elm,n,t,r,i)}catch(r){Le(r,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var jr=[xr,Sr];function Ur(n,e){var t=e.componentOptions;if(!(a(t)&&!1===t.Ctor.options.inheritAttrs||o(n.data.attrs)&&o(e.data.attrs))){var r,i,l=e.elm,c=n.data.attrs||{},u=e.data.attrs||{};for(r in(a(u.__ob__)||s(u._v_attr_proxy))&&(u=e.data.attrs=B({},u)),u)i=u[r],c[r]!==i&&Pr(l,r,i,e.data.pre);for(r in(Y||nn)&&u.value!==c.value&&Pr(l,"value",u.value),c)o(u[r])&&(lr(r)?l.removeAttributeNS(sr,cr(r)):ir(r)||l.removeAttribute(r))}}function Pr(n,e,t,r){r||n.tagName.indexOf("-")>-1?Dr(n,e,t):ar(e)?ur(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):ir(e)?n.setAttribute(e,function(n,e){return ur(e)||"false"===e?"false":"contenteditable"===n&&or(e)?e:"true"}(e,t)):lr(e)?ur(t)?n.removeAttributeNS(sr,cr(e)):n.setAttributeNS(sr,e,t):Dr(n,e,t)}function Dr(n,e,t){if(ur(t))n.removeAttribute(e);else{if(Y&&!J&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var Mr={create:Ur,update:Ur};function Nr(n,e){var t=e.elm,r=e.data,i=n.data;if(!(o(r.staticClass)&&o(r.class)&&(o(i)||o(i.staticClass)&&o(i.class)))){var s=dr(e),l=t._transitionClasses;a(l)&&(s=pr(s,fr(l))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var Fr,$r={create:Nr,update:Nr};function qr(n,e,t){var r=Fr;return function i(){var o=e.apply(null,arguments);null!==o&&Vr(n,i,t,r)}}var Hr=Be&&!(rn&&Number(rn[1])<=53);function Kr(n,e,t,r){if(Hr){var i=ct,o=e;e=o._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=i||n.timeStamp<=0||n.target.ownerDocument!==document)return o.apply(this,arguments)}}Fr.addEventListener(n,e,an?{capture:t,passive:r}:t)}function Vr(n,e,t,r){(r||Fr).removeEventListener(n,e._wrapper||e,t)}function Gr(n,e){if(!o(n.data.on)||!o(e.data.on)){var t=e.data.on||{},r=n.data.on||{};Fr=e.elm||n.elm,function(n){if(a(n.__r)){var e=Y?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}a(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),Wn(t,r,Kr,Vr,qr,e.context),Fr=void 0}}var Wr,Xr={create:Gr,update:Gr,destroy:function(n){return Gr(n,Tr)}};function Qr(n,e){if(!o(n.data.domProps)||!o(e.data.domProps)){var t,r,i=e.elm,l=n.data.domProps||{},c=e.data.domProps||{};for(t in(a(c.__ob__)||s(c._v_attr_proxy))&&(c=e.data.domProps=B({},c)),l)t in c||(i[t]="");for(t in c){if(r=c[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===l[t])continue;1===i.childNodes.length&&i.removeChild(i.childNodes[0])}if("value"===t&&"PROGRESS"!==i.tagName){i._value=r;var u=o(r)?"":String(r);Zr(i,u)&&(i.value=u)}else if("innerHTML"===t&&gr(i.tagName)&&o(i.innerHTML)){(Wr=Wr||document.createElement("div")).innerHTML="<svg>".concat(r,"</svg>");for(var d=Wr.firstChild;i.firstChild;)i.removeChild(i.firstChild);for(;d.firstChild;)i.appendChild(d.firstChild)}else if(r!==l[t])try{i[t]=r}catch(n){}}}}function Zr(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(a(r)){if(r.number)return b(t)!==b(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Yr={create:Qr,update:Qr},Jr=T((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function ni(n){var e=ei(n.style);return n.staticStyle?B(n.staticStyle,e):e}function ei(n){return Array.isArray(n)?O(n):"string"==typeof n?Jr(n):n}var ti,ri=/^--/,ii=/\s*!important$/,oi=function(n,e,t){if(ri.test(e))n.style.setProperty(e,t);else if(ii.test(t))n.style.setProperty(R(e),t.replace(ii,""),"important");else{var r=si(e);if(Array.isArray(t))for(var i=0,o=t.length;i<o;i++)n.style[r]=t[i];else n.style[r]=t}},ai=["Webkit","Moz","ms"],si=T((function(n){if(ti=ti||document.createElement("div").style,"filter"!==(n=C(n))&&n in ti)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<ai.length;t++){var r=ai[t]+e;if(r in ti)return r}}));function li(n,e){var t=e.data,r=n.data;if(!(o(t.staticStyle)&&o(t.style)&&o(r.staticStyle)&&o(r.style))){var i,s,l=e.elm,c=r.staticStyle,u=r.normalizedStyle||r.style||{},d=c||u,h=ei(e.data.style)||{};e.data.normalizedStyle=a(h.__ob__)?B({},h):h;var p=function(n,e){var t,r={};if(e)for(var i=n;i.componentInstance;)(i=i.componentInstance._vnode)&&i.data&&(t=ni(i.data))&&B(r,t);(t=ni(n.data))&&B(r,t);for(var o=n;o=o.parent;)o.data&&(t=ni(o.data))&&B(r,t);return r}(e,!0);for(s in d)o(p[s])&&oi(l,s,"");for(s in p)i=p[s],oi(l,s,null==i?"":i)}}var ci={create:li,update:li},ui=/\s+/;function di(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(ui).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function hi(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(ui).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function pi(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&B(e,fi(n.name||"v")),B(e,n),e}return"string"==typeof n?fi(n):void 0}}var fi=T((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),mi=Q&&!J,vi="transition",gi="transitionend",yi="animation",bi="animationend";mi&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(vi="WebkitTransition",gi="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(yi="WebkitAnimation",bi="webkitAnimationEnd"));var ki=Q?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function _i(n){ki((function(){ki(n)}))}function xi(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),di(n,e))}function Ei(n,e){n._transitionClasses&&x(n._transitionClasses,e),hi(n,e)}function wi(n,e,t){var r=Ai(n,e),i=r.type,o=r.timeout,a=r.propCount;if(!i)return t();var s="transition"===i?gi:bi,l=0,c=function(){n.removeEventListener(s,u),t()},u=function(e){e.target===n&&++l>=a&&c()};setTimeout((function(){l<a&&c()}),o+1),n.addEventListener(s,u)}var Ti=/\b(transform|all)(,|$)/;function Ai(n,e){var t,r=window.getComputedStyle(n),i=(r[vi+"Delay"]||"").split(", "),o=(r[vi+"Duration"]||"").split(", "),a=Ci(i,o),s=(r[yi+"Delay"]||"").split(", "),l=(r[yi+"Duration"]||"").split(", "),c=Ci(s,l),u=0,d=0;return"transition"===e?a>0&&(t="transition",u=a,d=o.length):"animation"===e?c>0&&(t="animation",u=c,d=l.length):d=(t=(u=Math.max(a,c))>0?a>c?"transition":"animation":null)?"transition"===t?o.length:l.length:0,{type:t,timeout:u,propCount:d,hasTransform:"transition"===t&&Ti.test(r[vi+"Property"])}}function Ci(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return Li(e)+Li(n[t])})))}function Li(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function Si(n,e){var t=n.elm;a(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=pi(n.data.transition);if(!o(r)&&!a(t._enterCb)&&1===t.nodeType){for(var i=r.css,s=r.type,l=r.enterClass,d=r.enterToClass,h=r.enterActiveClass,p=r.appearClass,f=r.appearToClass,m=r.appearActiveClass,v=r.beforeEnter,g=r.enter,y=r.afterEnter,k=r.enterCancelled,_=r.beforeAppear,x=r.appear,E=r.afterAppear,w=r.appearCancelled,T=r.duration,A=Ye,C=Ye.$vnode;C&&C.parent;)A=C.context,C=C.parent;var L=!A._isMounted||!n.isRootInsert;if(!L||x||""===x){var S=L&&p?p:l,R=L&&m?m:h,I=L&&f?f:d,z=L&&_||v,B=L&&c(x)?x:g,O=L&&E||y,j=L&&w||k,U=b(u(T)?T.enter:T);0;var P=!1!==i&&!J,D=zi(B),M=t._enterCb=N((function(){P&&(Ei(t,I),Ei(t,R)),M.cancelled?(P&&Ei(t,S),j&&j(t)):O&&O(t),t._enterCb=null}));n.data.show||Xn(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),B&&B(t,M)})),z&&z(t),P&&(xi(t,S),xi(t,R),_i((function(){Ei(t,S),M.cancelled||(xi(t,I),D||(Ii(U)?setTimeout(M,U):wi(t,s,M)))}))),n.data.show&&(e&&e(),B&&B(t,M)),P||D||M()}}}function Ri(n,e){var t=n.elm;a(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=pi(n.data.transition);if(o(r)||1!==t.nodeType)return e();if(!a(t._leaveCb)){var i=r.css,s=r.type,l=r.leaveClass,c=r.leaveToClass,d=r.leaveActiveClass,h=r.beforeLeave,p=r.leave,f=r.afterLeave,m=r.leaveCancelled,v=r.delayLeave,g=r.duration,y=!1!==i&&!J,k=zi(p),_=b(u(g)?g.leave:g);0;var x=t._leaveCb=N((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),y&&(Ei(t,c),Ei(t,d)),x.cancelled?(y&&Ei(t,l),m&&m(t)):(e(),f&&f(t)),t._leaveCb=null}));v?v(E):E()}function E(){x.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),h&&h(t),y&&(xi(t,l),xi(t,d),_i((function(){Ei(t,l),x.cancelled||(xi(t,c),k||(Ii(_)?setTimeout(x,_):wi(t,s,x)))}))),p&&p(t,x),y||k||x())}}function Ii(n){return"number"==typeof n&&!isNaN(n)}function zi(n){if(o(n))return!1;var e=n.fns;return a(e)?zi(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Bi(n,e){!0!==e.data.show&&Si(e)}var Oi=function(n){var e,t,r={},c=n.modules,u=n.nodeOps;for(e=0;e<Ar.length;++e)for(r[Ar[e]]=[],t=0;t<c.length;++t)a(c[t][Ar[e]])&&r[Ar[e]].push(c[t][Ar[e]]);function d(n){var e=u.parentNode(n);a(e)&&u.removeChild(e,n)}function h(n,e,t,i,o,l,c){if(a(n.elm)&&a(l)&&(n=l[c]=yn(n)),n.isRootInsert=!o,!function(n,e,t,i){var o=n.data;if(a(o)){var l=a(n.componentInstance)&&o.keepAlive;if(a(o=o.hook)&&a(o=o.init)&&o(n,!1),a(n.componentInstance))return p(n,e),f(t,n.elm,i),s(l)&&function(n,e,t,i){var o,s=n;for(;s.componentInstance;)if(s=s.componentInstance._vnode,a(o=s.data)&&a(o=o.transition)){for(o=0;o<r.activate.length;++o)r.activate[o](Tr,s);e.push(s);break}f(t,n.elm,i)}(n,e,t,i),!0}}(n,e,t,i)){var d=n.data,h=n.children,v=n.tag;a(v)?(n.elm=n.ns?u.createElementNS(n.ns,v):u.createElement(v,n),y(n),m(n,h,e),a(d)&&g(n,e),f(t,n.elm,i)):s(n.isComment)?(n.elm=u.createComment(n.text),f(t,n.elm,i)):(n.elm=u.createTextNode(n.text),f(t,n.elm,i))}}function p(n,e){a(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,v(n)?(g(n,e),y(n)):(Er(n),e.push(n))}function f(n,e,t){a(n)&&(a(t)?u.parentNode(t)===n&&u.insertBefore(n,e,t):u.appendChild(n,e))}function m(n,e,t){if(i(e)){0;for(var r=0;r<e.length;++r)h(e[r],t,n.elm,null,!0,e,r)}else l(n.text)&&u.appendChild(n.elm,u.createTextNode(String(n.text)))}function v(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return a(n.tag)}function g(n,t){for(var i=0;i<r.create.length;++i)r.create[i](Tr,n);a(e=n.data.hook)&&(a(e.create)&&e.create(Tr,n),a(e.insert)&&t.push(n))}function y(n){var e;if(a(e=n.fnScopeId))u.setStyleScope(n.elm,e);else for(var t=n;t;)a(e=t.context)&&a(e=e.$options._scopeId)&&u.setStyleScope(n.elm,e),t=t.parent;a(e=Ye)&&e!==n.context&&e!==n.fnContext&&a(e=e.$options._scopeId)&&u.setStyleScope(n.elm,e)}function b(n,e,t,r,i,o){for(;r<=i;++r)h(t[r],o,n,e,!1,t,r)}function _(n){var e,t,i=n.data;if(a(i))for(a(e=i.hook)&&a(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(a(e=n.children))for(t=0;t<n.children.length;++t)_(n.children[t])}function x(n,e,t){for(;e<=t;++e){var r=n[e];a(r)&&(a(r.tag)?(E(r),_(r)):d(r.elm))}}function E(n,e){if(a(e)||a(n.data)){var t,i=r.remove.length+1;for(a(e)?e.listeners+=i:e=function(n,e){function t(){0==--t.listeners&&d(n)}return t.listeners=e,t}(n.elm,i),a(t=n.componentInstance)&&a(t=t._vnode)&&a(t.data)&&E(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);a(t=n.data.hook)&&a(t=t.remove)?t(n,e):e()}else d(n.elm)}function w(n,e,t,r){for(var i=t;i<r;i++){var o=e[i];if(a(o)&&Cr(n,o))return i}}function T(n,e,t,i,l,c){if(n!==e){a(e.elm)&&a(i)&&(e=i[l]=yn(e));var d=e.elm=n.elm;if(s(n.isAsyncPlaceholder))a(e.asyncFactory.resolved)?L(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(s(e.isStatic)&&s(n.isStatic)&&e.key===n.key&&(s(e.isCloned)||s(e.isOnce)))e.componentInstance=n.componentInstance;else{var p,f=e.data;a(f)&&a(p=f.hook)&&a(p=p.prepatch)&&p(n,e);var m=n.children,g=e.children;if(a(f)&&v(e)){for(p=0;p<r.update.length;++p)r.update[p](n,e);a(p=f.hook)&&a(p=p.update)&&p(n,e)}o(e.text)?a(m)&&a(g)?m!==g&&function(n,e,t,r,i){var s,l,c,d=0,p=0,f=e.length-1,m=e[0],v=e[f],g=t.length-1,y=t[0],k=t[g],_=!i;for(0;d<=f&&p<=g;)o(m)?m=e[++d]:o(v)?v=e[--f]:Cr(m,y)?(T(m,y,r,t,p),m=e[++d],y=t[++p]):Cr(v,k)?(T(v,k,r,t,g),v=e[--f],k=t[--g]):Cr(m,k)?(T(m,k,r,t,g),_&&u.insertBefore(n,m.elm,u.nextSibling(v.elm)),m=e[++d],k=t[--g]):Cr(v,y)?(T(v,y,r,t,p),_&&u.insertBefore(n,v.elm,m.elm),v=e[--f],y=t[++p]):(o(s)&&(s=Lr(e,d,f)),o(l=a(y.key)?s[y.key]:w(y,e,d,f))?h(y,r,n,m.elm,!1,t,p):Cr(c=e[l],y)?(T(c,y,r,t,p),e[l]=void 0,_&&u.insertBefore(n,c.elm,m.elm)):h(y,r,n,m.elm,!1,t,p),y=t[++p]);d>f?b(n,o(t[g+1])?null:t[g+1].elm,t,p,g,r):p>g&&x(e,d,f)}(d,m,g,t,c):a(g)?(a(n.text)&&u.setTextContent(d,""),b(d,null,g,0,g.length-1,t)):a(m)?x(m,0,m.length-1):a(n.text)&&u.setTextContent(d,""):n.text!==e.text&&u.setTextContent(d,e.text),a(f)&&a(p=f.hook)&&a(p=p.postpatch)&&p(n,e)}}}function A(n,e,t){if(s(t)&&a(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var C=k("attrs,class,staticClass,staticStyle,key");function L(n,e,t,r){var i,o=e.tag,l=e.data,c=e.children;if(r=r||l&&l.pre,e.elm=n,s(e.isComment)&&a(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(a(l)&&(a(i=l.hook)&&a(i=i.init)&&i(e,!0),a(i=e.componentInstance)))return p(e,t),!0;if(a(o)){if(a(c))if(n.hasChildNodes())if(a(i=l)&&a(i=i.domProps)&&a(i=i.innerHTML)){if(i!==n.innerHTML)return!1}else{for(var u=!0,d=n.firstChild,h=0;h<c.length;h++){if(!d||!L(d,c[h],t,r)){u=!1;break}d=d.nextSibling}if(!u||d)return!1}else m(e,c,t);if(a(l)){var f=!1;for(var v in l)if(!C(v)){f=!0,g(e,t);break}!f&&l.class&&He(l.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,i){if(!o(e)){var l,c=!1,d=[];if(o(n))c=!0,h(e,d);else{var p=a(n.nodeType);if(!p&&Cr(n,e))T(n,e,d,null,null,i);else{if(p){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),s(t)&&L(n,e,d))return A(e,d,!0),n;l=n,n=new mn(u.tagName(l).toLowerCase(),{},[],void 0,l)}var f=n.elm,m=u.parentNode(f);if(h(e,d,f._leaveCb?null:m,u.nextSibling(f)),a(e.parent))for(var g=e.parent,y=v(e);g;){for(var b=0;b<r.destroy.length;++b)r.destroy[b](g);if(g.elm=e.elm,y){for(var k=0;k<r.create.length;++k)r.create[k](Tr,g);var E=g.data.hook.insert;if(E.merged)for(var w=E.fns.slice(1),C=0;C<w.length;C++)w[C]()}else Er(g);g=g.parent}a(m)?x([n],0,0):a(n.tag)&&_(n)}}return A(e,d,c),e.elm}a(n)&&_(n)}}({nodeOps:_r,modules:[Mr,$r,Xr,Yr,ci,Q?{create:Bi,activate:Bi,remove:function(n,e){!0!==n.data.show?Ri(n,e):e()}}:{}].concat(jr)});J&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&$i(n,"input")}));var ji={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?Xn(t,"postpatch",(function(){ji.componentUpdated(n,e,t)})):Ui(n,e,t.context),n._vOptions=[].map.call(n.options,Mi)):("textarea"===t.tag||kr(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",Ni),n.addEventListener("compositionend",Fi),n.addEventListener("change",Fi),J&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){Ui(n,e,t.context);var r=n._vOptions,i=n._vOptions=[].map.call(n.options,Mi);if(i.some((function(n,e){return!D(n,r[e])})))(n.multiple?e.value.some((function(n){return Di(n,i)})):e.value!==e.oldValue&&Di(e.value,i))&&$i(n,"change")}}};function Ui(n,e,t){Pi(n,e,t),(Y||nn)&&setTimeout((function(){Pi(n,e,t)}),0)}function Pi(n,e,t){var r=e.value,i=n.multiple;if(!i||Array.isArray(r)){for(var o,a,s=0,l=n.options.length;s<l;s++)if(a=n.options[s],i)o=M(r,Mi(a))>-1,a.selected!==o&&(a.selected=o);else if(D(Mi(a),r))return void(n.selectedIndex!==s&&(n.selectedIndex=s));i||(n.selectedIndex=-1)}}function Di(n,e){return e.every((function(e){return!D(e,n)}))}function Mi(n){return"_value"in n?n._value:n.value}function Ni(n){n.target.composing=!0}function Fi(n){n.target.composing&&(n.target.composing=!1,$i(n.target,"input"))}function $i(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function qi(n){return!n.componentInstance||n.data&&n.data.transition?n:qi(n.componentInstance._vnode)}var Hi={model:ji,show:{bind:function(n,e,t){var r=e.value,i=(t=qi(t)).data&&t.data.transition,o=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&i?(t.data.show=!0,Si(t,(function(){n.style.display=o}))):n.style.display=r?o:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=qi(t)).data&&t.data.transition?(t.data.show=!0,r?Si(t,(function(){n.style.display=n.__vOriginalDisplay})):Ri(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,i){i||(n.style.display=n.__vOriginalDisplay)}}},Ki={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Vi(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Vi(Ae(e.children)):n}function Gi(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var i=t._parentListeners;for(var r in i)e[C(r)]=i[r];return e}function Wi(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Xi=function(n){return n.tag||ve(n)},Qi=function(n){return"show"===n.name},Zi={name:"transition",props:Ki,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Xi)).length){0;var r=this.mode;0;var i=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return i;var o=Vi(i);if(!o)return i;if(this._leaving)return Wi(n,i);var a="__transition-".concat(this._uid,"-");o.key=null==o.key?o.isComment?a+"comment":a+o.tag:l(o.key)?0===String(o.key).indexOf(a)?o.key:a+o.key:o.key;var s=(o.data||(o.data={})).transition=Gi(this),c=this._vnode,u=Vi(c);if(o.data.directives&&o.data.directives.some(Qi)&&(o.data.show=!0),u&&u.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(o,u)&&!ve(u)&&(!u.componentInstance||!u.componentInstance._vnode.isComment)){var d=u.data.transition=B({},s);if("out-in"===r)return this._leaving=!0,Xn(d,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Wi(n,i);if("in-out"===r){if(ve(o))return c;var h,p=function(){h()};Xn(s,"afterEnter",p),Xn(s,"enterCancelled",p),Xn(d,"delayLeave",(function(n){h=n}))}}return i}}},Yi=B({tag:String,moveClass:String},Ki);function Ji(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function no(n){n.data.newPos=n.elm.getBoundingClientRect()}function eo(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,i=e.top-t.top;if(r||i){n.data.moved=!0;var o=n.elm.style;o.transform=o.WebkitTransform="translate(".concat(r,"px,").concat(i,"px)"),o.transitionDuration="0s"}}delete Yi.mode;var to={Transition:Zi,TransitionGroup:{props:Yi,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var i=Je(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,i(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,i=this.$slots.default||[],o=this.children=[],a=Gi(this),s=0;s<i.length;s++){if((u=i[s]).tag)if(null!=u.key&&0!==String(u.key).indexOf("__vlist"))o.push(u),t[u.key]=u,(u.data||(u.data={})).transition=a;else;}if(r){var l=[],c=[];for(s=0;s<r.length;s++){var u;(u=r[s]).data.transition=a,u.data.pos=u.elm.getBoundingClientRect(),t[u.key]?l.push(u):c.push(u)}this.kept=n(e,null,l),this.removed=c}return n(e,null,o)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Ji),n.forEach(no),n.forEach(eo),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;xi(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(gi,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(gi,n),t._moveCb=null,Ei(t,e))})}})))},methods:{hasMove:function(n,e){if(!mi)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){hi(t,n)})),di(t,e),t.style.display="none",this.$el.appendChild(t);var r=Ai(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};function ro(n,e){for(var t in e)n[t]=e[t];return n}Wt.config.mustUseProp=function(n,e,t){return"value"===t&&rr(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Wt.config.isReservedTag=yr,Wt.config.isReservedAttr=tr,Wt.config.getTagNamespace=function(n){return gr(n)?"svg":"math"===n?"math":void 0},Wt.config.isUnknownElement=function(n){if(!Q)return!0;if(yr(n))return!1;if(n=n.toLowerCase(),null!=br[n])return br[n];var e=document.createElement(n);return n.indexOf("-")>-1?br[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:br[n]=/HTMLUnknownElement/.test(e.toString())},B(Wt.options.directives,Hi),B(Wt.options.components,to),Wt.prototype.__patch__=Q?Oi:j,Wt.prototype.$mount=function(n,e){return function(n,e,t){var r;n.$el=e,n.$options.render||(n.$options.render=vn),tt(n,"beforeMount"),r=function(){n._update(n._render(),t)},new Ge(n,r,j,{before:function(){n._isMounted&&!n._isDestroyed&&tt(n,"beforeUpdate")}},!0),t=!1;var i=n._preWatchers;if(i)for(var o=0;o<i.length;o++)i[o].run();return null==n.$vnode&&(n._isMounted=!0,tt(n,"mounted")),n}(this,n=n&&Q?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},Q&&setTimeout((function(){H.devtools&&cn&&cn.emit("init",Wt)}),0);var io=/[!'()*]/g,oo=function(n){return"%"+n.charCodeAt(0).toString(16)},ao=/%2C/g,so=function(n){return encodeURIComponent(n).replace(io,oo).replace(ao,",")};function lo(n){try{return decodeURIComponent(n)}catch(n){0}return n}var co=function(n){return null==n||"object"==typeof n?n:String(n)};function uo(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=lo(t.shift()),i=t.length>0?lo(t.join("=")):null;void 0===e[r]?e[r]=i:Array.isArray(e[r])?e[r].push(i):e[r]=[e[r],i]})),e):e}function ho(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return so(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push(so(e)):r.push(so(e)+"="+so(n)))})),r.join("&")}return so(e)+"="+so(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var po=/\/?$/;function fo(n,e,t,r){var i=r&&r.options.stringifyQuery,o=e.query||{};try{o=mo(o)}catch(n){}var a={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:o,params:e.params||{},fullPath:yo(e,i),matched:n?go(n):[]};return t&&(a.redirectedFrom=yo(t,i)),Object.freeze(a)}function mo(n){if(Array.isArray(n))return n.map(mo);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=mo(n[t]);return e}return n}var vo=fo(null,{path:"/"});function go(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function yo(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var i=n.hash;return void 0===i&&(i=""),(t||"/")+(e||ho)(r)+i}function bo(n,e,t){return e===vo?n===e:!!e&&(n.path&&e.path?n.path.replace(po,"")===e.path.replace(po,"")&&(t||n.hash===e.hash&&ko(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&ko(n.query,e.query)&&ko(n.params,e.params))))}function ko(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,i){var o=n[t];if(r[i]!==t)return!1;var a=e[t];return null==o||null==a?o===a:"object"==typeof o&&"object"==typeof a?ko(o,a):String(o)===String(a)}))}function _o(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var i=t.instances[r],o=t.enteredCbs[r];if(i&&o){delete t.enteredCbs[r];for(var a=0;a<o.length;a++)i._isBeingDestroyed||o[a](i)}}}}var xo={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,i=e.parent,o=e.data;o.routerView=!0;for(var a=i.$createElement,s=t.name,l=i.$route,c=i._routerViewCache||(i._routerViewCache={}),u=0,d=!1;i&&i._routerRoot!==i;){var h=i.$vnode?i.$vnode.data:{};h.routerView&&u++,h.keepAlive&&i._directInactive&&i._inactive&&(d=!0),i=i.$parent}if(o.routerViewDepth=u,d){var p=c[s],f=p&&p.component;return f?(p.configProps&&Eo(f,o,p.route,p.configProps),a(f,o,r)):a()}var m=l.matched[u],v=m&&m.components[s];if(!m||!v)return c[s]=null,a();c[s]={component:v},o.registerRouteInstance=function(n,e){var t=m.instances[s];(e&&t!==n||!e&&t===n)&&(m.instances[s]=e)},(o.hook||(o.hook={})).prepatch=function(n,e){m.instances[s]=e.componentInstance},o.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==m.instances[s]&&(m.instances[s]=n.componentInstance),_o(l)};var g=m.props&&m.props[s];return g&&(ro(c[s],{route:l,configProps:g}),Eo(v,o,l,g)),a(v,o,r)}};function Eo(n,e,t,r){var i=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(i){i=e.props=ro({},i);var o=e.attrs=e.attrs||{};for(var a in i)n.props&&a in n.props||(o[a]=i[a],delete i[a])}}function wo(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var i=e.split("/");t&&i[i.length-1]||i.pop();for(var o=n.replace(/^\//,"").split("/"),a=0;a<o.length;a++){var s=o[a];".."===s?i.pop():"."!==s&&i.push(s)}return""!==i[0]&&i.unshift(""),i.join("/")}function To(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var Ao=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},Co=Fo,Lo=Bo,So=function(n,e){return jo(Bo(n,e),e)},Ro=jo,Io=No,zo=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function Bo(n,e){for(var t,r=[],i=0,o=0,a="",s=e&&e.delimiter||"/";null!=(t=zo.exec(n));){var l=t[0],c=t[1],u=t.index;if(a+=n.slice(o,u),o=u+l.length,c)a+=c[1];else{var d=n[o],h=t[2],p=t[3],f=t[4],m=t[5],v=t[6],g=t[7];a&&(r.push(a),a="");var y=null!=h&&null!=d&&d!==h,b="+"===v||"*"===v,k="?"===v||"*"===v,_=t[2]||s,x=f||m;r.push({name:p||i++,prefix:h||"",delimiter:_,optional:k,repeat:b,partial:y,asterisk:!!g,pattern:x?Po(x):g?".*":"[^"+Uo(_)+"]+?"})}}return o<n.length&&(a+=n.substr(o)),a&&r.push(a),r}function Oo(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function jo(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",Mo(e)));return function(e,r){for(var i="",o=e||{},a=(r||{}).pretty?Oo:encodeURIComponent,s=0;s<n.length;s++){var l=n[s];if("string"!=typeof l){var c,u=o[l.name];if(null==u){if(l.optional){l.partial&&(i+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(Ao(u)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(u)+"`");if(0===u.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var d=0;d<u.length;d++){if(c=a(u[d]),!t[s].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");i+=(0===d?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(u).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):a(u),!t[s].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');i+=l.prefix+c}}else i+=l}return i}}function Uo(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function Po(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function Do(n,e){return n.keys=e,n}function Mo(n){return n&&n.sensitive?"":"i"}function No(n,e,t){Ao(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,i=!1!==t.end,o="",a=0;a<n.length;a++){var s=n[a];if("string"==typeof s)o+=Uo(s);else{var l=Uo(s.prefix),c="(?:"+s.pattern+")";e.push(s),s.repeat&&(c+="(?:"+l+c+")*"),o+=c=s.optional?s.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var u=Uo(t.delimiter||"/"),d=o.slice(-u.length)===u;return r||(o=(d?o.slice(0,-u.length):o)+"(?:"+u+"(?=$))?"),o+=i?"$":r&&d?"":"(?="+u+"|$)",Do(new RegExp("^"+o,Mo(t)),e)}function Fo(n,e,t){return Ao(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Do(n,e)}(n,e):Ao(n)?function(n,e,t){for(var r=[],i=0;i<n.length;i++)r.push(Fo(n[i],e,t).source);return Do(new RegExp("(?:"+r.join("|")+")",Mo(t)),e)}(n,e,t):function(n,e,t){return No(Bo(n,t),e,t)}(n,e,t)}Co.parse=Lo,Co.compile=So,Co.tokensToFunction=Ro,Co.tokensToRegExp=Io;var $o=Object.create(null);function qo(n,e,t){e=e||{};try{var r=$o[n]||($o[n]=Co.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function Ho(n,e,t,r){var i="string"==typeof n?{path:n}:n;if(i._normalized)return i;if(i.name){var o=(i=ro({},n)).params;return o&&"object"==typeof o&&(i.params=ro({},o)),i}if(!i.path&&i.params&&e){(i=ro({},i))._normalized=!0;var a=ro(ro({},e.params),i.params);if(e.name)i.name=e.name,i.params=a;else if(e.matched.length){var s=e.matched[e.matched.length-1].path;i.path=qo(s,a,e.path)}else 0;return i}var l=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var i=n.indexOf("?");return i>=0&&(t=n.slice(i+1),n=n.slice(0,i)),{path:n,query:t,hash:e}}(i.path||""),c=e&&e.path||"/",u=l.path?wo(l.path,c,t||i.append):c,d=function(n,e,t){void 0===e&&(e={});var r,i=t||uo;try{r=i(n||"")}catch(n){r={}}for(var o in e){var a=e[o];r[o]=Array.isArray(a)?a.map(co):co(a)}return r}(l.query,i.query,r&&r.options.parseQuery),h=i.hash||l.hash;return h&&"#"!==h.charAt(0)&&(h="#"+h),{_normalized:!0,path:u,query:d,hash:h}}var Ko,Vo=function(){},Go={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,i=t.resolve(this.to,r,this.append),o=i.location,a=i.route,s=i.href,l={},c=t.options.linkActiveClass,u=t.options.linkExactActiveClass,d=null==c?"router-link-active":c,h=null==u?"router-link-exact-active":u,p=null==this.activeClass?d:this.activeClass,f=null==this.exactActiveClass?h:this.exactActiveClass,m=a.redirectedFrom?fo(null,Ho(a.redirectedFrom),null,t):a;l[f]=bo(r,m,this.exactPath),l[p]=this.exact||this.exactPath?l[f]:function(n,e){return 0===n.path.replace(po,"/").indexOf(e.path.replace(po,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,m);var v=l[f]?this.ariaCurrentValue:null,g=function(n){Wo(n)&&(e.replace?t.replace(o,Vo):t.push(o,Vo))},y={click:Wo};Array.isArray(this.event)?this.event.forEach((function(n){y[n]=g})):y[this.event]=g;var b={class:l},k=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:s,route:a,navigate:g,isActive:l[p],isExactActive:l[f]});if(k){if(1===k.length)return k[0];if(k.length>1||!k.length)return 0===k.length?n():n("span",{},k)}if("a"===this.tag)b.on=y,b.attrs={href:s,"aria-current":v};else{var _=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(_){_.isStatic=!1;var x=_.data=ro({},_.data);for(var E in x.on=x.on||{},x.on){var w=x.on[E];E in y&&(x.on[E]=Array.isArray(w)?w:[w])}for(var T in y)T in x.on?x.on[T].push(y[T]):x.on[T]=g;var A=_.data.attrs=ro({},_.data.attrs);A.href=s,A["aria-current"]=v}else b.on=y}return n(this.tag,b,this.$slots.default)}};function Wo(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Xo="undefined"!=typeof window;function Qo(n,e,t,r,i){var o=e||[],a=t||Object.create(null),s=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,i,o,a){var s=i.path,l=i.name;0;var c=i.pathToRegexpOptions||{},u=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return To(e.path+"/"+n)}(s,o,c.strict);"boolean"==typeof i.caseSensitive&&(c.sensitive=i.caseSensitive);var d={path:u,regex:Zo(u,c),components:i.components||{default:i.component},alias:i.alias?"string"==typeof i.alias?[i.alias]:i.alias:[],instances:{},enteredCbs:{},name:l,parent:o,matchAs:a,redirect:i.redirect,beforeEnter:i.beforeEnter,meta:i.meta||{},props:null==i.props?{}:i.components?i.props:{default:i.props}};i.children&&i.children.forEach((function(i){var o=a?To(a+"/"+i.path):void 0;n(e,t,r,i,d,o)}));t[d.path]||(e.push(d.path),t[d.path]=d);if(void 0!==i.alias)for(var h=Array.isArray(i.alias)?i.alias:[i.alias],p=0;p<h.length;++p){0;var f={path:h[p],children:i.children};n(e,t,r,f,o,d.path||"/")}l&&(r[l]||(r[l]=d))}(o,a,s,n,i)}));for(var l=0,c=o.length;l<c;l++)"*"===o[l]&&(o.push(o.splice(l,1)[0]),c--,l--);return{pathList:o,pathMap:a,nameMap:s}}function Zo(n,e){return Co(n,[],e)}function Yo(n,e){var t=Qo(n),r=t.pathList,i=t.pathMap,o=t.nameMap;function a(n,t,a){var s=Ho(n,t,!1,e),c=s.name;if(c){var u=o[c];if(!u)return l(null,s);var d=u.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var h in t.params)!(h in s.params)&&d.indexOf(h)>-1&&(s.params[h]=t.params[h]);return s.path=qo(u.path,s.params),l(u,s,a)}if(s.path){s.params={};for(var p=0;p<r.length;p++){var f=r[p],m=i[f];if(Jo(m.regex,s.path,s.params))return l(m,s,a)}}return l(null,s)}function s(n,t){var r=n.redirect,i="function"==typeof r?r(fo(n,t,null,e)):r;if("string"==typeof i&&(i={path:i}),!i||"object"!=typeof i)return l(null,t);var s=i,c=s.name,u=s.path,d=t.query,h=t.hash,p=t.params;if(d=s.hasOwnProperty("query")?s.query:d,h=s.hasOwnProperty("hash")?s.hash:h,p=s.hasOwnProperty("params")?s.params:p,c){o[c];return a({_normalized:!0,name:c,query:d,hash:h,params:p},void 0,t)}if(u){var f=function(n,e){return wo(n,e.parent?e.parent.path:"/",!0)}(u,n);return a({_normalized:!0,path:qo(f,p),query:d,hash:h},void 0,t)}return l(null,t)}function l(n,t,r){return n&&n.redirect?s(n,r||t):n&&n.matchAs?function(n,e,t){var r=a({_normalized:!0,path:qo(t,e.params)});if(r){var i=r.matched,o=i[i.length-1];return e.params=r.params,l(o,e)}return l(null,e)}(0,t,n.matchAs):fo(n,t,r,e)}return{match:a,addRoute:function(n,e){var t="object"!=typeof n?o[n]:void 0;Qo([e||n],r,i,o,t),t&&t.alias.length&&Qo(t.alias.map((function(n){return{path:n,children:[e]}})),r,i,o,t)},getRoutes:function(){return r.map((function(n){return i[n]}))},addRoutes:function(n){Qo(n,r,i,o)}}}function Jo(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var i=1,o=r.length;i<o;++i){var a=n.keys[i-1];a&&(t[a.name||"pathMatch"]="string"==typeof r[i]?lo(r[i]):r[i])}return!0}var na=Xo&&window.performance&&window.performance.now?window.performance:Date;function ea(){return na.now().toFixed(3)}var ta=ea();function ra(){return ta}function ia(n){return ta=n}var oa=Object.create(null);function aa(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=ro({},window.history.state);return t.key=ra(),window.history.replaceState(t,"",e),window.addEventListener("popstate",ca),function(){window.removeEventListener("popstate",ca)}}function sa(n,e,t,r){if(n.app){var i=n.options.scrollBehavior;i&&n.app.$nextTick((function(){var o=function(){var n=ra();if(n)return oa[n]}(),a=i.call(n,e,t,r?o:null);a&&("function"==typeof a.then?a.then((function(n){fa(n,o)})).catch((function(n){0})):fa(a,o))}))}}function la(){var n=ra();n&&(oa[n]={x:window.pageXOffset,y:window.pageYOffset})}function ca(n){la(),n.state&&n.state.key&&ia(n.state.key)}function ua(n){return ha(n.x)||ha(n.y)}function da(n){return{x:ha(n.x)?n.x:window.pageXOffset,y:ha(n.y)?n.y:window.pageYOffset}}function ha(n){return"number"==typeof n}var pa=/^#\d/;function fa(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var i=pa.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(i){var o=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(i,o={x:ha((t=o).x)?t.x:0,y:ha(t.y)?t.y:0})}else ua(n)&&(e=da(n))}else r&&ua(n)&&(e=da(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var ma,va=Xo&&((-1===(ma=window.navigator.userAgent).indexOf("Android 2.")&&-1===ma.indexOf("Android 4.0")||-1===ma.indexOf("Mobile Safari")||-1!==ma.indexOf("Chrome")||-1!==ma.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function ga(n,e){la();var t=window.history;try{if(e){var r=ro({},t.state);r.key=ra(),t.replaceState(r,"",n)}else t.pushState({key:ia(ea())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function ya(n){ga(n,!0)}var ba={redirected:2,aborted:4,cancelled:8,duplicated:16};function ka(n,e){return xa(n,e,ba.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return Ea.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function _a(n,e){return xa(n,e,ba.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function xa(n,e,t,r){var i=new Error(r);return i._isRouter=!0,i.from=n,i.to=e,i.type=t,i}var Ea=["params","query","hash"];function wa(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function Ta(n,e){return wa(n)&&n._isRouter&&(null==e||n.type===e)}function Aa(n,e,t){var r=function(i){i>=n.length?t():n[i]?e(n[i],(function(){r(i+1)})):r(i+1)};r(0)}function Ca(n){return function(e,t,r){var i=!1,o=0,a=null;La(n,(function(n,e,t,s){if("function"==typeof n&&void 0===n.cid){i=!0,o++;var l,c=Ia((function(e){var i;((i=e).__esModule||Ra&&"Module"===i[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:Ko.extend(e),t.components[s]=e,--o<=0&&r()})),u=Ia((function(n){var e="Failed to resolve async component "+s+": "+n;a||(a=wa(n)?n:new Error(e),r(a))}));try{l=n(c,u)}catch(n){u(n)}if(l)if("function"==typeof l.then)l.then(c,u);else{var d=l.component;d&&"function"==typeof d.then&&d.then(c,u)}}})),i||r()}}function La(n,e){return Sa(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function Sa(n){return Array.prototype.concat.apply([],n)}var Ra="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Ia(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var za=function(n,e){this.router=n,this.base=function(n){if(!n)if(Xo){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=vo,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Ba(n,e,t,r){var i=La(n,(function(n,r,i,o){var a=function(n,e){"function"!=typeof n&&(n=Ko.extend(n));return n.options[e]}(n,e);if(a)return Array.isArray(a)?a.map((function(n){return t(n,r,i,o)})):t(a,r,i,o)}));return Sa(r?i.reverse():i)}function Oa(n,e){if(e)return function(){return n.apply(e,arguments)}}za.prototype.listen=function(n){this.cb=n},za.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},za.prototype.onError=function(n){this.errorCbs.push(n)},za.prototype.transitionTo=function(n,e,t){var r,i=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var o=this.current;this.confirmTransition(r,(function(){i.updateRoute(r),e&&e(r),i.ensureURL(),i.router.afterHooks.forEach((function(n){n&&n(r,o)})),i.ready||(i.ready=!0,i.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!i.ready&&(Ta(n,ba.redirected)&&o===vo||(i.ready=!0,i.readyErrorCbs.forEach((function(e){e(n)}))))}))},za.prototype.confirmTransition=function(n,e,t){var r=this,i=this.current;this.pending=n;var o,a,s=function(n){!Ta(n)&&wa(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},l=n.matched.length-1,c=i.matched.length-1;if(bo(n,i)&&l===c&&n.matched[l]===i.matched[c])return this.ensureURL(),n.hash&&sa(this.router,i,n,!1),s(((a=xa(o=i,n,ba.duplicated,'Avoided redundant navigation to current location: "'+o.fullPath+'".')).name="NavigationDuplicated",a));var u=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),d=u.updated,h=u.deactivated,p=u.activated,f=[].concat(function(n){return Ba(n,"beforeRouteLeave",Oa,!0)}(h),this.router.beforeHooks,function(n){return Ba(n,"beforeRouteUpdate",Oa)}(d),p.map((function(n){return n.beforeEnter})),Ca(p)),m=function(e,t){if(r.pending!==n)return s(_a(i,n));try{e(n,i,(function(e){!1===e?(r.ensureURL(!0),s(function(n,e){return xa(n,e,ba.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(i,n))):wa(e)?(r.ensureURL(!0),s(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(s(ka(i,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){s(n)}};Aa(f,m,(function(){Aa(function(n){return Ba(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,i,o){return n(r,i,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),o(n)}))}}(n,t,r)}))}(p).concat(r.router.resolveHooks),m,(function(){if(r.pending!==n)return s(_a(i,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){_o(n)}))}))}))},za.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},za.prototype.setupListeners=function(){},za.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=vo,this.pending=null};var ja=function(n){function e(e,t){n.call(this,e,t),this._startLocation=Ua(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=va&&t;r&&this.listeners.push(aa());var i=function(){var t=n.current,i=Ua(n.base);n.current===vo&&i===n._startLocation||n.transitionTo(i,(function(n){r&&sa(e,n,t,!0)}))};window.addEventListener("popstate",i),this.listeners.push((function(){window.removeEventListener("popstate",i)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,i=this.current;this.transitionTo(n,(function(n){ga(To(r.base+n.fullPath)),sa(r.router,n,i,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,i=this.current;this.transitionTo(n,(function(n){ya(To(r.base+n.fullPath)),sa(r.router,n,i,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(Ua(this.base)!==this.current.fullPath){var e=To(this.base+this.current.fullPath);n?ga(e):ya(e)}},e.prototype.getCurrentLocation=function(){return Ua(this.base)},e}(za);function Ua(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(To(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var Pa=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=Ua(n);if(!/^\/#/.test(e))return window.location.replace(To(n+"/#"+e)),!0}(this.base)||Da()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=va&&e;t&&this.listeners.push(aa());var r=function(){var e=n.current;Da()&&n.transitionTo(Ma(),(function(r){t&&sa(n.router,r,e,!0),va||$a(r.fullPath)}))},i=va?"popstate":"hashchange";window.addEventListener(i,r),this.listeners.push((function(){window.removeEventListener(i,r)}))}},e.prototype.push=function(n,e,t){var r=this,i=this.current;this.transitionTo(n,(function(n){Fa(n.fullPath),sa(r.router,n,i,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,i=this.current;this.transitionTo(n,(function(n){$a(n.fullPath),sa(r.router,n,i,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Ma()!==e&&(n?Fa(e):$a(e))},e.prototype.getCurrentLocation=function(){return Ma()},e}(za);function Da(){var n=Ma();return"/"===n.charAt(0)||($a("/"+n),!1)}function Ma(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function Na(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function Fa(n){va?ga(Na(n)):window.location.hash=n}function $a(n){va?ya(Na(n)):window.location.replace(Na(n))}var qa=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){Ta(n,ba.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(za),Ha=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Yo(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!va&&!1!==n.fallback,this.fallback&&(e="hash"),Xo||(e="abstract"),this.mode=e,e){case"history":this.history=new ja(this,n.base);break;case"hash":this.history=new Pa(this,n.base,this.fallback);break;case"abstract":this.history=new qa(this,n.base);break;default:0}},Ka={currentRoute:{configurable:!0}};Ha.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},Ka.currentRoute.get=function(){return this.history&&this.history.current},Ha.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof ja||t instanceof Pa){var r=function(n){t.setupListeners(),function(n){var r=t.current,i=e.options.scrollBehavior;va&&i&&"fullPath"in n&&sa(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Ha.prototype.beforeEach=function(n){return Ga(this.beforeHooks,n)},Ha.prototype.beforeResolve=function(n){return Ga(this.resolveHooks,n)},Ha.prototype.afterEach=function(n){return Ga(this.afterHooks,n)},Ha.prototype.onReady=function(n,e){this.history.onReady(n,e)},Ha.prototype.onError=function(n){this.history.onError(n)},Ha.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},Ha.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},Ha.prototype.go=function(n){this.history.go(n)},Ha.prototype.back=function(){this.go(-1)},Ha.prototype.forward=function(){this.go(1)},Ha.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Ha.prototype.resolve=function(n,e,t){var r=Ho(n,e=e||this.history.current,t,this),i=this.match(r,e),o=i.redirectedFrom||i.fullPath;return{location:r,route:i,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?To(n+"/"+r):r}(this.history.base,o,this.mode),normalizedTo:r,resolved:i}},Ha.prototype.getRoutes=function(){return this.matcher.getRoutes()},Ha.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==vo&&this.history.transitionTo(this.history.getCurrentLocation())},Ha.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==vo&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Ha.prototype,Ka);var Va=Ha;function Ga(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Ha.install=function n(e){if(!n.installed||Ko!==e){n.installed=!0,Ko=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",xo),e.component("RouterLink",Go);var i=e.config.optionMergeStrategies;i.beforeRouteEnter=i.beforeRouteLeave=i.beforeRouteUpdate=i.created}},Ha.version="3.6.5",Ha.isNavigationFailure=Ta,Ha.NavigationFailureType=ba,Ha.START_LOCATION=vo,Xo&&window.Vue&&window.Vue.use(Ha);t(107);t(129),t(16);var Wa={NotFound:()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,335)),Layout:()=>Promise.all([t.e(0),t.e(2)]).then(t.bind(null,334))},Xa={"v-14d5b00e":()=>t.e(5).then(t.bind(null,336)),"v-6f4636bc":()=>t.e(6).then(t.bind(null,337)),"v-30a03cb6":()=>t.e(7).then(t.bind(null,338)),"v-be411e82":()=>t.e(8).then(t.bind(null,339)),"v-24d5fda5":()=>t.e(9).then(t.bind(null,340)),"v-67babc0e":()=>t.e(10).then(t.bind(null,341)),"v-6e4553fe":()=>t.e(11).then(t.bind(null,342)),"v-fb7b08d2":()=>t.e(12).then(t.bind(null,343)),"v-d89ce0de":()=>t.e(13).then(t.bind(null,344)),"v-53a35b2a":()=>t.e(14).then(t.bind(null,345)),"v-768b02c9":()=>t.e(15).then(t.bind(null,346)),"v-4c0a6dfc":()=>t.e(16).then(t.bind(null,347)),"v-cb82a926":()=>t.e(19).then(t.bind(null,348)),"v-31813d8e":()=>t.e(20).then(t.bind(null,349)),"v-08ebe39c":()=>t.e(21).then(t.bind(null,350)),"v-293e6008":()=>t.e(22).then(t.bind(null,351)),"v-bc60cd96":()=>t.e(17).then(t.bind(null,352)),"v-025c760c":()=>t.e(23).then(t.bind(null,353)),"v-ded3b0dc":()=>t.e(24).then(t.bind(null,354)),"v-415197ac":()=>t.e(25).then(t.bind(null,355)),"v-2432b466":()=>t.e(26).then(t.bind(null,356)),"v-b8b11d74":()=>t.e(18).then(t.bind(null,357)),"v-04b7b9e3":()=>t.e(27).then(t.bind(null,358)),"v-6d729576":()=>t.e(28).then(t.bind(null,359)),"v-352bf426":()=>t.e(30).then(t.bind(null,360)),"v-5dd3d42a":()=>t.e(29).then(t.bind(null,361)),"v-1c3f7e81":()=>t.e(31).then(t.bind(null,362)),"v-03654e78":()=>t.e(32).then(t.bind(null,363)),"v-52fa84a6":()=>t.e(33).then(t.bind(null,364)),"v-61d0fb85":()=>t.e(36).then(t.bind(null,365)),"v-7604068d":()=>t.e(34).then(t.bind(null,366)),"v-5c2bcd3a":()=>t.e(35).then(t.bind(null,367)),"v-a11d1cc4":()=>t.e(37).then(t.bind(null,368))};function Qa(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Za=/-(\w)/g,Ya=Qa(n=>n.replace(Za,(n,e)=>e?e.toUpperCase():"")),Ja=/\B([A-Z])/g,ns=Qa(n=>n.replace(Ja,"-$1").toLowerCase()),es=Qa(n=>n.charAt(0).toUpperCase()+n.slice(1));function ts(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(es(Ya(e))):n(es(e))||n(ns(e))}const rs=Object.assign({},Wa,Xa),is=n=>rs[n],os=n=>Xa[n],as=n=>Wa[n],ss=n=>Wt.component(n);function ls(n){return ts(os,n)}function cs(n){return ts(as,n)}function us(n){return ts(is,n)}function ds(n){return ts(ss,n)}function hs(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!ds(n)&&us(n)){const e=await us(n)();Wt.component(n,e.default)}}))}function ps(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var fs=t(92),ms=t.n(fs),vs=t(93),gs=t.n(vs),ys={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${gs()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=ks(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=_s(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return ms()([{name:"description",content:this.$description}],n,this.siteMeta,xs)},updateCanonicalLink(){bs(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",ks(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){_s(null,this.currentMetaTags),bs()}};function bs(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function ks(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function _s(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function xs(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}var Es=t(51),ws={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(Es)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),r=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),i=window.innerHeight+t;for(let n=0;n<e.length;n++){const o=e[n],a=e[n+1],s=0===n&&0===t||t>=o.parentElement.offsetTop+10&&(!a||t<a.parentElement.offsetTop-10),l=decodeURIComponent(this.$route.hash);if(s&&l!==decodeURIComponent(o.hash)){const t=o;if(i===r)for(let t=n+1;t<e.length;t++)if(l===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},Ts=t(24),As=t.n(Ts),Cs={mounted(){As.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||Wt.component(n.name)||As.a.start(),t()}),this.$router.afterEach(()=>{As.a.done(),this.isSidebarOpen=!1})}},Ls=t(94),Ss={noCopy:!0,noSelect:!1,disabled:!1,minLength:100,authorName:""},Rs={props:{html:String,lang:String},created(){this.authorName="string"==typeof Ss.authorName?Ss.authorName:this.getI18nValue(Ss.authorName),this.text=this.getI18nValue(Ls),this.location=String(location).replace(/#.+$/,"")},methods:{getI18nValue(n){return this.lang in n?n[this.lang]:n["en-US"]}}},Is=t(4),zs=Object(Is.a)(Rs,(function(){var n=this,e=n._self._c;return e("div",[e("p",[n._v(n._s(n.text.beforeAuthor)+n._s(n.authorName||n.text.author)+n._s(n.text.afterAuthor)),e("a",{attrs:{href:n.location}},[n._v(n._s(decodeURIComponent(n.location)))])]),n._v("\n\n"),e("div",{domProps:{innerHTML:n._s(n.html)}})])}),[],!1,null,null,null).exports,Bs={data:()=>({isElement:!1}),created(){this.onCopy=n=>{const e=getSelection().getRangeAt(0);if(String(e).length<this.minLength)return;if(n.preventDefault(),this.noCopy)return;const t=document.createElement("div");t.appendChild(getSelection().getRangeAt(0).cloneContents());const r=this.$lang,i=new Wt({render:n=>n(zs,{props:{html:t.innerHTML,lang:r}})}).$mount(),{innerHTML:o,innerText:a}=i.$el;n.clipboardData?(n.clipboardData.setData("text/html",o),n.clipboardData.setData("text/plain",a)):window.clipboardData&&window.clipboardData.setData("text",a)}},watch:{isElement(n){if(!n)return;let{copyright:e=!Ss.disabled}=this.$frontmatter;if(!e)return;"object"!=typeof e&&(e={});const t=e.noSelect||Ss.noSelect;this.minLength=e.minLength||Ss.minLength,this.noCopy=e.noCopy||Ss.noCopy,t?this.$el.style.userSelect="none":this.$el.addEventListener("copy",this.onCopy)}},updated(){this.isElement="#comment"!==this.$el.nodeName},beforeDestory(){this.$el.removeEventListener("copy",this.onCopy)}};t(241),t(242);class Os{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var js={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new Os).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var r=document.head||document.getElementsByTagName("head")[0],i=document.createElement("style");i.type="text/css","top"===t&&r.firstChild?r.insertBefore(i,r.firstChild):r.appendChild(i),i.styleSheet?i.styleSheet.cssText=n:i.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var Us={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Ps={},Ds=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},Ms=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:Us[n]},Ns=function n(e,t,r){var i=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))i[n]=t[n];else{var e=n.replace("data","");i.dataset[e]=t[n]}})),r&&r.forEach((function(e){var t=e.tag,r=e.attrs,o=e.children;i.appendChild(n(t,r,o))})),i},Fs=function(n,e,t){var r,i=(r=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(r));return 1!==i.length||t?i:i[0]},$s=function(n,e){var t,r,i=n.match(/<style>([\s\S]+)<\/style>/),o=n.match(/<template>([\s\S]+)<\/template>/),a=n.match(/<script>([\s\S]+)<\/script>/),s={css:i&&i[1].replace(/^\n|\n$/g,""),html:o&&o[1].replace(/^\n|\n$/g,""),js:a&&a[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};s.htmlTpl=Ds(s.html),s.jsTpl=(t=s.js,r=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(r,"\n})")),s.script=function(n,e){var t=n.split(/export\s+default/),r="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),i=window.Babel?window.Babel.transform(r,{presets:["es2015"]}).code:r,o=[eval][0](i);return o.template=e,o}(s.js,s.html);var l=Ms("vue");return s.jsLib.unshift(l),s},qs=function(n,e){var t,r=n.match(/<style>([\s\S]+)<\/style>/),i=n.match(/<html>([\s\S]+)<\/html>/),o=n.match(/<script>([\s\S]+)<\/script>/),a={css:r&&r[1].replace(/^\n|\n$/g,""),html:i&&i[1].replace(/^\n|\n$/g,""),js:o&&o[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return a.htmlTpl=a.html,a.jsTpl=a.js,a.script=(t=a.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),a},Hs=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function Ks(){var n=Fs(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=Fs(n,"vuepress-plugin-demo-block__code"),t=Fs(n,"vuepress-plugin-demo-block__display"),r=Fs(n,"vuepress-plugin-demo-block__footer"),i=Fs(t,"vuepress-plugin-demo-block__app"),o=decodeURIComponent(n.dataset.code),a=decodeURIComponent(n.dataset.config),s=decodeURIComponent(n.dataset.type);a=a?JSON.parse(a):{};var l=e.querySelector("div").clientHeight,c="react"===s?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,r="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),i=new Function("return ".concat(r))(),o={js:i,css:i.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:Hs(n),htmlTpl:Ds("")},a=Ms("react"),s=Ms("reactDOM");return o.jsLib.unshift(a,s),o}(o,a):"vanilla"===s?qs(o,a):$s(o,a),u=Ns("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(r.appendChild(u),u.addEventListener("click",Vs.bind(null,u,l,e,r)),Ms("jsfiddle")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,i=n.jsLib,o=n.cssLib,a=i.concat(o).concat(Ms("cssLib")).concat(Ms("jsLib")).join(",");return Ns("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:r}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:a}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(c)),Ms("codepen")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,i=n.jsLib,o=n.cssLib,a=JSON.stringify({css:e,html:t,js:r,js_external:i.concat(Ms("jsLib")).join(";"),css_external:o.concat(Ms("cssLib")).join(";"),layout:Ms("codepenLayout"),js_pre_processor:Ms("codepenJsProcessor"),editors:Ms("codepenEditors")});return Ns("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:a}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(c)),void 0!==a.horizontal?a.horizontal:Ms("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var d=e.firstChild.cloneNode(!0);d.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(d)}if(c.css&&function(n){if(!Ps[n]){var e=Ns("style",{innerHTML:n});document.body.appendChild(e),Ps[n]=!0}}(c.css),"react"===s)ReactDOM.render(React.createElement(c.js),i);else if("vue"===s){var h=(new(Vue.extend(c.script))).$mount();i.appendChild(h.$el)}else"vanilla"===s&&(i.innerHTML=c.html,new Function("return (function(){".concat(c.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){Ks()}),300)}function Vs(n,e,t,r){var i="1"!==n.dataset.isExpand;t.style.height=i?"".concat(e,"px"):0,i?r.classList.add("vuepress-plugin-demo-block__show-link"):r.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=i?"1":"0"}var Gs={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},Ks()},updated:function(){Ks()}},Ws="auto",Xs="zoom-in",Qs="zoom-out",Zs="grab",Ys="move";function Js(n,e,t){var r=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],i={passive:!1};r?n.addEventListener(e,t,i):n.removeEventListener(e,t,i)}function nl(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function el(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function tl(n,e,t){!function(n){var e=rl,t=il;if(n.transition){var r=n.transition;delete n.transition,n[e]=r}if(n.transform){var i=n.transform;delete n.transform,n[t]=i}}(e);var r=n.style,i={};for(var o in e)t&&(i[o]=r[o]||""),r[o]=e[o];return i}var rl="transition",il="transform",ol="transform",al="transitionend";var sl=function(){},ll={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:sl,onClose:sl,onGrab:sl,onMove:sl,onRelease:sl,onBeforeOpen:sl,onBeforeClose:sl,onBeforeGrab:sl,onBeforeRelease:sl,onImageLoading:sl,onImageLoaded:sl},cl={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),dl(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var r=this.lastScrollPosition.x-e,i=this.lastScrollPosition.y-t,o=this.options.scrollThreshold;(Math.abs(i)>=o||Math.abs(r)>=o)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(ul(n)&&!dl(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){ul(n)&&!dl(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,r=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,r)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,r=e.clientY;this.move(t,r)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function ul(n){return 0===n.button}function dl(n){return n.metaKey||n.ctrlKey}var hl={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,tl(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Js(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){tl(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},pl="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},fl=function(){function n(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}return function(e,t,r){return t&&n(e.prototype,t),r&&n(e,r),e}}(),ml=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(n[r]=t[r])}return n},vl={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=el(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,r=n.transitionDuration,i=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Zs:Qs,transition:ol+"\n        "+r+"s\n        "+i,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=tl(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,tl(this.el,{transform:"none"})},grab:function(n,e,t){var r=gl(),i=r.x-n,o=r.y-e;tl(this.el,{cursor:Ys,transform:"translate3d(\n        "+(this.translate.x+i)+"px, "+(this.translate.y+o)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var r=gl(),i=r.x-n,o=r.y-e;tl(this.el,{transition:ol,transform:"translate3d(\n        "+(this.translate.x+i)+"px, "+(this.translate.y+o)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){tl(this.el,this.styleClose)},restoreOpenStyle:function(){tl(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=gl(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,r=this.instance.options,i=r.customSize,o=r.scaleBase;if(!i&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(i&&"object"===(void 0===i?"undefined":pl(i)))return{x:i.width/this.rect.width,y:i.height/this.rect.height};var a=this.rect.width/2,s=this.rect.height/2,l=gl(),c={x:l.x-a,y:l.y-s},u=c.x/a,d=c.y/s,h=o+Math.min(u,d);if(i&&"string"==typeof i){var p=t||this.el.naturalWidth,f=e||this.el.naturalHeight,m=parseFloat(i)*p/(100*this.rect.width),v=parseFloat(i)*f/(100*this.rect.height);if(h>m||h>v)return{x:m,y:v}}return{x:h,y:h}}};function gl(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function yl(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(r){Js(n,r,e[r],t)}))}var bl=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(vl),this.overlay=Object.create(hl),this.handler=Object.create(cl),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=ml({},ll,e),this.overlay.init(this),this.handler.init(this)}return fl(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=Xs,Js(n,"click",this.handler.click),this.options.preloadImage&&nl(el(n)));return this}},{key:"config",value:function(n){return n?(ml(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var r="string"==typeof n?document.querySelector(n):n;if("IMG"===r.tagName){if(this.options.onBeforeOpen(r),this.target.init(r,this),!this.options.preloadImage){var i=this.target.srcOriginal;null!=i&&(this.options.onImageLoading(r),nl(i,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Js(document,"scroll",this.handler.scroll),Js(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Js(window,"resize",this.handler.resizeWindow);var o=function n(){Js(r,al,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&yl(document,e.handler,!0),t(r)};return Js(r,al,o),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Ws,this.overlay.fadeOut(),this.target.zoomOut(),Js(document,"scroll",this.handler.scroll,!1),Js(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Js(window,"resize",this.handler.resizeWindow,!1);var r=function r(){Js(t,al,r,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&yl(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Js(t,al,r),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var i=this.target.el;this.options.onBeforeGrab(i),this.released=!1,this.target.grab(n,e,t);var o=function n(){Js(i,al,n,!1),r(i)};return Js(i,al,o),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=Ys,this.target.move(n,e,t);var i=this.target.el,o=function n(){Js(i,al,n,!1),r(i)};return Js(i,al,o),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Ws,this.target.restoreOpenStyle();var r=function r(){Js(t,al,r,!1),n.lock=!1,n.released=!0,e(t)};return Js(t,al,r),this}}}]),n}();const kl=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),_l=Number("500");class xl{constructor(){this.instance=new bl(kl)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=_l){setTimeout(()=>this.update(n),e)}}var El=[ys,ws,Cs,Bs,js,Gs,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new xl,this.$vuepress.zooming.updateDelay()}}],wl={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return ps("layout",n),Wt.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},Tl=Object(Is.a)(wl,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(Tl,"mixins",El);const Al=[{name:"v-14d5b00e",path:"/pages/fccd91/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-14d5b00e").then(t)}},{path:"/pages/fccd91/index.html",redirect:"/pages/fccd91/"},{path:"/01.系统设计算法/01.系统设计算法/01.布隆过滤.html",redirect:"/pages/fccd91/"},{name:"v-6f4636bc",path:"/pages/1e28a2/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-6f4636bc").then(t)}},{path:"/pages/1e28a2/index.html",redirect:"/pages/1e28a2/"},{path:"/01.系统设计算法/01.系统设计算法/02.一致性哈希.html",redirect:"/pages/1e28a2/"},{name:"v-30a03cb6",path:"/pages/8624c5/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-30a03cb6").then(t)}},{path:"/pages/8624c5/index.html",redirect:"/pages/8624c5/"},{path:"/01.系统设计算法/01.系统设计算法/03.Count-Min Sketch.html",redirect:"/pages/8624c5/"},{name:"v-be411e82",path:"/pages/87589a/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-be411e82").then(t)}},{path:"/pages/87589a/index.html",redirect:"/pages/87589a/"},{path:"/01.系统设计算法/01.系统设计算法/04.LRU.html",redirect:"/pages/87589a/"},{name:"v-24d5fda5",path:"/pages/7d22be/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-24d5fda5").then(t)}},{path:"/pages/7d22be/index.html",redirect:"/pages/7d22be/"},{path:"/01.系统设计算法/01.系统设计算法/05.LFU.html",redirect:"/pages/7d22be/"},{name:"v-67babc0e",path:"/pages/2d43d1/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-67babc0e").then(t)}},{path:"/pages/2d43d1/index.html",redirect:"/pages/2d43d1/"},{path:"/01.系统设计算法/01.系统设计算法/06.渐进式 hash.html",redirect:"/pages/2d43d1/"},{name:"v-6e4553fe",path:"/pages/44dcc2/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-6e4553fe").then(t)}},{path:"/pages/44dcc2/index.html",redirect:"/pages/44dcc2/"},{path:"/01.系统设计算法/01.系统设计算法/10.时间轮.html",redirect:"/pages/44dcc2/"},{name:"v-fb7b08d2",path:"/pages/a95d7d/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-fb7b08d2").then(t)}},{path:"/pages/a95d7d/index.html",redirect:"/pages/a95d7d/"},{path:"/02.设计热门应用/01.社交类/01.设计 微信.html",redirect:"/pages/a95d7d/"},{name:"v-d89ce0de",path:"/pages/90ad66/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-d89ce0de").then(t)}},{path:"/pages/90ad66/index.html",redirect:"/pages/90ad66/"},{path:"/02.设计热门应用/01.社交类/02.设计Twitter.html",redirect:"/pages/90ad66/"},{name:"v-53a35b2a",path:"/pages/def08a/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-53a35b2a").then(t)}},{path:"/pages/def08a/index.html",redirect:"/pages/def08a/"},{path:"/03.经典场景设计/01.热门场景设计/01.双写一致性.html",redirect:"/pages/def08a/"},{name:"v-768b02c9",path:"/pages/1e9e8e/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-768b02c9").then(t)}},{path:"/pages/1e9e8e/index.html",redirect:"/pages/1e9e8e/"},{path:"/03.经典场景设计/01.热门场景设计/02.缓存穿透.html",redirect:"/pages/1e9e8e/"},{name:"v-4c0a6dfc",path:"/pages/1d96b2/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-4c0a6dfc").then(t)}},{path:"/pages/1d96b2/index.html",redirect:"/pages/1d96b2/"},{path:"/03.经典场景设计/01.热门场景设计/03.缓存击穿.html",redirect:"/pages/1d96b2/"},{name:"v-cb82a926",path:"/pages/8a57f2/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-cb82a926").then(t)}},{path:"/pages/8a57f2/index.html",redirect:"/pages/8a57f2/"},{path:"/03.经典场景设计/01.热门场景设计/06.超卖.html",redirect:"/pages/8a57f2/"},{name:"v-31813d8e",path:"/pages/51aa8b/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-31813d8e").then(t)}},{path:"/pages/51aa8b/index.html",redirect:"/pages/51aa8b/"},{path:"/03.经典场景设计/01.热门场景设计/07.多级缓存.html",redirect:"/pages/51aa8b/"},{name:"v-08ebe39c",path:"/pages/0dfb49/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-08ebe39c").then(t)}},{path:"/pages/0dfb49/index.html",redirect:"/pages/0dfb49/"},{path:"/03.经典场景设计/01.热门场景设计/08.超时&重试.html",redirect:"/pages/0dfb49/"},{name:"v-293e6008",path:"/pages/4fc8cb/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-293e6008").then(t)}},{path:"/pages/4fc8cb/index.html",redirect:"/pages/4fc8cb/"},{path:"/03.经典场景设计/01.热门场景设计/09.幂等&防重.html",redirect:"/pages/4fc8cb/"},{name:"v-bc60cd96",path:"/pages/24abe0/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-bc60cd96").then(t)}},{path:"/pages/24abe0/index.html",redirect:"/pages/24abe0/"},{path:"/03.经典场景设计/01.热门场景设计/04.任务补偿.html",redirect:"/pages/24abe0/"},{name:"v-025c760c",path:"/pages/f3295f/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-025c760c").then(t)}},{path:"/pages/f3295f/index.html",redirect:"/pages/f3295f/"},{path:"/03.经典场景设计/01.热门场景设计/10.海量数据计数.html",redirect:"/pages/f3295f/"},{name:"v-ded3b0dc",path:"/pages/6b9d68/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-ded3b0dc").then(t)}},{path:"/pages/6b9d68/index.html",redirect:"/pages/6b9d68/"},{path:"/03.经典场景设计/01.热门场景设计/11.消息未读数系统.html",redirect:"/pages/6b9d68/"},{name:"v-415197ac",path:"/pages/84cb49/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-415197ac").then(t)}},{path:"/pages/84cb49/index.html",redirect:"/pages/84cb49/"},{path:"/04.设计基础设施/01.设计基础设施/01.分布式缓存.html",redirect:"/pages/84cb49/"},{name:"v-2432b466",path:"/pages/57d5a5/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-2432b466").then(t)}},{path:"/pages/57d5a5/index.html",redirect:"/pages/57d5a5/"},{path:"/04.设计基础设施/01.设计基础设施/02.限流器.html",redirect:"/pages/57d5a5/"},{name:"v-b8b11d74",path:"/pages/a72629/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-b8b11d74").then(t)}},{path:"/pages/a72629/index.html",redirect:"/pages/a72629/"},{path:"/03.经典场景设计/01.热门场景设计/05.秒杀.html",redirect:"/pages/a72629/"},{name:"v-04b7b9e3",path:"/pages/5dcb6b/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-04b7b9e3").then(t)}},{path:"/pages/5dcb6b/index.html",redirect:"/pages/5dcb6b/"},{path:"/04.设计基础设施/01.设计基础设施/03.热点探查（Top k）.html",redirect:"/pages/5dcb6b/"},{name:"v-6d729576",path:"/pages/567090/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-6d729576").then(t)}},{path:"/pages/567090/index.html",redirect:"/pages/567090/"},{path:"/04.设计基础设施/01.设计基础设施/04.消息队列.html",redirect:"/pages/567090/"},{name:"v-352bf426",path:"/pages/d81a42/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-352bf426").then(t)}},{path:"/pages/d81a42/index.html",redirect:"/pages/d81a42/"},{path:"/04.设计基础设施/01.设计基础设施/06.动态线程池.html",redirect:"/pages/d81a42/"},{name:"v-5dd3d42a",path:"/pages/8416e6/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-5dd3d42a").then(t)}},{path:"/pages/8416e6/index.html",redirect:"/pages/8416e6/"},{path:"/04.设计基础设施/01.设计基础设施/05.订阅发布.html",redirect:"/pages/8416e6/"},{name:"v-1c3f7e81",path:"/pages/52ebd8/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-1c3f7e81").then(t)}},{path:"/pages/52ebd8/index.html",redirect:"/pages/52ebd8/"},{path:"/06.我的动态/01.碎碎念.html",redirect:"/pages/52ebd8/"},{name:"v-03654e78",path:"/pages/bd2edd/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-03654e78").then(t)}},{path:"/pages/bd2edd/index.html",redirect:"/pages/bd2edd/"},{path:"/08.学习路线/01.学习路线/01.第一步：一般性原则.html",redirect:"/pages/bd2edd/"},{name:"v-52fa84a6",path:"/pages/c64895/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-52fa84a6").then(t)}},{path:"/pages/c64895/index.html",redirect:"/pages/c64895/"},{path:"/08.学习路线/01.学习路线/02.第二步：核心组件.html",redirect:"/pages/c64895/"},{name:"v-61d0fb85",path:"/blog/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-61d0fb85").then(t)}},{path:"/blog/index.html",redirect:"/blog/"},{path:"/@pages/archivesPage.html",redirect:"/blog/"},{name:"v-7604068d",path:"/pages/b97db9/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-7604068d").then(t)}},{path:"/pages/b97db9/index.html",redirect:"/pages/b97db9/"},{path:"/08.学习路线/01.学习路线/03.第三步：核心系统.html",redirect:"/pages/b97db9/"},{name:"v-5c2bcd3a",path:"/pages/264b06/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-5c2bcd3a").then(t)}},{path:"/pages/264b06/index.html",redirect:"/pages/264b06/"},{path:"/09.系统设计鉴赏/01.Redis/01.Redis 架构概述.html",redirect:"/pages/264b06/"},{name:"v-a11d1cc4",path:"/",component:Tl,beforeEnter:(n,e,t)=>{hs("Layout","v-a11d1cc4").then(t)}},{path:"/index.html",redirect:"/"},{path:"*",component:Tl}],Cl={title:"Echo 系统设计之美",description:"将系统设计技能提升到一个新水平所需的一切",base:"/",headTags:[["link",{rel:"icon",href:"/img/favicon.ico"}],["meta",{name:"theme-color",content:"#11a8cd"}]],pages:[{title:"布隆过滤",frontmatter:{title:"布隆过滤",date:"2024-09-14T03:52:03.000Z",permalink:"/pages/fccd91/"},regularPath:"/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/01.%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4.html",relativePath:"01.系统设计算法/01.系统设计算法/01.布隆过滤.md",key:"v-14d5b00e",path:"/pages/fccd91/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:3,title:"优点",slug:"优点",normalizedTitle:"优点",charIndex:175},{level:3,title:"缺点",slug:"缺点",normalizedTitle:"缺点",charIndex:305},{level:3,title:"使用场景",slug:"使用场景",normalizedTitle:"使用场景",charIndex:361},{level:2,title:"布隆过滤器的原理",slug:"布隆过滤器的原理",normalizedTitle:"布隆过滤器的原理",charIndex:640},{level:3,title:"数据结构",slug:"数据结构",normalizedTitle:"数据结构",charIndex:289},{level:3,title:"空间计算",slug:"空间计算",normalizedTitle:"空间计算",charIndex:909},{level:3,title:"增加元素",slug:"增加元素",normalizedTitle:"增加元素",charIndex:921},{level:3,title:"查询元素",slug:"查询元素",normalizedTitle:"查询元素",charIndex:192},{level:3,title:"修改元素",slug:"修改元素",normalizedTitle:"修改元素",charIndex:1791},{level:3,title:"删除元素",slug:"删除元素",normalizedTitle:"删除元素",charIndex:352},{level:2,title:"Redis 中的 布隆过滤器",slug:"redis-中的-布隆过滤器",normalizedTitle:"redis 中的 布隆过滤器",charIndex:1927},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:1946}],headersStr:"前言 优点 缺点 使用场景 布隆过滤器的原理 数据结构 空间计算 增加元素 查询元素 修改元素 删除元素 Redis 中的 布隆过滤器 参考文献",content:"# 前言\n\n布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是 一个很长的二进制向量 和 一系列随机映射函数。布隆过滤器可以用于 检索一个元素是否在一个集合中。\n\n如果还是不太好理解的话，就可以把布隆过滤器理解为一个 set 集合，我们可以通过 add 往里面添加元素，通过 contains 来判断是否包含某个元素\n\n\n# 优点\n\n * 时间复杂度低，增加和查询元素的时间复杂为 O(N)，（N 为哈希函数的个数，通常情况比较小）\n * 保密性强，布隆过滤器不存储元素本身\n * 存储空间小，如果允许存在一定的误判，布隆过滤器是非常节省空间的（相比其他数据结构如Set集合）\n\n\n# 缺点\n\n * 有点一定的误判率，但是可以通过调整参数来降低\n * 无法获取元素本身\n * 很难删除元素\n\n\n# 使用场景\n\n布隆过滤器可以告诉我们 “某样东西一定不存在或者可能存在”，也就是说布隆过滤器说这个数不存在则一定不存，布隆过滤器说这个数存在则可能不存在（误判，后续会讲），利用这个判断是否存在的特点可以做很多有趣的事情。\n\n * 解决 Redis 缓存穿透问题（面试重点）\n * 邮件过滤，使用布隆过滤器来做邮件黑名单过滤\n * 对爬虫网址进行过滤，爬过的不再爬\n * 解决新闻推荐过的不再推荐(类似抖音刷过的往下滑动不再刷到)\n * HBase RocksDB LevelDB 等数据库内置布隆过滤器，用于判断数据是否存在，可以减少数据库的IO请求\n\n\n# 布隆过滤器的原理\n\n\n# 数据结构\n\n布隆过滤器它实际上是 一个很长的二进制向量 和 一系列随机映射函数。以Redis中的布隆过滤器实现为例，Redis 中的布隆过滤器底层是一个大型位数组（二进制数组）+多个无偏hash函数。\n\n\n\n多个无偏hash函数\n\n无偏hash函数就是能把元素的hash值计算的 比较均匀 的hash函数，能使得计算后的元素下标比较均匀的映射到位数组中。能有效减少误差。\n\n如下就是一个简单的布隆过滤器示意图，其中 k1、k2 代表增加的元素，a、b、c即为无偏hash函数，最下层则为二进制数组。\n\n\n\n\n# 空间计算\n\n在布隆过滤器增加元素之前，首先需要初始化布隆过滤器的空间，也就是上面说的二进制数组，除此之外还需要计算无偏hash函数的个数。\n\n布隆过滤器提供了两个参数，分别是预计加入元素的大小 n，运行的错误率 p。\n\n布隆过滤器中有算法根据这两个参数会计算出二进制数组的大小 m，以及无偏hash函数的个数 k。\n\n它们之间的关系比较简单：\n\n如下地址是一个免费的在线布隆过滤器在线计算的网址：\n\n> https://krisives.github.io/bloom-calculator/\n\n\n\n\n# 增加元素\n\n往布隆过滤器增加元素，添加的key需要根据k个无偏hash函数计算得到多个hash值，然后对数组长度进行取模得到数组下标的位置，然后将对应数组下标的位置的值置为1\n\n * 通过k个无偏hash函数计算得到k个hash值\n * 依次取模数组长度，得到数组索引\n * 将计算得到的数组索引下标位置数据修改为1\n\n例如，key = Liziba，无偏hash函数的个数k=3，分别为hash1、hash2、hash3。三个hash函数计算后得到三个数组下标值，并将其值修改为1.\n\n如图所示\n\n\n\n\n# 查询元素\n\n布隆过滤器最大的用处就在于判断某样东西一定不存在或者可能存在，而这个就是查询元素的结果。其查询元素的过程如下：\n\n * 通过 k 个无偏hash函数计算得到 k 个hash值\n * 依次取模数组长度，得到数组索引\n * 判断索引处的值是否全部为 1，如果全部为 1 则存在（这种存在可能是误判），如果存在一个 0 则必定不存在\n\n关于误判，其实非常好理解，hash函数再怎么牛逼，也无法完全避免hash冲突，也就是说可能会存在多个元素计算的hash值是相同的，那么它们取模数组长度后的到的数组索引也是相同的，这就是误判的原因。例如李子捌和李子柒的hash值取模后得到的数组索引都是1，但其实这里只有李子捌，如果此时判断李子柒在不在这里，误判就出现啦！因此布隆过滤器最大的缺点误判只要知道其判断元素是否存在的原理就很容易明白了！\n\n\n# 修改元素\n\n不允许修改\n\n\n# 删除元素\n\n布隆过滤器对元素的删除不太支持，目前有一些变形的特定布隆过滤器支持元素的删除！关于为什么对删除不太支持，其实也非常好理解，hash冲突必然存在，删除肯定是很苦难的！你将 A 的数组下标置为 0，那可能 B 也为受到影响\n\n\n# Redis 中的 布隆过滤器\n\n\n# 参考文献\n\n布隆(Bloom Filter)过滤器——全面讲解，建议收藏-CSDN博客",normalizedContent:"# 前言\n\n布隆过滤器（bloom filter）是1970年由布隆提出的。它实际上是 一个很长的二进制向量 和 一系列随机映射函数。布隆过滤器可以用于 检索一个元素是否在一个集合中。\n\n如果还是不太好理解的话，就可以把布隆过滤器理解为一个 set 集合，我们可以通过 add 往里面添加元素，通过 contains 来判断是否包含某个元素\n\n\n# 优点\n\n * 时间复杂度低，增加和查询元素的时间复杂为 o(n)，（n 为哈希函数的个数，通常情况比较小）\n * 保密性强，布隆过滤器不存储元素本身\n * 存储空间小，如果允许存在一定的误判，布隆过滤器是非常节省空间的（相比其他数据结构如set集合）\n\n\n# 缺点\n\n * 有点一定的误判率，但是可以通过调整参数来降低\n * 无法获取元素本身\n * 很难删除元素\n\n\n# 使用场景\n\n布隆过滤器可以告诉我们 “某样东西一定不存在或者可能存在”，也就是说布隆过滤器说这个数不存在则一定不存，布隆过滤器说这个数存在则可能不存在（误判，后续会讲），利用这个判断是否存在的特点可以做很多有趣的事情。\n\n * 解决 redis 缓存穿透问题（面试重点）\n * 邮件过滤，使用布隆过滤器来做邮件黑名单过滤\n * 对爬虫网址进行过滤，爬过的不再爬\n * 解决新闻推荐过的不再推荐(类似抖音刷过的往下滑动不再刷到)\n * hbase rocksdb leveldb 等数据库内置布隆过滤器，用于判断数据是否存在，可以减少数据库的io请求\n\n\n# 布隆过滤器的原理\n\n\n# 数据结构\n\n布隆过滤器它实际上是 一个很长的二进制向量 和 一系列随机映射函数。以redis中的布隆过滤器实现为例，redis 中的布隆过滤器底层是一个大型位数组（二进制数组）+多个无偏hash函数。\n\n\n\n多个无偏hash函数\n\n无偏hash函数就是能把元素的hash值计算的 比较均匀 的hash函数，能使得计算后的元素下标比较均匀的映射到位数组中。能有效减少误差。\n\n如下就是一个简单的布隆过滤器示意图，其中 k1、k2 代表增加的元素，a、b、c即为无偏hash函数，最下层则为二进制数组。\n\n\n\n\n# 空间计算\n\n在布隆过滤器增加元素之前，首先需要初始化布隆过滤器的空间，也就是上面说的二进制数组，除此之外还需要计算无偏hash函数的个数。\n\n布隆过滤器提供了两个参数，分别是预计加入元素的大小 n，运行的错误率 p。\n\n布隆过滤器中有算法根据这两个参数会计算出二进制数组的大小 m，以及无偏hash函数的个数 k。\n\n它们之间的关系比较简单：\n\n如下地址是一个免费的在线布隆过滤器在线计算的网址：\n\n> https://krisives.github.io/bloom-calculator/\n\n\n\n\n# 增加元素\n\n往布隆过滤器增加元素，添加的key需要根据k个无偏hash函数计算得到多个hash值，然后对数组长度进行取模得到数组下标的位置，然后将对应数组下标的位置的值置为1\n\n * 通过k个无偏hash函数计算得到k个hash值\n * 依次取模数组长度，得到数组索引\n * 将计算得到的数组索引下标位置数据修改为1\n\n例如，key = liziba，无偏hash函数的个数k=3，分别为hash1、hash2、hash3。三个hash函数计算后得到三个数组下标值，并将其值修改为1.\n\n如图所示\n\n\n\n\n# 查询元素\n\n布隆过滤器最大的用处就在于判断某样东西一定不存在或者可能存在，而这个就是查询元素的结果。其查询元素的过程如下：\n\n * 通过 k 个无偏hash函数计算得到 k 个hash值\n * 依次取模数组长度，得到数组索引\n * 判断索引处的值是否全部为 1，如果全部为 1 则存在（这种存在可能是误判），如果存在一个 0 则必定不存在\n\n关于误判，其实非常好理解，hash函数再怎么牛逼，也无法完全避免hash冲突，也就是说可能会存在多个元素计算的hash值是相同的，那么它们取模数组长度后的到的数组索引也是相同的，这就是误判的原因。例如李子捌和李子柒的hash值取模后得到的数组索引都是1，但其实这里只有李子捌，如果此时判断李子柒在不在这里，误判就出现啦！因此布隆过滤器最大的缺点误判只要知道其判断元素是否存在的原理就很容易明白了！\n\n\n# 修改元素\n\n不允许修改\n\n\n# 删除元素\n\n布隆过滤器对元素的删除不太支持，目前有一些变形的特定布隆过滤器支持元素的删除！关于为什么对删除不太支持，其实也非常好理解，hash冲突必然存在，删除肯定是很苦难的！你将 a 的数组下标置为 0，那可能 b 也为受到影响\n\n\n# redis 中的 布隆过滤器\n\n\n# 参考文献\n\n布隆(bloom filter)过滤器——全面讲解，建议收藏-csdn博客",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:14:59",lastUpdatedTimestamp:1726334099e3},{title:"一致性哈希",frontmatter:{title:"一致性哈希",date:"2024-09-14T03:52:03.000Z",permalink:"/pages/1e28a2/"},regularPath:"/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/02.%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C.html",relativePath:"01.系统设计算法/01.系统设计算法/02.一致性哈希.md",key:"v-6f4636bc",path:"/pages/1e28a2/",headers:[{level:2,title:"前言：使用普通 hash 算法 (取模算法)",slug:"前言-使用普通-hash-算法-取模算法",normalizedTitle:"前言：使用普通 hash 算法 (取模算法)",charIndex:2},{level:3,title:"普通 hash算法 与 使用场景描述：",slug:"普通-hash算法-与-使用场景描述",normalizedTitle:"普通 hash算法 与 使用场景描述：",charIndex:29},{level:3,title:"缺陷",slug:"缺陷",normalizedTitle:"缺陷",charIndex:804},{level:2,title:"一致性哈希算法",slug:"一致性哈希算法",normalizedTitle:"一致性哈希算法",charIndex:53},{level:3,title:"什么是 一致性 hash 算法",slug:"什么是-一致性-hash-算法",normalizedTitle:"什么是 一致性 hash 算法",charIndex:1161},{level:3,title:"一致性 hash 算法的优点",slug:"一致性-hash-算法的优点",normalizedTitle:"一致性 hash 算法的优点",charIndex:2083},{level:3,title:"hash 环的倾斜与虚拟节点",slug:"hash-环的倾斜与虚拟节点",normalizedTitle:"hash 环的倾斜与虚拟节点",charIndex:2521},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:2920}],headersStr:"前言：使用普通 hash 算法 (取模算法) 普通 hash算法 与 使用场景描述： 缺陷 一致性哈希算法 什么是 一致性 hash 算法 一致性 hash 算法的优点 hash 环的倾斜与虚拟节点 参考文献",content:"# 前言：使用普通 hash 算法 (取模算法)\n\n\n# 普通 hash算法 与 使用场景描述：\n\n在了解一致性哈希算法之前，我们先了解一下缓存中的一个应用场景，了解了这个应用场景之后，再来理解一致性哈希算法，就容易多了，也更能体现出一致性哈希算法的优点，那么，我们先来描述一下这个经典的分布式缓存的应用场景。\n\n假设我们有三台缓存服务器，用于缓存图片，我们为这三台缓存服务器编号为 0号、1号、2号，现在有3万张图片需要缓存，我们希望这些图片被均匀的缓存到这3台服务器上，以便它们能够分摊缓存的压力。也就是说，我们希望每台服务器能够缓存1万张左右的图片，那么我们应该怎样做呢？常见的做法是对缓存项的键进行哈希，将hash后的结果对缓存服务器的数量进行取模操作，通过取模后的结果，决定缓存项将会缓存在哪一台服务器上\n\n我们举例说明，以刚才描述的场景为例，假设图片名称是不重复的，那我们就可以使用图片名称作为访问图片的key，使用如下公式，计算出图片应该存放在哪台服务器上。\n\nhash(图片名称) % N\n\n当我们对同一个图片名称做相同的哈希计算时，得出的结果应该是不变的，如果我们有3台服务器，使用哈希后的结果对3求余，那么余数一定是0、1或者2；如果求余的结果为0， 就把当前图片缓存在0号服务器上，如果余数为1，就缓存在1号服务器上，以此类推；同理，当我们访问任意图片时，只要再次对图片名称进行上述运算，即可得出图片应该存放在哪一台缓存服务器上，我们只要在这一台服务器上查找图片即可，如果图片在对应的服务器上不存在，则证明对应的图片没有被缓存，也不用再去遍历其他缓存服务器了，通过这样的方法，即可将3万张图片随机的分布到3台缓存服务器上了，而且下次访问某张图片时，直接能够判断出该图片应该存在于哪台缓存服务器上，我们暂时称上述算法为 HASH 算法或者取模算法，取模算法的过程可以用下图表示：\n\n\n# 缺陷\n\n上述 HASH 算法时，会出现一些缺陷：如果服务器已经不能满足缓存需求，就需要增加服务器数量，假设我们增加了一台缓存服务器，此时如果仍然使用上述方法对同一张图片进行缓存，那么这张图片所在的服务器编号必定与原来3台服务器时所在的服务器编号不同，因为除数由3变为了4，最终导致所有缓存的位置都要发生改变，也就是说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端服务器请求数据；同理，假设突然有一台缓存服务器出现了故障，那么我们则需要将故障机器移除，那么缓存服务器数量从3台变为2台，同样会导致大量缓存在同一时间失效，造成了缓存的雪崩，后端服务器将会承受巨大的压力，整个系统很有可能被压垮。为了解决这种情况，就有了一致性哈希算法。\n\n\n# 一致性哈希算法\n\n\n# 什么是 一致性 hash 算法\n\n一致性哈希算法也是使用取模的方法，但是取模算法是对服务器的数量进行取模，而一致性哈希算法是对 2^32 取模，具体步骤如下：\n\n 1. 一致性哈希算法将整个哈希值空间按照顺时针方向组织成一个虚拟的圆环，称为 Hash 环；\n 2. 接着将各个服务器使用 Hash 函数进行哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，从而确定每台机器在哈希环上的位置\n 3. 最后使用算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针寻找，第一台遇到的服务器就是其应该定位到的服务器\n\n下面我们使用具体案例说明一下一致性哈希算法的具体流程：\n\n步骤一：哈希环的组织\n\n我们将 2^32 想象成一个圆，像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由**2^32个点**组成的圆，示意图如下：\n\n\n\n圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1,也就是说0点左侧的第一个点代表2^32-1，我们把这个由 2^32 个点组成的圆环称为hash环。\n\n步骤二：确定服务器在哈希环的位置\n\n哈希算法：hash(服务器的IP) % 2^32\n\n上述公式的计算结果一定是 0 到 2^32-1 之间的整数，那么上图中的 hash 环上必定有一个点与这个整数对应，所以我们可以使用这个整数代表服务器，也就是服务器就可以映射到这个环上，假设我们有 ABC 三台服务器，那么它们在哈希环上的示意图如下：\n\n步骤三：将数据映射到哈希环上\n\n我们还是使用图片的名称作为 key，所以我们使用下面算法将图片映射在哈希环上：hash（图片名称） % 2^32，假设我们有4张图片，映射后的示意图如下，其中橘黄色的点表示图片：\n\n\n\n那么，怎么算出上图中的图片应该被缓存到哪一台服务上面呢？我们只要从图片的位置开始，沿顺时针方向遇到的第一个服务器就是图片存放的服务器了。最终，1号、2号图片将会被缓存到服务器A上，3号图片将会被缓存到服务器B上，4号图片将会被缓存到服务器C上。\n\n\n# 一致性 hash 算法的优点\n\n前面提到，如果简单对服务器数量进行取模，那么当服务器数量发生变化时，会产生缓存的雪崩，从而很有可能导致系统崩溃，而使用一致性哈希算法就可以很好的解决这个问题，因为一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，只有部分缓存会失效，不至于将所有压力都在同一时间集中到后端服务器上，具有较好的容错性和可扩展性。\n\n假设服务器B出现了故障，需要将服务器B移除，那么移除前后的示意图如下图所示\n\n在服务器B未移除时，图片3应该被缓存到服务器B中，可是当服务器B移除以后，按照之前描述的一致性哈希算法的规则，图片3应该被缓存到服务器C中，因为从图片3的位置出发，沿顺时针方向遇到的第一个缓存服务器节点就是服务器C，也就是说，如果服务器B出现故障被移除时，图片3的缓存位置会发生改变，但是，图片4仍然会被缓存到服务器C中，图片1与图片2仍然会被缓存到服务器A中，这与服务器B移除之前并没有任何区别，这就是一致性哈希算法的优点。\n\n\n# hash 环的倾斜与虚拟节点\n\n一致性哈希算法在服务节点太少的情况下，容易因为节点分部不均匀而造成数据倾斜问题，也就是被缓存的对象大部分集中缓存在某一台服务器上，从而出现数据分布不均匀的情况，这种情况就称为 hash 环的倾斜。如下图所示：\n\n\n\n上述左图为理想情况，右图为出现了数据倾斜的情况\n\nhash 环的倾斜在极端情况下，仍然有可能引起系统的崩溃，为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点，一个实际物理节点可以对应多个虚拟节点，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大，hash环倾斜所带来的影响就越小，同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射。具体做法可以在服务器ip或主机名的后面增加编号来实现，加入虚拟节点以后的hash环如下：\n\n\n# 参考文献\n\n一致性哈希算法原理详解-CSDN博客\n\n白话解析：一致性哈希算法 consistent hashing-朱双印博客 (zsythink.net)",normalizedContent:"# 前言：使用普通 hash 算法 (取模算法)\n\n\n# 普通 hash算法 与 使用场景描述：\n\n在了解一致性哈希算法之前，我们先了解一下缓存中的一个应用场景，了解了这个应用场景之后，再来理解一致性哈希算法，就容易多了，也更能体现出一致性哈希算法的优点，那么，我们先来描述一下这个经典的分布式缓存的应用场景。\n\n假设我们有三台缓存服务器，用于缓存图片，我们为这三台缓存服务器编号为 0号、1号、2号，现在有3万张图片需要缓存，我们希望这些图片被均匀的缓存到这3台服务器上，以便它们能够分摊缓存的压力。也就是说，我们希望每台服务器能够缓存1万张左右的图片，那么我们应该怎样做呢？常见的做法是对缓存项的键进行哈希，将hash后的结果对缓存服务器的数量进行取模操作，通过取模后的结果，决定缓存项将会缓存在哪一台服务器上\n\n我们举例说明，以刚才描述的场景为例，假设图片名称是不重复的，那我们就可以使用图片名称作为访问图片的key，使用如下公式，计算出图片应该存放在哪台服务器上。\n\nhash(图片名称) % n\n\n当我们对同一个图片名称做相同的哈希计算时，得出的结果应该是不变的，如果我们有3台服务器，使用哈希后的结果对3求余，那么余数一定是0、1或者2；如果求余的结果为0， 就把当前图片缓存在0号服务器上，如果余数为1，就缓存在1号服务器上，以此类推；同理，当我们访问任意图片时，只要再次对图片名称进行上述运算，即可得出图片应该存放在哪一台缓存服务器上，我们只要在这一台服务器上查找图片即可，如果图片在对应的服务器上不存在，则证明对应的图片没有被缓存，也不用再去遍历其他缓存服务器了，通过这样的方法，即可将3万张图片随机的分布到3台缓存服务器上了，而且下次访问某张图片时，直接能够判断出该图片应该存在于哪台缓存服务器上，我们暂时称上述算法为 hash 算法或者取模算法，取模算法的过程可以用下图表示：\n\n\n# 缺陷\n\n上述 hash 算法时，会出现一些缺陷：如果服务器已经不能满足缓存需求，就需要增加服务器数量，假设我们增加了一台缓存服务器，此时如果仍然使用上述方法对同一张图片进行缓存，那么这张图片所在的服务器编号必定与原来3台服务器时所在的服务器编号不同，因为除数由3变为了4，最终导致所有缓存的位置都要发生改变，也就是说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端服务器请求数据；同理，假设突然有一台缓存服务器出现了故障，那么我们则需要将故障机器移除，那么缓存服务器数量从3台变为2台，同样会导致大量缓存在同一时间失效，造成了缓存的雪崩，后端服务器将会承受巨大的压力，整个系统很有可能被压垮。为了解决这种情况，就有了一致性哈希算法。\n\n\n# 一致性哈希算法\n\n\n# 什么是 一致性 hash 算法\n\n一致性哈希算法也是使用取模的方法，但是取模算法是对服务器的数量进行取模，而一致性哈希算法是对 2^32 取模，具体步骤如下：\n\n 1. 一致性哈希算法将整个哈希值空间按照顺时针方向组织成一个虚拟的圆环，称为 hash 环；\n 2. 接着将各个服务器使用 hash 函数进行哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，从而确定每台机器在哈希环上的位置\n 3. 最后使用算法定位数据访问到相应服务器：将数据key使用相同的函数hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针寻找，第一台遇到的服务器就是其应该定位到的服务器\n\n下面我们使用具体案例说明一下一致性哈希算法的具体流程：\n\n步骤一：哈希环的组织\n\n我们将 2^32 想象成一个圆，像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由**2^32个点**组成的圆，示意图如下：\n\n\n\n圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1,也就是说0点左侧的第一个点代表2^32-1，我们把这个由 2^32 个点组成的圆环称为hash环。\n\n步骤二：确定服务器在哈希环的位置\n\n哈希算法：hash(服务器的ip) % 2^32\n\n上述公式的计算结果一定是 0 到 2^32-1 之间的整数，那么上图中的 hash 环上必定有一个点与这个整数对应，所以我们可以使用这个整数代表服务器，也就是服务器就可以映射到这个环上，假设我们有 abc 三台服务器，那么它们在哈希环上的示意图如下：\n\n步骤三：将数据映射到哈希环上\n\n我们还是使用图片的名称作为 key，所以我们使用下面算法将图片映射在哈希环上：hash（图片名称） % 2^32，假设我们有4张图片，映射后的示意图如下，其中橘黄色的点表示图片：\n\n\n\n那么，怎么算出上图中的图片应该被缓存到哪一台服务上面呢？我们只要从图片的位置开始，沿顺时针方向遇到的第一个服务器就是图片存放的服务器了。最终，1号、2号图片将会被缓存到服务器a上，3号图片将会被缓存到服务器b上，4号图片将会被缓存到服务器c上。\n\n\n# 一致性 hash 算法的优点\n\n前面提到，如果简单对服务器数量进行取模，那么当服务器数量发生变化时，会产生缓存的雪崩，从而很有可能导致系统崩溃，而使用一致性哈希算法就可以很好的解决这个问题，因为一致性hash算法对于节点的增减都只需重定位环空间中的一小部分数据，只有部分缓存会失效，不至于将所有压力都在同一时间集中到后端服务器上，具有较好的容错性和可扩展性。\n\n假设服务器b出现了故障，需要将服务器b移除，那么移除前后的示意图如下图所示\n\n在服务器b未移除时，图片3应该被缓存到服务器b中，可是当服务器b移除以后，按照之前描述的一致性哈希算法的规则，图片3应该被缓存到服务器c中，因为从图片3的位置出发，沿顺时针方向遇到的第一个缓存服务器节点就是服务器c，也就是说，如果服务器b出现故障被移除时，图片3的缓存位置会发生改变，但是，图片4仍然会被缓存到服务器c中，图片1与图片2仍然会被缓存到服务器a中，这与服务器b移除之前并没有任何区别，这就是一致性哈希算法的优点。\n\n\n# hash 环的倾斜与虚拟节点\n\n一致性哈希算法在服务节点太少的情况下，容易因为节点分部不均匀而造成数据倾斜问题，也就是被缓存的对象大部分集中缓存在某一台服务器上，从而出现数据分布不均匀的情况，这种情况就称为 hash 环的倾斜。如下图所示：\n\n\n\n上述左图为理想情况，右图为出现了数据倾斜的情况\n\nhash 环的倾斜在极端情况下，仍然有可能引起系统的崩溃，为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点，一个实际物理节点可以对应多个虚拟节点，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大，hash环倾斜所带来的影响就越小，同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射。具体做法可以在服务器ip或主机名的后面增加编号来实现，加入虚拟节点以后的hash环如下：\n\n\n# 参考文献\n\n一致性哈希算法原理详解-csdn博客\n\n白话解析：一致性哈希算法 consistent hashing-朱双印博客 (zsythink.net)",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:14:59",lastUpdatedTimestamp:1726334099e3},{title:"Count-Min Sketch",frontmatter:{title:"Count-Min Sketch",date:"2024-09-14T13:30:19.000Z",permalink:"/pages/8624c5"},regularPath:"/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/03.Count-Min%20Sketch.html",relativePath:"01.系统设计算法/01.系统设计算法/03.Count-Min Sketch.md",key:"v-30a03cb6",path:"/pages/8624c5/",headers:[{level:2,title:"前言：如何统计元素出现频率？",slug:"前言-如何统计元素出现频率",normalizedTitle:"前言：如何统计元素出现频率？",charIndex:2},{level:4,title:"hashmap 解决",slug:"hashmap-解决",normalizedTitle:"hashmap 解决",charIndex:85},{level:2,title:"CMS简介",slug:"cms简介",normalizedTitle:"cms简介",charIndex:853},{level:4,title:"举个栗子",slug:"举个栗子",normalizedTitle:"举个栗子",charIndex:1044},{level:2,title:"CMS 的具体实现",slug:"cms-的具体实现",normalizedTitle:"cms 的具体实现",charIndex:1489},{level:2,title:"CMS 的参数选择",slug:"cms-的参数选择",normalizedTitle:"cms 的参数选择",charIndex:2919},{level:2,title:"Count-Mean-Min-Sketch",slug:"count-mean-min-sketch",normalizedTitle:"count-mean-min-sketch",charIndex:3171},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:3881}],headersStr:"前言：如何统计元素出现频率？ hashmap 解决 CMS简介 举个栗子 CMS 的具体实现 CMS 的参数选择 Count-Mean-Min-Sketch 参考文献",content:"# 前言：如何统计元素出现频率？\n\n问题： 如果老板让你统计一个实时的数据流中元素出现的频率，并且准备随时回答某个元素出现的频率，不需要的精确的计数，那该怎么办？\n\n# hashmap 解决\n\n在大数据场景下，比如网页的 TopK 问题，爬虫的是否访问过的问题，都是一种出现频次相关的问题，那么在系统设计的时候，如何选择策略和数据结构去存储相关的数据是最高效合适的呢？\n\n计算元素的出现频次，如果出现与普通的场景下，简单的方案就是用 hashmap 来记录元素出现的次数：\n\n// 用HashMap存储元素及其频率\nHashMap<String, Integer> freq = new HashMap<>();\n\n// 统计频率\nfor (String e : elements) {\n    if (!freq.containsKey(e)) {\n    \tfreq.put(e, 1);\n    } else {\n    \tfreq.put(e, freq.get(e) + 1);\n    }\n}\n\n\n但是这种方式在大量数据流的情况下，如果存在大量唯一元素的情况下，会占用大量的内存，导致其无法应对大数据场景，因此在”时间换空间” 的策略选择中，这里就需要考虑通过时间，或者准确率等其他的因素来换空间。\n\n通常来说，针对大数据场景，会无限扩张的数据结构显然是不适用的，所以希望能用固定的空间来进行计数的管理，同时希望尽量不要影响到运行的时间，换言之，可以牺牲掉一定的准确性，来实现节省空间的效果。\n\n基于上述需求，我们可以想到 Hash 算法：将无限大的空间映射到固定的 size 的输出上；而大数据场景下的 Hash 会遇到冲突会被无限放大的问题\n\n如何解决冲突是最核心的问题\n\n * 基于概率数据结构实现的 Bloom Filter 算法采取多 Hash 的方法来减少冲突\n * 而其衍生出来的 CMS 算法以同样的思想，基于不同的设计，更为适应这种计数场景 下面介绍该方法的具体实现\n\n\n# CMS简介\n\nCount-min Sketch 算法是一个可以用来计数的算法，在数据大小非常大时，一种高效的计数算法，通过牺牲准确性提高的效率。\n\n * 是一个概率数据机构\n\n * 算法效率高\n * 提供计数上线\n\n其中，重要参数包括\n\n * Hash 哈希函数的数量： k\n * 计数表格列的数量： m\n * 内存中用空间： k x m x size of counter\n\n# 举个栗子\n\n我们规定一个 m=5，k=3 的Count-min Sketch，用来计数，其中所有hash函数如下\n\n\n\n注意，所有hash函数的结果需 mod m\n\n下面开始填表，首先初始状态为\n\n\n\n首先，向里面添加字母B，其ASCII码为66，求hash函数的结果为\n\n\n\n因此，表格变为\n\n\n\n接下来，我们查询字母A，其ASCII码为65，求hash函数的结果为\n\n\n\n用这个结果去读表，发现其对应位置均为0，因此字母A最多出现0次，这个值是准确的。\n\n然后，我们在查询字母G，其ASCII码为71，求hash函数的结果为\n\n\n\n用这个结果去读表，发现其对应位置均为1，因此字母G最多出现1次；**出错了！**我们从未向里面添加过字母G，这就是一次collision。Count-min Sketch的确会有这种问题，因为这个模型是从Bloom Filter衍生过来的。所以说Count-min Sketch是一个概率模型，返回的结果是一个上限值（upper-bound）。\n\n\n# CMS 的具体实现\n\n首先第一点，通过 hash 来实现数值空间的转换，通过哈希函数 H 将输入元素 x 映射到一维数组上，通过该 index 的值来判断元素的 Count（是否存在）\n\nfor (char x : input_element)\n{\n\tidx = Hash(x);\n\tarray[idx] += 1;\n}\n\n\n实际上这就是 Bloom Filter 的基础思想，然而无论是定长数组的”有限”还是 Hash 函数本身，都需要考虑冲突问题（两个元素被映射到同一个 index 上），冲突会导致 Count 比真实的大。\n\n于是接下来面临的问题就是：**如何降低冲突的概率？**如何提高计数的准确性（实际上也包含在降低冲突的概率中）\n\n可以参考 Bloom Filter 的策略，其通过多个 Hash 函数来映射同一个数，从而来降低元素的冲突概率（未考虑超大数据场景），进而也能提高计数的准确性，那么我们看一下 bloom filter 方法：\n\n> Bloom Filter 算法解决的是存在性问题，因此只需要一个 01 向量，当且仅当所有 Hash 计算出来的 index 的值都为 1 的时候，这个元素才可能存在；\n\n考虑将该方法向 Count 问题上迁移：\n\n * 计数过程中：使用 n 个 Hash 函数计算 idx{1~n} ，然后 vec[idx[i]] += 1 对count+1\n * 查询过程中：使用 n 个 Hash 函数计算 idx{1~n}，然后取 vec[idx[i]] 的最小值，考虑冲突场景可知，这个最小值>=实际的 count。\n\nint query_count = INT_MAX;\nfor (size_t i=0; i < function_size; ++i){\n\tint idx = Hash[i](query);\n\tint tmp_count = count_set[idx];\n\tquery_count = (tmp_count < query_count)? tmp_count: query_count;\n}\n\n\n实际上取多个 hash 的最小值就是 Count-Min Sketch 的核心，但如果仅是如此很明显有个问题，就是多个 hash 函数算出的多个 idx 会进一步的“污染”计数，得不偿失，导致 Count 更加不准确。\n\n实际上很容易想到，为了通过多个 hash 来减少冲突，并使得多 hash 的索引更加的唯一，最好的办法就是使得每个 hash 对应的计数空间是独立的，也就是将我们的计数空间在拓展成二维数组,其 size 为 depth × width 其中 depth 就代表 hash 函数的个数。\n\n那么假设每个 Hash 函数的冲突概率是 p~i~ 那么优化后的冲突概率就从 min(P~i~) 减小到\n\n\n\nfor (size_t i=0; i<function_size; ++i){\n\tint idx = Hash[i](query);\n\tint tmp_count = count_set[i][idx];\n\tquery_count = (tmp_count < query_count)? tmp_count: query_count;\n}\n\n\n结合了这个二维数组就是完整的 CMS 算法了，最终求得的 count 是实际 Count 的近似值（上界）。\n\n\n# CMS 的参数选择\n\n如果确定使用 CMS，接下来面对的就是计数的精度问题，那么如何选择这个数组的 shape 才能尽可能的减少误差呢？（很明显都是越大越好，那么怎么样是最优/达标的呢）\n\n确定一些变量参数：\n\n\n\n设定误差范围：\n\n\n\n以及结果在这个范围内的概率为:\n\n\n\n那么可以计算出：e 是自然常数\n\n\n\n计算公式来自论文，有效性分析也可以从论文中阅读\n\n> 添加一个新哈希函数以指数级别迅速降低超出边界异常数据的概率；当然，增加矩阵的宽度也可以增加减少冲突的概率，但这个只是线性级别。\n\n\n# Count-Mean-Min-Sketch\n\n由于 Hash 的冲突，CMS 对于低频的元素误差还是太大了，引入噪音对于高频元素可以接受（topk）但是对于低频长尾来说太不准确了，因此有了以下的改进：\n\n * 首先按照 CMS 的流程取出 d 个 sketch\n * 对于每个 hash 估计出一个噪音，噪音为该行的所有整数（除了被查询元素）的平均值\n * 该行的 sketch 减去该行的噪音，作为真正的 sketch\n * 返回 d 个 sketch 的中位数\n\nclass CountMeanMinSketch {\n    // initialization and addition procedures as in CountMinSketch\n    // n is total number of added elements\n    long estimateFrequency(value) {\n        long e[] = new long[d]\n        for(i = 0; i < d; i++) {\n            sketchCounter = estimators[i][ hash(value, i) ]\n            noiseEstimation = (n - sketchCounter) / (m - 1)\n            e[i] = sketchCounter – noiseEstimator\n        }\n        return median(e)\n    }\n}\n\n\n该算法显著改善了在长尾数据上的精确度。\n\n\n# 参考文献\n\nCount-min Sketch 算法 - 知乎 (zhihu.com)\n\nCount_Min Sketch算法 - AikenH Blogs",normalizedContent:"# 前言：如何统计元素出现频率？\n\n问题： 如果老板让你统计一个实时的数据流中元素出现的频率，并且准备随时回答某个元素出现的频率，不需要的精确的计数，那该怎么办？\n\n# hashmap 解决\n\n在大数据场景下，比如网页的 topk 问题，爬虫的是否访问过的问题，都是一种出现频次相关的问题，那么在系统设计的时候，如何选择策略和数据结构去存储相关的数据是最高效合适的呢？\n\n计算元素的出现频次，如果出现与普通的场景下，简单的方案就是用 hashmap 来记录元素出现的次数：\n\n// 用hashmap存储元素及其频率\nhashmap<string, integer> freq = new hashmap<>();\n\n// 统计频率\nfor (string e : elements) {\n    if (!freq.containskey(e)) {\n    \tfreq.put(e, 1);\n    } else {\n    \tfreq.put(e, freq.get(e) + 1);\n    }\n}\n\n\n但是这种方式在大量数据流的情况下，如果存在大量唯一元素的情况下，会占用大量的内存，导致其无法应对大数据场景，因此在”时间换空间” 的策略选择中，这里就需要考虑通过时间，或者准确率等其他的因素来换空间。\n\n通常来说，针对大数据场景，会无限扩张的数据结构显然是不适用的，所以希望能用固定的空间来进行计数的管理，同时希望尽量不要影响到运行的时间，换言之，可以牺牲掉一定的准确性，来实现节省空间的效果。\n\n基于上述需求，我们可以想到 hash 算法：将无限大的空间映射到固定的 size 的输出上；而大数据场景下的 hash 会遇到冲突会被无限放大的问题\n\n如何解决冲突是最核心的问题\n\n * 基于概率数据结构实现的 bloom filter 算法采取多 hash 的方法来减少冲突\n * 而其衍生出来的 cms 算法以同样的思想，基于不同的设计，更为适应这种计数场景 下面介绍该方法的具体实现\n\n\n# cms简介\n\ncount-min sketch 算法是一个可以用来计数的算法，在数据大小非常大时，一种高效的计数算法，通过牺牲准确性提高的效率。\n\n * 是一个概率数据机构\n\n * 算法效率高\n * 提供计数上线\n\n其中，重要参数包括\n\n * hash 哈希函数的数量： k\n * 计数表格列的数量： m\n * 内存中用空间： k x m x size of counter\n\n# 举个栗子\n\n我们规定一个 m=5，k=3 的count-min sketch，用来计数，其中所有hash函数如下\n\n\n\n注意，所有hash函数的结果需 mod m\n\n下面开始填表，首先初始状态为\n\n\n\n首先，向里面添加字母b，其ascii码为66，求hash函数的结果为\n\n\n\n因此，表格变为\n\n\n\n接下来，我们查询字母a，其ascii码为65，求hash函数的结果为\n\n\n\n用这个结果去读表，发现其对应位置均为0，因此字母a最多出现0次，这个值是准确的。\n\n然后，我们在查询字母g，其ascii码为71，求hash函数的结果为\n\n\n\n用这个结果去读表，发现其对应位置均为1，因此字母g最多出现1次；**出错了！**我们从未向里面添加过字母g，这就是一次collision。count-min sketch的确会有这种问题，因为这个模型是从bloom filter衍生过来的。所以说count-min sketch是一个概率模型，返回的结果是一个上限值（upper-bound）。\n\n\n# cms 的具体实现\n\n首先第一点，通过 hash 来实现数值空间的转换，通过哈希函数 h 将输入元素 x 映射到一维数组上，通过该 index 的值来判断元素的 count（是否存在）\n\nfor (char x : input_element)\n{\n\tidx = hash(x);\n\tarray[idx] += 1;\n}\n\n\n实际上这就是 bloom filter 的基础思想，然而无论是定长数组的”有限”还是 hash 函数本身，都需要考虑冲突问题（两个元素被映射到同一个 index 上），冲突会导致 count 比真实的大。\n\n于是接下来面临的问题就是：**如何降低冲突的概率？**如何提高计数的准确性（实际上也包含在降低冲突的概率中）\n\n可以参考 bloom filter 的策略，其通过多个 hash 函数来映射同一个数，从而来降低元素的冲突概率（未考虑超大数据场景），进而也能提高计数的准确性，那么我们看一下 bloom filter 方法：\n\n> bloom filter 算法解决的是存在性问题，因此只需要一个 01 向量，当且仅当所有 hash 计算出来的 index 的值都为 1 的时候，这个元素才可能存在；\n\n考虑将该方法向 count 问题上迁移：\n\n * 计数过程中：使用 n 个 hash 函数计算 idx{1~n} ，然后 vec[idx[i]] += 1 对count+1\n * 查询过程中：使用 n 个 hash 函数计算 idx{1~n}，然后取 vec[idx[i]] 的最小值，考虑冲突场景可知，这个最小值>=实际的 count。\n\nint query_count = int_max;\nfor (size_t i=0; i < function_size; ++i){\n\tint idx = hash[i](query);\n\tint tmp_count = count_set[idx];\n\tquery_count = (tmp_count < query_count)? tmp_count: query_count;\n}\n\n\n实际上取多个 hash 的最小值就是 count-min sketch 的核心，但如果仅是如此很明显有个问题，就是多个 hash 函数算出的多个 idx 会进一步的“污染”计数，得不偿失，导致 count 更加不准确。\n\n实际上很容易想到，为了通过多个 hash 来减少冲突，并使得多 hash 的索引更加的唯一，最好的办法就是使得每个 hash 对应的计数空间是独立的，也就是将我们的计数空间在拓展成二维数组,其 size 为 depth × width 其中 depth 就代表 hash 函数的个数。\n\n那么假设每个 hash 函数的冲突概率是 p~i~ 那么优化后的冲突概率就从 min(p~i~) 减小到\n\n\n\nfor (size_t i=0; i<function_size; ++i){\n\tint idx = hash[i](query);\n\tint tmp_count = count_set[i][idx];\n\tquery_count = (tmp_count < query_count)? tmp_count: query_count;\n}\n\n\n结合了这个二维数组就是完整的 cms 算法了，最终求得的 count 是实际 count 的近似值（上界）。\n\n\n# cms 的参数选择\n\n如果确定使用 cms，接下来面对的就是计数的精度问题，那么如何选择这个数组的 shape 才能尽可能的减少误差呢？（很明显都是越大越好，那么怎么样是最优/达标的呢）\n\n确定一些变量参数：\n\n\n\n设定误差范围：\n\n\n\n以及结果在这个范围内的概率为:\n\n\n\n那么可以计算出：e 是自然常数\n\n\n\n计算公式来自论文，有效性分析也可以从论文中阅读\n\n> 添加一个新哈希函数以指数级别迅速降低超出边界异常数据的概率；当然，增加矩阵的宽度也可以增加减少冲突的概率，但这个只是线性级别。\n\n\n# count-mean-min-sketch\n\n由于 hash 的冲突，cms 对于低频的元素误差还是太大了，引入噪音对于高频元素可以接受（topk）但是对于低频长尾来说太不准确了，因此有了以下的改进：\n\n * 首先按照 cms 的流程取出 d 个 sketch\n * 对于每个 hash 估计出一个噪音，噪音为该行的所有整数（除了被查询元素）的平均值\n * 该行的 sketch 减去该行的噪音，作为真正的 sketch\n * 返回 d 个 sketch 的中位数\n\nclass countmeanminsketch {\n    // initialization and addition procedures as in countminsketch\n    // n is total number of added elements\n    long estimatefrequency(value) {\n        long e[] = new long[d]\n        for(i = 0; i < d; i++) {\n            sketchcounter = estimators[i][ hash(value, i) ]\n            noiseestimation = (n - sketchcounter) / (m - 1)\n            e[i] = sketchcounter – noiseestimator\n        }\n        return median(e)\n    }\n}\n\n\n该算法显著改善了在长尾数据上的精确度。\n\n\n# 参考文献\n\ncount-min sketch 算法 - 知乎 (zhihu.com)\n\ncount_min sketch算法 - aikenh blogs",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:14:59",lastUpdatedTimestamp:1726334099e3},{title:"LRU",frontmatter:{title:"LRU",date:"2024-09-14T16:39:57.000Z",permalink:"/pages/87589a"},regularPath:"/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/04.LRU.html",relativePath:"01.系统设计算法/01.系统设计算法/04.LRU.md",key:"v-be411e82",path:"/pages/87589a/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"基于 HashMap 和 双向链表 实现 LRU",slug:"基于-hashmap-和-双向链表-实现-lru",normalizedTitle:"基于 hashmap 和 双向链表 实现 lru",charIndex:431},{level:2,title:"Redis 如何实现 LRU",slug:"redis-如何实现-lru",normalizedTitle:"redis 如何实现 lru",charIndex:2879},{level:3,title:"一些点子",slug:"一些点子",normalizedTitle:"一些点子",charIndex:2898},{level:3,title:"如何实现",slug:"如何实现",normalizedTitle:"如何实现",charIndex:2885},{level:3,title:"全局 LRU 时钟值的计算",slug:"全局-lru-时钟值的计算",normalizedTitle:"全局 lru 时钟值的计算",charIndex:4042},{level:3,title:"键值对 LRU 时钟值的初始化与更新",slug:"键值对-lru-时钟值的初始化与更新",normalizedTitle:"键值对 lru 时钟值的初始化与更新",charIndex:4122},{level:3,title:"近似 LRU 算法的实际执行",slug:"近似-lru-算法的实际执行",normalizedTitle:"近似 lru 算法的实际执行",charIndex:4192},{level:4,title:"何时触发算法执行？",slug:"何时触发算法执行",normalizedTitle:"何时触发算法执行？",charIndex:10134},{level:4,title:"近似 LRU 算法具体如何执行？",slug:"近似-lru-算法具体如何执行",normalizedTitle:"近似 lru 算法具体如何执行？",charIndex:11330},{level:5,title:"判断当前内存使用情况",slug:"判断当前内存使用情况",normalizedTitle:"判断当前内存使用情况",charIndex:11377},{level:5,title:"更新待淘汰的候选键值对集合",slug:"更新待淘汰的候选键值对集合",normalizedTitle:"更新待淘汰的候选键值对集合",charIndex:11391},{level:5,title:"选择被淘汰的键值对并删除",slug:"选择被淘汰的键值对并删除",normalizedTitle:"选择被淘汰的键值对并删除",charIndex:11408},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:20047},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:20579}],headersStr:"前言 基于 HashMap 和 双向链表 实现 LRU Redis 如何实现 LRU 一些点子 如何实现 全局 LRU 时钟值的计算 键值对 LRU 时钟值的初始化与更新 近似 LRU 算法的实际执行 何时触发算法执行？ 近似 LRU 算法具体如何执行？ 判断当前内存使用情况 更新待淘汰的候选键值对集合 选择被淘汰的键值对并删除 总结 参考文献",content:"# 前言\n\nLRU 是 Least Recently Used 的缩写，即最近最少使用置换算法，最经典的场景是作为虚拟页式存储管理服务的，是根据页面调入内存后的使用情况进行决策了。由于无法预测各页面将来的使用情况，只能利用“最近的过去”作为“最近的将来”的近似，因此，LRU 算法就是将最近最久未使用的页面予以淘汰。\n\n操作系统课程里有学过，在内存不够的场景下，淘汰旧内容的策略。LRU … Least Recent Used，淘汰掉最不经常使用的。可以稍微多补充两句，因为计算机体系结构中，最大的最可靠的存储是硬盘，它容量很大，并且内容可以固化，但是访问速度很慢，所以需要把使用的内容载入内存中；内存速度很快，但是容量有限，并且断电后内容会丢失，并且为了进一步提升性能，还有 CPU 内部的 L1 Cache，L2 Cache 等概念。因为速度越快的地方，它的单位成本越高，容量越小，新的内容不断被载入，旧的内容肯定要被淘汰，所以就有这样的使用背景。\n\n\n# 基于 HashMap 和 双向链表 实现 LRU\n\n146. LRU 缓存 - 力扣（LeetCode）\n\npublic class LRUCache {\n    class DLinkedNode {\n        int key;\n        int value;\n        DLinkedNode prev;\n        DLinkedNode next;\n        public DLinkedNode() {}\n        public DLinkedNode(int _key, int _value) {key = _key; value = _value;}\n    }\n\n    private Map<Integer, DLinkedNode> cache = new HashMap<Integer, DLinkedNode>();\n    private int size;\n    private int capacity;\n    private DLinkedNode head, tail;\n\n    public LRUCache(int capacity) {\n        this.size = 0;\n        this.capacity = capacity;\n        // 使用伪头部和伪尾部节点\n        head = new DLinkedNode();\n        tail = new DLinkedNode();\n        head.next = tail;\n        tail.prev = head;\n    }\n\n    public int get(int key) {\n        DLinkedNode node = cache.get(key);\n        if (node == null) {\n            return -1;\n        }\n        // 如果 key 存在，先通过哈希表定位，再移到头部\n        moveToHead(node);\n        return node.value;\n    }\n\n    public void put(int key, int value) {\n        DLinkedNode node = cache.get(key);\n        if (node == null) {\n            // 如果 key 不存在，创建一个新的节点\n            DLinkedNode newNode = new DLinkedNode(key, value);\n            // 添加进哈希表\n            cache.put(key, newNode);\n            // 添加至双向链表的头部\n            addToHead(newNode);\n            ++size;\n            if (size > capacity) {\n                // 如果超出容量，删除双向链表的尾部节点\n                DLinkedNode tail = removeTail();\n                // 删除哈希表中对应的项\n                cache.remove(tail.key);\n                --size;\n            }\n        }\n        else {\n            // 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部\n            node.value = value;\n            moveToHead(node);\n        }\n    }\n\n    private void addToHead(DLinkedNode node) {\n        node.prev = head;\n        node.next = head.next;\n        head.next.prev = node;\n        head.next = node;\n    }\n\n    private void removeNode(DLinkedNode node) {\n        node.prev.next = node.next;\n        node.next.prev = node.prev;\n    }\n\n    private void moveToHead(DLinkedNode node) {\n        removeNode(node);\n        addToHead(node);\n    }\n\n    private DLinkedNode removeTail() {\n        DLinkedNode res = tail.prev;\n        removeNode(res);\n        return res;\n    }\n}\n\n\nLRU 算法的执行，可以分成三种情况来掌握\n\n * 当有新数据插入时，LRU 算法会把该数据插入到链表头部，同时把原来链表头部的数据及其之后的数据，都向尾部移动一位。\n * 当有数据刚被访问了一次之后，LRU 算法就会把该数据从它在链表中的当前位置，移动到链表头部。同时，把从链表头部到它当前位置的其他数据，都向尾部移动一位。\n * 情况三：当链表长度无法再容纳更多数据时，若再有新数据插入，LRU 算法就会去除链表尾部的数据，这也相当于将数据从缓存中淘汰掉。\n\n\n# Redis 如何实现 LRU\n\n\n# 一些点子\n\n最直观的想法：LRU 啊，记录下每个 key 最近一次的访问时间（比如 unix timestamp），unix timestamp 最小的 Key，就是最近未使用的，把这个 Key 移除。看下来一个 HashMap 就能搞定啊。是的，但是首先需要存储每个 Key 和它的 timestamp。其次，还要比较 timestamp 得出最小值。代价很大，不现实啊。\n\n第二种方法：换个角度，不记录具体的访问时间点(unix timestamp)，而是记录 idle time：idle time 越小，意味着是最近被访问的。\n\n> The LRU algorithm evicts the Least Recently Used key, which means the one with the greatest idle time.\n\n\n\n比如 A、B、C、D 四个 Key，A 每 5s 访问一次，B 每 2s 访问一次，C 和 D 每 10s 访问一次。（一个波浪号代表 1s），从上图中可看出：A 的空闲时间是 2s，B 的 idle time 是 1s，C 的 idle time 是 5s，D 刚刚访问了所以 idle time 是 0s\n\n这里，用一个双向链表(linkedlist)把所有的 Key 链表起来，如果一个 Key 被访问了，将就这个 Key 移到链表的表头，而要移除 Key 时，直接从表尾移除。\n\n你其实可以发现，如果要严格按照 LRU 算法的基本原理来实现的话，你需要在代码中实现如下内容：\n\n * 要为 Redis 使用最大内存时，可容纳的所有数据维护一个链表；\n * 每当有新数据插入或是现有数据被再次访问时，需要执行多次链表操作。\n\n而假设 Redis 保存的数据比较多的话，那么，这两部分的代码实现，就既需要额外的内存空间来保存链表，还会在访问数据的过程中，让 Redis 受到数据移动和链表操作的开销影响，从而就会降低 Redis 访问性能。\n\n\n# 如何实现\n\n这和 Redis 配置文件 redis.conf 中的两个配置参数有关：\n\n * maxmemory，该配置项设定了 Redis server 可以使用的最大内存容量，一旦 server 使用的实际内存量超出该阈值时，server 就会根据 maxmemory-policy 配置项定义的策略，执行内存淘汰操作；\n * maxmemory-policy，该配置项设定了 Redis server 的内存淘汰策略，主要包括近似 LRU 算法、LFU 算法、按 TTL 值淘汰和随机淘汰等几种算法。\n\n我们把 Redis 对近似 LRU 算法的实现分成三个部分。\n\n * 全局 LRU 时钟值的计算：这部分包括，Redis 源码为了实现近似 LRU 算法的效果，是如何计算全局 LRU 时钟值的，以用来判断数据访问的时效性；\n * 键值对 LRU 时钟值的初始化与更新：这部分包括，Redis 源码在哪些函数中对每个键值对对应的 LRU 时钟值，进行初始化与更新；\n * 近似 LRU 算法的实际执行：这部分包括，Redis 源码具体如何执行近似 LRU 算法，也就是何时触发数据淘汰，以及实际淘汰的机制是怎么实现的。\n\n\n# 全局 LRU 时钟值的计算\n\n虽然 Redis 使用了近似 LRU 算法，但是，这个算法仍然需要区分不同数据的访问时效性，也就是说，Redis 需要知道数据的最近一次访问时间。因此，Redis 就设计了 LRU 时钟来记录数据每次访问的时间戳。\n\n我们在前面中已经了解到，Redis 在源码中对于每个键值对中的值，会使用一个 redisObject 结构体来保存指向值的指针。那么，redisObject 结构体除了记录值的指针以外，它其实还会使用 24 bits 来保存 LRU 时钟信息，对应的是 lru 成员变量。所以这样一来，每个键值对都会把它最近一次被访问的时间戳，记录在 lru 变量当中。\n\ntypedef struct redisObject {\n    unsigned type:4;\n    unsigned encoding:4;\n    unsigned lru:LRU_BITS;  //记录LRU信息，宏定义LRU_BITS是24 bits\n    int refcount;\n    void *ptr;\n} robj;\n\n\n那么，每个键值对的 LRU 时钟值具体是如何计算的呢？其实，Redis server 使用了一个实例级别的全局 LRU 时钟，每个键值对的 LRU 时钟值会根据全局 LRU 时钟进行设置。\n\n这个全局 LRU 时钟保存在了 Redis 全局变量 server 的成员变量 lruclock 中。当 Redis server 启动后，调用 initServerConfig 函数初始化各项参数时，就会对这个全局 LRU 时钟 lruclock 进行设置。具体来说，initServerConfig 函数是调用 getLRUClock 函数，来设置 lruclock 的值，如下所示：\n\n// 调用getLRUClock函数计算全局LRU时钟值\nunsigned int lruclock = getLRUClock();\n//设置lruclock为刚计算的LRU时钟值\natomicSet(server.lruclock,lruclock);\n\n\n所以，全局 LRU 时钟值就是通过 getLRUClock 函数计算得到的。\n\ngetLRUClock 函数是在 evict.c 文件中实现的，它会调用 mstime 函数（在 server.c 文件中）获得以毫秒为单位计算的 UNIX 时间戳，然后将这个 UNIX 时间戳除以宏定义 LRU_CLOCK_RESOLUTION。宏定义 LRU_CLOCK_RESOLUTION 是在 server.h 文件中定义的，它表示的是以毫秒为单位的 LRU 时钟精度，也就是以毫秒为单位来表示的 LRU 时钟最小单位。\n\n因为 LRU_CLOCK_RESOLUTION 的默认值是 1000，所以，LRU 时钟精度就是 1000 毫秒，也就是 1 秒。\n\n这样一来，你需要注意的就是，如果一个数据前后两次访问的时间间隔小于 1 秒，那么这两次访问的时间戳就是一样的。因为 LRU 时钟的精度就是 1 秒，它无法区分间隔小于 1 秒的不同时间戳。\n\n了解了宏定义 LRU_CLOCK_RESOLUTION 的含义之后，我们再来看下 getLRUClock 函数中的计算。\n\n 1. 首先，getLRUClock 函数将获得的 UNIX 时间戳，除以 LRU_CLOCK_RESOLUTION 后，就得到了以 LRU 时钟精度来计算的 UNIX 时间戳，也就是当前的 LRU 时钟值。\n 2. 紧接着，getLRUClock 函数会把 LRU 时钟值和宏定义 LRU_CLOCK_MAX 做与运算，其中宏定义 LRU_CLOCK_MAX 表示的是 LRU 时钟能表示的最大值。\n\n/* Return the LRU clock, based on the clock resolution. This is a time\n * in a reduced-bits format that can be used to set and check the\n * object->lru field of redisObject structures. */\nunsigned int getLRUClock(void) {\n    return (mstime()/LRU_CLOCK_RESOLUTION) & LRU_CLOCK_MAX;\n}\n\n\n#define LRU_BITS 24\n#define LRU_CLOCK_MAX ((1<<LRU_BITS)-1) /* Max value of obj->lru */\n#define LRU_CLOCK_RESOLUTION 1000 /* LRU clock resolution in ms */\n\n\n所以现在，你就知道了在默认情况下，全局 LRU 时钟值是以 1 秒为精度来计算的 UNIX 时间戳，并且它是在 initServerConfig 函数中进行了初始化。那么接下来，你可能还会困惑的问题是：在 Redis server 的运行过程中，全局 LRU 时钟值是如何更新的呢？\n\n这就和 Redis server 在事件驱动框架中，定期运行的时间事件所对应的 serverCron 函数有关了。\n\nserverCron 函数作为时间事件的回调函数，本身会按照一定的频率周期性执行，其频率值是由 Redis 配置文件 redis.conf 中的 hz 配置项决定的。hz 配置项的默认值是 10，这表示 serverCron 函数会每 100 毫秒（1 秒 /10 = 100 毫秒）运行一次。\n\n这样，在 serverCron 函数中，全局 LRU 时钟值就会按照这个函数的执行频率，定期调用 getLRUClock 函数进行更新，如下所示：\n\nint serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {\n    ...\n    unsigned int lruclock = getLRUClock(); //默认情况下，每100毫秒调用getLRUClock函数更新一次全局LRU时钟值\n    atomicSet(server.lruclock,lruclock); //设置lruclock变量\n    ...\n}\n\n\n所以这样一来，每个键值对就可以从全局 LRU 时钟获取最新的访问时间戳了。\n\n好，那么接下来，我们就来了解下，对于每个键值对来说，它对应的 redisObject 结构体中的 lru 变量，是在哪些函数中进行初始化和更新的。\n\n\n# 键值对 LRU 时钟值的初始化与更新\n\n首先，对于一个键值对来说，它的 LRU 时钟值最初是在这个键值对被创建的时候，进行初始化设置的，这个初始化操作是在 createObject 函数中调用的。createObject 函数实现在 object.c 文件当中，当 Redis 要创建一个键值对时，就会调用这个函数。\n\nrobj *createObject(int type, void *ptr) {\n    robj *o = zmalloc(sizeof(*o));\n    o->type = type;\n    o->encoding = OBJ_ENCODING_RAW;\n    o->ptr = ptr;\n    o->refcount = 1;\n\n    /* Set the LRU to the current lruclock (minutes resolution), or\n     * alternatively the LFU counter. */\n    if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {\n        o->lru = (LFUGetTimeInMinutes()<<8) | LFU_INIT_VAL;\n    } else {\n        o->lru = LRU_CLOCK();\n    }\n    return o;\n}\n\n\n而 createObject 函数除了会给 redisObject 结构体分配内存空间之外，它还会根据我刚才提到的 maxmemory_policy 配置项的值，来初始化设置 redisObject 结构体中的 lru 变量。\n\n具体来说，就是如果 maxmemory_policy 配置为使用 LFU 策略，那么 lru 变量值会被初始化设置为 LFU 算法的计算值。而如果 maxmemory_policy 配置项没有使用 LFU 策略，那么，createObject 函数就会调用 LRU_CLOCK 函数来设置 lru 变量的值，也就是键值对对应的 LRU 时钟值。\n\nLRU_CLOCK 函数是在 evict.c 文件中实现的，它的作用就是返回当前的全局 LRU 时钟值。因为一个键值对一旦被创建，也就相当于有了一次访问，所以它对应的 LRU 时钟值就表示了它的访问时间戳。\n\n/* This function is used to obtain the current LRU clock.\n * If the current resolution is lower than the frequency we refresh the\n * LRU clock (as it should be in production servers) we return the\n * precomputed value, otherwise we need to resort to a system call. */\nunsigned int LRU_CLOCK(void) {\n    unsigned int lruclock;\n    if (1000/server.hz <= LRU_CLOCK_RESOLUTION) {\n        atomicGet(server.lruclock,lruclock);\n    } else {\n        lruclock = getLRUClock();\n    }\n    return lruclock;\n}\n\n\n那么到这里，又出现了一个新的问题：一个键值对的 LRU 时钟值又是在什么时候被再次更新的呢？\n\n其实，只要一个键值对被访问了，它的 LRU 时钟值就会被更新。而当一个键值对被访问时，访问操作最终都会调用 lookupKey 函数。\n\nlookupKey 函数是在 db.c 文件中实现的，它会从全局哈希表中查找要访问的键值对。如果该键值对存在，那么 lookupKey 函数就会根据 maxmemory_policy 的配置值，来更新键值对的 LRU 时钟值，也就是它的访问时间戳。\n\n而当 maxmemory_policy 没有配置为 LFU 策略时，lookupKey 函数就会调用 LRU_CLOCK 函数，来获取当前的全局 LRU 时钟值，并将其赋值给键值对的 redisObject 结构体中的 lru 变量，如下所示：\n\n/* Low level key lookup API, not actually called directly from commands\n * implementations that should instead rely on lookupKeyRead(),\n * lookupKeyWrite() and lookupKeyReadWithFlags(). */\nrobj *lookupKey(redisDb *db, robj *key, int flags) {\n    dictEntry *de = dictFind(db->dict,key->ptr);\n    if (de) {\n        // 获取键值对对应的redisObject结构体\n        robj *val = dictGetVal(de);\n\n        /* Update the access time for the ageing algorithm.\n         * Don't do it if we have a saving child, as this will trigger\n         * a copy on write madness. */\n        if (!hasActiveChildProcess() && !(flags & LOOKUP_NOTOUCH)){\n            if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {\n                // 如果使用了LFU策略，更新LFU计数值\n                updateLFU(val);\n            } else {\n                 // 否则，调用LRU_CLOCK函数获取全局LRU时钟值\n                val->lru = LRU_CLOCK();\n            }\n        }\n        return val;\n    } else {\n        return NULL;\n    }\n}\n\n\n这样一来，每个键值对一旦被访问，就能获得最新的访问时间戳了。不过现在，你可能要问了：这些访问时间戳最终是如何被用于近似 LRU 算法，来进行数据淘汰的呢？接下来，我们就来学习下近似 LRU 算法的实际执行过程。\n\n\n# 近似 LRU 算法的实际执行\n\n现在我们已经知道，Redis 之所以实现近似 LRU 算法的目的，是为了减少内存资源和操作时间上的开销。那么在这里，我们其实可以从两个方面来了解近似 LRU 算法的执行过程，分别是：\n\n * 何时触发算法执行？\n * 算法具体如何执行？\n\n# 何时触发算法执行？\n\n首先，近似 LRU 算法的主要逻辑是在 freeMemoryIfNeeded 函数中实现的，而这个函数本身是在 evict.c 文件中实现。\n\nfreeMemoryIfNeeded 函数是被 freeMemoryIfNeededAndSafe 函数（在 evict.c 文件中）调用，而 freeMemoryIfNeededAndSafe 函数又是被 processCommand 函数所调用的。你可以参考下面的图，展示了这三者的调用关系。\n\n\n\n所以，我们看到 processCommand 函数，就应该知道这个函数是 Redis 处理每个命令时都会被调用的。\n\n那么，processCommand 函数在执行的时候，实际上会根据两个条件来判断是否调用 freeMemoryIfNeededAndSafe 函数。\n\n * 条件一：设置了 maxmemory 配置项为非 0 值。\n * 条件二：Lua 脚本没有在超时运行。\n\n如果这两个条件成立，那么 processCommand 函数就会调用 freeMemoryIfNeededAndSafe 函数，如下所示：\n\nif (server.maxmemory && !server.lua_timedout) {\n        int out_of_memory = freeMemoryIfNeededAndSafe() == C_ERR;\n\n\n也就是说，只有在这两个条件都不成立的情况下，freeMemoryIfNeeded 函数才会被调用。下面的代码展示了 freeMemoryIfNeededAndSafe 函数的执行逻辑，你可以看下。\n\n * 条件一：Lua 脚本在超时运行。\n * 条件二：Redis server 正在加载数据。\n\n也就是说，只有在这两个条件都不成立的情况下，freeMemoryIfNeeded 函数才会被调用。下面的代码展示了 freeMemoryIfNeededAndSafe 函数的执行逻辑，你可以看下。\n\nint freeMemoryIfNeededAndSafe(void) {\n    if (server.lua_timedout || server.loading) return C_OK;\n    return freeMemoryIfNeeded();\n}\n\n\n这样，一旦 freeMemoryIfNeeded 函数被调用了，并且 maxmemory-policy 被设置为了 allkeys-lru 或 volatile-lru，那么近似 LRU 算法就开始被触发执行了。接下来，我们就来看下近似 LRU 算法具体是如何执行的，也就是来了解 freeMemoryIfNeeded 函数的主要执行流程。\n\n# 近似 LRU 算法具体如何执行？\n\n近似 LRU 算法的执行可以分成三大步骤，分别是\n\n * 判断当前内存使用情况\n * 更新待淘汰的候选键值对集合\n * 选择被淘汰的键值对并删除\n\n下面我们就依次来看下。\n\n# 判断当前内存使用情况\n\n * 首先，freeMemoryIfNeeded 函数会调用 getMaxmemoryState 函数，评估当前的内存使用情况。getMaxmemoryState 函数是在 evict.c 文件中实现的，它会判断当前 Redis server 使用的内存容量是否超过了 maxmemory 配置的值。\n * 如果当前内存使用量没有超过 maxmemory，那么，getMaxmemoryState 函数会返回 C_OK，紧接着，freeMemoryIfNeeded 函数也会直接返回了。\n\nint freeMemoryIfNeeded(void) {\n    ...\n    if (getMaxmemoryState(&mem_reported,NULL,&mem_tofree,NULL) == C_OK)\n            return C_OK;\n    ...\n}\n\n\n这里，你需要注意的是，getMaxmemoryState 函数在评估当前内存使用情况的时候，如果发现已用内存超出了 maxmemory，它就会计算需要释放的内存量。这个释放的内存大小等于已使用的内存量减去 maxmemory。不过，已使用的内存量并不包括用于主从复制的复制缓冲区大小，这是 getMaxmemoryState 函数，通过调用 freeMemoryGetNotCountedMemory 函数来计算的。\n\n/* Get the memory status from the point of view of the maxmemory directive:\n * if the memory used is under the maxmemory setting then C_OK is returned.\n * Otherwise, if we are over the memory limit, the function returns\n * C_ERR.\n *\n * The function may return additional info via reference, only if the\n * pointers to the respective arguments is not NULL. Certain fields are\n * populated only when C_ERR is returned:\n *\n *  'total'     total amount of bytes used.\n *              (Populated both for C_ERR and C_OK)\n *\n *  'logical'   the amount of memory used minus the slaves/AOF buffers.\n *              (Populated when C_ERR is returned)\n *\n *  'tofree'    the amount of memory that should be released\n *              in order to return back into the memory limits.\n *              (Populated when C_ERR is returned)\n *\n *  'level'     this usually ranges from 0 to 1, and reports the amount of\n *              memory currently used. May be > 1 if we are over the memory\n *              limit.\n *              (Populated both for C_ERR and C_OK)\n */\nint getMaxmemoryState(size_t *total, size_t *logical, size_t *tofree, float *level) {\n    size_t mem_reported, mem_used, mem_tofree;\n\n    /* Check if we are over the memory usage limit. If we are not, no need\n     * to subtract the slaves output buffers. We can just return ASAP. */\n    // 计算已使用的内存量\n    mem_reported = zmalloc_used_memory();\n    if (total) *total = mem_reported;\n\n    /* We may return ASAP if there is no need to compute the level. */\n    int return_ok_asap = !server.maxmemory || mem_reported <= server.maxmemory;\n    if (return_ok_asap && !level) return C_OK;\n\n    /* Remove the size of slaves output buffers and AOF buffer from the\n     * count of used memory. */\n    // 将用于主从复制的复制缓冲区大小和AOF缓冲区大小从已使用内存量中扣除\n    mem_used = mem_reported;\n    size_t overhead = freeMemoryGetNotCountedMemory();\n    mem_used = (mem_used > overhead) ? mem_used-overhead : 0;\n\n\n    /* Compute the ratio of memory usage. */\n    // 计算内存使用率。\n    if (level) {\n        if (!server.maxmemory) {\n            *level = 0;\n        } else {\n            *level = (float)mem_used / (float)server.maxmemory;\n        }\n    }\n\n    if (return_ok_asap) return C_OK;\n\n    /* Check if we are still over the memory limit. */\n    // 检查我们是否仍然超过内存限制。\n    if (mem_used <= server.maxmemory) return C_OK;\n\n    // 计算需要释放的内存量\n    /* Compute how much memory we need to free. */\n    mem_tofree = mem_used - server.maxmemory;\n\n    if (logical) *logical = mem_used;\n    if (tofree) *tofree = mem_tofree;\n\n    return C_ERR;\n}\n\n\n而如果当前 server 使用的内存量，的确已经超出 maxmemory 的上限了，那么 freeMemoryIfNeeded 函数就会执行一个 while 循环，来淘汰数据释放内存。\n\n其实，为了淘汰数据，Redis 定义了一个数组 EvictionPoolLRU，用来保存待淘汰的候选键值对。这个数组的元素类型是 evictionPoolEntry 结构体，该结构体保存了待淘汰键值对的空闲时间 idle、对应的 key 等信息。以下代码展示了 EvictionPoolLRU 数组和 evictionPoolEntry 结构体，它们都是在 evict.c 文件中定义的。\n\nstruct evictionPoolEntry {\n    // 待淘汰的键值对的空闲时间\n    unsigned long long idle;    /* Object idle time (inverse frequency for LFU) */\n    // 待淘汰的键值对的key\n    sds key;                    /* Key name. */\n    // 缓存的SDS对象\n    sds cached;                 /* Cached SDS object for key name. */\n    // 待淘汰键值对的key所在的数据库ID\n    int dbid;                   /* Key DB number. */\n};\n\nstatic struct evictionPoolEntry *EvictionPoolLRU;\n\n\n这样，Redis server 在执行 initSever 函数进行初始化时，会调用 evictionPoolAlloc 函数（在 evict.c 文件中）为 EvictionPoolLRU 数组分配内存空间，该数组的大小由宏定义 EVPOOL_SIZE（在 evict.c 文件中）决定，默认是 16 个元素，也就是可以保存 16 个待淘汰的候选键值对。\n\n#define EVPOOL_SIZE 16\n\n/* Create a new eviction pool. */\nvoid evictionPoolAlloc(void) {\n    struct evictionPoolEntry *ep;\n    int j;\n\n    ep = zmalloc(sizeof(*ep)*EVPOOL_SIZE);\n    for (j = 0; j < EVPOOL_SIZE; j++) {\n        ep[j].idle = 0;\n        ep[j].key = NULL;\n        ep[j].cached = sdsnewlen(NULL,EVPOOL_CACHED_SDS_SIZE);\n        ep[j].dbid = 0;\n    }\n    EvictionPoolLRU = ep;\n}\n\n\n那么，freeMemoryIfNeeded 函数在淘汰数据的循环流程中，就会更新这个待淘汰的候选键值对集合，也就是 EvictionPoolLRU 数组。下面我就来给你具体介绍一下。\n\n# 更新待淘汰的候选键值对集合\n\n首先，freeMemoryIfNeeded 函数会调用 evictionPoolPopulate 函数（在 evict.c 文件中），而 evictionPoolPopulate 函数会先调用 dictGetSomeKeys 函数（在 dict.c 文件中），从待采样的哈希表中随机获取一定数量的 key。不过，这里还有两个地方你需要注意下。\n\n第一点，dictGetSomeKeys 函数采样的哈希表，是由 maxmemory_policy 配置项来决定的。如果 maxmemory_policy 配置的是 allkeys_lru，那么待采样哈希表就是 Redis server 的全局哈希表，也就是在所有键值对中进行采样；否则，待采样哈希表就是保存着设置了过期时间的 key 的哈希表。\n\n以下代码是 freeMemoryIfNeeded 函数中对 evictionPoolPopulate 函数的调用过程，你可以看下。\n\n/* We don't want to make local-db choices when expiring keys,\n * so to start populate the eviction pool sampling keys from\n * every DB. */\nfor (i = 0; i < server.dbnum; i++) {\n    // 对Redis server上的每一个数据库都执行\n    db = server.db+i;\n    // 根据淘汰策略，决定使用全局哈希表还是设置了过期时间的key的哈希表\n    dict = (server.maxmemory_policy & MAXMEMORY_FLAG_ALLKEYS) ?\n            db->dict : db->expires;\n    // 将选择的哈希表dict传入evictionPoolPopulate函数，同时将全局哈希表也传给evictionPoolPopulate函数\n    if ((keys = dictSize(dict)) != 0) {\n        evictionPoolPopulate(i, dict, db->dict, pool);\n        total_keys += keys;\n    }\n}\n\n\n第二点，dictGetSomeKeys 函数采样的 key 的数量，是由 redis.conf 中的配置项 maxmemory-samples 决定的，该配置项的默认值是 5。下面代码就展示了 evictionPoolPopulate 函数对 dictGetSomeKeys 函数的调用：\n\nvoid evictionPoolPopulate(int dbid, dict *sampledict, dict *keydict, struct evictionPoolEntry *pool) {\n    ...\n    dictEntry *samples[server.maxmemory_samples];  //采样后的集合，大小为maxmemory_samples\n    //将待采样的哈希表sampledict、采样后的集合samples、以及采样数量maxmemory_samples，作为参数传给dictGetSomeKeys\n    count = dictGetSomeKeys(sampledict,samples,server.maxmemory_samples);\n    ...\n}\n\n\n如此一来，dictGetSomeKeys 函数就能返回采样的键值对集合了。然后，evictionPoolPopulate 函数会根据实际采样到的键值对数量 count，执行一个循环。\n\nfor (j = 0; j < count; j++) {\n...\nif (server.maxmemory_policy & MAXMEMORY_FLAG_LRU) {\n            idle = estimateObjectIdleTime(o);\n}\n...\n\n\n紧接着，evictionPoolPopulate 函数会遍历待淘汰的候选键值对集合，也就是 EvictionPoolLRU 数组。在遍历过程中，它会尝试把采样的每一个键值对插入 EvictionPoolLRU 数组，这主要取决于以下两个条件之一：\n\n * 一是，它能在数组中找到一个尚未插入键值对的空位；\n * 二是，它能在数组中找到一个空闲时间小于采样键值对空闲时间的键值对\n\n这两个条件有一个成立的话，evictionPoolPopulate 函数就可以把采样键值对插入 EvictionPoolLRU 数组。等所有采样键值对都处理完后，evictionPoolPopulate 函数就完成对待淘汰候选键值对集合的更新了。\n\n接下来，freeMemoryIfNeeded 函数，就可以开始选择最终被淘汰的键值对了。\n\n# 选择被淘汰的键值对并删除\n\n因为 evictionPoolPopulate 函数已经更新了 EvictionPoolLRU 数组，而且这个数组里面的 key，是按照空闲时间从小到大排好序了。所以，freeMemoryIfNeeded 函数会遍历一次 EvictionPoolLRU 数组，从数组的最后一个 key 开始选择，如果选到的 key 不是空值，那么就把它作为最终淘汰的 key。\n\n// 从数组最后一个key开始查找\n/* Go backward from best to worst element to evict. */\nfor (k = EVPOOL_SIZE-1; k >= 0; k--) {\n    // 当前key为空值，则查找下一个key\n    if (pool[k].key == NULL) continue;\n    bestdbid = pool[k].dbid;\n    // 从全局哈希表或是expire哈希表中，获取当前key对应的键值对；并将当前key从EvictionPoolLRU数组删除\n    if (server.maxmemory_policy & MAXMEMORY_FLAG_ALLKEYS) {\n        de = dictFind(server.db[pool[k].dbid].dict,\n            pool[k].key);\n    } else {\n        de = dictFind(server.db[pool[k].dbid].expires,\n            pool[k].key);\n    }\n\n    /* Remove the entry from the pool. */\n    if (pool[k].key != pool[k].cached)\n        sdsfree(pool[k].key);\n    pool[k].key = NULL;\n    pool[k].idle = 0;\n\n    /* If the key exists, is our pick. Otherwise it is\n     * a ghost and we need to try the next element. */\n    // 如果当前key对应的键值对不为空，选择当前key为被淘汰的key\n    if (de) {\n        bestkey = dictGetKey(de);\n        break;\n    } else {\n        //否则，继续查找下个key\n        /* Ghost... Iterate again. */\n    }\n}\n\n\n最后，一旦选到了被淘汰的 key，freeMemoryIfNeeded 函数就会根据 Redis server 的惰性删除配置，来执行同步删除或异步删除，如下所示：\n\nif (bestkey) {\n    db = server.db+bestdbid;\n    robj *keyobj = createStringObject(bestkey,sdslen(bestkey));        //将删除key的信息传递给从库和AOF文件\n    propagateExpire(db,keyobj,server.lazyfree_lazy_eviction);\n    //如果配置了惰性删除，则进行异步删除\n    if (server.lazyfree_lazy_eviction)\n    \tdbAsyncDelete(db,keyobj);\n    else  //否则进行同步删除\n    \tdbSyncDelete(db,keyobj);\n}\n\n\n好了，到这里，freeMemoryIfNeeded 函数就淘汰了一个 key。而如果此时，释放的内存空间还不够，也就是说没有达到我前面介绍的待释放空间，那么 freeMemoryIfNeeded 函数还会重复执行前面所说的更新待淘汰候选键值对集合、选择最终淘汰 key 的过程，直到满足待释放空间的大小要求。\n\n下图就展示了 freeMemoryIfNeeded 函数涉及的基本流程，你可以再来整体回顾下。\n\n\n\n其实，从刚才介绍的内容中，你就可以看到，近似 LRU 算法并没有使用耗时耗空间的链表，而是使用了固定大小的待淘汰数据集合，每次随机选择一些 key 加入待淘汰数据集合中。最后，再按照待淘汰集合中 key 的空闲时间长度，删除空闲时间最长的 key。这样一来，Redis 就近似实现了 LRU 算法的效果了。\n\n\n# 总结\n\n你现在应该知道了 Redis 是如何实现 LRU 算法来进行缓存数据替换的。其中，我们根据 LRU 算法的基本原理，可以发现如果严格按照原理来实现 LRU 算法，那么开发的系统就需要用额外的内存空间来保存 LRU 链表，而且系统运行时也会受到 LRU 链表操作的开销影响。\n\n而对于 Redis 来说，内存资源和性能都很重要，所以 Redis 实现了近似 LRU 算法。而为了实现近似 LRU 算法，Redis 首先是设置了全局 LRU 时钟，并在键值对创建时获取全局 LRU 时钟值作为访问时间戳，以及在每次访问时获取全局 LRU 时钟值，更新访问时间戳。\n\n然后，当 Redis 每处理一个命令时，都会调用 freeMemoryIfNeeded 函数来判断是否需要释放内存。如果已使用内存超出了 maxmemory，那么，近似 LRU 算法就会随机选择一些键值对，组成待淘汰候选集合，并根据它们的访问时间戳，选出最旧的数据，将其淘汰。\n\nRedis 计算实例内存时，不会把「主从复制」的缓冲区计算在内，也就是说不管一个实例后面挂了多少个从库，主库不会把主从复制所需的「缓冲区」内存，计算到实例内存中，即这部分内存增加，不会对数据淘汰产生影响。\n\n\n# 参考文献\n\nRedis 源码剖析与实战 (geekbang.org)",normalizedContent:"# 前言\n\nlru 是 least recently used 的缩写，即最近最少使用置换算法，最经典的场景是作为虚拟页式存储管理服务的，是根据页面调入内存后的使用情况进行决策了。由于无法预测各页面将来的使用情况，只能利用“最近的过去”作为“最近的将来”的近似，因此，lru 算法就是将最近最久未使用的页面予以淘汰。\n\n操作系统课程里有学过，在内存不够的场景下，淘汰旧内容的策略。lru … least recent used，淘汰掉最不经常使用的。可以稍微多补充两句，因为计算机体系结构中，最大的最可靠的存储是硬盘，它容量很大，并且内容可以固化，但是访问速度很慢，所以需要把使用的内容载入内存中；内存速度很快，但是容量有限，并且断电后内容会丢失，并且为了进一步提升性能，还有 cpu 内部的 l1 cache，l2 cache 等概念。因为速度越快的地方，它的单位成本越高，容量越小，新的内容不断被载入，旧的内容肯定要被淘汰，所以就有这样的使用背景。\n\n\n# 基于 hashmap 和 双向链表 实现 lru\n\n146. lru 缓存 - 力扣（leetcode）\n\npublic class lrucache {\n    class dlinkednode {\n        int key;\n        int value;\n        dlinkednode prev;\n        dlinkednode next;\n        public dlinkednode() {}\n        public dlinkednode(int _key, int _value) {key = _key; value = _value;}\n    }\n\n    private map<integer, dlinkednode> cache = new hashmap<integer, dlinkednode>();\n    private int size;\n    private int capacity;\n    private dlinkednode head, tail;\n\n    public lrucache(int capacity) {\n        this.size = 0;\n        this.capacity = capacity;\n        // 使用伪头部和伪尾部节点\n        head = new dlinkednode();\n        tail = new dlinkednode();\n        head.next = tail;\n        tail.prev = head;\n    }\n\n    public int get(int key) {\n        dlinkednode node = cache.get(key);\n        if (node == null) {\n            return -1;\n        }\n        // 如果 key 存在，先通过哈希表定位，再移到头部\n        movetohead(node);\n        return node.value;\n    }\n\n    public void put(int key, int value) {\n        dlinkednode node = cache.get(key);\n        if (node == null) {\n            // 如果 key 不存在，创建一个新的节点\n            dlinkednode newnode = new dlinkednode(key, value);\n            // 添加进哈希表\n            cache.put(key, newnode);\n            // 添加至双向链表的头部\n            addtohead(newnode);\n            ++size;\n            if (size > capacity) {\n                // 如果超出容量，删除双向链表的尾部节点\n                dlinkednode tail = removetail();\n                // 删除哈希表中对应的项\n                cache.remove(tail.key);\n                --size;\n            }\n        }\n        else {\n            // 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部\n            node.value = value;\n            movetohead(node);\n        }\n    }\n\n    private void addtohead(dlinkednode node) {\n        node.prev = head;\n        node.next = head.next;\n        head.next.prev = node;\n        head.next = node;\n    }\n\n    private void removenode(dlinkednode node) {\n        node.prev.next = node.next;\n        node.next.prev = node.prev;\n    }\n\n    private void movetohead(dlinkednode node) {\n        removenode(node);\n        addtohead(node);\n    }\n\n    private dlinkednode removetail() {\n        dlinkednode res = tail.prev;\n        removenode(res);\n        return res;\n    }\n}\n\n\nlru 算法的执行，可以分成三种情况来掌握\n\n * 当有新数据插入时，lru 算法会把该数据插入到链表头部，同时把原来链表头部的数据及其之后的数据，都向尾部移动一位。\n * 当有数据刚被访问了一次之后，lru 算法就会把该数据从它在链表中的当前位置，移动到链表头部。同时，把从链表头部到它当前位置的其他数据，都向尾部移动一位。\n * 情况三：当链表长度无法再容纳更多数据时，若再有新数据插入，lru 算法就会去除链表尾部的数据，这也相当于将数据从缓存中淘汰掉。\n\n\n# redis 如何实现 lru\n\n\n# 一些点子\n\n最直观的想法：lru 啊，记录下每个 key 最近一次的访问时间（比如 unix timestamp），unix timestamp 最小的 key，就是最近未使用的，把这个 key 移除。看下来一个 hashmap 就能搞定啊。是的，但是首先需要存储每个 key 和它的 timestamp。其次，还要比较 timestamp 得出最小值。代价很大，不现实啊。\n\n第二种方法：换个角度，不记录具体的访问时间点(unix timestamp)，而是记录 idle time：idle time 越小，意味着是最近被访问的。\n\n> the lru algorithm evicts the least recently used key, which means the one with the greatest idle time.\n\n\n\n比如 a、b、c、d 四个 key，a 每 5s 访问一次，b 每 2s 访问一次，c 和 d 每 10s 访问一次。（一个波浪号代表 1s），从上图中可看出：a 的空闲时间是 2s，b 的 idle time 是 1s，c 的 idle time 是 5s，d 刚刚访问了所以 idle time 是 0s\n\n这里，用一个双向链表(linkedlist)把所有的 key 链表起来，如果一个 key 被访问了，将就这个 key 移到链表的表头，而要移除 key 时，直接从表尾移除。\n\n你其实可以发现，如果要严格按照 lru 算法的基本原理来实现的话，你需要在代码中实现如下内容：\n\n * 要为 redis 使用最大内存时，可容纳的所有数据维护一个链表；\n * 每当有新数据插入或是现有数据被再次访问时，需要执行多次链表操作。\n\n而假设 redis 保存的数据比较多的话，那么，这两部分的代码实现，就既需要额外的内存空间来保存链表，还会在访问数据的过程中，让 redis 受到数据移动和链表操作的开销影响，从而就会降低 redis 访问性能。\n\n\n# 如何实现\n\n这和 redis 配置文件 redis.conf 中的两个配置参数有关：\n\n * maxmemory，该配置项设定了 redis server 可以使用的最大内存容量，一旦 server 使用的实际内存量超出该阈值时，server 就会根据 maxmemory-policy 配置项定义的策略，执行内存淘汰操作；\n * maxmemory-policy，该配置项设定了 redis server 的内存淘汰策略，主要包括近似 lru 算法、lfu 算法、按 ttl 值淘汰和随机淘汰等几种算法。\n\n我们把 redis 对近似 lru 算法的实现分成三个部分。\n\n * 全局 lru 时钟值的计算：这部分包括，redis 源码为了实现近似 lru 算法的效果，是如何计算全局 lru 时钟值的，以用来判断数据访问的时效性；\n * 键值对 lru 时钟值的初始化与更新：这部分包括，redis 源码在哪些函数中对每个键值对对应的 lru 时钟值，进行初始化与更新；\n * 近似 lru 算法的实际执行：这部分包括，redis 源码具体如何执行近似 lru 算法，也就是何时触发数据淘汰，以及实际淘汰的机制是怎么实现的。\n\n\n# 全局 lru 时钟值的计算\n\n虽然 redis 使用了近似 lru 算法，但是，这个算法仍然需要区分不同数据的访问时效性，也就是说，redis 需要知道数据的最近一次访问时间。因此，redis 就设计了 lru 时钟来记录数据每次访问的时间戳。\n\n我们在前面中已经了解到，redis 在源码中对于每个键值对中的值，会使用一个 redisobject 结构体来保存指向值的指针。那么，redisobject 结构体除了记录值的指针以外，它其实还会使用 24 bits 来保存 lru 时钟信息，对应的是 lru 成员变量。所以这样一来，每个键值对都会把它最近一次被访问的时间戳，记录在 lru 变量当中。\n\ntypedef struct redisobject {\n    unsigned type:4;\n    unsigned encoding:4;\n    unsigned lru:lru_bits;  //记录lru信息，宏定义lru_bits是24 bits\n    int refcount;\n    void *ptr;\n} robj;\n\n\n那么，每个键值对的 lru 时钟值具体是如何计算的呢？其实，redis server 使用了一个实例级别的全局 lru 时钟，每个键值对的 lru 时钟值会根据全局 lru 时钟进行设置。\n\n这个全局 lru 时钟保存在了 redis 全局变量 server 的成员变量 lruclock 中。当 redis server 启动后，调用 initserverconfig 函数初始化各项参数时，就会对这个全局 lru 时钟 lruclock 进行设置。具体来说，initserverconfig 函数是调用 getlruclock 函数，来设置 lruclock 的值，如下所示：\n\n// 调用getlruclock函数计算全局lru时钟值\nunsigned int lruclock = getlruclock();\n//设置lruclock为刚计算的lru时钟值\natomicset(server.lruclock,lruclock);\n\n\n所以，全局 lru 时钟值就是通过 getlruclock 函数计算得到的。\n\ngetlruclock 函数是在 evict.c 文件中实现的，它会调用 mstime 函数（在 server.c 文件中）获得以毫秒为单位计算的 unix 时间戳，然后将这个 unix 时间戳除以宏定义 lru_clock_resolution。宏定义 lru_clock_resolution 是在 server.h 文件中定义的，它表示的是以毫秒为单位的 lru 时钟精度，也就是以毫秒为单位来表示的 lru 时钟最小单位。\n\n因为 lru_clock_resolution 的默认值是 1000，所以，lru 时钟精度就是 1000 毫秒，也就是 1 秒。\n\n这样一来，你需要注意的就是，如果一个数据前后两次访问的时间间隔小于 1 秒，那么这两次访问的时间戳就是一样的。因为 lru 时钟的精度就是 1 秒，它无法区分间隔小于 1 秒的不同时间戳。\n\n了解了宏定义 lru_clock_resolution 的含义之后，我们再来看下 getlruclock 函数中的计算。\n\n 1. 首先，getlruclock 函数将获得的 unix 时间戳，除以 lru_clock_resolution 后，就得到了以 lru 时钟精度来计算的 unix 时间戳，也就是当前的 lru 时钟值。\n 2. 紧接着，getlruclock 函数会把 lru 时钟值和宏定义 lru_clock_max 做与运算，其中宏定义 lru_clock_max 表示的是 lru 时钟能表示的最大值。\n\n/* return the lru clock, based on the clock resolution. this is a time\n * in a reduced-bits format that can be used to set and check the\n * object->lru field of redisobject structures. */\nunsigned int getlruclock(void) {\n    return (mstime()/lru_clock_resolution) & lru_clock_max;\n}\n\n\n#define lru_bits 24\n#define lru_clock_max ((1<<lru_bits)-1) /* max value of obj->lru */\n#define lru_clock_resolution 1000 /* lru clock resolution in ms */\n\n\n所以现在，你就知道了在默认情况下，全局 lru 时钟值是以 1 秒为精度来计算的 unix 时间戳，并且它是在 initserverconfig 函数中进行了初始化。那么接下来，你可能还会困惑的问题是：在 redis server 的运行过程中，全局 lru 时钟值是如何更新的呢？\n\n这就和 redis server 在事件驱动框架中，定期运行的时间事件所对应的 servercron 函数有关了。\n\nservercron 函数作为时间事件的回调函数，本身会按照一定的频率周期性执行，其频率值是由 redis 配置文件 redis.conf 中的 hz 配置项决定的。hz 配置项的默认值是 10，这表示 servercron 函数会每 100 毫秒（1 秒 /10 = 100 毫秒）运行一次。\n\n这样，在 servercron 函数中，全局 lru 时钟值就会按照这个函数的执行频率，定期调用 getlruclock 函数进行更新，如下所示：\n\nint servercron(struct aeeventloop *eventloop, long long id, void *clientdata) {\n    ...\n    unsigned int lruclock = getlruclock(); //默认情况下，每100毫秒调用getlruclock函数更新一次全局lru时钟值\n    atomicset(server.lruclock,lruclock); //设置lruclock变量\n    ...\n}\n\n\n所以这样一来，每个键值对就可以从全局 lru 时钟获取最新的访问时间戳了。\n\n好，那么接下来，我们就来了解下，对于每个键值对来说，它对应的 redisobject 结构体中的 lru 变量，是在哪些函数中进行初始化和更新的。\n\n\n# 键值对 lru 时钟值的初始化与更新\n\n首先，对于一个键值对来说，它的 lru 时钟值最初是在这个键值对被创建的时候，进行初始化设置的，这个初始化操作是在 createobject 函数中调用的。createobject 函数实现在 object.c 文件当中，当 redis 要创建一个键值对时，就会调用这个函数。\n\nrobj *createobject(int type, void *ptr) {\n    robj *o = zmalloc(sizeof(*o));\n    o->type = type;\n    o->encoding = obj_encoding_raw;\n    o->ptr = ptr;\n    o->refcount = 1;\n\n    /* set the lru to the current lruclock (minutes resolution), or\n     * alternatively the lfu counter. */\n    if (server.maxmemory_policy & maxmemory_flag_lfu) {\n        o->lru = (lfugettimeinminutes()<<8) | lfu_init_val;\n    } else {\n        o->lru = lru_clock();\n    }\n    return o;\n}\n\n\n而 createobject 函数除了会给 redisobject 结构体分配内存空间之外，它还会根据我刚才提到的 maxmemory_policy 配置项的值，来初始化设置 redisobject 结构体中的 lru 变量。\n\n具体来说，就是如果 maxmemory_policy 配置为使用 lfu 策略，那么 lru 变量值会被初始化设置为 lfu 算法的计算值。而如果 maxmemory_policy 配置项没有使用 lfu 策略，那么，createobject 函数就会调用 lru_clock 函数来设置 lru 变量的值，也就是键值对对应的 lru 时钟值。\n\nlru_clock 函数是在 evict.c 文件中实现的，它的作用就是返回当前的全局 lru 时钟值。因为一个键值对一旦被创建，也就相当于有了一次访问，所以它对应的 lru 时钟值就表示了它的访问时间戳。\n\n/* this function is used to obtain the current lru clock.\n * if the current resolution is lower than the frequency we refresh the\n * lru clock (as it should be in production servers) we return the\n * precomputed value, otherwise we need to resort to a system call. */\nunsigned int lru_clock(void) {\n    unsigned int lruclock;\n    if (1000/server.hz <= lru_clock_resolution) {\n        atomicget(server.lruclock,lruclock);\n    } else {\n        lruclock = getlruclock();\n    }\n    return lruclock;\n}\n\n\n那么到这里，又出现了一个新的问题：一个键值对的 lru 时钟值又是在什么时候被再次更新的呢？\n\n其实，只要一个键值对被访问了，它的 lru 时钟值就会被更新。而当一个键值对被访问时，访问操作最终都会调用 lookupkey 函数。\n\nlookupkey 函数是在 db.c 文件中实现的，它会从全局哈希表中查找要访问的键值对。如果该键值对存在，那么 lookupkey 函数就会根据 maxmemory_policy 的配置值，来更新键值对的 lru 时钟值，也就是它的访问时间戳。\n\n而当 maxmemory_policy 没有配置为 lfu 策略时，lookupkey 函数就会调用 lru_clock 函数，来获取当前的全局 lru 时钟值，并将其赋值给键值对的 redisobject 结构体中的 lru 变量，如下所示：\n\n/* low level key lookup api, not actually called directly from commands\n * implementations that should instead rely on lookupkeyread(),\n * lookupkeywrite() and lookupkeyreadwithflags(). */\nrobj *lookupkey(redisdb *db, robj *key, int flags) {\n    dictentry *de = dictfind(db->dict,key->ptr);\n    if (de) {\n        // 获取键值对对应的redisobject结构体\n        robj *val = dictgetval(de);\n\n        /* update the access time for the ageing algorithm.\n         * don't do it if we have a saving child, as this will trigger\n         * a copy on write madness. */\n        if (!hasactivechildprocess() && !(flags & lookup_notouch)){\n            if (server.maxmemory_policy & maxmemory_flag_lfu) {\n                // 如果使用了lfu策略，更新lfu计数值\n                updatelfu(val);\n            } else {\n                 // 否则，调用lru_clock函数获取全局lru时钟值\n                val->lru = lru_clock();\n            }\n        }\n        return val;\n    } else {\n        return null;\n    }\n}\n\n\n这样一来，每个键值对一旦被访问，就能获得最新的访问时间戳了。不过现在，你可能要问了：这些访问时间戳最终是如何被用于近似 lru 算法，来进行数据淘汰的呢？接下来，我们就来学习下近似 lru 算法的实际执行过程。\n\n\n# 近似 lru 算法的实际执行\n\n现在我们已经知道，redis 之所以实现近似 lru 算法的目的，是为了减少内存资源和操作时间上的开销。那么在这里，我们其实可以从两个方面来了解近似 lru 算法的执行过程，分别是：\n\n * 何时触发算法执行？\n * 算法具体如何执行？\n\n# 何时触发算法执行？\n\n首先，近似 lru 算法的主要逻辑是在 freememoryifneeded 函数中实现的，而这个函数本身是在 evict.c 文件中实现。\n\nfreememoryifneeded 函数是被 freememoryifneededandsafe 函数（在 evict.c 文件中）调用，而 freememoryifneededandsafe 函数又是被 processcommand 函数所调用的。你可以参考下面的图，展示了这三者的调用关系。\n\n\n\n所以，我们看到 processcommand 函数，就应该知道这个函数是 redis 处理每个命令时都会被调用的。\n\n那么，processcommand 函数在执行的时候，实际上会根据两个条件来判断是否调用 freememoryifneededandsafe 函数。\n\n * 条件一：设置了 maxmemory 配置项为非 0 值。\n * 条件二：lua 脚本没有在超时运行。\n\n如果这两个条件成立，那么 processcommand 函数就会调用 freememoryifneededandsafe 函数，如下所示：\n\nif (server.maxmemory && !server.lua_timedout) {\n        int out_of_memory = freememoryifneededandsafe() == c_err;\n\n\n也就是说，只有在这两个条件都不成立的情况下，freememoryifneeded 函数才会被调用。下面的代码展示了 freememoryifneededandsafe 函数的执行逻辑，你可以看下。\n\n * 条件一：lua 脚本在超时运行。\n * 条件二：redis server 正在加载数据。\n\n也就是说，只有在这两个条件都不成立的情况下，freememoryifneeded 函数才会被调用。下面的代码展示了 freememoryifneededandsafe 函数的执行逻辑，你可以看下。\n\nint freememoryifneededandsafe(void) {\n    if (server.lua_timedout || server.loading) return c_ok;\n    return freememoryifneeded();\n}\n\n\n这样，一旦 freememoryifneeded 函数被调用了，并且 maxmemory-policy 被设置为了 allkeys-lru 或 volatile-lru，那么近似 lru 算法就开始被触发执行了。接下来，我们就来看下近似 lru 算法具体是如何执行的，也就是来了解 freememoryifneeded 函数的主要执行流程。\n\n# 近似 lru 算法具体如何执行？\n\n近似 lru 算法的执行可以分成三大步骤，分别是\n\n * 判断当前内存使用情况\n * 更新待淘汰的候选键值对集合\n * 选择被淘汰的键值对并删除\n\n下面我们就依次来看下。\n\n# 判断当前内存使用情况\n\n * 首先，freememoryifneeded 函数会调用 getmaxmemorystate 函数，评估当前的内存使用情况。getmaxmemorystate 函数是在 evict.c 文件中实现的，它会判断当前 redis server 使用的内存容量是否超过了 maxmemory 配置的值。\n * 如果当前内存使用量没有超过 maxmemory，那么，getmaxmemorystate 函数会返回 c_ok，紧接着，freememoryifneeded 函数也会直接返回了。\n\nint freememoryifneeded(void) {\n    ...\n    if (getmaxmemorystate(&mem_reported,null,&mem_tofree,null) == c_ok)\n            return c_ok;\n    ...\n}\n\n\n这里，你需要注意的是，getmaxmemorystate 函数在评估当前内存使用情况的时候，如果发现已用内存超出了 maxmemory，它就会计算需要释放的内存量。这个释放的内存大小等于已使用的内存量减去 maxmemory。不过，已使用的内存量并不包括用于主从复制的复制缓冲区大小，这是 getmaxmemorystate 函数，通过调用 freememorygetnotcountedmemory 函数来计算的。\n\n/* get the memory status from the point of view of the maxmemory directive:\n * if the memory used is under the maxmemory setting then c_ok is returned.\n * otherwise, if we are over the memory limit, the function returns\n * c_err.\n *\n * the function may return additional info via reference, only if the\n * pointers to the respective arguments is not null. certain fields are\n * populated only when c_err is returned:\n *\n *  'total'     total amount of bytes used.\n *              (populated both for c_err and c_ok)\n *\n *  'logical'   the amount of memory used minus the slaves/aof buffers.\n *              (populated when c_err is returned)\n *\n *  'tofree'    the amount of memory that should be released\n *              in order to return back into the memory limits.\n *              (populated when c_err is returned)\n *\n *  'level'     this usually ranges from 0 to 1, and reports the amount of\n *              memory currently used. may be > 1 if we are over the memory\n *              limit.\n *              (populated both for c_err and c_ok)\n */\nint getmaxmemorystate(size_t *total, size_t *logical, size_t *tofree, float *level) {\n    size_t mem_reported, mem_used, mem_tofree;\n\n    /* check if we are over the memory usage limit. if we are not, no need\n     * to subtract the slaves output buffers. we can just return asap. */\n    // 计算已使用的内存量\n    mem_reported = zmalloc_used_memory();\n    if (total) *total = mem_reported;\n\n    /* we may return asap if there is no need to compute the level. */\n    int return_ok_asap = !server.maxmemory || mem_reported <= server.maxmemory;\n    if (return_ok_asap && !level) return c_ok;\n\n    /* remove the size of slaves output buffers and aof buffer from the\n     * count of used memory. */\n    // 将用于主从复制的复制缓冲区大小和aof缓冲区大小从已使用内存量中扣除\n    mem_used = mem_reported;\n    size_t overhead = freememorygetnotcountedmemory();\n    mem_used = (mem_used > overhead) ? mem_used-overhead : 0;\n\n\n    /* compute the ratio of memory usage. */\n    // 计算内存使用率。\n    if (level) {\n        if (!server.maxmemory) {\n            *level = 0;\n        } else {\n            *level = (float)mem_used / (float)server.maxmemory;\n        }\n    }\n\n    if (return_ok_asap) return c_ok;\n\n    /* check if we are still over the memory limit. */\n    // 检查我们是否仍然超过内存限制。\n    if (mem_used <= server.maxmemory) return c_ok;\n\n    // 计算需要释放的内存量\n    /* compute how much memory we need to free. */\n    mem_tofree = mem_used - server.maxmemory;\n\n    if (logical) *logical = mem_used;\n    if (tofree) *tofree = mem_tofree;\n\n    return c_err;\n}\n\n\n而如果当前 server 使用的内存量，的确已经超出 maxmemory 的上限了，那么 freememoryifneeded 函数就会执行一个 while 循环，来淘汰数据释放内存。\n\n其实，为了淘汰数据，redis 定义了一个数组 evictionpoollru，用来保存待淘汰的候选键值对。这个数组的元素类型是 evictionpoolentry 结构体，该结构体保存了待淘汰键值对的空闲时间 idle、对应的 key 等信息。以下代码展示了 evictionpoollru 数组和 evictionpoolentry 结构体，它们都是在 evict.c 文件中定义的。\n\nstruct evictionpoolentry {\n    // 待淘汰的键值对的空闲时间\n    unsigned long long idle;    /* object idle time (inverse frequency for lfu) */\n    // 待淘汰的键值对的key\n    sds key;                    /* key name. */\n    // 缓存的sds对象\n    sds cached;                 /* cached sds object for key name. */\n    // 待淘汰键值对的key所在的数据库id\n    int dbid;                   /* key db number. */\n};\n\nstatic struct evictionpoolentry *evictionpoollru;\n\n\n这样，redis server 在执行 initsever 函数进行初始化时，会调用 evictionpoolalloc 函数（在 evict.c 文件中）为 evictionpoollru 数组分配内存空间，该数组的大小由宏定义 evpool_size（在 evict.c 文件中）决定，默认是 16 个元素，也就是可以保存 16 个待淘汰的候选键值对。\n\n#define evpool_size 16\n\n/* create a new eviction pool. */\nvoid evictionpoolalloc(void) {\n    struct evictionpoolentry *ep;\n    int j;\n\n    ep = zmalloc(sizeof(*ep)*evpool_size);\n    for (j = 0; j < evpool_size; j++) {\n        ep[j].idle = 0;\n        ep[j].key = null;\n        ep[j].cached = sdsnewlen(null,evpool_cached_sds_size);\n        ep[j].dbid = 0;\n    }\n    evictionpoollru = ep;\n}\n\n\n那么，freememoryifneeded 函数在淘汰数据的循环流程中，就会更新这个待淘汰的候选键值对集合，也就是 evictionpoollru 数组。下面我就来给你具体介绍一下。\n\n# 更新待淘汰的候选键值对集合\n\n首先，freememoryifneeded 函数会调用 evictionpoolpopulate 函数（在 evict.c 文件中），而 evictionpoolpopulate 函数会先调用 dictgetsomekeys 函数（在 dict.c 文件中），从待采样的哈希表中随机获取一定数量的 key。不过，这里还有两个地方你需要注意下。\n\n第一点，dictgetsomekeys 函数采样的哈希表，是由 maxmemory_policy 配置项来决定的。如果 maxmemory_policy 配置的是 allkeys_lru，那么待采样哈希表就是 redis server 的全局哈希表，也就是在所有键值对中进行采样；否则，待采样哈希表就是保存着设置了过期时间的 key 的哈希表。\n\n以下代码是 freememoryifneeded 函数中对 evictionpoolpopulate 函数的调用过程，你可以看下。\n\n/* we don't want to make local-db choices when expiring keys,\n * so to start populate the eviction pool sampling keys from\n * every db. */\nfor (i = 0; i < server.dbnum; i++) {\n    // 对redis server上的每一个数据库都执行\n    db = server.db+i;\n    // 根据淘汰策略，决定使用全局哈希表还是设置了过期时间的key的哈希表\n    dict = (server.maxmemory_policy & maxmemory_flag_allkeys) ?\n            db->dict : db->expires;\n    // 将选择的哈希表dict传入evictionpoolpopulate函数，同时将全局哈希表也传给evictionpoolpopulate函数\n    if ((keys = dictsize(dict)) != 0) {\n        evictionpoolpopulate(i, dict, db->dict, pool);\n        total_keys += keys;\n    }\n}\n\n\n第二点，dictgetsomekeys 函数采样的 key 的数量，是由 redis.conf 中的配置项 maxmemory-samples 决定的，该配置项的默认值是 5。下面代码就展示了 evictionpoolpopulate 函数对 dictgetsomekeys 函数的调用：\n\nvoid evictionpoolpopulate(int dbid, dict *sampledict, dict *keydict, struct evictionpoolentry *pool) {\n    ...\n    dictentry *samples[server.maxmemory_samples];  //采样后的集合，大小为maxmemory_samples\n    //将待采样的哈希表sampledict、采样后的集合samples、以及采样数量maxmemory_samples，作为参数传给dictgetsomekeys\n    count = dictgetsomekeys(sampledict,samples,server.maxmemory_samples);\n    ...\n}\n\n\n如此一来，dictgetsomekeys 函数就能返回采样的键值对集合了。然后，evictionpoolpopulate 函数会根据实际采样到的键值对数量 count，执行一个循环。\n\nfor (j = 0; j < count; j++) {\n...\nif (server.maxmemory_policy & maxmemory_flag_lru) {\n            idle = estimateobjectidletime(o);\n}\n...\n\n\n紧接着，evictionpoolpopulate 函数会遍历待淘汰的候选键值对集合，也就是 evictionpoollru 数组。在遍历过程中，它会尝试把采样的每一个键值对插入 evictionpoollru 数组，这主要取决于以下两个条件之一：\n\n * 一是，它能在数组中找到一个尚未插入键值对的空位；\n * 二是，它能在数组中找到一个空闲时间小于采样键值对空闲时间的键值对\n\n这两个条件有一个成立的话，evictionpoolpopulate 函数就可以把采样键值对插入 evictionpoollru 数组。等所有采样键值对都处理完后，evictionpoolpopulate 函数就完成对待淘汰候选键值对集合的更新了。\n\n接下来，freememoryifneeded 函数，就可以开始选择最终被淘汰的键值对了。\n\n# 选择被淘汰的键值对并删除\n\n因为 evictionpoolpopulate 函数已经更新了 evictionpoollru 数组，而且这个数组里面的 key，是按照空闲时间从小到大排好序了。所以，freememoryifneeded 函数会遍历一次 evictionpoollru 数组，从数组的最后一个 key 开始选择，如果选到的 key 不是空值，那么就把它作为最终淘汰的 key。\n\n// 从数组最后一个key开始查找\n/* go backward from best to worst element to evict. */\nfor (k = evpool_size-1; k >= 0; k--) {\n    // 当前key为空值，则查找下一个key\n    if (pool[k].key == null) continue;\n    bestdbid = pool[k].dbid;\n    // 从全局哈希表或是expire哈希表中，获取当前key对应的键值对；并将当前key从evictionpoollru数组删除\n    if (server.maxmemory_policy & maxmemory_flag_allkeys) {\n        de = dictfind(server.db[pool[k].dbid].dict,\n            pool[k].key);\n    } else {\n        de = dictfind(server.db[pool[k].dbid].expires,\n            pool[k].key);\n    }\n\n    /* remove the entry from the pool. */\n    if (pool[k].key != pool[k].cached)\n        sdsfree(pool[k].key);\n    pool[k].key = null;\n    pool[k].idle = 0;\n\n    /* if the key exists, is our pick. otherwise it is\n     * a ghost and we need to try the next element. */\n    // 如果当前key对应的键值对不为空，选择当前key为被淘汰的key\n    if (de) {\n        bestkey = dictgetkey(de);\n        break;\n    } else {\n        //否则，继续查找下个key\n        /* ghost... iterate again. */\n    }\n}\n\n\n最后，一旦选到了被淘汰的 key，freememoryifneeded 函数就会根据 redis server 的惰性删除配置，来执行同步删除或异步删除，如下所示：\n\nif (bestkey) {\n    db = server.db+bestdbid;\n    robj *keyobj = createstringobject(bestkey,sdslen(bestkey));        //将删除key的信息传递给从库和aof文件\n    propagateexpire(db,keyobj,server.lazyfree_lazy_eviction);\n    //如果配置了惰性删除，则进行异步删除\n    if (server.lazyfree_lazy_eviction)\n    \tdbasyncdelete(db,keyobj);\n    else  //否则进行同步删除\n    \tdbsyncdelete(db,keyobj);\n}\n\n\n好了，到这里，freememoryifneeded 函数就淘汰了一个 key。而如果此时，释放的内存空间还不够，也就是说没有达到我前面介绍的待释放空间，那么 freememoryifneeded 函数还会重复执行前面所说的更新待淘汰候选键值对集合、选择最终淘汰 key 的过程，直到满足待释放空间的大小要求。\n\n下图就展示了 freememoryifneeded 函数涉及的基本流程，你可以再来整体回顾下。\n\n\n\n其实，从刚才介绍的内容中，你就可以看到，近似 lru 算法并没有使用耗时耗空间的链表，而是使用了固定大小的待淘汰数据集合，每次随机选择一些 key 加入待淘汰数据集合中。最后，再按照待淘汰集合中 key 的空闲时间长度，删除空闲时间最长的 key。这样一来，redis 就近似实现了 lru 算法的效果了。\n\n\n# 总结\n\n你现在应该知道了 redis 是如何实现 lru 算法来进行缓存数据替换的。其中，我们根据 lru 算法的基本原理，可以发现如果严格按照原理来实现 lru 算法，那么开发的系统就需要用额外的内存空间来保存 lru 链表，而且系统运行时也会受到 lru 链表操作的开销影响。\n\n而对于 redis 来说，内存资源和性能都很重要，所以 redis 实现了近似 lru 算法。而为了实现近似 lru 算法，redis 首先是设置了全局 lru 时钟，并在键值对创建时获取全局 lru 时钟值作为访问时间戳，以及在每次访问时获取全局 lru 时钟值，更新访问时间戳。\n\n然后，当 redis 每处理一个命令时，都会调用 freememoryifneeded 函数来判断是否需要释放内存。如果已使用内存超出了 maxmemory，那么，近似 lru 算法就会随机选择一些键值对，组成待淘汰候选集合，并根据它们的访问时间戳，选出最旧的数据，将其淘汰。\n\nredis 计算实例内存时，不会把「主从复制」的缓冲区计算在内，也就是说不管一个实例后面挂了多少个从库，主库不会把主从复制所需的「缓冲区」内存，计算到实例内存中，即这部分内存增加，不会对数据淘汰产生影响。\n\n\n# 参考文献\n\nredis 源码剖析与实战 (geekbang.org)",charsets:{cjk:!0},lastUpdated:"2024/09/14, 20:19:06",lastUpdatedTimestamp:1726345146e3},{title:"LFU",frontmatter:{title:"LFU",date:"2024-09-14T18:14:42.000Z",permalink:"/pages/7d22be/"},regularPath:"/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/05.LFU.html",relativePath:"01.系统设计算法/01.系统设计算法/05.LFU.md",key:"v-24d5fda5",path:"/pages/7d22be/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"LFU算法的基本原理",slug:"lfu算法的基本原理",normalizedTitle:"lfu算法的基本原理",charIndex:182},{level:2,title:"LFU算法的实现",slug:"lfu算法的实现",normalizedTitle:"lfu算法的实现",charIndex:648},{level:3,title:"键值对访问频率记录",slug:"键值对访问频率记录",normalizedTitle:"键值对访问频率记录",charIndex:862},{level:3,title:"键值对访问频率的初始化与更新",slug:"键值对访问频率的初始化与更新",normalizedTitle:"键值对访问频率的初始化与更新",charIndex:1303},{level:4,title:"第一步，根据距离上次访问的时长，衰减访问次数。",slug:"第一步-根据距离上次访问的时长-衰减访问次数。",normalizedTitle:"第一步，根据距离上次访问的时长，衰减访问次数。",charIndex:3832},{level:4,title:"第二步，根据当前访问更新访问次数",slug:"第二步-根据当前访问更新访问次数",normalizedTitle:"第二步，根据当前访问更新访问次数",charIndex:6846},{level:4,title:"第三步，更新 lru 变量值",slug:"第三步-更新-lru-变量值",normalizedTitle:"第三步，更新 lru 变量值",charIndex:8610},{level:3,title:"LFU 算法淘汰数据",slug:"lfu-算法淘汰数据",normalizedTitle:"lfu 算法淘汰数据",charIndex:8954},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:9222},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:10702}],headersStr:"前言 LFU算法的基本原理 LFU算法的实现 键值对访问频率记录 键值对访问频率的初始化与更新 第一步，根据距离上次访问的时长，衰减访问次数。 第二步，根据当前访问更新访问次数 第三步，更新 lru 变量值 LFU 算法淘汰数据 总结 参考文献",content:"# 前言\n\nRedis在4.0版本后，还引入了LFU算法，也就是，最不频繁使用（Least Frequently Used，LFU）\n\nLFU算法在进行数据淘汰时，会把最不频繁访问的数据淘汰掉。而LRU算法是把最近最少使用的数据淘汰掉，看起来也是淘汰不频繁访问的数据。\n\nLFU算法和LRU算法的区别到底有哪些呢？我们在实际场景中，需要使用LFU算法吗？\n\n\n# LFU算法的基本原理\n\n因为LFU算法是根据数据访问的频率来选择被淘汰数据的，所以LFU算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。\n\n不过，访问次数和访问频率还不能完全等同。\n\n访问频率是指在一定时间内的访问次数，也就是说，在计算访问频率时，我们不仅需要记录访问次数，还要记录这些访问是在多长时间内执行的。否则，如果只记录访问次数的话，就缺少了时间维度的信息，进而就无法按照频率来淘汰数据了\n\n> 我来给你举个例子，假设数据A在15分钟内访问了15次，数据B在5分钟内访问了10次。如果只是按访问次数来统计的话，数据A的访问次数大于数据B，所以淘汰数据时会优先淘汰数据B。不过，如果按照访问频率来统计的话，数据A的访问频率是1分钟访问1次，而数据B的访问频率是1分钟访问2次，所以按访问频率淘汰数据的话，数据A应该被淘汰掉。 所以说，当要实现LFU算法时，我们需要能统计到数据的访问频率，而不是简单地记录数据访问次数就行。 那么接下来，我们就来学习下Redis是如何实现LFU算法的。\n\n\n# LFU算法的实现\n\n首先，LFU算法的启用，是通过设置Redis配置文件redis.conf中的maxmemory和maxmemory-policy。其中，maxmemory设置为Redis会用的最大内存容量，而maxmemory-policy可以设置为allkeys-lfu或是volatile-lfu，表示淘汰的键值对会分别从所有键值对或是设置了过期时间的键值对中筛选\n\nLFU算法的实现可以分成三部分内容，分别是\n\n * 键值对访问频率记录\n * 键值对访问频率初始化和更新\n * LFU算法淘汰数据\n\n\n# 键值对访问频率记录\n\n每个键值对的值都对应了一个redisObject结构体，其中有一个24 bits的lru变量。lru变量在LRU算法实现时，是用来记录数据的访问时间戳。因为Redis server每次运行时，只能将maxmemory-policy配置项设置为使用一种淘汰策略，所以，LRU算法和LFU算法并不会同时使用。而为了节省内存开销，Redis源码就复用了lru变量来记录LFU算法所需的访问频率信息。\n\n具体来说，当lru变量用来记录LFU算法的所需信息时，它会用24 bits中的低8 bits作为计数器，来记录键值对的访问次数，同时它会用24 bits中的高16 bits，记录访问的时间戳。下图就展示了用来记录访问频率时的lru变量内容，你可以看下。\n\n好，了解了 LFU 算法所需的访问频率是如何记录的，接下来，我们再来看下键值对的访问频率是如何初始化和更新的。\n\n\n# 键值对访问频率的初始化与更新\n\n首先，我们要知道，LFU 算法和 LRU 算法的基本步骤，实际上是在相同的入口函数中执行的。围绕 LRU 算法的实现，我们已经了解到这些基本步骤包括数据访问信息的初始化、访问信息更新，以及实际淘汰数据。这些步骤对应的入口函数如下表所示，你也可以再去回顾下内容。\n\n了解了这些入口函数后，我们再去分析 LFU 算法的实现，就容易找到对应的函数了。\n\n对于键值对访问频率的初始化来说，当一个键值对被创建后，createObject 函数就会被调用，用来分配 redisObject 结构体的空间和设置初始化值。如果 Redis 将 maxmemory-policy 设置为 LFU 算法，那么，键值对 redisObject 结构体中的 lru 变量初始化值，会由两部分组成：\n\n * 第一部分是 lru 变量的高 16 位，是以 1 分钟为精度的 UNIX 时间戳。这是通过调用 LFUGetTimeInMinutes 函数（在 evict.c 文件中）计算得到的。\n * 第二部分是 lru 变量的低 8 位，被设置为宏定义 LFU_INIT_VAL（在server.h文件中），默认值为 5。\n\n你会发现，这和我刚才给你介绍的键值对访问频率记录是一致的，也就是说，当使用 LFU 算法时，lru 变量包括了键值对的访问时间戳和访问次数。以下代码也展示了这部分的执行逻辑，你可以看下。\n\nrobj *createObject(int type, void *ptr) {\n    robj *o = zmalloc(sizeof(*o));\n    o->type = type;\n    o->encoding = OBJ_ENCODING_RAW;\n    o->ptr = ptr;\n    o->refcount = 1;\n\n    /* Set the LRU to the current lruclock (minutes resolution), or\n     * alternatively the LFU counter. */\n    // 使用LFU算法时，lru变量包括以分钟为精度的UNIX时间戳和访问次数5\n    if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {\n        o->lru = (LFUGetTimeInMinutes()<<8) | LFU_INIT_VAL;\n    } else {\n        o->lru = LRU_CLOCK();\n    }\n    return o;\n}\n\n\n/* Return the current time in minutes, just taking the least significant\n * 16 bits. The returned time is suitable to be stored as LDT (last decrement\n * time) for the LFU implementation. */\nunsigned long LFUGetTimeInMinutes(void) {\n    return (server.unixtime/60) & 65535;\n}\n\n\n#define LFU_INIT_VAL 5\n\n\n下面，我们再来看下键值对访问频率的更新。\n\n当一个键值对被访问时，Redis 会调用 lookupKey 函数进行查找。当 maxmemory-policy 设置使用 LFU 算法时，lookupKey 函数会调用 updateLFU 函数来更新键值对的访问频率，也就是 lru 变量值，如下所示：\n\n/* Low level key lookup API, not actually called directly from commands\n * implementations that should instead rely on lookupKeyRead(),\n * lookupKeyWrite() and lookupKeyReadWithFlags(). */\nrobj *lookupKey(redisDb *db, robj *key, int flags) {\n    dictEntry *de = dictFind(db->dict,key->ptr);\n    if (de) {\n        robj *val = dictGetVal(de);\n\n        /* Update the access time for the ageing algorithm.\n         * Don't do it if we have a saving child, as this will trigger\n         * a copy on write madness. */\n        if (!hasActiveChildProcess() && !(flags & LOOKUP_NOTOUCH)){\n            // 使用LFU算法时，调用updateLFU函数更新访问频率\n            if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {\n                updateLFU(val);\n            } else {\n                // 使用LRU算法时，调用LRU_CLOCK\n                val->lru = LRU_CLOCK();\n            }\n        }\n        return val;\n    } else {\n        return NULL;\n    }\n}\n\n\nupdateLFU 函数是在db.c文件中实现的，它的执行逻辑比较明确，一共分成三步。\n\n# 第一步，根据距离上次访问的时长，衰减访问次数。\n\nupdateLFU 函数首先会调用 LFUDecrAndReturn 函数（在 evict.c 文件中），对键值对的访问次数进行衰减操作，如下所示：\n\n/* Update LFU when an object is accessed.\n * Firstly, decrement the counter if the decrement time is reached.\n * Then logarithmically increment the counter, and update the access time. */\nvoid updateLFU(robj *val) {\n    // 首先，递减计数器\n    unsigned long counter = LFUDecrAndReturn(val);\n    // 然后以logN级别递增计数器，并更新访问次数。\n    counter = LFULogIncr(counter);\n    val->lru = (LFUGetTimeInMinutes()<<8) | counter;\n}\n\n\n看到这里，你可能会有疑问：访问键值对时不是要增加键值对的访问次数吗，为什么要先衰减访问次数呢？\n\n其实，这就是我在前面一开始和你介绍的，LFU 算法是根据访问频率来淘汰数据的，而不只是访问次数。访问频率需要考虑键值对的访问是多长时间段内发生的。键值对的先前访问距离当前时间越长，那么这个键值对的访问频率相应地也就会降低。\n\n我给你举个例子，假设数据 A 在时刻 T 到 T+10 分钟这段时间内，被访问了 30 次，那么，这段时间内数据 A 的访问频率可以计算为 3 次 / 分钟（30 次 /10 分钟 = 3 次 / 分钟）。\n\n紧接着，在 T+10 分钟到 T+20 分钟这段时间内，数据 A 没有再被访问，那么此时，如果我们计算数据 A 在 T 到 T+20 分钟这段时间内的访问频率，它的访问频率就会降为 1.5 次 / 分钟（30 次 /20 分钟 = 1.5 次 / 分钟）。以此类推，随着时间的推移，如果数据 A 在 T+10 分钟后一直没有新的访问，那么它的访问频率就会逐步降低。这就是所谓的访问频率衰减。\n\n因为 Redis 是使用 lru 变量中的访问次数来表示访问频率，所以在每次更新键值对的访问频率时，就会通过 LFUDecrAndReturn 函数对访问次数进行衰减。\n\n具体来说，LFUDecrAndReturn 函数会首先获取当前键值对的上一次访问时间，这是保存在 lru 变量高 16 位上的值。然后，LFUDecrAndReturn 函数会根据全局变量 server 的 lru_decay_time 成员变量的取值，来计算衰减的大小 num_period。\n\n这个计算过程会判断 lfu_decay_time 的值是否为 0。如果 lfu_decay_time 值为 0，那么衰减大小也为 0。此时，访问次数不进行衰减。\n\n否则的话，LFUDecrAndReturn 函数会调用 LFUTimeElapsed 函数（在 evict.c 文件中），计算距离键值对的上一次访问已经过去的时长。这个时长也是以 1 分钟为精度来计算的。有了距离上次访问的时长后，LFUDecrAndReturn 函数会把这个时长除以 lfu_decay_time 的值，并把结果作为访问次数的衰减大小。\n\n这里，你需要注意的是，lfu_decay_time 变量值，是由 redis.conf 文件中的配置项 lfu-decay-time 来决定的。Redis 在初始化时，会通过 initServerConfig 函数来设置 lfu_decay_time 变量的值，默认值为 1。所以，在默认情况下，访问次数的衰减大小就是等于上一次访问距离当前的分钟数。比如，假设上一次访问是 10 分钟前，那么在默认情况下，访问次数的衰减大小就等于 10。\n\n当然，如果上一次访问距离当前的分钟数，已经超过访问次数的值了，那么访问次数就会被设置为 0，这就表示键值对已经很长时间没有被访问了。\n\n下面的代码展示了 LFUDecrAndReturn 函数的执行逻辑，你可以看下。\n\n/* If the object decrement time is reached decrement the LFU counter but\n * do not update LFU fields of the object, we update the access time\n * and counter in an explicit way when the object is really accessed.\n * And we will times halve the counter according to the times of\n * elapsed time than server.lfu_decay_time.\n * Return the object frequency counter.\n *\n * This function is used in order to scan the dataset for the best object\n * to fit: as we check for the candidate, we incrementally decrement the\n * counter of the scanned objects if needed. */\nunsigned long LFUDecrAndReturn(robj *o) {\n    // 获取当前键值对的上一次访问时间，lru右移8位，相当于保留的是前面16位的时间戳\n    unsigned long ldt = o->lru >> 8;\n    // 获取当前的访问次数，相当于后8位与255做与运算，即得到计数器\n    unsigned long counter = o->lru & 255;\n    // 计算衰减大小\n    unsigned long num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : 0;\n    // 如果衰减大小不为0\n    if (num_periods)\n        // 如果衰减大小小于当前访问次数，那么，衰减后的访问次数是当前访问次数减去衰减大小；否则，衰减后的访问次数等于0\n        counter = (num_periods > counter) ? 0 : counter - num_periods;\n    // 如果衰减大小为0，则返回原来的访问次数\n    return counter;\n}\t\n\n\n好了，到这里，updateLFU 函数就通过 LFUDecrAndReturn 函数，完成了键值对访问次数的衰减。紧接着，updateLFU 函数还是会基于键值对当前的这次访问，来更新它的访问次数。\n\n# 第二步，根据当前访问更新访问次数\n\n在这一步中，updateLFU 函数会调用 LFULogIncr 函数，来增加键值对的访问次数，如下所示：\n\n/* Logarithmically increment a counter. The greater is the current counter value\n * the less likely is that it gets really implemented. Saturate it at 255. */\n// 对数递增计数值\n//核心就是访问次数越大，访问次数被递增的可能性越小，最大 255，此外你可以在配置 redis.conf 中写明访问多少次递增多少。\nuint8_t LFULogIncr(uint8_t counter) {\n    // 到最大值了，不能在增加了\n    if (counter == 255) return 255;\n    //    rand()产生一个0-0x7fff的随机数,一个随机数去除以 RAND_MAX也就是Ox7FFF，也就是随机概率\n    double r = (double)rand()/RAND_MAX;\n    // 减去新对象初始化的基数值 (LFU_INIT_VAL 默认是 5)\n    double baseval = counter - LFU_INIT_VAL;\n    // baseval 如果小于零，说明这个对象快不行了，不过本次 incr 将会延长它的寿命\n    if (baseval < 0) baseval = 0;\n    // baseval * LFU 对数计数器因子 + 1保证分母大于1\n    // 当 baseval 特别大时，最大是 (255-5)，p 值会非常小，很难会走到 counter++ 这一步\n    // p 就是 counter 通往 [+1] 权力的门缝，baseval 越大，这个门缝越窄，通过就越艰难\n    double p = 1.0/(baseval*server.lfu_log_factor+1);\n    // 如果随机概率小于当前计算的访问概率，那么访问次数加1\n    if (r < p) counter++;\n    return counter;\n}\n\n\n * 第一个分支对应了当前访问次数等于最大值 255 的情况。此时，LFULogIncr 函数不再增加访问次数。\n\n * 第二个分支对应了当前访问次数小于 255 的情况。此时，LFULogIncr 函数会计算一个阈值 p，以及一个取值为 0 到 1 之间的随机概率值 r。如果概率 r 小于阈值 p，那么 LFULogIncr 函数才会将访问次数加 1。否则的话，LFULogIncr 函数会返回当前的访问次数，不做更新。\n\n从这里你可以看到，因为概率值 r 是随机定的，所以，阈值 p 的大小就决定了访问次数增加的难度。阈值 p 越小，概率值 r 小于 p 的可能性也越小，此时，访问次数也越难增加；相反，如果阈值 p 越大，概率值 r 小于 p 的可能性就越大，访问次数就越容易增加。\n\n而阈值 p 的值大小，其实是由两个因素决定的。一个是当前访问次数和宏定义 LFU_INIT_VAL 的差值 baseval，另一个是 reids.conf 文件中定义的配置项 lfu-log-factor。\n\n当计算阈值 p 时，我们是把 baseval 和 lfu-log-factor 乘积后，加上 1，然后再取其倒数。所以，baseval 或者 lfu-log-factor 越大，那么其倒数就越小，也就是阈值 p 就越小；反之，阈值 p 就越大。也就是说，这里其实就对应了两种影响因素。\n\n * baseval 的大小：这反映了当前访问次数的多少。比如，访问次数越多的键值对，它的访问次数再增加的难度就会越大；(有点类似指数退避算法)\n * lfu-log-factor 的大小：这是可以被设置的。也就是说，Redis 源码提供了让我们人为调节访问次数增加难度的方法。\n\n这样，等到 LFULogIncr 函数执行完成后，键值对的访问次数就算更新完了。\n\n# 第三步，更新 lru 变量值\n\n最后，到这一步，updateLFU 函数已经完成了键值对访问次数的更新。接着，它就会调用 LFUGetTimeInMinutes 函数，来获取当前的时间戳，并和更新后的访问次数组合，形成最新的访问频率信息，赋值给键值对的 lru 变量，如下所示：\n\n好了，到这里，你就了解了，Redis 源码在更新键值对访问频率时，对于访问次数，它是先按照上次访问距离当前的时长，来对访问次数进行衰减。然后，再按照一定概率增加访问次数。这样的设计方法，就既包含了访问的时间段对访问频率的影响，也避免了 8 bits 计数器对访问次数的影响。而对于访问时间来说，Redis 还会获取最新访问时间戳并更新到 lru 变量中。\n\n那么最后，我们再来看下 Redis 是如何基于 LFU 算法淘汰数据的。\n\n\n# LFU 算法淘汰数据\n\n在实现使用 LFU 算法淘汰数据时，Redis 是采用了和实现近似 LRU 算法相同的方法。也就是说，Redis 会使用一个全局数组 EvictionPoolLRU，来保存待淘汰候选键值对集合。然后，在 processCommand 函数处理每个命令时，它会调用 freeMemoryIfNeededAndSafe 函数和 freeMemoryIfNeeded 函数，来执行具体的数据淘汰流程。\n\n这个淘汰流程我在上篇文章已经给你介绍过了，你可以再去整体回顾下。这里，我也再简要总结下，也就是分成三个步骤：\n\n * 第一步，调用 getMaxmemoryState 函数计算待释放的内存空间；\n * 第二步，调用 evictionPoolPopulate 函数随机采样键值对，并插入到待淘汰集合 EvictionPoolLRU 中；\n * 第三步，遍历待淘汰集合 EvictionPoolLRU，选择实际被淘汰数据，并删除。\n\n虽然这个基本流程和 LRU 算法相同，但是你要注意，LFU 算法在淘汰数据时，在第二步的 evictionPoolPopulate 函数中，使用了不同的方法来计算每个待淘汰键值对的空闲时间\n\n具体来说，在实现 LRU 算法时，待淘汰候选键值对集合 EvictionPoolLRU 中的每个元素，都使用成员变量 idle 来记录它距离上次访问的空闲时间。\n\n而当实现 LFU 算法时，因为 LFU 算法会对访问次数进行衰减和按概率增加，所以，它是使用访问次数来近似表示访问频率的。相应的，LFU 算法其实是用 255 减去键值对的访问次数，这样来计算 EvictionPoolLRU 数组中每个元素的 idle 变量值的。而且，在计算 idle 变量值前，LFU 算法还会调用 LFUDecrAndReturn 函数，衰减一次键值对的访问次数，以便能更加准确地反映实际选择待淘汰数据时，数据的访问频率。\n\n下面的代码展示了 LFU 算法计算 idle 变量值的过程，你可以看下。\n\nif (server.maxmemory_policy & MAXMEMORY_FLAG_LRU) {\n    idle = estimateObjectIdleTime(o);\n} else if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {\n    idle = 255-LFUDecrAndReturn(o);\n}\n\n\n所以说，当 LFU 算法按照访问频率，计算了待淘汰键值对集合中每个元素的 idle 值后，键值对访问次数越大，它的 idle 值就越小，反之 idle 值越大。而 EvictionPoolLRU 数组中的元素，是按 idle 值从小到大来排序的。最后当 freeMemoryIfNeeded 函数按照 idle 值从大到小，遍历 EvictionPoolLRU 数组，选择实际被淘汰的键值对时，它就能选出访问次数小的键值对了，也就是把访问频率低的键值对淘汰出去。\n\n这样，Redis 就完成了按访问频率来淘汰数据的操作了。\n\n\n# 总结\n\n 1. LFU 是在 Redis 4.0 新增的淘汰策略，它涉及的巧妙之处在于，其复用了 redisObject 结构的 lru 字段，把这个字段「一分为二」，高16位保存最后访问时间和低8位保存访问次数\n 2. key 的访问次数不能只增不减，它需要根据时间间隔来做衰减，才能达到 LFU 的目的\n 3. 每次在访问一个 key 时，会**「懒惰」**更新这个 key 的访问次数：先衰减访问次数，再更新访问次数\n 4. 衰减访问次数，会根据时间间隔计算，间隔时间越久，衰减越厉害\n 5. 因为 redisObject lru 字段宽度限制，这个访问次数是有上限的（8 bit 最大值 255），所以递增访问次数时，会根据「当前」访问次数和「概率」的方式做递增，访问次数越大，递增因子越大，递增概率越低\n 6. Redis 实现的 LFU 算法也是**「近似」**LFU，是在性能和内存方面平衡的结果\n\n\n# 参考文献\n\nhttps://time.geekbang.org/column/intro/100084301",normalizedContent:"# 前言\n\nredis在4.0版本后，还引入了lfu算法，也就是，最不频繁使用（least frequently used，lfu）\n\nlfu算法在进行数据淘汰时，会把最不频繁访问的数据淘汰掉。而lru算法是把最近最少使用的数据淘汰掉，看起来也是淘汰不频繁访问的数据。\n\nlfu算法和lru算法的区别到底有哪些呢？我们在实际场景中，需要使用lfu算法吗？\n\n\n# lfu算法的基本原理\n\n因为lfu算法是根据数据访问的频率来选择被淘汰数据的，所以lfu算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。\n\n不过，访问次数和访问频率还不能完全等同。\n\n访问频率是指在一定时间内的访问次数，也就是说，在计算访问频率时，我们不仅需要记录访问次数，还要记录这些访问是在多长时间内执行的。否则，如果只记录访问次数的话，就缺少了时间维度的信息，进而就无法按照频率来淘汰数据了\n\n> 我来给你举个例子，假设数据a在15分钟内访问了15次，数据b在5分钟内访问了10次。如果只是按访问次数来统计的话，数据a的访问次数大于数据b，所以淘汰数据时会优先淘汰数据b。不过，如果按照访问频率来统计的话，数据a的访问频率是1分钟访问1次，而数据b的访问频率是1分钟访问2次，所以按访问频率淘汰数据的话，数据a应该被淘汰掉。 所以说，当要实现lfu算法时，我们需要能统计到数据的访问频率，而不是简单地记录数据访问次数就行。 那么接下来，我们就来学习下redis是如何实现lfu算法的。\n\n\n# lfu算法的实现\n\n首先，lfu算法的启用，是通过设置redis配置文件redis.conf中的maxmemory和maxmemory-policy。其中，maxmemory设置为redis会用的最大内存容量，而maxmemory-policy可以设置为allkeys-lfu或是volatile-lfu，表示淘汰的键值对会分别从所有键值对或是设置了过期时间的键值对中筛选\n\nlfu算法的实现可以分成三部分内容，分别是\n\n * 键值对访问频率记录\n * 键值对访问频率初始化和更新\n * lfu算法淘汰数据\n\n\n# 键值对访问频率记录\n\n每个键值对的值都对应了一个redisobject结构体，其中有一个24 bits的lru变量。lru变量在lru算法实现时，是用来记录数据的访问时间戳。因为redis server每次运行时，只能将maxmemory-policy配置项设置为使用一种淘汰策略，所以，lru算法和lfu算法并不会同时使用。而为了节省内存开销，redis源码就复用了lru变量来记录lfu算法所需的访问频率信息。\n\n具体来说，当lru变量用来记录lfu算法的所需信息时，它会用24 bits中的低8 bits作为计数器，来记录键值对的访问次数，同时它会用24 bits中的高16 bits，记录访问的时间戳。下图就展示了用来记录访问频率时的lru变量内容，你可以看下。\n\n好，了解了 lfu 算法所需的访问频率是如何记录的，接下来，我们再来看下键值对的访问频率是如何初始化和更新的。\n\n\n# 键值对访问频率的初始化与更新\n\n首先，我们要知道，lfu 算法和 lru 算法的基本步骤，实际上是在相同的入口函数中执行的。围绕 lru 算法的实现，我们已经了解到这些基本步骤包括数据访问信息的初始化、访问信息更新，以及实际淘汰数据。这些步骤对应的入口函数如下表所示，你也可以再去回顾下内容。\n\n了解了这些入口函数后，我们再去分析 lfu 算法的实现，就容易找到对应的函数了。\n\n对于键值对访问频率的初始化来说，当一个键值对被创建后，createobject 函数就会被调用，用来分配 redisobject 结构体的空间和设置初始化值。如果 redis 将 maxmemory-policy 设置为 lfu 算法，那么，键值对 redisobject 结构体中的 lru 变量初始化值，会由两部分组成：\n\n * 第一部分是 lru 变量的高 16 位，是以 1 分钟为精度的 unix 时间戳。这是通过调用 lfugettimeinminutes 函数（在 evict.c 文件中）计算得到的。\n * 第二部分是 lru 变量的低 8 位，被设置为宏定义 lfu_init_val（在server.h文件中），默认值为 5。\n\n你会发现，这和我刚才给你介绍的键值对访问频率记录是一致的，也就是说，当使用 lfu 算法时，lru 变量包括了键值对的访问时间戳和访问次数。以下代码也展示了这部分的执行逻辑，你可以看下。\n\nrobj *createobject(int type, void *ptr) {\n    robj *o = zmalloc(sizeof(*o));\n    o->type = type;\n    o->encoding = obj_encoding_raw;\n    o->ptr = ptr;\n    o->refcount = 1;\n\n    /* set the lru to the current lruclock (minutes resolution), or\n     * alternatively the lfu counter. */\n    // 使用lfu算法时，lru变量包括以分钟为精度的unix时间戳和访问次数5\n    if (server.maxmemory_policy & maxmemory_flag_lfu) {\n        o->lru = (lfugettimeinminutes()<<8) | lfu_init_val;\n    } else {\n        o->lru = lru_clock();\n    }\n    return o;\n}\n\n\n/* return the current time in minutes, just taking the least significant\n * 16 bits. the returned time is suitable to be stored as ldt (last decrement\n * time) for the lfu implementation. */\nunsigned long lfugettimeinminutes(void) {\n    return (server.unixtime/60) & 65535;\n}\n\n\n#define lfu_init_val 5\n\n\n下面，我们再来看下键值对访问频率的更新。\n\n当一个键值对被访问时，redis 会调用 lookupkey 函数进行查找。当 maxmemory-policy 设置使用 lfu 算法时，lookupkey 函数会调用 updatelfu 函数来更新键值对的访问频率，也就是 lru 变量值，如下所示：\n\n/* low level key lookup api, not actually called directly from commands\n * implementations that should instead rely on lookupkeyread(),\n * lookupkeywrite() and lookupkeyreadwithflags(). */\nrobj *lookupkey(redisdb *db, robj *key, int flags) {\n    dictentry *de = dictfind(db->dict,key->ptr);\n    if (de) {\n        robj *val = dictgetval(de);\n\n        /* update the access time for the ageing algorithm.\n         * don't do it if we have a saving child, as this will trigger\n         * a copy on write madness. */\n        if (!hasactivechildprocess() && !(flags & lookup_notouch)){\n            // 使用lfu算法时，调用updatelfu函数更新访问频率\n            if (server.maxmemory_policy & maxmemory_flag_lfu) {\n                updatelfu(val);\n            } else {\n                // 使用lru算法时，调用lru_clock\n                val->lru = lru_clock();\n            }\n        }\n        return val;\n    } else {\n        return null;\n    }\n}\n\n\nupdatelfu 函数是在db.c文件中实现的，它的执行逻辑比较明确，一共分成三步。\n\n# 第一步，根据距离上次访问的时长，衰减访问次数。\n\nupdatelfu 函数首先会调用 lfudecrandreturn 函数（在 evict.c 文件中），对键值对的访问次数进行衰减操作，如下所示：\n\n/* update lfu when an object is accessed.\n * firstly, decrement the counter if the decrement time is reached.\n * then logarithmically increment the counter, and update the access time. */\nvoid updatelfu(robj *val) {\n    // 首先，递减计数器\n    unsigned long counter = lfudecrandreturn(val);\n    // 然后以logn级别递增计数器，并更新访问次数。\n    counter = lfulogincr(counter);\n    val->lru = (lfugettimeinminutes()<<8) | counter;\n}\n\n\n看到这里，你可能会有疑问：访问键值对时不是要增加键值对的访问次数吗，为什么要先衰减访问次数呢？\n\n其实，这就是我在前面一开始和你介绍的，lfu 算法是根据访问频率来淘汰数据的，而不只是访问次数。访问频率需要考虑键值对的访问是多长时间段内发生的。键值对的先前访问距离当前时间越长，那么这个键值对的访问频率相应地也就会降低。\n\n我给你举个例子，假设数据 a 在时刻 t 到 t+10 分钟这段时间内，被访问了 30 次，那么，这段时间内数据 a 的访问频率可以计算为 3 次 / 分钟（30 次 /10 分钟 = 3 次 / 分钟）。\n\n紧接着，在 t+10 分钟到 t+20 分钟这段时间内，数据 a 没有再被访问，那么此时，如果我们计算数据 a 在 t 到 t+20 分钟这段时间内的访问频率，它的访问频率就会降为 1.5 次 / 分钟（30 次 /20 分钟 = 1.5 次 / 分钟）。以此类推，随着时间的推移，如果数据 a 在 t+10 分钟后一直没有新的访问，那么它的访问频率就会逐步降低。这就是所谓的访问频率衰减。\n\n因为 redis 是使用 lru 变量中的访问次数来表示访问频率，所以在每次更新键值对的访问频率时，就会通过 lfudecrandreturn 函数对访问次数进行衰减。\n\n具体来说，lfudecrandreturn 函数会首先获取当前键值对的上一次访问时间，这是保存在 lru 变量高 16 位上的值。然后，lfudecrandreturn 函数会根据全局变量 server 的 lru_decay_time 成员变量的取值，来计算衰减的大小 num_period。\n\n这个计算过程会判断 lfu_decay_time 的值是否为 0。如果 lfu_decay_time 值为 0，那么衰减大小也为 0。此时，访问次数不进行衰减。\n\n否则的话，lfudecrandreturn 函数会调用 lfutimeelapsed 函数（在 evict.c 文件中），计算距离键值对的上一次访问已经过去的时长。这个时长也是以 1 分钟为精度来计算的。有了距离上次访问的时长后，lfudecrandreturn 函数会把这个时长除以 lfu_decay_time 的值，并把结果作为访问次数的衰减大小。\n\n这里，你需要注意的是，lfu_decay_time 变量值，是由 redis.conf 文件中的配置项 lfu-decay-time 来决定的。redis 在初始化时，会通过 initserverconfig 函数来设置 lfu_decay_time 变量的值，默认值为 1。所以，在默认情况下，访问次数的衰减大小就是等于上一次访问距离当前的分钟数。比如，假设上一次访问是 10 分钟前，那么在默认情况下，访问次数的衰减大小就等于 10。\n\n当然，如果上一次访问距离当前的分钟数，已经超过访问次数的值了，那么访问次数就会被设置为 0，这就表示键值对已经很长时间没有被访问了。\n\n下面的代码展示了 lfudecrandreturn 函数的执行逻辑，你可以看下。\n\n/* if the object decrement time is reached decrement the lfu counter but\n * do not update lfu fields of the object, we update the access time\n * and counter in an explicit way when the object is really accessed.\n * and we will times halve the counter according to the times of\n * elapsed time than server.lfu_decay_time.\n * return the object frequency counter.\n *\n * this function is used in order to scan the dataset for the best object\n * to fit: as we check for the candidate, we incrementally decrement the\n * counter of the scanned objects if needed. */\nunsigned long lfudecrandreturn(robj *o) {\n    // 获取当前键值对的上一次访问时间，lru右移8位，相当于保留的是前面16位的时间戳\n    unsigned long ldt = o->lru >> 8;\n    // 获取当前的访问次数，相当于后8位与255做与运算，即得到计数器\n    unsigned long counter = o->lru & 255;\n    // 计算衰减大小\n    unsigned long num_periods = server.lfu_decay_time ? lfutimeelapsed(ldt) / server.lfu_decay_time : 0;\n    // 如果衰减大小不为0\n    if (num_periods)\n        // 如果衰减大小小于当前访问次数，那么，衰减后的访问次数是当前访问次数减去衰减大小；否则，衰减后的访问次数等于0\n        counter = (num_periods > counter) ? 0 : counter - num_periods;\n    // 如果衰减大小为0，则返回原来的访问次数\n    return counter;\n}\t\n\n\n好了，到这里，updatelfu 函数就通过 lfudecrandreturn 函数，完成了键值对访问次数的衰减。紧接着，updatelfu 函数还是会基于键值对当前的这次访问，来更新它的访问次数。\n\n# 第二步，根据当前访问更新访问次数\n\n在这一步中，updatelfu 函数会调用 lfulogincr 函数，来增加键值对的访问次数，如下所示：\n\n/* logarithmically increment a counter. the greater is the current counter value\n * the less likely is that it gets really implemented. saturate it at 255. */\n// 对数递增计数值\n//核心就是访问次数越大，访问次数被递增的可能性越小，最大 255，此外你可以在配置 redis.conf 中写明访问多少次递增多少。\nuint8_t lfulogincr(uint8_t counter) {\n    // 到最大值了，不能在增加了\n    if (counter == 255) return 255;\n    //    rand()产生一个0-0x7fff的随机数,一个随机数去除以 rand_max也就是ox7fff，也就是随机概率\n    double r = (double)rand()/rand_max;\n    // 减去新对象初始化的基数值 (lfu_init_val 默认是 5)\n    double baseval = counter - lfu_init_val;\n    // baseval 如果小于零，说明这个对象快不行了，不过本次 incr 将会延长它的寿命\n    if (baseval < 0) baseval = 0;\n    // baseval * lfu 对数计数器因子 + 1保证分母大于1\n    // 当 baseval 特别大时，最大是 (255-5)，p 值会非常小，很难会走到 counter++ 这一步\n    // p 就是 counter 通往 [+1] 权力的门缝，baseval 越大，这个门缝越窄，通过就越艰难\n    double p = 1.0/(baseval*server.lfu_log_factor+1);\n    // 如果随机概率小于当前计算的访问概率，那么访问次数加1\n    if (r < p) counter++;\n    return counter;\n}\n\n\n * 第一个分支对应了当前访问次数等于最大值 255 的情况。此时，lfulogincr 函数不再增加访问次数。\n\n * 第二个分支对应了当前访问次数小于 255 的情况。此时，lfulogincr 函数会计算一个阈值 p，以及一个取值为 0 到 1 之间的随机概率值 r。如果概率 r 小于阈值 p，那么 lfulogincr 函数才会将访问次数加 1。否则的话，lfulogincr 函数会返回当前的访问次数，不做更新。\n\n从这里你可以看到，因为概率值 r 是随机定的，所以，阈值 p 的大小就决定了访问次数增加的难度。阈值 p 越小，概率值 r 小于 p 的可能性也越小，此时，访问次数也越难增加；相反，如果阈值 p 越大，概率值 r 小于 p 的可能性就越大，访问次数就越容易增加。\n\n而阈值 p 的值大小，其实是由两个因素决定的。一个是当前访问次数和宏定义 lfu_init_val 的差值 baseval，另一个是 reids.conf 文件中定义的配置项 lfu-log-factor。\n\n当计算阈值 p 时，我们是把 baseval 和 lfu-log-factor 乘积后，加上 1，然后再取其倒数。所以，baseval 或者 lfu-log-factor 越大，那么其倒数就越小，也就是阈值 p 就越小；反之，阈值 p 就越大。也就是说，这里其实就对应了两种影响因素。\n\n * baseval 的大小：这反映了当前访问次数的多少。比如，访问次数越多的键值对，它的访问次数再增加的难度就会越大；(有点类似指数退避算法)\n * lfu-log-factor 的大小：这是可以被设置的。也就是说，redis 源码提供了让我们人为调节访问次数增加难度的方法。\n\n这样，等到 lfulogincr 函数执行完成后，键值对的访问次数就算更新完了。\n\n# 第三步，更新 lru 变量值\n\n最后，到这一步，updatelfu 函数已经完成了键值对访问次数的更新。接着，它就会调用 lfugettimeinminutes 函数，来获取当前的时间戳，并和更新后的访问次数组合，形成最新的访问频率信息，赋值给键值对的 lru 变量，如下所示：\n\n好了，到这里，你就了解了，redis 源码在更新键值对访问频率时，对于访问次数，它是先按照上次访问距离当前的时长，来对访问次数进行衰减。然后，再按照一定概率增加访问次数。这样的设计方法，就既包含了访问的时间段对访问频率的影响，也避免了 8 bits 计数器对访问次数的影响。而对于访问时间来说，redis 还会获取最新访问时间戳并更新到 lru 变量中。\n\n那么最后，我们再来看下 redis 是如何基于 lfu 算法淘汰数据的。\n\n\n# lfu 算法淘汰数据\n\n在实现使用 lfu 算法淘汰数据时，redis 是采用了和实现近似 lru 算法相同的方法。也就是说，redis 会使用一个全局数组 evictionpoollru，来保存待淘汰候选键值对集合。然后，在 processcommand 函数处理每个命令时，它会调用 freememoryifneededandsafe 函数和 freememoryifneeded 函数，来执行具体的数据淘汰流程。\n\n这个淘汰流程我在上篇文章已经给你介绍过了，你可以再去整体回顾下。这里，我也再简要总结下，也就是分成三个步骤：\n\n * 第一步，调用 getmaxmemorystate 函数计算待释放的内存空间；\n * 第二步，调用 evictionpoolpopulate 函数随机采样键值对，并插入到待淘汰集合 evictionpoollru 中；\n * 第三步，遍历待淘汰集合 evictionpoollru，选择实际被淘汰数据，并删除。\n\n虽然这个基本流程和 lru 算法相同，但是你要注意，lfu 算法在淘汰数据时，在第二步的 evictionpoolpopulate 函数中，使用了不同的方法来计算每个待淘汰键值对的空闲时间\n\n具体来说，在实现 lru 算法时，待淘汰候选键值对集合 evictionpoollru 中的每个元素，都使用成员变量 idle 来记录它距离上次访问的空闲时间。\n\n而当实现 lfu 算法时，因为 lfu 算法会对访问次数进行衰减和按概率增加，所以，它是使用访问次数来近似表示访问频率的。相应的，lfu 算法其实是用 255 减去键值对的访问次数，这样来计算 evictionpoollru 数组中每个元素的 idle 变量值的。而且，在计算 idle 变量值前，lfu 算法还会调用 lfudecrandreturn 函数，衰减一次键值对的访问次数，以便能更加准确地反映实际选择待淘汰数据时，数据的访问频率。\n\n下面的代码展示了 lfu 算法计算 idle 变量值的过程，你可以看下。\n\nif (server.maxmemory_policy & maxmemory_flag_lru) {\n    idle = estimateobjectidletime(o);\n} else if (server.maxmemory_policy & maxmemory_flag_lfu) {\n    idle = 255-lfudecrandreturn(o);\n}\n\n\n所以说，当 lfu 算法按照访问频率，计算了待淘汰键值对集合中每个元素的 idle 值后，键值对访问次数越大，它的 idle 值就越小，反之 idle 值越大。而 evictionpoollru 数组中的元素，是按 idle 值从小到大来排序的。最后当 freememoryifneeded 函数按照 idle 值从大到小，遍历 evictionpoollru 数组，选择实际被淘汰的键值对时，它就能选出访问次数小的键值对了，也就是把访问频率低的键值对淘汰出去。\n\n这样，redis 就完成了按访问频率来淘汰数据的操作了。\n\n\n# 总结\n\n 1. lfu 是在 redis 4.0 新增的淘汰策略，它涉及的巧妙之处在于，其复用了 redisobject 结构的 lru 字段，把这个字段「一分为二」，高16位保存最后访问时间和低8位保存访问次数\n 2. key 的访问次数不能只增不减，它需要根据时间间隔来做衰减，才能达到 lfu 的目的\n 3. 每次在访问一个 key 时，会**「懒惰」**更新这个 key 的访问次数：先衰减访问次数，再更新访问次数\n 4. 衰减访问次数，会根据时间间隔计算，间隔时间越久，衰减越厉害\n 5. 因为 redisobject lru 字段宽度限制，这个访问次数是有上限的（8 bit 最大值 255），所以递增访问次数时，会根据「当前」访问次数和「概率」的方式做递增，访问次数越大，递增因子越大，递增概率越低\n 6. redis 实现的 lfu 算法也是**「近似」**lfu，是在性能和内存方面平衡的结果\n\n\n# 参考文献\n\nhttps://time.geekbang.org/column/intro/100084301",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:14:59",lastUpdatedTimestamp:1726334099e3},{title:"渐进式 hash",frontmatter:{title:"渐进式 hash",date:"2024-09-14T18:44:06.000Z",permalink:"/pages/2d43d1/"},regularPath:"/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/06.%E6%B8%90%E8%BF%9B%E5%BC%8F%20hash.html",relativePath:"01.系统设计算法/01.系统设计算法/06.渐进式 hash.md",key:"v-67babc0e",path:"/pages/2d43d1/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"Redis 如何避免hash冲突？",slug:"redis-如何避免hash冲突",normalizedTitle:"redis 如何避免hash冲突？",charIndex:636},{level:2,title:"Redis 如何实现 rehash？",slug:"redis-如何实现-rehash",normalizedTitle:"redis 如何实现 rehash？",charIndex:1092},{level:3,title:"什么时候触发 rehash？",slug:"什么时候触发-rehash",normalizedTitle:"什么时候触发 rehash？",charIndex:1977},{level:3,title:"rehash 扩容扩多大？",slug:"rehash-扩容扩多大",normalizedTitle:"rehash 扩容扩多大？",charIndex:1995},{level:3,title:"渐进式 rehash 如何实现？",slug:"渐进式-rehash-如何实现",normalizedTitle:"渐进式 rehash 如何实现？",charIndex:6392},{level:2,title:"小结",slug:"小结",normalizedTitle:"小结",charIndex:12098},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:12512}],headersStr:"前言 Redis 如何避免hash冲突？ Redis 如何实现 rehash？ 什么时候触发 rehash？ rehash 扩容扩多大？ 渐进式 rehash 如何实现？ 小结 参考文献",content:"# 前言\n\n今天我们来聊聊Redis中的Hash\n\n对于Redis键值数据库来说，Hash表既是键值对中的一种值类型，同时，Redis也使用一个全局Hash表来保存所有的键值对，从而既满足应用存取Hash结构数据需求，又能提供快速查询功能。 那么，Hash表应用如此广泛的一个重要原因，就是从理论上来说，它能以O(1)的复杂度快速查询数据。Hash表通过Hash函数的计算，就能定位数据在表中的位置，紧接着可以对数据进行操作，这就使得数据操作非常快速。\n\nHash 表这个结构也并不难理解，但是在实际应用 Hash 表时，当数据量不断增加，它的性能就经常会受到哈希冲突和 rehash 开销的影响。而这两个问题的核心，其实都来自于 Hash 表要保存的数据量，超过了当前 Hash 表能容纳的数据量。 那么要如何应对这两个问题呢？事实上，这也是在大厂面试中，面试官经常会考核的问题。所以你现在可以先想想，如果你在面试中遇到了这两个问题，你会怎么回答呢？ OK，思考先到这里，现在我来告诉你 Redis 是怎么很好地解决这两个问题的\n\nRedis 为我们提供了一个经典的 Hash 表实现方案。针对哈希冲突，Redis 采用了链式哈希，在不扩容哈希表的前提下，将具有相同哈希值的数据链接起来，以便这些数据在表中 仍然可以被查询到；对于 rehash 开销，Redis 实现了渐进式 rehash 设计，进而缓解了 rehash 操作带来的额外开销对系统的性能影响。\n\n\n# Redis 如何避免hash冲突？\n\n * 第一种方案，就是我接下来要给你介绍的链式哈希。这里你需要先知道，链式哈希的链 不能太长，否则会降低 Hash 表性能。\n * 第二种方案，就是当链式哈希的链长达到一定长度时，我们可以使用 rehash。不过， 执行 rehash 本身开销比较大，所以就需要采用我稍后会给你介绍的渐进式 rehash 设 计。\n\n这样，当我们要查询 key5 时，可以先通过哈希函数计算，得到 key5 的哈希值被映射到了桶 9 中。然后，我们再逐一比较桶 9 中串接的 key，直到查找到 key5。如此一来，我们就能在链式哈希中找到所查的哈希项了。 不过，链式哈希也存在局限性，那就是随着链表长度的增加，Hash 表在一个位置上查询哈希项的耗时就会增加，从而增加了 Hash 表的整体查询时间，这样也会导致 Hash 表的性能下降。\n\n那么，有没有什么其他的方法可以减少对 Hash 表性能的影响呢？当然是有的，这就是接 下来我要给你介绍的 rehash 的设计与实现了。\n\n\n# Redis 如何实现 rehash？\n\nrehash 操作，其实就是指扩大 Hash 表空间。而 Redis 实现 rehash 的基本思路是这样 的：\n\n首先，Redis 准备了两个哈希表，用于 rehash 时交替保存数据。我在前面给你介绍过，Redis 在 dict.h 文件中使用 dictht 结构体定义了 Hash 表。不过， 在实际使用 Hash 表时，Redis 又在 dict.h 文件中，定义了一个 dict 结构体。这个结构体中有一个数组（ht[2]），包含了两个 Hash 表 ht[0]和 ht[1]。dict 结构体的代码定义如下 所示：\n\ntypedef struct dict {\n    dictType *type;\n    void *privdata;\n    //两个Hash表，交替使用，用于rehash操作\n    dictht ht[2];\n    // Hash表是否在进行rehash的标识，-1表示没有进行rehash\n    long rehashidx; /* rehashing not in progress if rehashidx == -1 */\n    int16_t pauserehash; /* If >0 rehashing is paused (<0 indicates coding error) */\n} dict;\n\n\n其次，在正常服务请求阶段，所有的键值对写入哈希表 ht[0]。\n\n接着，当进行 rehash 时，键值对被迁移到哈希表 ht[1]中。\n\n最后，当迁移完成后，ht[0]的空间会被释放，并把 ht[1]的地址赋值给 ht[0]，ht[1]的表 大小设置为 0。这样一来，又回到了正常服务请求的阶段，ht[0]接收和服务请求，ht[1] 作为下一次 rehash 时的迁移表。\n\n好，那么在了解了 Redis 交替使用两个 Hash 表实现 rehash 的基本思路后，我们还需要明确的是：在实现 rehash 时，都需要解决哪些问题？我认为主要有以下三点：\n\n * 什么时候触发 rehash？\n * rehash 扩容扩多大？\n * rehash 如何执行？\n\n所以下面，我就带你来逐一学习 Redis 对这三个问题的代码实现，通过代码实现，你就能明晰 Redis 针对这三个问题的设计思想了。\n\n\n# 什么时候触发 rehash？\n\n首先要知道，Redis 用来判断是否触发 rehash 的函数是 _dictExpandIfNeeded。所以接 下来我们就先看看， _dictExpandIfNeeded函数中进行扩容的触发条件；然后，我们再来了解下 _dictExpandIfNeeded又是在哪些函数中被调用的。\n\n实际上， _dictExpandIfNeeded 函数中定义了三个扩容条件。 下面的代码就展示了 _dictExpandIfNeeded 函数对这三个条件的定义，你可以看下。 那么，对于条件一来说，此时 Hash 表是空的，所以 Redis 就需要将 Hash 表空间设置为初始大小，而这是初始化的工作，并不属于 rehash 操作。\n\n什么时候触发 rehash？ rehash 扩容扩多大？ rehash 如何执行？\n\n * 条件一：ht[0]的大小为 0。\n * 条件二：ht[0]承载的元素个数已经超过了 ht[0]的大小，同时 Hash 表可以进行扩容。\n * 条件三：ht[0]承载的元素个数，是 ht[0]的大小的 dict_force_resize_ratio 倍，其中， dict_force_resize_ratio 的默认值是 5。\n\n/* Expand the hash table if needed */\nstatic int _dictExpandIfNeeded(dict *d)\n{\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n\n    /* If the hash table is empty expand it to the initial size. */\n    if (d->ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE);\n\n    /* If we reached the 1:1 ratio, and we are allowed to resize the hash\n     * table (global setting) or we should avoid it but the ratio between\n     * elements/buckets is over the \"safe\" threshold, we resize doubling\n     * the number of buckets. */\n    // ht[0]表使用的元素个数超过当前大小\n    // 并且可以扩容或者 ht[0]使用的元素个数/ht[0]表的大小 大于 dict_force_resize_ratio\n    // 并且能够允许扩展\n    if (d->ht[0].used >= d->ht[0].size &&\n        (dict_can_resize ||\n         d->ht[0].used/d->ht[0].size > dict_force_resize_ratio) &&\n        dictTypeExpandAllowed(d))\n    {\n        return dictExpand(d, d->ht[0].used + 1);\n    }\n    return DICT_OK;\n}\n\n\n那么，对于条件一来说，此时 Hash 表是空的，所以 Redis 就需要将 Hash 表空间设置为初始大小，而这是初始化的工作，并不属于 rehash 操作。\n\n而条件二和三就对应了 rehash 的场景。因为在这两个条件中，都比较了 Hash 表当前承载 的元素个数（d->ht[0].used）和 Hash 表当前设定的大小（d->ht[0].size），这两个值的比值一般称为负载因子（load factor）。也就是说，Redis 判断是否进行 rehash 的条 件，就是看 load factor 是否大于等于 1 和是否大于 5。\n\n实际上，当 load factor 大于 5 时，就表明 Hash 表已经过载比较严重了，需要立刻进行库扩容。而当 load factor 大于等于 1 时，Redis 还会再判断 dict_can_resize 这个变量值，查看当前是否可以进行扩容。 你可能要问了，这里的 dict_can_resize 变量值是啥呀？其实，这个变量值是在 dictEnableResize 和 dictDisableResize 两个函数中设置的，它们的作用分别是启用和禁止哈希表执行 rehash 功能，如下所示：\n\nvoid dictEnableResize(void) {\n    dict_can_resize = 1;\n}\n\nvoid dictDisableResize(void) {\n    dict_can_resize = 0;\n}\n\n\n然后，这两个函数又被封装在了 updateDictResizePolicy 函数中。\n\nupdateDictResizePolicy 函数是用来启用或禁用 rehash 扩容功能的，这个函数调用 dictEnableResize 函数启用扩容功能的条件是：\n\n * 当前没有 RDB 子进程，并且也没有 AOF 子进程。\n\n这就对应了 Redis 没有执行 RDB 快照和没有进行 AOF 重写的场景。你可以参考下面给出的代码：\n\nvoid updateDictResizePolicy(void) {\nif (server.rdb_child_pid == -1 && server.aof_child_pid == -1)\n\tdictEnableResize();\nelse\n\tdictDisableResize();\n}\n\n\n好，到这里我们就了解了 _dictExpandIfNeeded 对 rehash 的判断触发条件，那么现在， 我们再来看下 Redis 会在哪些函数中，调用 _dictExpandIfNeeded 进行判断。 首先，通过在dict.c文件中查看 _dictExpandIfNeeded 的被调用关系，我们可以发现， _dictExpandIfNeeded 是被 _dictKeyIndex 函数调用的，而 _dictKeyIndex 函数又会被 dictAddRaw 函数调用，然后 dictAddRaw 会被以下三个函数调用。\n\n * dictAdd：用来往 Hash 表中添加一个键值对。\n * dictRelace：用来往 Hash 表中添加一个键值对，或者键值对存在时，修改键值对。\n * dictAddorFind：直接调用 dictAddRaw\n\n因此，当我们往 Redis 中写入新的键值对或是修改键值对时，Redis 都会判断下是否需要进行 rehash。这里你可以参考下面给出的示意图，其中就展示了 _dictExpandIfNeeded 被调用的关系。\n\n好了，简而言之，Redis 中触发 rehash 操作的关键，就是dictExpandIfNeeded 函数 和 updateDictResizePolicy 函数。dictExpandIfNeeded 函数会根据 Hash 表的负载因子 以及能否进行 rehash 的标识，判断是否进行 rehash，而 updateDictResizePolicy 函数 会根据 RDB 和 AOF 的执行情况，启用或禁用 rehash。\n\n接下来，我们继续探讨 Redis 在实现 rehash 时，要解决的第二个问题：rehash 扩容扩多 大？\n\n\n# rehash 扩容扩多大？\n\n在 Redis 中，rehash 对 Hash 表空间的扩容是通过调用 dictExpand 函数来完成的。 dictExpand 函数的参数有两个，一个是要扩容的 Hash 表，另一个是要扩到的容量，下面 的代码就展示了 dictExpand 函数的原型定义：\n\n int dictExpand(dict *d, unsigned long size);\n\n\n那么，对于一个 Hash 表来说，我们就可以根据前面提到的 _dictExpandIfNeeded 函数， 来判断是否要对其进行扩容。而一旦判断要扩容，Redis 在执行 rehash 操作时，对 Hash 表扩容的思路也很简单，就是如果当前表的已用空间大小为 size，那么就将表扩容到 size*2 的大小。\n\n如下所示，当 _dictExpandIfNeeded 函数在判断了需要进行 rehash 后，就调用 dictExpand 进行扩容。这里你可以看到，rehash 的扩容大小是当前 ht[0]已使用大小的 2 倍。\n\ndictExpand(d, d->ht[0].used*2);\n\n\n而在 dictExpand 函数中，具体执行是由 _dictNextPower 函数完成的，以下代码显示的 Hash 表扩容的操作，就是从 Hash 表的初始大小（DICT_HT_INITIAL_SIZE），不停地乘 以 2，直到达到目标大小。\n\nstatic unsigned long _dictNextPower(unsigned long size)\n{\n    // 哈希表的初始大小\n    unsigned long i = DICT_HT_INITIAL_SIZE;\n\t// 如果要扩容的大小已经超过最大值，则返回最大值加1\n    if (size >= LONG_MAX) return LONG_MAX + 1LU;\n    // 扩容大小没有超过最大值\n    while(1) {\n        if (i >= size)\n            return i;\n        // 每一步扩容都在现有大小基础上乘以2\n        i *= 2;\n    }\n}\n\n\n好，下面我们再来看看 Redis 要解决的第三个问题，即 rehash 要如何执行？而这个问 题，本质上就是 Redis 要如何实现渐进式 rehash 设计。\n\n\n# 渐进式 rehash 如何实现？\n\n那么这里，我们要先搞清楚一个问题，就是为什么要实现渐进式 rehash？ 其实这是因为，Hash 表在执行 rehash 时，由于 Hash 表空间扩大，原本映射到某一位置 的键可能会被映射到一个新的位置上，因此，很多键就需要从原来的位置拷贝到新的位 置。而在键拷贝时，由于 Redis 主线程无法执行其他请求，所以键拷贝会阻塞主线程，这样就会产生 rehash 开销。\n\n而为了降低 rehash 开销，Redis 就提出了渐进式 rehash 的方法。\n\n简单来说，渐进式 rehash 的意思就是 Redis 并不会一次性把当前 Hash 表中的所有键， 都拷贝到新位置，而是会分批拷贝，每次的键拷贝只拷贝 Hash 表中一个 bucket 中的哈希项。这样一来，每次键拷贝的时长有限，对主线程的影响也就有限了。\n\n那么，渐进式 rehash 在代码层面是如何实现的呢？这里有两个关键函数：dictRehash 和 _dictRehashStep。\n\n我们先来看 dictRehash 函数，这个函数实际执行键拷贝，它的输入参数有两个，分别是 全局哈希表（即前面提到的 dict 结构体，包含了 ht[0]和 ht[1]）和需要进行键拷贝的桶数量（bucket 数量）。\n\ndictRehash 函数的整体逻辑包括两部分：\n\n首先，该函数会执行一个循环，根据要进行键拷贝的 bucket 数量 n，依次完成这些 bucket 内部所有键的迁移。当然，如果 ht[0]哈希表中的数据已经都迁移完成了，键拷贝的循环也会停止执行\n\n其次，在完成了 n 个 bucket 拷贝后，dictRehash 函数的第二部分逻辑，就是判断 ht[0]表中数据是否都已迁移完。如果都迁移完了，那么 ht[0]的空间会被释放。因为 Redis 在处理请求时，代码逻辑中都是使用 ht[0]，所以当 rehash 执行完成后，虽然数据都在 ht[1]中了，但 Redis仍然会把 ht[1]赋值给ht[0]，以便其他部分的代码逻辑正常使用。\n\n而在 ht[1]赋值给 ht[0]后，它的大小就会被重置为 0，等待下一次 rehash。与此同时， 全局哈希表中的rehashidx 变量会被标为 -1，表示 rehash 结束了（这里的 rehashidx 变量用来表示 rehash 的进度，稍后我会给你具体解释）。\n\n我画了下面这张图，展示了 dictRehash 的主要执行流程，你可以看下。\n\nint dictRehash(dict *d, int n) {\n    int empty_visits = n*10; /* Max number of empty buckets to visit. */\n    if (!dictIsRehashing(d)) return 0;\n\n    // 主循环，根据要拷贝的bucket数量n，循环n次后停止或ht[0]中的数据迁移完停止\n    while(n-- && d->ht[0].used != 0) {\n        dictEntry *de, *nextde;\n\n        /* Note that rehashidx can't overflow as we are sure there are more\n         * elements because ht[0].used != 0 */\n        assert(d->ht[0].size > (unsigned long)d->rehashidx);\n        while(d->ht[0].table[d->rehashidx] == NULL) {\n            d->rehashidx++;\n            if (--empty_visits == 0) return 1;\n        }\n        de = d->ht[0].table[d->rehashidx];\n        /* Move all the keys in this bucket from the old to the new hash HT */\n        while(de) {\n            uint64_t h;\n\n            nextde = de->next;\n            /* Get the index in the new hash table */\n            h = dictHashKey(d, de->key) & d->ht[1].sizemask;\n            de->next = d->ht[1].table[h];\n            d->ht[1].table[h] = de;\n            d->ht[0].used--;\n            d->ht[1].used++;\n            de = nextde;\n        }\n        d->ht[0].table[d->rehashidx] = NULL;\n        d->rehashidx++;\n    }\n\n    //判断ht[0]的数据是否迁移完成\n    /* Check if we already rehashed the whole table... */\n    if (d->ht[0].used == 0) {\n        // ht[0]迁移完后，释放ht[0]内存空间\n        zfree(d->ht[0].table);\n        // 让ht[0]指向ht[1]，以便接受正常的请求\n        d->ht[0] = d->ht[1];\n        // 重置ht[1]的大小为0\n        _dictReset(&d->ht[1]);\n        // 设置全局哈希表的rehashidx标识为-1，表示rehash结束\n        d->rehashidx = -1;\n        // 返回0，表示ht[0]中所有元素都迁移完\n        return 0;\n    }\n\n    //返回1，表示ht[0]中仍然有元素没有迁移完\n    /* More to rehash... */\n    return 1;\n}\n\n\n好，在了解了 dictRehash 函数的主体逻辑后，我们再看下渐进式 rehash 是如何按照 bucket 粒度拷贝数据的，这其实就和全局哈希表 dict 结构中的 rehashidx 变量相关了。\n\nrehashidx 变量表示的是当前 rehash 在对哪个 bucket 做数据迁移。比如，当 rehashidx 等于 0 时，表示对 ht[0]中的第一个 bucket 进行数据迁移；当 rehashidx 等于 1 时，表 示对 ht[0]中的第二个 bucket 进行数据迁移，以此类推。\n\n而 dictRehash 函数的主循环，首先会判断 rehashidx 指向的 bucket 是否为空，如果为 空，那就将 rehashidx 的值加 1，检查下一个 bucket。\n\n那么，有没有可能连续几个 bucket 都为空呢？其实是有可能的，在这种情况下，渐进式 rehash 不会一直递增 rehashidx 进行检查。这是因为一旦执行了 rehash，Redis 主线程就无法处理其他请求了。\n\n所以，渐进式 rehash 在执行时设置了一个变量 empty_visits，用来表示已经检查过的空 bucket，当检查了一定数量的空 bucket 后，这一轮的 rehash 就停止执行，转而继续处理外来请求，避免了对 Redis 性能的影响。下面的代码显示了这部分逻辑，你可以看下。\n\n// 如果当前要迁移的bucket中没有元素\nwhile(d->ht[0].table[d->rehashidx] == NULL) {\n    d->rehashidx++;\n    if (--empty_visits == 0) return 1;\n}\n\n\n而如果 rehashidx 指向的 bucket 有数据可以迁移，那么 Redis 就会把这个 bucket 中的哈希项依次取出来，并根据 ht[1]的表空间大小，重新计算哈希项在 ht[1]中的 bucket 位置，然后把这个哈希项赋值到 ht[1]对应 bucket 中。\n\n这样，每做完一个哈希项的迁移，ht[0]和 ht[1]用来表示承载哈希项多少的变量 used，就 会分别减一和加一。当然，如果当前 rehashidx 指向的 bucket 中数据都迁移完了， rehashidx 就会递增加 1，指向下一个 bucket。下面的代码显示了这一迁移过程。\n\n while(n-- && d->ht[0].used != 0) {\n     dictEntry *de, *nextde;\n\n     /* Note that rehashidx can't overflow as we are sure there are more\n         * elements because ht[0].used != 0 */\n     assert(d->ht[0].size > (unsigned long)d->rehashidx);\n     while(d->ht[0].table[d->rehashidx] == NULL) {\n         d->rehashidx++;\n         if (--empty_visits == 0) return 1;\n     }\n     // 获得哈希表中哈希项\n     de = d->ht[0].table[d->rehashidx];\n     /* Move all the keys in this bucket from the old to the new hash HT */\n     while(de) {\n         uint64_t h;\n\t\t // 获得同一个bucket中下一个哈希项\n         nextde = de->next;\n         /* Get the index in the new hash table */\n         // 根据扩容后的哈希表ht[1]大小，计算当前哈希项在扩容后哈希表中的bucket位置\n         h = dictHashKey(d, de->key) & d->ht[1].sizemask;\n         // 将当前哈希项添加到扩容后的哈希表ht[1]中\n         de->next = d->ht[1].table[h];\n         d->ht[1].table[h] = de;\n         // 减少当前哈希表的哈希项个数\n         d->ht[0].used--;\n         // 增加扩容后哈希表的哈希项个数\n         d->ht[1].used++;\n         de = nextde;\n     }\n     // 如果当前bucket中已经没有哈希项了，将该bucket置为NULL\n     d->ht[0].table[d->rehashidx] = NULL;\n     // 将rehash加1，下一次将迁移下一个bucket中的元素\n     d->rehashidx++;\n }\n\n\n好了，到这里，我们就已经基本了解了 dictRehash 函数的全部逻辑。 现在我们知道，dictRehash 函数本身是按照 bucket 粒度执行哈希项迁移的，它内部执行 的 bucket 迁移个数，主要由传入的循环次数变量 n 来决定。但凡 Redis 要进行 rehash操作，最终都会调用 dictRehash 函数。\n\n接下来，我们来学习和渐进式 rehash 相关的第二个关键函数 _dictRehashStep，这个函 数实现了每次只对一个 bucket 执行 rehash。 从 Redis 的源码中我们可以看到，一共会有 5 个函数通过调用 _dictRehashStep 函数，进而调用 dictRehash 函数，来执行 rehash，它们分别是：dictAddRaw， dictGenericDelete，dictFind，dictGetRandomKey，dictGetSomeKeys。\n\n其中，dictAddRaw 和 dictGenericDelete 函数，分别对应了往 Redis 中增加和删除键值对，而后三个函数则对应了在 Redis 中进行查询操作。下图展示了这些函数间的调用关系：\n\n但你要注意，不管是增删查哪种操作，这 5 个函数调用的 _dictRehashStep 函数，给 dictRehash 传入的循环次数变量 n 的值都为 1，下面的代码就显示了这一传参的情况。\n\nstatic void _dictRehashStep(dict *d) {\n    // 给dictRehash传入的循环次数参数为1，表明每迁移完一个bucket ，就执行正常操作\n    if (d->pauserehash == 0) dictRehash(d,1);\n}\n\n\n这样一来，每次迁移完一个 bucket，Hash 表就会执行正常的增删查请求操作，这就是在代码层面实现渐进式 rehash 的方法。\n\n\n# 小结\n\n实现一个高性能的Hash表不仅是Redis的需求，也是很多计算机系统开发过程中的重要目标。而要想实现一个性能优异的Hash表，就需要重点解决哈希冲突和rehash开销这两个问题。 今天这节课，我带你学习了Redis中Hash表的结构设计、链式哈希方法的实现，以及渐进式rehash方法的设计实现。Redis中Hash表的结构设计很特别，它的每个哈希项都包含了一个指针，用于实现链式哈希。同时，Redis在全局哈希表中还包含了两个Hash表，这种设计思路也是为了在实现rehash时，帮助数据从一个表迁移到另一个表。 此外，Redis实现的渐进式rehash是一个用于Hash表扩容的通用方法，非常值得我们学习。这个设计方法的关键是每次仅迁移有限个数的bucket，避免一次性迁移给所有bucket带来的性能影响。当你掌握了渐进式rehash这个设计思想和实现方法，你就可以把它应用到自己的Hash表实现场景中。\n\n\n# 参考文献\n\nRedis 源码剖析与实战 (geekbang.org)",normalizedContent:"# 前言\n\n今天我们来聊聊redis中的hash\n\n对于redis键值数据库来说，hash表既是键值对中的一种值类型，同时，redis也使用一个全局hash表来保存所有的键值对，从而既满足应用存取hash结构数据需求，又能提供快速查询功能。 那么，hash表应用如此广泛的一个重要原因，就是从理论上来说，它能以o(1)的复杂度快速查询数据。hash表通过hash函数的计算，就能定位数据在表中的位置，紧接着可以对数据进行操作，这就使得数据操作非常快速。\n\nhash 表这个结构也并不难理解，但是在实际应用 hash 表时，当数据量不断增加，它的性能就经常会受到哈希冲突和 rehash 开销的影响。而这两个问题的核心，其实都来自于 hash 表要保存的数据量，超过了当前 hash 表能容纳的数据量。 那么要如何应对这两个问题呢？事实上，这也是在大厂面试中，面试官经常会考核的问题。所以你现在可以先想想，如果你在面试中遇到了这两个问题，你会怎么回答呢？ ok，思考先到这里，现在我来告诉你 redis 是怎么很好地解决这两个问题的\n\nredis 为我们提供了一个经典的 hash 表实现方案。针对哈希冲突，redis 采用了链式哈希，在不扩容哈希表的前提下，将具有相同哈希值的数据链接起来，以便这些数据在表中 仍然可以被查询到；对于 rehash 开销，redis 实现了渐进式 rehash 设计，进而缓解了 rehash 操作带来的额外开销对系统的性能影响。\n\n\n# redis 如何避免hash冲突？\n\n * 第一种方案，就是我接下来要给你介绍的链式哈希。这里你需要先知道，链式哈希的链 不能太长，否则会降低 hash 表性能。\n * 第二种方案，就是当链式哈希的链长达到一定长度时，我们可以使用 rehash。不过， 执行 rehash 本身开销比较大，所以就需要采用我稍后会给你介绍的渐进式 rehash 设 计。\n\n这样，当我们要查询 key5 时，可以先通过哈希函数计算，得到 key5 的哈希值被映射到了桶 9 中。然后，我们再逐一比较桶 9 中串接的 key，直到查找到 key5。如此一来，我们就能在链式哈希中找到所查的哈希项了。 不过，链式哈希也存在局限性，那就是随着链表长度的增加，hash 表在一个位置上查询哈希项的耗时就会增加，从而增加了 hash 表的整体查询时间，这样也会导致 hash 表的性能下降。\n\n那么，有没有什么其他的方法可以减少对 hash 表性能的影响呢？当然是有的，这就是接 下来我要给你介绍的 rehash 的设计与实现了。\n\n\n# redis 如何实现 rehash？\n\nrehash 操作，其实就是指扩大 hash 表空间。而 redis 实现 rehash 的基本思路是这样 的：\n\n首先，redis 准备了两个哈希表，用于 rehash 时交替保存数据。我在前面给你介绍过，redis 在 dict.h 文件中使用 dictht 结构体定义了 hash 表。不过， 在实际使用 hash 表时，redis 又在 dict.h 文件中，定义了一个 dict 结构体。这个结构体中有一个数组（ht[2]），包含了两个 hash 表 ht[0]和 ht[1]。dict 结构体的代码定义如下 所示：\n\ntypedef struct dict {\n    dicttype *type;\n    void *privdata;\n    //两个hash表，交替使用，用于rehash操作\n    dictht ht[2];\n    // hash表是否在进行rehash的标识，-1表示没有进行rehash\n    long rehashidx; /* rehashing not in progress if rehashidx == -1 */\n    int16_t pauserehash; /* if >0 rehashing is paused (<0 indicates coding error) */\n} dict;\n\n\n其次，在正常服务请求阶段，所有的键值对写入哈希表 ht[0]。\n\n接着，当进行 rehash 时，键值对被迁移到哈希表 ht[1]中。\n\n最后，当迁移完成后，ht[0]的空间会被释放，并把 ht[1]的地址赋值给 ht[0]，ht[1]的表 大小设置为 0。这样一来，又回到了正常服务请求的阶段，ht[0]接收和服务请求，ht[1] 作为下一次 rehash 时的迁移表。\n\n好，那么在了解了 redis 交替使用两个 hash 表实现 rehash 的基本思路后，我们还需要明确的是：在实现 rehash 时，都需要解决哪些问题？我认为主要有以下三点：\n\n * 什么时候触发 rehash？\n * rehash 扩容扩多大？\n * rehash 如何执行？\n\n所以下面，我就带你来逐一学习 redis 对这三个问题的代码实现，通过代码实现，你就能明晰 redis 针对这三个问题的设计思想了。\n\n\n# 什么时候触发 rehash？\n\n首先要知道，redis 用来判断是否触发 rehash 的函数是 _dictexpandifneeded。所以接 下来我们就先看看， _dictexpandifneeded函数中进行扩容的触发条件；然后，我们再来了解下 _dictexpandifneeded又是在哪些函数中被调用的。\n\n实际上， _dictexpandifneeded 函数中定义了三个扩容条件。 下面的代码就展示了 _dictexpandifneeded 函数对这三个条件的定义，你可以看下。 那么，对于条件一来说，此时 hash 表是空的，所以 redis 就需要将 hash 表空间设置为初始大小，而这是初始化的工作，并不属于 rehash 操作。\n\n什么时候触发 rehash？ rehash 扩容扩多大？ rehash 如何执行？\n\n * 条件一：ht[0]的大小为 0。\n * 条件二：ht[0]承载的元素个数已经超过了 ht[0]的大小，同时 hash 表可以进行扩容。\n * 条件三：ht[0]承载的元素个数，是 ht[0]的大小的 dict_force_resize_ratio 倍，其中， dict_force_resize_ratio 的默认值是 5。\n\n/* expand the hash table if needed */\nstatic int _dictexpandifneeded(dict *d)\n{\n    /* incremental rehashing already in progress. return. */\n    if (dictisrehashing(d)) return dict_ok;\n\n    /* if the hash table is empty expand it to the initial size. */\n    if (d->ht[0].size == 0) return dictexpand(d, dict_ht_initial_size);\n\n    /* if we reached the 1:1 ratio, and we are allowed to resize the hash\n     * table (global setting) or we should avoid it but the ratio between\n     * elements/buckets is over the \"safe\" threshold, we resize doubling\n     * the number of buckets. */\n    // ht[0]表使用的元素个数超过当前大小\n    // 并且可以扩容或者 ht[0]使用的元素个数/ht[0]表的大小 大于 dict_force_resize_ratio\n    // 并且能够允许扩展\n    if (d->ht[0].used >= d->ht[0].size &&\n        (dict_can_resize ||\n         d->ht[0].used/d->ht[0].size > dict_force_resize_ratio) &&\n        dicttypeexpandallowed(d))\n    {\n        return dictexpand(d, d->ht[0].used + 1);\n    }\n    return dict_ok;\n}\n\n\n那么，对于条件一来说，此时 hash 表是空的，所以 redis 就需要将 hash 表空间设置为初始大小，而这是初始化的工作，并不属于 rehash 操作。\n\n而条件二和三就对应了 rehash 的场景。因为在这两个条件中，都比较了 hash 表当前承载 的元素个数（d->ht[0].used）和 hash 表当前设定的大小（d->ht[0].size），这两个值的比值一般称为负载因子（load factor）。也就是说，redis 判断是否进行 rehash 的条 件，就是看 load factor 是否大于等于 1 和是否大于 5。\n\n实际上，当 load factor 大于 5 时，就表明 hash 表已经过载比较严重了，需要立刻进行库扩容。而当 load factor 大于等于 1 时，redis 还会再判断 dict_can_resize 这个变量值，查看当前是否可以进行扩容。 你可能要问了，这里的 dict_can_resize 变量值是啥呀？其实，这个变量值是在 dictenableresize 和 dictdisableresize 两个函数中设置的，它们的作用分别是启用和禁止哈希表执行 rehash 功能，如下所示：\n\nvoid dictenableresize(void) {\n    dict_can_resize = 1;\n}\n\nvoid dictdisableresize(void) {\n    dict_can_resize = 0;\n}\n\n\n然后，这两个函数又被封装在了 updatedictresizepolicy 函数中。\n\nupdatedictresizepolicy 函数是用来启用或禁用 rehash 扩容功能的，这个函数调用 dictenableresize 函数启用扩容功能的条件是：\n\n * 当前没有 rdb 子进程，并且也没有 aof 子进程。\n\n这就对应了 redis 没有执行 rdb 快照和没有进行 aof 重写的场景。你可以参考下面给出的代码：\n\nvoid updatedictresizepolicy(void) {\nif (server.rdb_child_pid == -1 && server.aof_child_pid == -1)\n\tdictenableresize();\nelse\n\tdictdisableresize();\n}\n\n\n好，到这里我们就了解了 _dictexpandifneeded 对 rehash 的判断触发条件，那么现在， 我们再来看下 redis 会在哪些函数中，调用 _dictexpandifneeded 进行判断。 首先，通过在dict.c文件中查看 _dictexpandifneeded 的被调用关系，我们可以发现， _dictexpandifneeded 是被 _dictkeyindex 函数调用的，而 _dictkeyindex 函数又会被 dictaddraw 函数调用，然后 dictaddraw 会被以下三个函数调用。\n\n * dictadd：用来往 hash 表中添加一个键值对。\n * dictrelace：用来往 hash 表中添加一个键值对，或者键值对存在时，修改键值对。\n * dictaddorfind：直接调用 dictaddraw\n\n因此，当我们往 redis 中写入新的键值对或是修改键值对时，redis 都会判断下是否需要进行 rehash。这里你可以参考下面给出的示意图，其中就展示了 _dictexpandifneeded 被调用的关系。\n\n好了，简而言之，redis 中触发 rehash 操作的关键，就是dictexpandifneeded 函数 和 updatedictresizepolicy 函数。dictexpandifneeded 函数会根据 hash 表的负载因子 以及能否进行 rehash 的标识，判断是否进行 rehash，而 updatedictresizepolicy 函数 会根据 rdb 和 aof 的执行情况，启用或禁用 rehash。\n\n接下来，我们继续探讨 redis 在实现 rehash 时，要解决的第二个问题：rehash 扩容扩多 大？\n\n\n# rehash 扩容扩多大？\n\n在 redis 中，rehash 对 hash 表空间的扩容是通过调用 dictexpand 函数来完成的。 dictexpand 函数的参数有两个，一个是要扩容的 hash 表，另一个是要扩到的容量，下面 的代码就展示了 dictexpand 函数的原型定义：\n\n int dictexpand(dict *d, unsigned long size);\n\n\n那么，对于一个 hash 表来说，我们就可以根据前面提到的 _dictexpandifneeded 函数， 来判断是否要对其进行扩容。而一旦判断要扩容，redis 在执行 rehash 操作时，对 hash 表扩容的思路也很简单，就是如果当前表的已用空间大小为 size，那么就将表扩容到 size*2 的大小。\n\n如下所示，当 _dictexpandifneeded 函数在判断了需要进行 rehash 后，就调用 dictexpand 进行扩容。这里你可以看到，rehash 的扩容大小是当前 ht[0]已使用大小的 2 倍。\n\ndictexpand(d, d->ht[0].used*2);\n\n\n而在 dictexpand 函数中，具体执行是由 _dictnextpower 函数完成的，以下代码显示的 hash 表扩容的操作，就是从 hash 表的初始大小（dict_ht_initial_size），不停地乘 以 2，直到达到目标大小。\n\nstatic unsigned long _dictnextpower(unsigned long size)\n{\n    // 哈希表的初始大小\n    unsigned long i = dict_ht_initial_size;\n\t// 如果要扩容的大小已经超过最大值，则返回最大值加1\n    if (size >= long_max) return long_max + 1lu;\n    // 扩容大小没有超过最大值\n    while(1) {\n        if (i >= size)\n            return i;\n        // 每一步扩容都在现有大小基础上乘以2\n        i *= 2;\n    }\n}\n\n\n好，下面我们再来看看 redis 要解决的第三个问题，即 rehash 要如何执行？而这个问 题，本质上就是 redis 要如何实现渐进式 rehash 设计。\n\n\n# 渐进式 rehash 如何实现？\n\n那么这里，我们要先搞清楚一个问题，就是为什么要实现渐进式 rehash？ 其实这是因为，hash 表在执行 rehash 时，由于 hash 表空间扩大，原本映射到某一位置 的键可能会被映射到一个新的位置上，因此，很多键就需要从原来的位置拷贝到新的位 置。而在键拷贝时，由于 redis 主线程无法执行其他请求，所以键拷贝会阻塞主线程，这样就会产生 rehash 开销。\n\n而为了降低 rehash 开销，redis 就提出了渐进式 rehash 的方法。\n\n简单来说，渐进式 rehash 的意思就是 redis 并不会一次性把当前 hash 表中的所有键， 都拷贝到新位置，而是会分批拷贝，每次的键拷贝只拷贝 hash 表中一个 bucket 中的哈希项。这样一来，每次键拷贝的时长有限，对主线程的影响也就有限了。\n\n那么，渐进式 rehash 在代码层面是如何实现的呢？这里有两个关键函数：dictrehash 和 _dictrehashstep。\n\n我们先来看 dictrehash 函数，这个函数实际执行键拷贝，它的输入参数有两个，分别是 全局哈希表（即前面提到的 dict 结构体，包含了 ht[0]和 ht[1]）和需要进行键拷贝的桶数量（bucket 数量）。\n\ndictrehash 函数的整体逻辑包括两部分：\n\n首先，该函数会执行一个循环，根据要进行键拷贝的 bucket 数量 n，依次完成这些 bucket 内部所有键的迁移。当然，如果 ht[0]哈希表中的数据已经都迁移完成了，键拷贝的循环也会停止执行\n\n其次，在完成了 n 个 bucket 拷贝后，dictrehash 函数的第二部分逻辑，就是判断 ht[0]表中数据是否都已迁移完。如果都迁移完了，那么 ht[0]的空间会被释放。因为 redis 在处理请求时，代码逻辑中都是使用 ht[0]，所以当 rehash 执行完成后，虽然数据都在 ht[1]中了，但 redis仍然会把 ht[1]赋值给ht[0]，以便其他部分的代码逻辑正常使用。\n\n而在 ht[1]赋值给 ht[0]后，它的大小就会被重置为 0，等待下一次 rehash。与此同时， 全局哈希表中的rehashidx 变量会被标为 -1，表示 rehash 结束了（这里的 rehashidx 变量用来表示 rehash 的进度，稍后我会给你具体解释）。\n\n我画了下面这张图，展示了 dictrehash 的主要执行流程，你可以看下。\n\nint dictrehash(dict *d, int n) {\n    int empty_visits = n*10; /* max number of empty buckets to visit. */\n    if (!dictisrehashing(d)) return 0;\n\n    // 主循环，根据要拷贝的bucket数量n，循环n次后停止或ht[0]中的数据迁移完停止\n    while(n-- && d->ht[0].used != 0) {\n        dictentry *de, *nextde;\n\n        /* note that rehashidx can't overflow as we are sure there are more\n         * elements because ht[0].used != 0 */\n        assert(d->ht[0].size > (unsigned long)d->rehashidx);\n        while(d->ht[0].table[d->rehashidx] == null) {\n            d->rehashidx++;\n            if (--empty_visits == 0) return 1;\n        }\n        de = d->ht[0].table[d->rehashidx];\n        /* move all the keys in this bucket from the old to the new hash ht */\n        while(de) {\n            uint64_t h;\n\n            nextde = de->next;\n            /* get the index in the new hash table */\n            h = dicthashkey(d, de->key) & d->ht[1].sizemask;\n            de->next = d->ht[1].table[h];\n            d->ht[1].table[h] = de;\n            d->ht[0].used--;\n            d->ht[1].used++;\n            de = nextde;\n        }\n        d->ht[0].table[d->rehashidx] = null;\n        d->rehashidx++;\n    }\n\n    //判断ht[0]的数据是否迁移完成\n    /* check if we already rehashed the whole table... */\n    if (d->ht[0].used == 0) {\n        // ht[0]迁移完后，释放ht[0]内存空间\n        zfree(d->ht[0].table);\n        // 让ht[0]指向ht[1]，以便接受正常的请求\n        d->ht[0] = d->ht[1];\n        // 重置ht[1]的大小为0\n        _dictreset(&d->ht[1]);\n        // 设置全局哈希表的rehashidx标识为-1，表示rehash结束\n        d->rehashidx = -1;\n        // 返回0，表示ht[0]中所有元素都迁移完\n        return 0;\n    }\n\n    //返回1，表示ht[0]中仍然有元素没有迁移完\n    /* more to rehash... */\n    return 1;\n}\n\n\n好，在了解了 dictrehash 函数的主体逻辑后，我们再看下渐进式 rehash 是如何按照 bucket 粒度拷贝数据的，这其实就和全局哈希表 dict 结构中的 rehashidx 变量相关了。\n\nrehashidx 变量表示的是当前 rehash 在对哪个 bucket 做数据迁移。比如，当 rehashidx 等于 0 时，表示对 ht[0]中的第一个 bucket 进行数据迁移；当 rehashidx 等于 1 时，表 示对 ht[0]中的第二个 bucket 进行数据迁移，以此类推。\n\n而 dictrehash 函数的主循环，首先会判断 rehashidx 指向的 bucket 是否为空，如果为 空，那就将 rehashidx 的值加 1，检查下一个 bucket。\n\n那么，有没有可能连续几个 bucket 都为空呢？其实是有可能的，在这种情况下，渐进式 rehash 不会一直递增 rehashidx 进行检查。这是因为一旦执行了 rehash，redis 主线程就无法处理其他请求了。\n\n所以，渐进式 rehash 在执行时设置了一个变量 empty_visits，用来表示已经检查过的空 bucket，当检查了一定数量的空 bucket 后，这一轮的 rehash 就停止执行，转而继续处理外来请求，避免了对 redis 性能的影响。下面的代码显示了这部分逻辑，你可以看下。\n\n// 如果当前要迁移的bucket中没有元素\nwhile(d->ht[0].table[d->rehashidx] == null) {\n    d->rehashidx++;\n    if (--empty_visits == 0) return 1;\n}\n\n\n而如果 rehashidx 指向的 bucket 有数据可以迁移，那么 redis 就会把这个 bucket 中的哈希项依次取出来，并根据 ht[1]的表空间大小，重新计算哈希项在 ht[1]中的 bucket 位置，然后把这个哈希项赋值到 ht[1]对应 bucket 中。\n\n这样，每做完一个哈希项的迁移，ht[0]和 ht[1]用来表示承载哈希项多少的变量 used，就 会分别减一和加一。当然，如果当前 rehashidx 指向的 bucket 中数据都迁移完了， rehashidx 就会递增加 1，指向下一个 bucket。下面的代码显示了这一迁移过程。\n\n while(n-- && d->ht[0].used != 0) {\n     dictentry *de, *nextde;\n\n     /* note that rehashidx can't overflow as we are sure there are more\n         * elements because ht[0].used != 0 */\n     assert(d->ht[0].size > (unsigned long)d->rehashidx);\n     while(d->ht[0].table[d->rehashidx] == null) {\n         d->rehashidx++;\n         if (--empty_visits == 0) return 1;\n     }\n     // 获得哈希表中哈希项\n     de = d->ht[0].table[d->rehashidx];\n     /* move all the keys in this bucket from the old to the new hash ht */\n     while(de) {\n         uint64_t h;\n\t\t // 获得同一个bucket中下一个哈希项\n         nextde = de->next;\n         /* get the index in the new hash table */\n         // 根据扩容后的哈希表ht[1]大小，计算当前哈希项在扩容后哈希表中的bucket位置\n         h = dicthashkey(d, de->key) & d->ht[1].sizemask;\n         // 将当前哈希项添加到扩容后的哈希表ht[1]中\n         de->next = d->ht[1].table[h];\n         d->ht[1].table[h] = de;\n         // 减少当前哈希表的哈希项个数\n         d->ht[0].used--;\n         // 增加扩容后哈希表的哈希项个数\n         d->ht[1].used++;\n         de = nextde;\n     }\n     // 如果当前bucket中已经没有哈希项了，将该bucket置为null\n     d->ht[0].table[d->rehashidx] = null;\n     // 将rehash加1，下一次将迁移下一个bucket中的元素\n     d->rehashidx++;\n }\n\n\n好了，到这里，我们就已经基本了解了 dictrehash 函数的全部逻辑。 现在我们知道，dictrehash 函数本身是按照 bucket 粒度执行哈希项迁移的，它内部执行 的 bucket 迁移个数，主要由传入的循环次数变量 n 来决定。但凡 redis 要进行 rehash操作，最终都会调用 dictrehash 函数。\n\n接下来，我们来学习和渐进式 rehash 相关的第二个关键函数 _dictrehashstep，这个函 数实现了每次只对一个 bucket 执行 rehash。 从 redis 的源码中我们可以看到，一共会有 5 个函数通过调用 _dictrehashstep 函数，进而调用 dictrehash 函数，来执行 rehash，它们分别是：dictaddraw， dictgenericdelete，dictfind，dictgetrandomkey，dictgetsomekeys。\n\n其中，dictaddraw 和 dictgenericdelete 函数，分别对应了往 redis 中增加和删除键值对，而后三个函数则对应了在 redis 中进行查询操作。下图展示了这些函数间的调用关系：\n\n但你要注意，不管是增删查哪种操作，这 5 个函数调用的 _dictrehashstep 函数，给 dictrehash 传入的循环次数变量 n 的值都为 1，下面的代码就显示了这一传参的情况。\n\nstatic void _dictrehashstep(dict *d) {\n    // 给dictrehash传入的循环次数参数为1，表明每迁移完一个bucket ，就执行正常操作\n    if (d->pauserehash == 0) dictrehash(d,1);\n}\n\n\n这样一来，每次迁移完一个 bucket，hash 表就会执行正常的增删查请求操作，这就是在代码层面实现渐进式 rehash 的方法。\n\n\n# 小结\n\n实现一个高性能的hash表不仅是redis的需求，也是很多计算机系统开发过程中的重要目标。而要想实现一个性能优异的hash表，就需要重点解决哈希冲突和rehash开销这两个问题。 今天这节课，我带你学习了redis中hash表的结构设计、链式哈希方法的实现，以及渐进式rehash方法的设计实现。redis中hash表的结构设计很特别，它的每个哈希项都包含了一个指针，用于实现链式哈希。同时，redis在全局哈希表中还包含了两个hash表，这种设计思路也是为了在实现rehash时，帮助数据从一个表迁移到另一个表。 此外，redis实现的渐进式rehash是一个用于hash表扩容的通用方法，非常值得我们学习。这个设计方法的关键是每次仅迁移有限个数的bucket，避免一次性迁移给所有bucket带来的性能影响。当你掌握了渐进式rehash这个设计思想和实现方法，你就可以把它应用到自己的hash表实现场景中。\n\n\n# 参考文献\n\nredis 源码剖析与实战 (geekbang.org)",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:14:59",lastUpdatedTimestamp:1726334099e3},{title:"时间轮",frontmatter:{title:"时间轮",date:"2024-09-15T02:25:42.000Z",permalink:"/pages/44dcc2/"},regularPath:"/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/01.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%97%E6%B3%95/10.%E6%97%B6%E9%97%B4%E8%BD%AE.html",relativePath:"01.系统设计算法/01.系统设计算法/10.时间轮.md",key:"v-6e4553fe",path:"/pages/44dcc2/",headers:[{level:2,title:"带着疑问",slug:"带着疑问",normalizedTitle:"带着疑问",charIndex:2},{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:1227},{level:2,title:"添加定时任务",slug:"添加定时任务",normalizedTitle:"添加定时任务",charIndex:1780},{level:2,title:'"动态"时间轮',slug:"动态-时间轮",normalizedTitle:"&quot;动态&quot;时间轮",charIndex:null},{level:3,title:"复用时间格",slug:"复用时间格",normalizedTitle:"复用时间格",charIndex:2395},{level:3,title:"时间轮升级",slug:"时间轮升级",normalizedTitle:"时间轮升级",charIndex:2644},{level:3,title:"层级时间轮",slug:"层级时间轮",normalizedTitle:"层级时间轮",charIndex:2932},{level:3,title:"添加定时任务",slug:"添加定时任务-2",normalizedTitle:"添加定时任务",charIndex:1780},{level:3,title:'"动态"层级时间轮',slug:"动态-层级时间轮",normalizedTitle:"&quot;动态&quot;层级时间轮",charIndex:null},{level:3,title:"时间轮降级",slug:"时间轮降级",normalizedTitle:"时间轮降级",charIndex:3896},{level:3,title:"时间轮的推进",slug:"时间轮的推进",normalizedTitle:"时间轮的推进",charIndex:4332},{level:2,title:"时间轮在 Kafka 中的实现",slug:"时间轮在-kafka-中的实现",normalizedTitle:"时间轮在 kafka 中的实现",charIndex:4580},{level:3,title:"时间轮的数据结构",slug:"时间轮的数据结构",normalizedTitle:"时间轮的数据结构",charIndex:4949},{level:3,title:"时间轮中的任务存放",slug:"时间轮中的任务存放",normalizedTitle:"时间轮中的任务存放",charIndex:5772},{level:3,title:"时间轮的升降级",slug:"时间轮的升降级",normalizedTitle:"时间轮的升降级",charIndex:6279},{level:3,title:"任务添加和驱动时间轮滚动核心流程图",slug:"任务添加和驱动时间轮滚动核心流程图",normalizedTitle:"任务添加和驱动时间轮滚动核心流程图",charIndex:7535},{level:3,title:"重点代码介绍",slug:"重点代码介绍",normalizedTitle:"重点代码介绍",charIndex:7559},{level:3,title:"DelayQueue 与 kafka 时间轮",slug:"delayqueue-与-kafka-时间轮",normalizedTitle:"delayqueue 与 kafka 时间轮",charIndex:10701},{level:3,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:11397},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:11621}],headersStr:'带着疑问 前言 添加定时任务 "动态"时间轮 复用时间格 时间轮升级 层级时间轮 添加定时任务 "动态"层级时间轮 时间轮降级 时间轮的推进 时间轮在 Kafka 中的实现 时间轮的数据结构 时间轮中的任务存放 时间轮的升降级 任务添加和驱动时间轮滚动核心流程图 重点代码介绍 DelayQueue 与 kafka 时间轮 总结 参考文献',content:'# 带着疑问\n\n第一个问题：如果一台机器上有 10w 个定时任务，如何做到高效触发？\n\n具体场景是：\n\n> 有一个 APP 实时消息通道系统，对每个用户会维护一个 APP 到服务器的 TCP 连接，用来实时收发消息，对这个 TCP 连接，有这样一个需求：“如果连续 30s 没有请求包（例如登录，消息，keepalive 包），服务端就要将这个用户的状态置为离线”。\n> \n> 其中，单机 TCP 同时在线量约在 10w 级别，keepalive 请求包较分散大概 30s 一次，吞吐量约在 3000qps。\n\n怎么做？\n\n常用方案使用 time 定时任务，每秒扫描一次所有连接的集合 Map<uid, last_packet_time>，把连接时间（每次有新的请求更新对应连接的连接时间）比当前时间的差值大 30s 的连接找出来处理。\n\n另一种方案，使用环形队列法：\n\n三个重要的数据结构：\n\n 1. 30s 超时，就创建一个 index 从 0 到 30 的环形队列（本质是个数组）\n 2. 环上每一个 slot 是一个 Set，任务集合\n 3. 同时还有一个 Map<uid, index>，记录 uid 落在环上的哪个 slot 里\n\n这样当有某用户 uid 有请求包到达时：\n\n 1. 从 Map 结构中，查找出这个 uid 存储在哪一个 slot 里\n 2. 从这个 slot 的 Set 结构中，删除这个 uid\n 3. 将 uid 重新加入到新的 slot 中，具体是哪一个 slot 呢 => Current Index 指针所指向的上一个 slot，因为这个 slot，会被 timer 在 30s 之后扫描到\n 4. 更新 Map，这个 uid 对应 slot 的 index 值\n\n哪些元素会被超时掉呢？\n\nCurrent Index 每秒种移动一个 slot，这个 slot 对应的 Set中所有 uid 都应该被集体超时！如果最近 30s 有请求包来到，一定被放到 Current Index 的前一个 slot 了，Current Index 所在的 slot 对应 Set 中所有元素，都是最近 30s 没有请求包来到的。\n\n所以，当没有超时时，Current Index 扫到的每一个 slot 的 Set 中应该都没有元素。\n\n两种方案对比：\n\n方案一每次都要轮询所有数据，而方案二使用环形队列只需要轮询这一刻需要过期的数据，如果没有数据过期则没有数据要处理，并且是批量超时，并且由于是环形结构更加节约空间，这很适合高性能场景。\n\n第二个问题： 在开发过程中有延迟一定时间的任务要执行，怎么做？\n\n如果不重复造轮子的话，我们的选择当然是延迟队列或者 Timer。\n\n延迟队列和在 Timer 中增 加延时任务采用数组表示的最小堆的数据结构实现，每次放入新元素和移除队首元素时间复杂度为 O(nlog(n))。\n\n\n# 前言\n\n时间轮，是一种实现延迟功能（定时器）的巧妙算法，在 Netty，Zookeeper，Kafka 等各种框架中，甚至Linux内核中都有用到。\n\n设计源于生活\n\n时间轮，其设计正是来源于生活中的时钟。\n\n如图就是一个简单的时间轮：\n\n\n\n图中大圆的圆心位置表示的是当前的时间，随着时间推移, 圆心处的时间也会不断跳动。\n\n下面我们对着这个图，来说说Kafka的时间轮TimingWheel。\n\nKafka时间轮的底层就是一个环形数组，而数组中每个元素都存放一个双向链表TimerTaskList，链表中封装了很多延时任务。\n\nKafka中一个时间轮TimingWheel是由20个时间格组成，wheelSize = 20；每格的时间跨度是1ms，tickMs = 1ms。参照Kafka，上图中也用了20个灰边小圆表示时间格，为了动画演示可以看得清楚，我们这里每个小圆的时间跨度是1s。\n\n所以现在整个时间轮的时间跨度就是 tickMs * wheelSize ，也就是 20s。从0s到19s，我们都分别有一个灰边小圆来承载。\n\nKafka的时间轮还有一个表盘指针 currentTime，表示时间轮当前所处的时间。也就是图中用黑色粗线表示的圆，随着时间推移, 这个指针也会不断前进;\n\n\n\n\n# 添加定时任务\n\n有了时间轮，现在可以往里面添加定时任务了。我们用一个粉红色的小圆来表示一个定时任务。\n\n\n\n这里先讲一下设定，每一个定时任务都有延时时间delayTime，和过期时间ExpiredTime。比如当前时间是10s，我们添加了个延时时间为2s的任务，那么这个任务的过期时间就是12s，也就是当前时间10s再走两秒，变成了12s的时候，就到了触发这个定时任务的时间。\n\n而时间轮上代表时间格的灰边小圆上显示的数字，可以理解为任务的过期时间。\n\n\n\n讲清楚这些设定后，我们就开始添加定时任务吧。\n\n初始的时候, 时间轮的指针定格在0。此时添加一个超时时间为2s的任务, 那么这个任务将会插入到第二个时间格中。\n\n\n\n当时间轮的指针到达第二个时间格时, 会处理该时间格上对应的任务。在动画上就是让红色的小圆消失!\n\n\n\n如果这个时候又插入一个延时时间为8s的任务进来, 这个任务的过期时间就是在当前时间2s的基础上加8s, 也就是10s, 那么这个任务将会插入到过期时间为10s的时间格中。\n\n\n\n\n# "动态"时间轮\n\n到目前为止，一切都很好理解。\n\n那么如果在当前时间是2s的时候, 插入一个延时时间为19s的任务时,这个任务的过期时间就是在当前时间2s的基础上加19s, 也就是21s。\n\n请看下图，当前的时间轮是没有过期时间为21s的时间格。这个任务将会插入到过期时间为1s的时间格中，这是怎么回事呢？\n\n\n\n\n# 复用时间格\n\n为了解答上面的问题，我们先来点魔法， 让时间轮上的时间都动起来！\n\n\n\n其实呢，当指针定格在2s的位置时, 时间格0s, 1s和2s就已经是过期的时间格。\n\n也就是说指针可以用来划分过期的时间格[0,2]和未来的时间格 [3,19]。而过期的时间格可以继续复用。比如过期的时间格0s就变成了20s, 存放过期时间为20s的任务。\n\n理解了时间格的复用之后，再看回刚刚的例子，当前时间是2s时，添加延时时间为19s的任务，那么这个任务就会插入到过期时间为21s的时间格中。\n\n\n\n\n# 时间轮升级\n\n下面，新的问题来了，请坐好扶稳。\n\n如果在当前时间是2s的时候, 插入一个延时时间为22s的任务, 这个任务的过期时间就是在2s的基础上加22s，也就是24s。\n\n\n\n显然当前时间轮是无法找到过期时间格为24秒的时间格，因为当前过期时间最大的时间格才到21s。而且我们也没办法像前面那样再复用时间格，因为除了过期时间为2s的时间格，其他的时间格都还没过期呢。当前时间轮无法承载这个定时任务,那么应该怎么办呢?\n\n当然我们可以选择扩展时间轮上的时间格, 但是这样一来，时间轮就失去了意义。\n\n是时候要升级时间轮了！\n\n我们先来理解下多层时间轮之间的联系。\n\n\n# 层级时间轮\n\n如图是一个两层的时间轮:\n\n\n\n第二层时间轮也是由20个时间格组成, 每个时间格的跨度是20s。\n\n图中展示了每个时间格对应的过期时间范围, 我们可以清晰地看到, 第二层时间轮的第0个时间格的过期时间范围是 [0,19]。也就是说, 第二层时间轮的一个时间格就可以表示第一层时间轮的所有(20个)时间格;\n\n为了进一步理清第一层时间轮和第二层时间轮的关系, 我们拉着时间的小手, 一起观看下面的动图:\n\n\n\n可以看到，第二层时间轮同样也有自己的指针, 每当第一层时间轮走完一个周期，第二层时间轮的指针就会推进一格。\n\n\n# 添加定时任务\n\n回到一开始的问题，在当前时间是2s的时候, 插入一个延时时间为22s的任务，该任务过期时间为24s。\n\n\n\n当第一层时间轮容纳不下时，进入第二层时间轮，并插入到过期时间为[20,39]的时间格中。\n\n我们再来个例子，如果在当前时间是2s的时候, 插入一个延时时间为350s的任务, 这个任务的过期时间就是在2s的基础上加350s，也就是352s。\n\n\n\n从图中可以看到，该任务插入到第二层时间轮过期时间为[340,359]s的时间格中，也就是第17格的位置。\n\n\n# "动态"层级时间轮\n\n通常来说, 第二层时间轮的第0个时间格是用来表示第一层时间轮的, 这一格是存放不了任务的, 因为超时时间0-20s的任务, 第一层时间轮就可以处理了。\n\n但是! 事情往往没这么简单, 我们时间轮上的时间格都是可以复用的! 那么这在第二层时间轮上又是怎么体现的呢?\n\n下面是魔法时间， 我们让时间轮上的过期时间都动起来！\n\n\n\n从图中可以看到，当第一层时间轮的指针定格在1s时，超时时间0s的时间格就过期了。而这个时候，第二层时间轮第0个时间格的时间范围就从[0,19]分为了过期的[0],和未过期的[1,19]。而过期的[0]就会被新的过期时间[400]复用。\n\n[0-19]\n\n[400][1,19]\n\n[400,401][2,19]\n\n......\n\n[400,419]\n\n\n所以，如果在当前时间是2s的时候, 插入一个延时时间为399s的任务, 这个任务的过期时间就是在2s的基础上加399s，也就是401s。如图，这个任务还是会插到第二层时间轮第0个时间格中去。\n\n\n\n\n# 时间轮降级\n\n还是用回这个大家都已经耳熟能详的例子，在当前时间是2s的时候, 插入一个延时时间为22s的任务，该任务过期时间为24s。最后进入第二层时间轮，并插入到过期时间为[20,39]的时间格中。\n\n当二层时间轮上的定时任务到期后，时间轮是怎么做的呢？\n\n\n\n从图中可以看到，随着当前时间从2s继续往前推进，一直到20s的时候，总共经过了18s。此时第二层时间轮中，超时时间为[20-39s]的时间格上的任务到期。\n\n原本超时时间为24s的任务会被取出来，重新加入时间轮。此时该定时任务的延时时间从原本的22s，到现在还剩下4s（22s-18s）。最后停留在第一层时间轮超时时间为24s的时间格，也就是第4个时间格。\n\n随着当前时间继续推进，再经过4s后，该定时任务到期被执行。\n\n从这里可以看出时间轮的巧妙之处，两层时间轮只用了40个数组元素，却可以承载[0-399s]的定时任务。而三层时间轮用60个数组元素，就可以承载[0-7999s]的定时任务！\n\n\n\n\n# 时间轮的推进\n\n从动画中可以注意到, 随着时间推进, 时间轮的指针循环往复地定格在每一个时间格上, 每一次都要判断当前定格的时间格里是不是有任务存在;\n\n其中有很多时间格都是没有任务的, 指针定格在这种空的时间格中, 就是一次"空推进";\n\n比如说, 插入一个延时时间400s的任务, 指针就要执行399次"空推进", 这是一种浪费!\n\n那么Kafka是怎么解决这个问题的呢？这就要从延迟队列DelayQueue开始讲起了！时间轮搭配延迟队列DelayQueue，会发生什么化学反应呢？\n\n\n# 时间轮在 Kafka 中的实现\n\n方案二所采用的环形队列，就是时间轮的底层数据结构，它能够让需要处理的数据（任务的抽象）集中，在 Kafka 中存在大量的延迟操作，比如延迟生产、延迟拉取以及延迟删除等。Kafka 并没有使用 JDK 自带的 Timer 或者 DelayQueue 来实现延迟的功能，而是基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）。JDK 的 Timer 和 DelayQueue 插入和删除操作的平均时间复杂度为 O(nlog(n))，并不能满足 Kafka 的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为 O(1)。时间轮的应用并非 Kafka 独有，其应用场景还有很多，在 Netty、Akka、Quartz、Zookeeper 等组件中都存在时间轮的踪影。\n\n\n# 时间轮的数据结构\n\n参考下图，Kafka 中的时间轮（TimingWheel）是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表（TimerTaskList）。TimerTaskList 是一个环形的双向链表，链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务 TimerTask。在 Kafka 源码中对这个 TimeTaskList 是用一个名称为 buckets 的数组表示的，所以后面介绍中可能 TimerTaskList 也会被称为 bucket。\n\n\n\n针对上图的几个名词简单解释下：\n\n * tickMs： 时间轮由多个时间格组成，每个时间格就是 tickMs，它代表当前时间轮的基本时间跨度。\n * wheelSize： 代表每一层时间轮的格数\n * interval： 当前时间轮的总体时间跨度，interval=tickMs × wheelSize\n * startMs： 构造当层时间轮时候的当前时间，第一层的时间轮的 startMs 是 TimeUnit.NANOSECONDS.toMillis(nanoseconds()),上层时间轮的 startMs 为下层时间轮的 currentTime。\n * currentTime： 表示时间轮当前所处的时间，currentTime 是 tickMs 的整数倍（通过 currentTime=startMs - (startMs % tickMs 来保正 currentTime 一定是 tickMs 的整数倍），这个运算类比钟表中分钟里 65 秒分钟指针指向的还是 1 分钟）。currentTime 可以将整个时间轮划分为到期部分和未到期部分，currentTime 当前指向的时间格也属于到期部分，表示刚好到期，需要处理此时间格所对应的 TimerTaskList 的所有任务。\n\n\n# 时间轮中的任务存放\n\n若时间轮的 tickMs=1ms，wheelSize=20，那么可以计算得出 interval 为 20ms。初始情况下表盘指针 currentTime 指向时间格 0，此时有一个定时为 2ms 的任务插入进来会存放到时间格为 2 的 TimerTaskList 中。随着时间的不断推移，指针 currentTime 不断向前推进，过了 2ms 之后，当到达时间格 2 时，就需要将时间格 2 所对应的 TimeTaskList 中的任务做相应的到期操作。此时若又有一个定时为 8ms 的任务插入进来，则会存放到时间格 10 中，currentTime 再过 8ms 后会指向时间格 10。如果同时有一个定时为 19ms 的任务插入进来怎么办？新来的 TimerTaskEntry 会复用原来的 TimerTaskList，所以它会插入到原本已经到期的时间格 1 中。总之，整个时间轮的总体跨度是不变的，随着指针 currentTime 的不断推进，当前时间轮所能处理的时间段也在不断后移，总体时间范围在 currentTime 和 currentTime+interval 之间。\n\n\n# 时间轮的升降级\n\n如果此时有个定时为 350ms 的任务该如何处理？直接扩充 wheelSize 的大小么？Kafka 中不乏几万甚至几十万毫秒的定时任务，这个 wheelSize 的扩充没有底线，就算将所有的定时任务的到期时间都设定一个上限，比如 100 万毫秒，那么这个 wheelSize 为 100 万毫秒的时间轮不仅占用很大的内存空间，而且效率也会拉低。Kafka 为此引入了层级时间轮的概念，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中。\n\n\n\n参考上图，复用之前的案例，第一层的时间轮 tickMs=1ms, wheelSize=20, interval=20ms。第二层的时间轮的 tickMs 为第一层时间轮的 interval，即为 20ms。每一层时间轮的 wheelSize 是固定的，都是 20，那么第二层的时间轮的总体时间跨度 interval 为 400ms。以此类推，这个 400ms 也是第三层的 tickMs 的大小，第三层的时间轮的总体时间跨度为 8000ms。\n\n刚才提到的 350ms 的任务，不会插入到第一层时间轮，会插入到 interval=20*20 的第二层时间轮中，具体插入到时间轮的哪个 bucket 呢？先用 350/tickMs(20)=virtualId(17)，然后 virtualId(17) %wheelSize (20) = 17，所以 350 会放在第 17 个 bucket。如果此时有一个 450ms 后执行的任务，那么会放在第三层时间轮中，按照刚才的计算公式，会放在第 0 个 bucket。第 0 个 bucket 里会包含[400,800)ms 的任务。随着时间流逝，当时间过去了 400ms，那么 450ms 后就要执行的任务还剩下 50ms 的时间才能执行，此时有一个时间轮降级的操作，将 50ms 任务重新提交到层级时间轮中，那么此时 50ms 的任务根据公式会放入第二个时间轮的第 2 个 bucket 中，此 bucket 的时间范围为[40,60)ms，然后再经过 40ms，这个 50ms 的任务又会被监控到，此时距离任务执行还有 10ms，同样将 10ms 的任务提交到层级时间轮，此时会加入到第一层时间轮的第 10 个 bucket，所以再经过 10ms 后，此任务到期，最终执行。\n\n整个时间轮的升级降级操作是不是很类似于我们的时钟？ 第一层时间轮 tickMs=1s, wheelSize=60，interval=1min，此为秒钟；第二层 tickMs=1min，wheelSize=60，interval=1hour，此为分钟；第三层 tickMs=1hour，wheelSize 为 12，interval 为 12hours，此为时钟。而钟表的指针就对应程序中的 currentTime，这个后面分析代码时候会讲到（对这个的理解也是时间轮理解的重点和难点）。\n\n\n# 任务添加和驱动时间轮滚动核心流程图\n\n\n\n\n# 重点代码介绍\n\n这是往 SystenTimer 中添加一个任务。\n\n//在Systemtimer中添加一个任务，任务被包装为一个TimerTaskEntry\nprivate def addTimerTaskEntry(timerTaskEntry: TimerTaskEntry): Unit = {\n//先判断是否可以添加进时间轮中，如果不可以添加进去代表任务已经过期或者任务被取消，注意这里的timingWheel持有上一层时间轮的引用，所以可能存在递归调用\n  if (!timingWheel.add(timerTaskEntry)) {\n    // Already expired or cancelled\n    if (!timerTaskEntry.cancelled)\n     //过期任务直接线程池异步执行掉\n      taskExecutor.submit(timerTaskEntry.timerTask)\n  }\n}\n//timingWheel添加任务，递归添加直到添加该任务进合适的时间轮的bucket中\ndef add(timerTaskEntry: TimerTaskEntry): Boolean = {\n  val expiration = timerTaskEntry.expirationMs\n  //任务取消\n  if (timerTaskEntry.cancelled) {\n    // Cancelled\n    false\n  } else if (expiration < currentTime + tickMs) {\n    // 任务过期后会被执行\n    false\n  } else if (expiration < currentTime + interval) {//任务过期时间比当前时间轮时间加周期小说明任务过期时间在本时间轮周期内\n    val virtualId = expiration / tickMs\n    //找到任务对应本时间轮的bucket\n    val bucket = buckets((virtualId % wheelSize.toLong).toInt)\n    bucket.add(timerTaskEntry)\n    // Set the bucket expiration time\n   //只有本bucket内的任务都过期后才会bucket.setExpiration返回true此时将bucket放入延迟队列\n    if (bucket.setExpiration(virtualId * tickMs)) {\n     //bucket是一个TimerTaskList，它实现了java.util.concurrent.Delayed接口，里面是一个多任务组成的链表，图2有说明\n      queue.offer(bucket)\n    }\n    true\n  } else {\n    // Out of the interval. Put it into the parent timer\n    //任务的过期时间不在本时间轮周期内说明需要升级时间轮，如果不存在则构造上一层时间轮，继续用上一层时间轮添加任务\n    if (overflowWheel == null) addOverflowWheel()\n    overflowWheel.add(timerTaskEntry)\n  }\n}\n\n\n在本层级时间轮里添加上一层时间轮里的过程，注意的是在下一层时间轮的 interval 为上一层时间轮的 tickMs。\n\nprivate[this] def addOverflowWheel(): Unit = {\n  synchronized {\n    if (overflowWheel == null) {\n      overflowWheel = new TimingWheel(\n        tickMs = interval,\n        wheelSize = wheelSize,\n        startMs = currentTime,\n        taskCounter = taskCounter,\n        queue\n      )\n    }\n  }\n}\n\n\n驱动时间轮滚动过程：\n\n注意这里会存在一个递归，一直驱动时间轮的指针滚动直到时间不足于驱动上层的时间轮滚动。\n\ndef advanceClock(timeMs: Long): Unit = {\n  if (timeMs >= currentTime + tickMs) {\n   //把当前时间打平为时间轮tickMs的整数倍\n    currentTime = timeMs - (timeMs % tickMs)\n    // Try to advance the clock of the overflow wheel if present\n    //驱动上层时间轮，这里的传给上层的currentTime时间是本层时间轮打平过的，但是在上层时间轮还是会继续打平\n    if (overflowWheel != null) overflowWheel.advanceClock(currentTime)\n  }\n}\n\n\n驱动源：\n\n//循环bucket里面的任务列表，一个个重新添加进时间轮，对符合条件的时间轮进行升降级或者执行任务\nprivate[this] val reinsert = (timerTaskEntry: TimerTaskEntry) => addTimerTaskEntry(timerTaskEntry)\n \n/*\n * Advances the clock if there is an expired bucket. If there isn\'t any expired bucket when called,\n * waits up to timeoutMs before giving up.\n */\ndef advanceClock(timeoutMs: Long): Boolean = {\n  var bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)\n  if (bucket != null) {\n    writeLock.lock()\n    try {\n      while (bucket != null) {\n        //驱动时间轮\n        timingWheel.advanceClock(bucket.getExpiration())\n       //循环buckek也就是任务列表，任务列表一个个继续添加进时间轮以此来升级或者降级时间轮，把过期任务找出来执行\n        bucket.flush(reinsert)\n       //循环\n        //这里就是从延迟队列取出bucket，bucket是有延迟时间的，取出代表该bucket过期，我们通过bucket能取到bucket包含的任务列表\n        bucket = delayQueue.poll()\n      }\n    } finally {\n      writeLock.unlock()\n    }\n    true\n  } else {\n    false\n  }\n}\n\n\n\n# DelayQueue 与 kafka 时间轮\n\nkafka 的延迟队列使用时间轮实现，能够支持大量任务的高效触发，但是在 kafka 延迟队列实现方案里还是看到了 delayQueue 的影子，使用 delayQueue 是对时间轮里面的 bucket 放入延迟队列，以此来推动时间轮滚动，但是基于将插入和删除操作则放入时间轮中，将这些操作的时间复杂度都降为 O(1)，提升效率。Kafka 对性能的极致追求让它把最合适的组件放在最适合的位置。\n\n如何推进时间轮的前进，让时间轮的时间往前走。\n\n * Netty 中的时间轮是通过工作线程按照固定的时间间隔 tickDuration 推进的\n   * 如果长时间没有到期任务，这种方案会带来空推进的问题，从而造成一定的性能损耗；\n * Kafka 则是通过 DelayQueue 来推进，是一种空间换时间的思想；\n   * DelayQueue 中保存着所有的 TimerTaskList 对象，根据时间来排序，这样延时越小的任务排在越前面。\n   * 外部通过一个线程（叫做ExpiredOperationReaper）从 DelayQueue 中获取超时的任务列表 TimerTaskList，然后根据 TimerTaskList 的 过期时间来精确推进时间轮的时间，这样就不会存在空推进的问题啦。\n\n其实 Kafka 采用的是一种权衡的策略，把 DelayQueue 用在了合适的地方。DelayQueue 只存放了 TimerTaskList，并不是所有的 TimerTask，数量并不多，相比空推进带来的影响是利大于弊的。\n\n\n# 总结\n\n * Kafka 使用时间轮来实现延时队列，因为其底层是任务的添加和删除是基于链表实现的，是 O(1) 的时间复杂度，满足高性能的要求；\n * 对于时间跨度大的延时任务，Kafka 引入了层级时间轮，能更好控制时间粒度，可以应对更加复杂的定时任务处理场景；\n * 对于如何实现时间轮的推进和避免空推进影响性能，Kafka 采用空间换时间的思想，通过 DelayQueue 来推进时间轮，算是一个经典的 trade off（权衡）。\n\n\n# 参考文献\n\n一张图理解Kafka时间轮(TimingWheel),看不懂算我输!时间轮，是一种实现延迟功能（定时器）的巧妙算法，在N - 掘金 (juejin.cn)\n\n面试官：你给我说一下什么是时间轮吧？今天我带大家来卷一下时间轮吧，这个玩意其实还是挺实用的。 常见于各种框架之中，偶现于 - 掘金 (juejin.cn)\n\n任务调度之时间轮实现 | 京东云技术团队在生活中太阳的东升西落，鸟类的南飞北归，四级的轮换，每天的上下班，海水的潮汐，每 - 掘金 (juejin.cn)\n\n一张图理解Kafka时间轮(TimingWheel) - 知乎 (zhihu.com)\n\n时间轮在Kafka的实践_移动_滴滴技术_InfoQ精选文章',normalizedContent:'# 带着疑问\n\n第一个问题：如果一台机器上有 10w 个定时任务，如何做到高效触发？\n\n具体场景是：\n\n> 有一个 app 实时消息通道系统，对每个用户会维护一个 app 到服务器的 tcp 连接，用来实时收发消息，对这个 tcp 连接，有这样一个需求：“如果连续 30s 没有请求包（例如登录，消息，keepalive 包），服务端就要将这个用户的状态置为离线”。\n> \n> 其中，单机 tcp 同时在线量约在 10w 级别，keepalive 请求包较分散大概 30s 一次，吞吐量约在 3000qps。\n\n怎么做？\n\n常用方案使用 time 定时任务，每秒扫描一次所有连接的集合 map<uid, last_packet_time>，把连接时间（每次有新的请求更新对应连接的连接时间）比当前时间的差值大 30s 的连接找出来处理。\n\n另一种方案，使用环形队列法：\n\n三个重要的数据结构：\n\n 1. 30s 超时，就创建一个 index 从 0 到 30 的环形队列（本质是个数组）\n 2. 环上每一个 slot 是一个 set，任务集合\n 3. 同时还有一个 map<uid, index>，记录 uid 落在环上的哪个 slot 里\n\n这样当有某用户 uid 有请求包到达时：\n\n 1. 从 map 结构中，查找出这个 uid 存储在哪一个 slot 里\n 2. 从这个 slot 的 set 结构中，删除这个 uid\n 3. 将 uid 重新加入到新的 slot 中，具体是哪一个 slot 呢 => current index 指针所指向的上一个 slot，因为这个 slot，会被 timer 在 30s 之后扫描到\n 4. 更新 map，这个 uid 对应 slot 的 index 值\n\n哪些元素会被超时掉呢？\n\ncurrent index 每秒种移动一个 slot，这个 slot 对应的 set中所有 uid 都应该被集体超时！如果最近 30s 有请求包来到，一定被放到 current index 的前一个 slot 了，current index 所在的 slot 对应 set 中所有元素，都是最近 30s 没有请求包来到的。\n\n所以，当没有超时时，current index 扫到的每一个 slot 的 set 中应该都没有元素。\n\n两种方案对比：\n\n方案一每次都要轮询所有数据，而方案二使用环形队列只需要轮询这一刻需要过期的数据，如果没有数据过期则没有数据要处理，并且是批量超时，并且由于是环形结构更加节约空间，这很适合高性能场景。\n\n第二个问题： 在开发过程中有延迟一定时间的任务要执行，怎么做？\n\n如果不重复造轮子的话，我们的选择当然是延迟队列或者 timer。\n\n延迟队列和在 timer 中增 加延时任务采用数组表示的最小堆的数据结构实现，每次放入新元素和移除队首元素时间复杂度为 o(nlog(n))。\n\n\n# 前言\n\n时间轮，是一种实现延迟功能（定时器）的巧妙算法，在 netty，zookeeper，kafka 等各种框架中，甚至linux内核中都有用到。\n\n设计源于生活\n\n时间轮，其设计正是来源于生活中的时钟。\n\n如图就是一个简单的时间轮：\n\n\n\n图中大圆的圆心位置表示的是当前的时间，随着时间推移, 圆心处的时间也会不断跳动。\n\n下面我们对着这个图，来说说kafka的时间轮timingwheel。\n\nkafka时间轮的底层就是一个环形数组，而数组中每个元素都存放一个双向链表timertasklist，链表中封装了很多延时任务。\n\nkafka中一个时间轮timingwheel是由20个时间格组成，wheelsize = 20；每格的时间跨度是1ms，tickms = 1ms。参照kafka，上图中也用了20个灰边小圆表示时间格，为了动画演示可以看得清楚，我们这里每个小圆的时间跨度是1s。\n\n所以现在整个时间轮的时间跨度就是 tickms * wheelsize ，也就是 20s。从0s到19s，我们都分别有一个灰边小圆来承载。\n\nkafka的时间轮还有一个表盘指针 currenttime，表示时间轮当前所处的时间。也就是图中用黑色粗线表示的圆，随着时间推移, 这个指针也会不断前进;\n\n\n\n\n# 添加定时任务\n\n有了时间轮，现在可以往里面添加定时任务了。我们用一个粉红色的小圆来表示一个定时任务。\n\n\n\n这里先讲一下设定，每一个定时任务都有延时时间delaytime，和过期时间expiredtime。比如当前时间是10s，我们添加了个延时时间为2s的任务，那么这个任务的过期时间就是12s，也就是当前时间10s再走两秒，变成了12s的时候，就到了触发这个定时任务的时间。\n\n而时间轮上代表时间格的灰边小圆上显示的数字，可以理解为任务的过期时间。\n\n\n\n讲清楚这些设定后，我们就开始添加定时任务吧。\n\n初始的时候, 时间轮的指针定格在0。此时添加一个超时时间为2s的任务, 那么这个任务将会插入到第二个时间格中。\n\n\n\n当时间轮的指针到达第二个时间格时, 会处理该时间格上对应的任务。在动画上就是让红色的小圆消失!\n\n\n\n如果这个时候又插入一个延时时间为8s的任务进来, 这个任务的过期时间就是在当前时间2s的基础上加8s, 也就是10s, 那么这个任务将会插入到过期时间为10s的时间格中。\n\n\n\n\n# "动态"时间轮\n\n到目前为止，一切都很好理解。\n\n那么如果在当前时间是2s的时候, 插入一个延时时间为19s的任务时,这个任务的过期时间就是在当前时间2s的基础上加19s, 也就是21s。\n\n请看下图，当前的时间轮是没有过期时间为21s的时间格。这个任务将会插入到过期时间为1s的时间格中，这是怎么回事呢？\n\n\n\n\n# 复用时间格\n\n为了解答上面的问题，我们先来点魔法， 让时间轮上的时间都动起来！\n\n\n\n其实呢，当指针定格在2s的位置时, 时间格0s, 1s和2s就已经是过期的时间格。\n\n也就是说指针可以用来划分过期的时间格[0,2]和未来的时间格 [3,19]。而过期的时间格可以继续复用。比如过期的时间格0s就变成了20s, 存放过期时间为20s的任务。\n\n理解了时间格的复用之后，再看回刚刚的例子，当前时间是2s时，添加延时时间为19s的任务，那么这个任务就会插入到过期时间为21s的时间格中。\n\n\n\n\n# 时间轮升级\n\n下面，新的问题来了，请坐好扶稳。\n\n如果在当前时间是2s的时候, 插入一个延时时间为22s的任务, 这个任务的过期时间就是在2s的基础上加22s，也就是24s。\n\n\n\n显然当前时间轮是无法找到过期时间格为24秒的时间格，因为当前过期时间最大的时间格才到21s。而且我们也没办法像前面那样再复用时间格，因为除了过期时间为2s的时间格，其他的时间格都还没过期呢。当前时间轮无法承载这个定时任务,那么应该怎么办呢?\n\n当然我们可以选择扩展时间轮上的时间格, 但是这样一来，时间轮就失去了意义。\n\n是时候要升级时间轮了！\n\n我们先来理解下多层时间轮之间的联系。\n\n\n# 层级时间轮\n\n如图是一个两层的时间轮:\n\n\n\n第二层时间轮也是由20个时间格组成, 每个时间格的跨度是20s。\n\n图中展示了每个时间格对应的过期时间范围, 我们可以清晰地看到, 第二层时间轮的第0个时间格的过期时间范围是 [0,19]。也就是说, 第二层时间轮的一个时间格就可以表示第一层时间轮的所有(20个)时间格;\n\n为了进一步理清第一层时间轮和第二层时间轮的关系, 我们拉着时间的小手, 一起观看下面的动图:\n\n\n\n可以看到，第二层时间轮同样也有自己的指针, 每当第一层时间轮走完一个周期，第二层时间轮的指针就会推进一格。\n\n\n# 添加定时任务\n\n回到一开始的问题，在当前时间是2s的时候, 插入一个延时时间为22s的任务，该任务过期时间为24s。\n\n\n\n当第一层时间轮容纳不下时，进入第二层时间轮，并插入到过期时间为[20,39]的时间格中。\n\n我们再来个例子，如果在当前时间是2s的时候, 插入一个延时时间为350s的任务, 这个任务的过期时间就是在2s的基础上加350s，也就是352s。\n\n\n\n从图中可以看到，该任务插入到第二层时间轮过期时间为[340,359]s的时间格中，也就是第17格的位置。\n\n\n# "动态"层级时间轮\n\n通常来说, 第二层时间轮的第0个时间格是用来表示第一层时间轮的, 这一格是存放不了任务的, 因为超时时间0-20s的任务, 第一层时间轮就可以处理了。\n\n但是! 事情往往没这么简单, 我们时间轮上的时间格都是可以复用的! 那么这在第二层时间轮上又是怎么体现的呢?\n\n下面是魔法时间， 我们让时间轮上的过期时间都动起来！\n\n\n\n从图中可以看到，当第一层时间轮的指针定格在1s时，超时时间0s的时间格就过期了。而这个时候，第二层时间轮第0个时间格的时间范围就从[0,19]分为了过期的[0],和未过期的[1,19]。而过期的[0]就会被新的过期时间[400]复用。\n\n[0-19]\n\n[400][1,19]\n\n[400,401][2,19]\n\n......\n\n[400,419]\n\n\n所以，如果在当前时间是2s的时候, 插入一个延时时间为399s的任务, 这个任务的过期时间就是在2s的基础上加399s，也就是401s。如图，这个任务还是会插到第二层时间轮第0个时间格中去。\n\n\n\n\n# 时间轮降级\n\n还是用回这个大家都已经耳熟能详的例子，在当前时间是2s的时候, 插入一个延时时间为22s的任务，该任务过期时间为24s。最后进入第二层时间轮，并插入到过期时间为[20,39]的时间格中。\n\n当二层时间轮上的定时任务到期后，时间轮是怎么做的呢？\n\n\n\n从图中可以看到，随着当前时间从2s继续往前推进，一直到20s的时候，总共经过了18s。此时第二层时间轮中，超时时间为[20-39s]的时间格上的任务到期。\n\n原本超时时间为24s的任务会被取出来，重新加入时间轮。此时该定时任务的延时时间从原本的22s，到现在还剩下4s（22s-18s）。最后停留在第一层时间轮超时时间为24s的时间格，也就是第4个时间格。\n\n随着当前时间继续推进，再经过4s后，该定时任务到期被执行。\n\n从这里可以看出时间轮的巧妙之处，两层时间轮只用了40个数组元素，却可以承载[0-399s]的定时任务。而三层时间轮用60个数组元素，就可以承载[0-7999s]的定时任务！\n\n\n\n\n# 时间轮的推进\n\n从动画中可以注意到, 随着时间推进, 时间轮的指针循环往复地定格在每一个时间格上, 每一次都要判断当前定格的时间格里是不是有任务存在;\n\n其中有很多时间格都是没有任务的, 指针定格在这种空的时间格中, 就是一次"空推进";\n\n比如说, 插入一个延时时间400s的任务, 指针就要执行399次"空推进", 这是一种浪费!\n\n那么kafka是怎么解决这个问题的呢？这就要从延迟队列delayqueue开始讲起了！时间轮搭配延迟队列delayqueue，会发生什么化学反应呢？\n\n\n# 时间轮在 kafka 中的实现\n\n方案二所采用的环形队列，就是时间轮的底层数据结构，它能够让需要处理的数据（任务的抽象）集中，在 kafka 中存在大量的延迟操作，比如延迟生产、延迟拉取以及延迟删除等。kafka 并没有使用 jdk 自带的 timer 或者 delayqueue 来实现延迟的功能，而是基于时间轮自定义了一个用于实现延迟功能的定时器（systemtimer）。jdk 的 timer 和 delayqueue 插入和删除操作的平均时间复杂度为 o(nlog(n))，并不能满足 kafka 的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为 o(1)。时间轮的应用并非 kafka 独有，其应用场景还有很多，在 netty、akka、quartz、zookeeper 等组件中都存在时间轮的踪影。\n\n\n# 时间轮的数据结构\n\n参考下图，kafka 中的时间轮（timingwheel）是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表（timertasklist）。timertasklist 是一个环形的双向链表，链表中的每一项表示的都是定时任务项（timertaskentry），其中封装了真正的定时任务 timertask。在 kafka 源码中对这个 timetasklist 是用一个名称为 buckets 的数组表示的，所以后面介绍中可能 timertasklist 也会被称为 bucket。\n\n\n\n针对上图的几个名词简单解释下：\n\n * tickms： 时间轮由多个时间格组成，每个时间格就是 tickms，它代表当前时间轮的基本时间跨度。\n * wheelsize： 代表每一层时间轮的格数\n * interval： 当前时间轮的总体时间跨度，interval=tickms × wheelsize\n * startms： 构造当层时间轮时候的当前时间，第一层的时间轮的 startms 是 timeunit.nanoseconds.tomillis(nanoseconds()),上层时间轮的 startms 为下层时间轮的 currenttime。\n * currenttime： 表示时间轮当前所处的时间，currenttime 是 tickms 的整数倍（通过 currenttime=startms - (startms % tickms 来保正 currenttime 一定是 tickms 的整数倍），这个运算类比钟表中分钟里 65 秒分钟指针指向的还是 1 分钟）。currenttime 可以将整个时间轮划分为到期部分和未到期部分，currenttime 当前指向的时间格也属于到期部分，表示刚好到期，需要处理此时间格所对应的 timertasklist 的所有任务。\n\n\n# 时间轮中的任务存放\n\n若时间轮的 tickms=1ms，wheelsize=20，那么可以计算得出 interval 为 20ms。初始情况下表盘指针 currenttime 指向时间格 0，此时有一个定时为 2ms 的任务插入进来会存放到时间格为 2 的 timertasklist 中。随着时间的不断推移，指针 currenttime 不断向前推进，过了 2ms 之后，当到达时间格 2 时，就需要将时间格 2 所对应的 timetasklist 中的任务做相应的到期操作。此时若又有一个定时为 8ms 的任务插入进来，则会存放到时间格 10 中，currenttime 再过 8ms 后会指向时间格 10。如果同时有一个定时为 19ms 的任务插入进来怎么办？新来的 timertaskentry 会复用原来的 timertasklist，所以它会插入到原本已经到期的时间格 1 中。总之，整个时间轮的总体跨度是不变的，随着指针 currenttime 的不断推进，当前时间轮所能处理的时间段也在不断后移，总体时间范围在 currenttime 和 currenttime+interval 之间。\n\n\n# 时间轮的升降级\n\n如果此时有个定时为 350ms 的任务该如何处理？直接扩充 wheelsize 的大小么？kafka 中不乏几万甚至几十万毫秒的定时任务，这个 wheelsize 的扩充没有底线，就算将所有的定时任务的到期时间都设定一个上限，比如 100 万毫秒，那么这个 wheelsize 为 100 万毫秒的时间轮不仅占用很大的内存空间，而且效率也会拉低。kafka 为此引入了层级时间轮的概念，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中。\n\n\n\n参考上图，复用之前的案例，第一层的时间轮 tickms=1ms, wheelsize=20, interval=20ms。第二层的时间轮的 tickms 为第一层时间轮的 interval，即为 20ms。每一层时间轮的 wheelsize 是固定的，都是 20，那么第二层的时间轮的总体时间跨度 interval 为 400ms。以此类推，这个 400ms 也是第三层的 tickms 的大小，第三层的时间轮的总体时间跨度为 8000ms。\n\n刚才提到的 350ms 的任务，不会插入到第一层时间轮，会插入到 interval=20*20 的第二层时间轮中，具体插入到时间轮的哪个 bucket 呢？先用 350/tickms(20)=virtualid(17)，然后 virtualid(17) %wheelsize (20) = 17，所以 350 会放在第 17 个 bucket。如果此时有一个 450ms 后执行的任务，那么会放在第三层时间轮中，按照刚才的计算公式，会放在第 0 个 bucket。第 0 个 bucket 里会包含[400,800)ms 的任务。随着时间流逝，当时间过去了 400ms，那么 450ms 后就要执行的任务还剩下 50ms 的时间才能执行，此时有一个时间轮降级的操作，将 50ms 任务重新提交到层级时间轮中，那么此时 50ms 的任务根据公式会放入第二个时间轮的第 2 个 bucket 中，此 bucket 的时间范围为[40,60)ms，然后再经过 40ms，这个 50ms 的任务又会被监控到，此时距离任务执行还有 10ms，同样将 10ms 的任务提交到层级时间轮，此时会加入到第一层时间轮的第 10 个 bucket，所以再经过 10ms 后，此任务到期，最终执行。\n\n整个时间轮的升级降级操作是不是很类似于我们的时钟？ 第一层时间轮 tickms=1s, wheelsize=60，interval=1min，此为秒钟；第二层 tickms=1min，wheelsize=60，interval=1hour，此为分钟；第三层 tickms=1hour，wheelsize 为 12，interval 为 12hours，此为时钟。而钟表的指针就对应程序中的 currenttime，这个后面分析代码时候会讲到（对这个的理解也是时间轮理解的重点和难点）。\n\n\n# 任务添加和驱动时间轮滚动核心流程图\n\n\n\n\n# 重点代码介绍\n\n这是往 systentimer 中添加一个任务。\n\n//在systemtimer中添加一个任务，任务被包装为一个timertaskentry\nprivate def addtimertaskentry(timertaskentry: timertaskentry): unit = {\n//先判断是否可以添加进时间轮中，如果不可以添加进去代表任务已经过期或者任务被取消，注意这里的timingwheel持有上一层时间轮的引用，所以可能存在递归调用\n  if (!timingwheel.add(timertaskentry)) {\n    // already expired or cancelled\n    if (!timertaskentry.cancelled)\n     //过期任务直接线程池异步执行掉\n      taskexecutor.submit(timertaskentry.timertask)\n  }\n}\n//timingwheel添加任务，递归添加直到添加该任务进合适的时间轮的bucket中\ndef add(timertaskentry: timertaskentry): boolean = {\n  val expiration = timertaskentry.expirationms\n  //任务取消\n  if (timertaskentry.cancelled) {\n    // cancelled\n    false\n  } else if (expiration < currenttime + tickms) {\n    // 任务过期后会被执行\n    false\n  } else if (expiration < currenttime + interval) {//任务过期时间比当前时间轮时间加周期小说明任务过期时间在本时间轮周期内\n    val virtualid = expiration / tickms\n    //找到任务对应本时间轮的bucket\n    val bucket = buckets((virtualid % wheelsize.tolong).toint)\n    bucket.add(timertaskentry)\n    // set the bucket expiration time\n   //只有本bucket内的任务都过期后才会bucket.setexpiration返回true此时将bucket放入延迟队列\n    if (bucket.setexpiration(virtualid * tickms)) {\n     //bucket是一个timertasklist，它实现了java.util.concurrent.delayed接口，里面是一个多任务组成的链表，图2有说明\n      queue.offer(bucket)\n    }\n    true\n  } else {\n    // out of the interval. put it into the parent timer\n    //任务的过期时间不在本时间轮周期内说明需要升级时间轮，如果不存在则构造上一层时间轮，继续用上一层时间轮添加任务\n    if (overflowwheel == null) addoverflowwheel()\n    overflowwheel.add(timertaskentry)\n  }\n}\n\n\n在本层级时间轮里添加上一层时间轮里的过程，注意的是在下一层时间轮的 interval 为上一层时间轮的 tickms。\n\nprivate[this] def addoverflowwheel(): unit = {\n  synchronized {\n    if (overflowwheel == null) {\n      overflowwheel = new timingwheel(\n        tickms = interval,\n        wheelsize = wheelsize,\n        startms = currenttime,\n        taskcounter = taskcounter,\n        queue\n      )\n    }\n  }\n}\n\n\n驱动时间轮滚动过程：\n\n注意这里会存在一个递归，一直驱动时间轮的指针滚动直到时间不足于驱动上层的时间轮滚动。\n\ndef advanceclock(timems: long): unit = {\n  if (timems >= currenttime + tickms) {\n   //把当前时间打平为时间轮tickms的整数倍\n    currenttime = timems - (timems % tickms)\n    // try to advance the clock of the overflow wheel if present\n    //驱动上层时间轮，这里的传给上层的currenttime时间是本层时间轮打平过的，但是在上层时间轮还是会继续打平\n    if (overflowwheel != null) overflowwheel.advanceclock(currenttime)\n  }\n}\n\n\n驱动源：\n\n//循环bucket里面的任务列表，一个个重新添加进时间轮，对符合条件的时间轮进行升降级或者执行任务\nprivate[this] val reinsert = (timertaskentry: timertaskentry) => addtimertaskentry(timertaskentry)\n \n/*\n * advances the clock if there is an expired bucket. if there isn\'t any expired bucket when called,\n * waits up to timeoutms before giving up.\n */\ndef advanceclock(timeoutms: long): boolean = {\n  var bucket = delayqueue.poll(timeoutms, timeunit.milliseconds)\n  if (bucket != null) {\n    writelock.lock()\n    try {\n      while (bucket != null) {\n        //驱动时间轮\n        timingwheel.advanceclock(bucket.getexpiration())\n       //循环buckek也就是任务列表，任务列表一个个继续添加进时间轮以此来升级或者降级时间轮，把过期任务找出来执行\n        bucket.flush(reinsert)\n       //循环\n        //这里就是从延迟队列取出bucket，bucket是有延迟时间的，取出代表该bucket过期，我们通过bucket能取到bucket包含的任务列表\n        bucket = delayqueue.poll()\n      }\n    } finally {\n      writelock.unlock()\n    }\n    true\n  } else {\n    false\n  }\n}\n\n\n\n# delayqueue 与 kafka 时间轮\n\nkafka 的延迟队列使用时间轮实现，能够支持大量任务的高效触发，但是在 kafka 延迟队列实现方案里还是看到了 delayqueue 的影子，使用 delayqueue 是对时间轮里面的 bucket 放入延迟队列，以此来推动时间轮滚动，但是基于将插入和删除操作则放入时间轮中，将这些操作的时间复杂度都降为 o(1)，提升效率。kafka 对性能的极致追求让它把最合适的组件放在最适合的位置。\n\n如何推进时间轮的前进，让时间轮的时间往前走。\n\n * netty 中的时间轮是通过工作线程按照固定的时间间隔 tickduration 推进的\n   * 如果长时间没有到期任务，这种方案会带来空推进的问题，从而造成一定的性能损耗；\n * kafka 则是通过 delayqueue 来推进，是一种空间换时间的思想；\n   * delayqueue 中保存着所有的 timertasklist 对象，根据时间来排序，这样延时越小的任务排在越前面。\n   * 外部通过一个线程（叫做expiredoperationreaper）从 delayqueue 中获取超时的任务列表 timertasklist，然后根据 timertasklist 的 过期时间来精确推进时间轮的时间，这样就不会存在空推进的问题啦。\n\n其实 kafka 采用的是一种权衡的策略，把 delayqueue 用在了合适的地方。delayqueue 只存放了 timertasklist，并不是所有的 timertask，数量并不多，相比空推进带来的影响是利大于弊的。\n\n\n# 总结\n\n * kafka 使用时间轮来实现延时队列，因为其底层是任务的添加和删除是基于链表实现的，是 o(1) 的时间复杂度，满足高性能的要求；\n * 对于时间跨度大的延时任务，kafka 引入了层级时间轮，能更好控制时间粒度，可以应对更加复杂的定时任务处理场景；\n * 对于如何实现时间轮的推进和避免空推进影响性能，kafka 采用空间换时间的思想，通过 delayqueue 来推进时间轮，算是一个经典的 trade off（权衡）。\n\n\n# 参考文献\n\n一张图理解kafka时间轮(timingwheel),看不懂算我输!时间轮，是一种实现延迟功能（定时器）的巧妙算法，在n - 掘金 (juejin.cn)\n\n面试官：你给我说一下什么是时间轮吧？今天我带大家来卷一下时间轮吧，这个玩意其实还是挺实用的。 常见于各种框架之中，偶现于 - 掘金 (juejin.cn)\n\n任务调度之时间轮实现 | 京东云技术团队在生活中太阳的东升西落，鸟类的南飞北归，四级的轮换，每天的上下班，海水的潮汐，每 - 掘金 (juejin.cn)\n\n一张图理解kafka时间轮(timingwheel) - 知乎 (zhihu.com)\n\n时间轮在kafka的实践_移动_滴滴技术_infoq精选文章',charsets:{cjk:!0},lastUpdated:"2024/09/14, 20:45:35",lastUpdatedTimestamp:1726346735e3},{title:"设计 微信",frontmatter:{title:"设计 微信",date:"2024-09-14T02:08:51.000Z",permalink:"/pages/a95d7d/"},regularPath:"/02.%E8%AE%BE%E8%AE%A1%E7%83%AD%E9%97%A8%E5%BA%94%E7%94%A8/01.%E7%A4%BE%E4%BA%A4%E7%B1%BB/01.%E8%AE%BE%E8%AE%A1%20%E5%BE%AE%E4%BF%A1.html",relativePath:"02.设计热门应用/01.社交类/01.设计 微信.md",key:"v-fb7b08d2",path:"/pages/a95d7d/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2024/09/14, 08:54:46",lastUpdatedTimestamp:1726304086e3},{title:"设计Twitter",frontmatter:{title:"设计Twitter",date:"2024-09-14T02:08:51.000Z",permalink:"/pages/90ad66/"},regularPath:"/02.%E8%AE%BE%E8%AE%A1%E7%83%AD%E9%97%A8%E5%BA%94%E7%94%A8/01.%E7%A4%BE%E4%BA%A4%E7%B1%BB/02.%E8%AE%BE%E8%AE%A1Twitter.html",relativePath:"02.设计热门应用/01.社交类/02.设计Twitter.md",key:"v-d89ce0de",path:"/pages/90ad66/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2024/09/14, 08:54:46",lastUpdatedTimestamp:1726304086e3},{title:"双写一致性",frontmatter:{title:"双写一致性",date:"2024-09-14T16:50:17.000Z",permalink:"/pages/def08a/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7.html",relativePath:"03.经典场景设计/01.热门场景设计/01.双写一致性.md",key:"v-53a35b2a",path:"/pages/def08a/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"引入缓存提高性能",slug:"引入缓存提高性能",normalizedTitle:"引入缓存提高性能",charIndex:136},{level:2,title:"缓存利用率和一致性问题",slug:"缓存利用率和一致性问题",normalizedTitle:"缓存利用率和一致性问题",charIndex:841},{level:3,title:"先来看第一个问题，如何提高缓存利用率？",slug:"先来看第一个问题-如何提高缓存利用率",normalizedTitle:"先来看第一个问题，如何提高缓存利用率？",charIndex:857},{level:2,title:"并发引发的一致性问题",slug:"并发引发的一致性问题",normalizedTitle:"并发引发的一致性问题",charIndex:1822},{level:2,title:"删除缓存可以保证一致性吗？",slug:"删除缓存可以保证一致性吗",normalizedTitle:"删除缓存可以保证一致性吗？",charIndex:2434},{level:2,title:"如何保证两步都执行成功？",slug:"如何保证两步都执行成功",normalizedTitle:"如何保证两步都执行成功？",charIndex:3376},{level:2,title:"主从库延迟和延迟双删问题",slug:"主从库延迟和延迟双删问题",normalizedTitle:"主从库延迟和延迟双删问题",charIndex:4973},{level:2,title:"可以做到强一致吗？",slug:"可以做到强一致吗",normalizedTitle:"可以做到强一致吗？",charIndex:6103},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:6604},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:7140}],headersStr:"前言 引入缓存提高性能 缓存利用率和一致性问题 先来看第一个问题，如何提高缓存利用率？ 并发引发的一致性问题 删除缓存可以保证一致性吗？ 如何保证两步都执行成功？ 主从库延迟和延迟双删问题 可以做到强一致吗？ 总结 参考文献",content:"# 前言\n\n感觉这是一个很宏大的命题\n\n我个人觉得引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要\n\n可以将请求分流，要保证强一致的请求走数据库，能忍受不一致的请求走缓存\n\necho 带着你沿着场景渐进式的了解双写一致性问题\n\n\n# 引入缓存提高性能\n\n我们从最简单的场景开始讲起。\n\n如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的：\n\n\n\n但随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。\n\n这个阶段通常的做法是，引入「缓存」来提高读性能，架构模型就变成了这样：\n\n\n\n当下优秀的缓存中间件，当属 Redis 莫属，它不仅性能非常高，还提供了很多友好的数据类型，可以很好地满足我们的业务需求。\n\n但引入缓存之后，你就会面临一个问题：之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢？\n\n有三种方案：\n\n * Cache Aside Pattern（旁路缓存模式）\n * Read/Write Through Pattern（读写穿透）\n * Write Behind Pattern（异步缓存写入）\n\n最简单直接的方案是「全量数据刷到缓存中」：\n\n * 数据库的数据，全量刷入缓存（不设置失效时间）\n * 写请求只更新数据库，不更新缓存\n * 启动一个定时任务，定时把数据库的数据，更新到缓存中\n\n\n\n这个方案的优点是，所有读请求都可以直接「命中」缓存，不需要再查数据库，性能非常高。\n\n但缺点也很明显，有 2 个问题：\n\n 1. 缓存利用率低：不经常访问的数据，还一直留在缓存中\n 2. 数据不一致：因为是「定时」刷新缓存，缓存和数据库存在不一致（取决于定时任务的执行频率）\n\n所以，这种方案一般更适合业务「体量小」，且对数据一致性要求不高的业务场景。\n\n那如果我们的业务体量很大，怎么解决这 2 个问题呢？\n\n\n# 缓存利用率和一致性问题\n\n\n# 先来看第一个问题，如何提高缓存利用率？\n\n想要缓存利用率「最大化」，我们很容易想到的方案是，缓存中只保留最近访问的「热数据」。但具体要怎么做呢？\n\n我们可以这样优化：\n\n * 写请求依旧只写数据库\n * 读请求先读缓存，如果缓存不存在，则从数据库读取，并重建缓存\n * 同时，写入缓存中的数据，都设置失效时间\n\n\n\n这样一来，缓存中不经常访问的数据，随着时间的推移，都会逐渐「过期」淘汰掉，最终缓存中保留的，都是经常被访问的「热数据」，缓存利用率得以最大化。\n\n再来看数据一致性问题。\n\n要想保证缓存和数据库「实时」一致，那就不能再用定时任务刷新缓存了。\n\n所以，当数据发生更新时，我们不仅要操作数据库，还要一并操作缓存。具体操作就是，修改一条数据时，不仅要更新数据库，也要连带缓存一起更新。\n\n但数据库和缓存都更新，又存在先后问题，那对应的方案就有 2 个：\n\n 1. 先更新缓存，后更新数据库\n 2. 先更新数据库，后更新缓存\n\n哪个方案更好呢？\n\n先不考虑并发问题，正常情况下，无论谁先谁后，都可以让两者保持一致，但现在我们需要重点考虑「异常」情况。\n\n因为操作分为两步，那么就很有可能存在「第一步成功、第二步失败」的情况发生。\n\n这 2 种方案我们一个个来分析。\n\n1) 先更新缓存，后更新数据库\n\n如果缓存更新成功了，但数据库更新失败，那么此时缓存中是最新值，但数据库中是「旧值」。\n\n虽然此时读请求可以命中缓存，拿到正确的值，但是，一旦缓存「失效」，就会从数据库中读取到「旧值」，重建缓存也是这个旧值。\n\n这时用户会发现自己之前修改的数据又「变回去」了，对业务造成影响。\n\n2) 先更新数据库，后更新缓存\n\n如果数据库更新成功了，但缓存更新失败，那么此时数据库中是最新值，缓存中是「旧值」。\n\n之后的读请求读到的都是旧数据，只有当缓存「失效」后，才能从数据库中得到正确的值。\n\n这时用户会发现，自己刚刚修改了数据，但却看不到变更，一段时间过后，数据才变更过来，对业务也会有影响。\n\n可见，无论谁先谁后，但凡后者发生异常，就会对业务造成影响。那怎么解决这个问题呢？\n\n别急，后面我会详细给出对应的解决方案。\n\n我们继续分析，除了操作失败问题，还有什么场景会影响数据一致性？\n\n这里我们还需要重点关注：并发问题。\n\n\n# 并发引发的一致性问题\n\n假设我们采用**「先更新数据库，再更新缓存」**的方案，并且两步都可以「成功执行」的前提下，如果存在并发，情况会是怎样的呢？\n\n有线程 A 和线程 B 两个线程，需要更新「同一条」数据，会发生这样的场景：\n\n 1. 线程 A 更新数据库（X = 1）\n 2. 线程 B 更新数据库（X = 2）\n 3. 线程 B 更新缓存（X = 2）\n 4. 线程 A 更新缓存（X = 1）\n\n最终 X 的值在缓存中是 1，在数据库中是 2，发生不一致。\n\n也就是说，A 虽然先于 B 发生，但 B 操作数据库和缓存的时间，却要比 A 的时间短，执行时序发生「错乱」，最终这条数据结果是不符合预期的。\n\n> 同样地，采用「先更新缓存，再更新数据库」的方案，也会有类似问题，这里不再详述。\n\n除此之外，我们从「缓存利用率」的角度来评估这个方案，也是不太推荐的。\n\n这是因为每次数据发生变更，都「无脑」更新缓存，但是缓存中的数据不一定会被「马上读取」，这就会导致缓存中可能存放了很多不常访问的数据，浪费缓存资源。\n\n而且很多情况下，写到缓存中的值，并不是与数据库中的值一一对应的，很有可能是先查询数据库，再经过一系列「计算」得出一个值，才把这个值才写到缓存中。\n\n由此可见，这种「更新数据库 + 更新缓存」的方案，不仅缓存利用率不高，还会造成机器性能的浪费。\n\n所以此时我们需要考虑另外一种方案：删除缓存。\n\n\n# 删除缓存可以保证一致性吗？\n\n删除缓存对应的方案也有 2 种：\n\n 1. 先删除缓存，后更新数据库\n 2. 先更新数据库，后删除缓存\n\n经过前面的分析我们已经得知，但凡「第二步」操作失败，都会导致数据不一致。\n\n这里我不再详述具体场景，你可以按照前面的思路推演一下，就可以看到依旧存在数据不一致的情况。\n\n这里我们重点来看「并发」问题。\n\n1) 先删除缓存，后更新数据库\n\n如果有 2 个线程要并发「读写」数据，可能会发生以下场景：\n\n 1. 线程 A 要更新 X = 2（原值 X = 1）\n 2. 线程 A 先删除缓存\n 3. 线程 B 读缓存，发现不存在，从数据库中读取到旧值（X = 1）\n 4. 线程 A 将新值写入数据库（X = 2）\n 5. 线程 B 将旧值写入缓存（X = 1）\n\n最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。\n\n可见，先删除缓存，后更新数据库，当发生「读+写」并发时，还是存在数据不一致的情况。\n\n2) 先更新数据库，后删除缓存\n\n依旧是 2 个线程并发「读写」数据：\n\n 1. 缓存中 X 不存在（数据库 X = 1）\n 2. 线程 A 读取数据库，得到旧值（X = 1）\n 3. 线程 B 更新数据库（X = 2)\n 4. 线程 B 删除缓存\n 5. 线程 A 将旧值写入缓存（X = 1）\n\n最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），也发生不一致。\n\n这种情况「理论」来说是可能发生的，但实际真的有可能发生吗？\n\n其实概率「很低」，这是因为它必须满足 3 个条件：\n\n 1. 缓存刚好已失效\n 2. 读请求 + 写请求并发\n 3. 更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5）\n\n仔细想一下，条件 3 发生的概率其实是非常低的。\n\n因为写数据库一般会先「加锁」，所以写数据库，通常是要比读数据库的时间更长的。\n\n这么来看，「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的。\n\n所以，我们应该采用这种方案，来操作数据库和缓存。\n\n好，解决了并发问题，我们继续来看前面遗留的，第二步执行「失败」导致数据不一致的问题。\n\n\n# 如何保证两步都执行成功？\n\n前面我们分析到，无论是更新缓存还是删除缓存，只要第二步发生失败，那么就会导致数据库和缓存不一致。\n\n前面我们分析到，无论是更新缓存还是删除缓存，只要第二步发生失败，那么就会导致数据库和缓存不一致。\n\n保证第二步成功执行，就是解决问题的关键。\n\n想一下，程序在执行过程中发生异常，最简单的解决办法是什么？\n\n答案是：重试。\n\n是的，其实这里我们也可以这样做。\n\n无论是先操作缓存，还是先操作数据库，但凡后者执行失败了，我们就可以发起重试，尽可能地去做「补偿」。\n\n那这是不是意味着，只要执行失败，我们「无脑重试」就可以了呢？\n\n答案是否定的。现实情况往往没有想的这么简单，失败后立即重试的问题在于：\n\n * 立即重试很大概率「还会失败」\n * 「重试次数」设置多少才合理？\n * 重试会一直「占用」这个线程资源，无法服务其它客户端请求\n\n看到了么，虽然我们想通过重试的方式解决问题，但这种「同步」重试的方案依旧不严谨。\n\n那更好的方案应该怎么做？\n\n答案是：异步重试。什么是异步重试？\n\n其实就是把重试请求写到「消息队列」中，然后由专门的消费者来重试，直到成功。\n\n或者更直接的做法，为了避免第二步执行失败，我们可以把操作缓存这一步，直接放到消息队列中，由消费者来操作缓存。\n\n到这里你可能会问，写消息队列也有可能会失败啊？而且，引入消息队列，这又增加了更多的维护成本，这样做值得吗？\n\n这个问题很好，但我们思考这样一个问题：如果在执行失败的线程中一直重试，还没等执行成功，此时如果项目「重启」了，那这次重试请求也就「丢失」了，那这条数据就一直不一致了。\n\n所以，这里我们必须把重试或第二步操作放到另一个「服务」中，这个服务用「消息队列」最为合适。这是因为消息队列的特性，正好符合我们的需求：\n\n * 消息队列保证可靠性：写到队列中的消息，成功消费之前不会丢失（重启项目也不担心）\n * 消息队列保证消息成功投递：下游从队列拉取消息，成功消费后才会删除消息，否则还会继续投递消息给消费者（符合我们重试的场景）\n\n至于写队列失败和消息队列的维护成本问题：\n\n * 写队列失败：操作缓存和写消息队列，「同时失败」的概率其实是很小的\n * 维护成本：我们项目中一般都会用到消息队列，维护成本并没有新增很多\n\n所以，引入消息队列来解决这个问题，是比较合适的。这时架构模型就变成了这样：\n\n那如果你确实不想在应用中去写消息队列，是否有更简单的方案，同时又可以保证一致性呢？\n\n方案还是有的，这就是近几年比较流行的解决方案：订阅数据库变更日志，再操作缓存。\n\n具体来讲就是，我们的业务应用在修改数据时，「只需」修改数据库，无需操作缓存。\n\n那什么时候操作缓存呢？这就和数据库的「变更日志」有关了。\n\n拿 MySQL 举例，当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。\n\n订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 canal，使用这种方案的优点在于：\n\n * 无需考虑写消息队列失败情况：只要写 MySQL 成功，Binlog 肯定会有\n * 自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列\n\n当然，与此同时，我们需要投入精力去维护 canal 的高可用和稳定性。\n\n> 如果你有留意观察很多数据库的特性，就会发现其实很多数据库都逐渐开始提供「订阅变更日志」的功能了，相信不远的将来，我们就不用通过中间件来拉取日志，自己写程序就可以订阅变更日志了，这样可以进一步简化流程。\n\n至此，我们可以得出结论，想要保证数据库和缓存一致性，推荐采用「先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做。\n\n\n# 主从库延迟和延迟双删问题\n\n到这里，还有 2 个问题，是我们没有重点分析过的。\n\n第一个问题，还记得前面讲到的「先删除缓存，再更新数据库」方案，导致不一致的场景么？\n\n这里我再把例子拿过来让你复习一下：\n\n2 个线程要并发「读写」数据，可能会发生以下场景：\n\n 1. 线程 A 要更新 X = 2（原值 X = 1）\n 2. 线程 A 先删除缓存\n 3. 线程 B 读缓存，发现不存在，从数据库中读取到旧值（X = 1）\n 4. 线程 A 将新值写入数据库（X = 2）\n 5. 线程 B 将旧值写入缓存（X = 1）\n\n最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。\n\n第二个问题：是关于「读写分离 + 主从复制延迟」情况下，缓存和数据库一致性的问题。\n\n在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」其实也会导致不一致：\n\n 1. 线程 A 更新主库 X = 2（原值 X = 1）\n 2. 线程 A 删除缓存\n 3. 线程 B 查询缓存，没有命中，查询「从库」得到旧值（从库 X = 1）\n 4. 从库「同步」完成（主从库 X = 2）\n 5. 线程 B 将「旧值」写入缓存（X = 1）\n\n最终 X 的值在缓存中是 1（旧值），在主从库中是 2（新值），也发生不一致。\n\n看到了么？这 2 个问题的核心在于：缓存都被回种了「旧值」。\n\n那怎么解决这类问题呢？\n\n最有效的办法就是，把缓存删掉。\n\n但是，不能立即删，而是需要「延迟删」，这就是业界给出的方案：缓存延迟双删策略。\n\n按照延时双删策略，这 2 个问题的解决方案是这样的：\n\n解决第一个问题：在线程 A 删除缓存、更新完数据库之后，先「休眠一会」，再「删除」一次缓存。\n\n解决第二个问题：线程 A 可以生成一条「延时消息」，写到消息队列中，消费者延时「删除」缓存。\n\n这两个方案的目的，都是为了把缓存清掉，这样一来，下次就可以从数据库读取到最新值，写入缓存。\n\n但问题来了，这个「延迟删除」缓存，延迟时间到底设置要多久呢？\n\n * 问题1：延迟时间要大于「主从复制」的延迟时间\n * 问题2：延迟时间要大于线程 B 读取数据库 + 写入缓存的时间\n\n但是，这个时间在分布式和高并发场景下，其实是很难评估的\n\n很多时候，我们都是凭借经验大致估算这个延迟时间，例如延迟 1-5s，只能尽可能地降低不一致的概率。\n\n所以你看，采用这种方案，也只是尽可能保证一致性而已，极端情况下，还是有可能发生不一致。\n\n所以实际使用中，我还是建议你采用「先更新数据库，再删除缓存」的方案，同时，要尽可能地保证「主从复制」不要有太大延迟，降低出问题的概率。\n\n\n# 可以做到强一致吗？\n\n看到这里你可能会想，这些方案还是不够完美，我就想让缓存和数据库「强一致」，到底能不能做到呢？\n\n其实很难。\n\n要想做到强一致，最常见的方案是 2PC、3PC、Paxos、Raft 这类一致性协议，但它们的性能往往比较差，而且这些方案也比较复杂，还要考虑各种容错问题。\n\n相反，这时我们换个角度思考一下，我们引入缓存的目的是什么？\n\n没错，性能。\n\n一旦我们决定使用缓存，那必然要面临一致性问题。性能和一致性就像天平的两端，无法做到都满足要求。\n\n而且，就拿我们前面讲到的方案来说，当操作数据库和缓存完成之前，只要有其它请求可以进来，都有可能查到「中间状态」的数据。\n\n所以如果非要追求强一致，那必须要求所有更新操作完成之前期间，不能有「任何请求」进来。\n\n虽然我们可以通过加「分布锁」的方式来实现，但我们要付出的代价，很可能会超过引入缓存带来的性能提升。\n\n所以，既然决定使用缓存，就必须容忍「一致性」问题，我们只能尽可能地去降低问题出现的概率。\n\n同时我们也要知道，缓存都是有「失效时间」的，就算在这期间存在短期不一致，我们依旧有失效时间来兜底，这样也能达到最终一致。\n\n\n# 总结\n\n好了，总结一下这篇文章的重点。\n\n 1. 想要提高应用的性能，可以引入「缓存」来解决\n 2. 引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」\n 3. 更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，且存在「缓存资源浪费」和「机器性能浪费」的情况发生\n 4. 在更新数据库 + 删除缓存的方案中，「先删除缓存，再更新数据库」在「并发」场景下依旧有数据不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估，所以推荐用「先更新数据库，再删除缓存」的方案\n 5. 在「先更新数据库，再删除缓存」方案下，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据一致性\n 6. 在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率\n 7. 如果要实现强一致性可以采用的方案是 2PC、3PC、Paxos、Raft 这类一致性协议，或者使用分布式锁\n\n\n# 参考文献\n\n缓存和数据库一致性问题，看这篇就够了 - 水滴与银弹",normalizedContent:"# 前言\n\n感觉这是一个很宏大的命题\n\n我个人觉得引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要\n\n可以将请求分流，要保证强一致的请求走数据库，能忍受不一致的请求走缓存\n\necho 带着你沿着场景渐进式的了解双写一致性问题\n\n\n# 引入缓存提高性能\n\n我们从最简单的场景开始讲起。\n\n如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的：\n\n\n\n但随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。\n\n这个阶段通常的做法是，引入「缓存」来提高读性能，架构模型就变成了这样：\n\n\n\n当下优秀的缓存中间件，当属 redis 莫属，它不仅性能非常高，还提供了很多友好的数据类型，可以很好地满足我们的业务需求。\n\n但引入缓存之后，你就会面临一个问题：之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢？\n\n有三种方案：\n\n * cache aside pattern（旁路缓存模式）\n * read/write through pattern（读写穿透）\n * write behind pattern（异步缓存写入）\n\n最简单直接的方案是「全量数据刷到缓存中」：\n\n * 数据库的数据，全量刷入缓存（不设置失效时间）\n * 写请求只更新数据库，不更新缓存\n * 启动一个定时任务，定时把数据库的数据，更新到缓存中\n\n\n\n这个方案的优点是，所有读请求都可以直接「命中」缓存，不需要再查数据库，性能非常高。\n\n但缺点也很明显，有 2 个问题：\n\n 1. 缓存利用率低：不经常访问的数据，还一直留在缓存中\n 2. 数据不一致：因为是「定时」刷新缓存，缓存和数据库存在不一致（取决于定时任务的执行频率）\n\n所以，这种方案一般更适合业务「体量小」，且对数据一致性要求不高的业务场景。\n\n那如果我们的业务体量很大，怎么解决这 2 个问题呢？\n\n\n# 缓存利用率和一致性问题\n\n\n# 先来看第一个问题，如何提高缓存利用率？\n\n想要缓存利用率「最大化」，我们很容易想到的方案是，缓存中只保留最近访问的「热数据」。但具体要怎么做呢？\n\n我们可以这样优化：\n\n * 写请求依旧只写数据库\n * 读请求先读缓存，如果缓存不存在，则从数据库读取，并重建缓存\n * 同时，写入缓存中的数据，都设置失效时间\n\n\n\n这样一来，缓存中不经常访问的数据，随着时间的推移，都会逐渐「过期」淘汰掉，最终缓存中保留的，都是经常被访问的「热数据」，缓存利用率得以最大化。\n\n再来看数据一致性问题。\n\n要想保证缓存和数据库「实时」一致，那就不能再用定时任务刷新缓存了。\n\n所以，当数据发生更新时，我们不仅要操作数据库，还要一并操作缓存。具体操作就是，修改一条数据时，不仅要更新数据库，也要连带缓存一起更新。\n\n但数据库和缓存都更新，又存在先后问题，那对应的方案就有 2 个：\n\n 1. 先更新缓存，后更新数据库\n 2. 先更新数据库，后更新缓存\n\n哪个方案更好呢？\n\n先不考虑并发问题，正常情况下，无论谁先谁后，都可以让两者保持一致，但现在我们需要重点考虑「异常」情况。\n\n因为操作分为两步，那么就很有可能存在「第一步成功、第二步失败」的情况发生。\n\n这 2 种方案我们一个个来分析。\n\n1) 先更新缓存，后更新数据库\n\n如果缓存更新成功了，但数据库更新失败，那么此时缓存中是最新值，但数据库中是「旧值」。\n\n虽然此时读请求可以命中缓存，拿到正确的值，但是，一旦缓存「失效」，就会从数据库中读取到「旧值」，重建缓存也是这个旧值。\n\n这时用户会发现自己之前修改的数据又「变回去」了，对业务造成影响。\n\n2) 先更新数据库，后更新缓存\n\n如果数据库更新成功了，但缓存更新失败，那么此时数据库中是最新值，缓存中是「旧值」。\n\n之后的读请求读到的都是旧数据，只有当缓存「失效」后，才能从数据库中得到正确的值。\n\n这时用户会发现，自己刚刚修改了数据，但却看不到变更，一段时间过后，数据才变更过来，对业务也会有影响。\n\n可见，无论谁先谁后，但凡后者发生异常，就会对业务造成影响。那怎么解决这个问题呢？\n\n别急，后面我会详细给出对应的解决方案。\n\n我们继续分析，除了操作失败问题，还有什么场景会影响数据一致性？\n\n这里我们还需要重点关注：并发问题。\n\n\n# 并发引发的一致性问题\n\n假设我们采用**「先更新数据库，再更新缓存」**的方案，并且两步都可以「成功执行」的前提下，如果存在并发，情况会是怎样的呢？\n\n有线程 a 和线程 b 两个线程，需要更新「同一条」数据，会发生这样的场景：\n\n 1. 线程 a 更新数据库（x = 1）\n 2. 线程 b 更新数据库（x = 2）\n 3. 线程 b 更新缓存（x = 2）\n 4. 线程 a 更新缓存（x = 1）\n\n最终 x 的值在缓存中是 1，在数据库中是 2，发生不一致。\n\n也就是说，a 虽然先于 b 发生，但 b 操作数据库和缓存的时间，却要比 a 的时间短，执行时序发生「错乱」，最终这条数据结果是不符合预期的。\n\n> 同样地，采用「先更新缓存，再更新数据库」的方案，也会有类似问题，这里不再详述。\n\n除此之外，我们从「缓存利用率」的角度来评估这个方案，也是不太推荐的。\n\n这是因为每次数据发生变更，都「无脑」更新缓存，但是缓存中的数据不一定会被「马上读取」，这就会导致缓存中可能存放了很多不常访问的数据，浪费缓存资源。\n\n而且很多情况下，写到缓存中的值，并不是与数据库中的值一一对应的，很有可能是先查询数据库，再经过一系列「计算」得出一个值，才把这个值才写到缓存中。\n\n由此可见，这种「更新数据库 + 更新缓存」的方案，不仅缓存利用率不高，还会造成机器性能的浪费。\n\n所以此时我们需要考虑另外一种方案：删除缓存。\n\n\n# 删除缓存可以保证一致性吗？\n\n删除缓存对应的方案也有 2 种：\n\n 1. 先删除缓存，后更新数据库\n 2. 先更新数据库，后删除缓存\n\n经过前面的分析我们已经得知，但凡「第二步」操作失败，都会导致数据不一致。\n\n这里我不再详述具体场景，你可以按照前面的思路推演一下，就可以看到依旧存在数据不一致的情况。\n\n这里我们重点来看「并发」问题。\n\n1) 先删除缓存，后更新数据库\n\n如果有 2 个线程要并发「读写」数据，可能会发生以下场景：\n\n 1. 线程 a 要更新 x = 2（原值 x = 1）\n 2. 线程 a 先删除缓存\n 3. 线程 b 读缓存，发现不存在，从数据库中读取到旧值（x = 1）\n 4. 线程 a 将新值写入数据库（x = 2）\n 5. 线程 b 将旧值写入缓存（x = 1）\n\n最终 x 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。\n\n可见，先删除缓存，后更新数据库，当发生「读+写」并发时，还是存在数据不一致的情况。\n\n2) 先更新数据库，后删除缓存\n\n依旧是 2 个线程并发「读写」数据：\n\n 1. 缓存中 x 不存在（数据库 x = 1）\n 2. 线程 a 读取数据库，得到旧值（x = 1）\n 3. 线程 b 更新数据库（x = 2)\n 4. 线程 b 删除缓存\n 5. 线程 a 将旧值写入缓存（x = 1）\n\n最终 x 的值在缓存中是 1（旧值），在数据库中是 2（新值），也发生不一致。\n\n这种情况「理论」来说是可能发生的，但实际真的有可能发生吗？\n\n其实概率「很低」，这是因为它必须满足 3 个条件：\n\n 1. 缓存刚好已失效\n 2. 读请求 + 写请求并发\n 3. 更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5）\n\n仔细想一下，条件 3 发生的概率其实是非常低的。\n\n因为写数据库一般会先「加锁」，所以写数据库，通常是要比读数据库的时间更长的。\n\n这么来看，「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的。\n\n所以，我们应该采用这种方案，来操作数据库和缓存。\n\n好，解决了并发问题，我们继续来看前面遗留的，第二步执行「失败」导致数据不一致的问题。\n\n\n# 如何保证两步都执行成功？\n\n前面我们分析到，无论是更新缓存还是删除缓存，只要第二步发生失败，那么就会导致数据库和缓存不一致。\n\n前面我们分析到，无论是更新缓存还是删除缓存，只要第二步发生失败，那么就会导致数据库和缓存不一致。\n\n保证第二步成功执行，就是解决问题的关键。\n\n想一下，程序在执行过程中发生异常，最简单的解决办法是什么？\n\n答案是：重试。\n\n是的，其实这里我们也可以这样做。\n\n无论是先操作缓存，还是先操作数据库，但凡后者执行失败了，我们就可以发起重试，尽可能地去做「补偿」。\n\n那这是不是意味着，只要执行失败，我们「无脑重试」就可以了呢？\n\n答案是否定的。现实情况往往没有想的这么简单，失败后立即重试的问题在于：\n\n * 立即重试很大概率「还会失败」\n * 「重试次数」设置多少才合理？\n * 重试会一直「占用」这个线程资源，无法服务其它客户端请求\n\n看到了么，虽然我们想通过重试的方式解决问题，但这种「同步」重试的方案依旧不严谨。\n\n那更好的方案应该怎么做？\n\n答案是：异步重试。什么是异步重试？\n\n其实就是把重试请求写到「消息队列」中，然后由专门的消费者来重试，直到成功。\n\n或者更直接的做法，为了避免第二步执行失败，我们可以把操作缓存这一步，直接放到消息队列中，由消费者来操作缓存。\n\n到这里你可能会问，写消息队列也有可能会失败啊？而且，引入消息队列，这又增加了更多的维护成本，这样做值得吗？\n\n这个问题很好，但我们思考这样一个问题：如果在执行失败的线程中一直重试，还没等执行成功，此时如果项目「重启」了，那这次重试请求也就「丢失」了，那这条数据就一直不一致了。\n\n所以，这里我们必须把重试或第二步操作放到另一个「服务」中，这个服务用「消息队列」最为合适。这是因为消息队列的特性，正好符合我们的需求：\n\n * 消息队列保证可靠性：写到队列中的消息，成功消费之前不会丢失（重启项目也不担心）\n * 消息队列保证消息成功投递：下游从队列拉取消息，成功消费后才会删除消息，否则还会继续投递消息给消费者（符合我们重试的场景）\n\n至于写队列失败和消息队列的维护成本问题：\n\n * 写队列失败：操作缓存和写消息队列，「同时失败」的概率其实是很小的\n * 维护成本：我们项目中一般都会用到消息队列，维护成本并没有新增很多\n\n所以，引入消息队列来解决这个问题，是比较合适的。这时架构模型就变成了这样：\n\n那如果你确实不想在应用中去写消息队列，是否有更简单的方案，同时又可以保证一致性呢？\n\n方案还是有的，这就是近几年比较流行的解决方案：订阅数据库变更日志，再操作缓存。\n\n具体来讲就是，我们的业务应用在修改数据时，「只需」修改数据库，无需操作缓存。\n\n那什么时候操作缓存呢？这就和数据库的「变更日志」有关了。\n\n拿 mysql 举例，当一条数据发生修改时，mysql 就会产生一条变更日志（binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。\n\n订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 canal，使用这种方案的优点在于：\n\n * 无需考虑写消息队列失败情况：只要写 mysql 成功，binlog 肯定会有\n * 自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列\n\n当然，与此同时，我们需要投入精力去维护 canal 的高可用和稳定性。\n\n> 如果你有留意观察很多数据库的特性，就会发现其实很多数据库都逐渐开始提供「订阅变更日志」的功能了，相信不远的将来，我们就不用通过中间件来拉取日志，自己写程序就可以订阅变更日志了，这样可以进一步简化流程。\n\n至此，我们可以得出结论，想要保证数据库和缓存一致性，推荐采用「先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做。\n\n\n# 主从库延迟和延迟双删问题\n\n到这里，还有 2 个问题，是我们没有重点分析过的。\n\n第一个问题，还记得前面讲到的「先删除缓存，再更新数据库」方案，导致不一致的场景么？\n\n这里我再把例子拿过来让你复习一下：\n\n2 个线程要并发「读写」数据，可能会发生以下场景：\n\n 1. 线程 a 要更新 x = 2（原值 x = 1）\n 2. 线程 a 先删除缓存\n 3. 线程 b 读缓存，发现不存在，从数据库中读取到旧值（x = 1）\n 4. 线程 a 将新值写入数据库（x = 2）\n 5. 线程 b 将旧值写入缓存（x = 1）\n\n最终 x 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。\n\n第二个问题：是关于「读写分离 + 主从复制延迟」情况下，缓存和数据库一致性的问题。\n\n在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」其实也会导致不一致：\n\n 1. 线程 a 更新主库 x = 2（原值 x = 1）\n 2. 线程 a 删除缓存\n 3. 线程 b 查询缓存，没有命中，查询「从库」得到旧值（从库 x = 1）\n 4. 从库「同步」完成（主从库 x = 2）\n 5. 线程 b 将「旧值」写入缓存（x = 1）\n\n最终 x 的值在缓存中是 1（旧值），在主从库中是 2（新值），也发生不一致。\n\n看到了么？这 2 个问题的核心在于：缓存都被回种了「旧值」。\n\n那怎么解决这类问题呢？\n\n最有效的办法就是，把缓存删掉。\n\n但是，不能立即删，而是需要「延迟删」，这就是业界给出的方案：缓存延迟双删策略。\n\n按照延时双删策略，这 2 个问题的解决方案是这样的：\n\n解决第一个问题：在线程 a 删除缓存、更新完数据库之后，先「休眠一会」，再「删除」一次缓存。\n\n解决第二个问题：线程 a 可以生成一条「延时消息」，写到消息队列中，消费者延时「删除」缓存。\n\n这两个方案的目的，都是为了把缓存清掉，这样一来，下次就可以从数据库读取到最新值，写入缓存。\n\n但问题来了，这个「延迟删除」缓存，延迟时间到底设置要多久呢？\n\n * 问题1：延迟时间要大于「主从复制」的延迟时间\n * 问题2：延迟时间要大于线程 b 读取数据库 + 写入缓存的时间\n\n但是，这个时间在分布式和高并发场景下，其实是很难评估的\n\n很多时候，我们都是凭借经验大致估算这个延迟时间，例如延迟 1-5s，只能尽可能地降低不一致的概率。\n\n所以你看，采用这种方案，也只是尽可能保证一致性而已，极端情况下，还是有可能发生不一致。\n\n所以实际使用中，我还是建议你采用「先更新数据库，再删除缓存」的方案，同时，要尽可能地保证「主从复制」不要有太大延迟，降低出问题的概率。\n\n\n# 可以做到强一致吗？\n\n看到这里你可能会想，这些方案还是不够完美，我就想让缓存和数据库「强一致」，到底能不能做到呢？\n\n其实很难。\n\n要想做到强一致，最常见的方案是 2pc、3pc、paxos、raft 这类一致性协议，但它们的性能往往比较差，而且这些方案也比较复杂，还要考虑各种容错问题。\n\n相反，这时我们换个角度思考一下，我们引入缓存的目的是什么？\n\n没错，性能。\n\n一旦我们决定使用缓存，那必然要面临一致性问题。性能和一致性就像天平的两端，无法做到都满足要求。\n\n而且，就拿我们前面讲到的方案来说，当操作数据库和缓存完成之前，只要有其它请求可以进来，都有可能查到「中间状态」的数据。\n\n所以如果非要追求强一致，那必须要求所有更新操作完成之前期间，不能有「任何请求」进来。\n\n虽然我们可以通过加「分布锁」的方式来实现，但我们要付出的代价，很可能会超过引入缓存带来的性能提升。\n\n所以，既然决定使用缓存，就必须容忍「一致性」问题，我们只能尽可能地去降低问题出现的概率。\n\n同时我们也要知道，缓存都是有「失效时间」的，就算在这期间存在短期不一致，我们依旧有失效时间来兜底，这样也能达到最终一致。\n\n\n# 总结\n\n好了，总结一下这篇文章的重点。\n\n 1. 想要提高应用的性能，可以引入「缓存」来解决\n 2. 引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」\n 3. 更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，且存在「缓存资源浪费」和「机器性能浪费」的情况发生\n 4. 在更新数据库 + 删除缓存的方案中，「先删除缓存，再更新数据库」在「并发」场景下依旧有数据不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估，所以推荐用「先更新数据库，再删除缓存」的方案\n 5. 在「先更新数据库，再删除缓存」方案下，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据一致性\n 6. 在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率\n 7. 如果要实现强一致性可以采用的方案是 2pc、3pc、paxos、raft 这类一致性协议，或者使用分布式锁\n\n\n# 参考文献\n\n缓存和数据库一致性问题，看这篇就够了 - 水滴与银弹",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"缓存穿透",frontmatter:{title:"缓存穿透",date:"2024-09-14T16:50:37.000Z",permalink:"/pages/1e9e8e/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/02.%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F.html",relativePath:"03.经典场景设计/01.热门场景设计/02.缓存穿透.md",key:"v-768b02c9",path:"/pages/1e9e8e/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"什么是缓存穿透",slug:"什么是缓存穿透",normalizedTitle:"什么是缓存穿透",charIndex:149},{level:2,title:"缓存穿透如何解决",slug:"缓存穿透如何解决",normalizedTitle:"缓存穿透如何解决",charIndex:606},{level:3,title:"设置空值",slug:"设置空值",normalizedTitle:"设置空值",charIndex:908},{level:3,title:"布隆过滤器",slug:"布隆过滤器",normalizedTitle:"布隆过滤器",charIndex:96},{level:3,title:"接口限流",slug:"接口限流",normalizedTitle:"接口限流",charIndex:1390}],headersStr:"前言 什么是缓存穿透 缓存穿透如何解决 设置空值 布隆过滤器 接口限流",content:"# 前言\n\n先来一个问题：如何解决复杂 where 下的缓存穿透？\n\n * 分为正常请求和非法请求\n * 正常请求：给 where 进行 hash，然后存 redis，合理设置过期时间，并利用布隆过滤器过滤\n * 非法请求：记录查询 null 的次数，如果太大，进行封禁，采用指数退避算法\n\n\n# 什么是缓存穿透\n\n缓存穿透最直白的意思就是，我们的业务系统在接收到请求时在缓存中并没有查到数据，从而穿透到了后端数据库里面查数据的过程。\n\n当然，既然使用了缓存，肯定会难免有穿透的发生，正常的少量穿透是对我们业务来说是不会造成任何影响的，因为:\n\n * 毕竟我们的缓存容量有限，不可能去缓存所有数据，当面临较大请求时，查询到未被缓存的数据时，就会发生穿透。\n * 互联网业务的数据访问模型一般是遵循“二八”原则的，即 20% 的数据为热点数据，80% 的数据是非热点不被常访问的数据。\n\n现在既然我们的缓存容量有限，然后 20% 的数据为热点数据，也就是说，我们可以利用有限的容量去缓存那 20% 的数据，其实就是可以保护我们的后端系统的，至于80%非热点不常用的数据发生穿透了，是我们能够接受的。\n\n那究竟什么的缓存穿透会影响到我们的系统呢？是大量的穿透请求超过了我们后端系统的承受范围，比如恶意的穿透攻击，这样的穿透就很有可能把我们的系统给干崩溃。接下来，我们就来基于相关应用场景来解决这种缓存穿透。\n\n\n# 缓存穿透如何解决\n\n在我们APP的在线搜索相关系统里面，有个产品product 1 并没有在数据库中进行存储，现在通过cache aside pattern 策略（缓存读写策略，开发必备）查这个product 1 。\n\n那查询一个数据库中本身就没有的数据后面会怎样呢？依照cache aside 策略，读取时，首先会读取缓存，没读到数据就会穿透到读数据库，现在数据库也没有，也就没有数据写回缓存。那么，再来个请求依然如此，更多的请求来还是一样，这样的缓存就没意义了。\n\n通过上面场景我们可以看到，这样的系统面临非正常的穿透是会崩溃掉的，那我们该怎么去解决呢？一般我们对此有两种方案，都是有用的：\n\n * 设置空值\n * 布隆过滤器\n\n\n# 设置空值\n\n通过上面场景我们知道，当有大量恶意的穿透请求到数据库，就会给我们系统带来灾难。\n\n所以，当我们请求数据中没有数据或者因为代码bug带来的异常造成的数据为空，这个时候我们就可以回写一个空值null到缓存中。同时，我们还要给这个null值设置过期时间，因为这个空值不具有实际业务性，而且还占用空间。\n\n可见设置空值是可以阻挡大量穿透请求的，但是如果有大量的获取并不存在数据的穿透请求的话例如恶意攻击，则会浪费缓存空间，如果这种null值过量的话，还会淘汰掉本身缓存存在的数据，这就会使我们的缓存命中率下降。\n\n**生产建议，**在使用设置空值方案时，我们要做好监控，预防缓存空间被过多null值占领造成的缓存空间浪费，如果这种数据量太大，就不再建议使用，那就使用另一种方案，即布隆过滤器。\n\n\n# 布隆过滤器\n\n生产建议：\n\n * 采用多个hash 算法计算hash 值，这样可以减少误判的几率。\n * 布隆过滤器会消耗一定内存空间，根据业务场景进行评估需要多大内存，最后依据公司资源以及成本，看是否能够接受。\n\n\n# 接口限流\n\n根据用户或者 IP 对接口进行限流，对于异常频繁的访问行为，还可以采取黑名单机制，例如将异常 IP 列入黑名单。\n\n后面提到的缓存击穿和雪崩都可以配合接口限流来解决，毕竟这些问题的关键都是有很多请求落到了数据库上造成数据库压力过大。",normalizedContent:"# 前言\n\n先来一个问题：如何解决复杂 where 下的缓存穿透？\n\n * 分为正常请求和非法请求\n * 正常请求：给 where 进行 hash，然后存 redis，合理设置过期时间，并利用布隆过滤器过滤\n * 非法请求：记录查询 null 的次数，如果太大，进行封禁，采用指数退避算法\n\n\n# 什么是缓存穿透\n\n缓存穿透最直白的意思就是，我们的业务系统在接收到请求时在缓存中并没有查到数据，从而穿透到了后端数据库里面查数据的过程。\n\n当然，既然使用了缓存，肯定会难免有穿透的发生，正常的少量穿透是对我们业务来说是不会造成任何影响的，因为:\n\n * 毕竟我们的缓存容量有限，不可能去缓存所有数据，当面临较大请求时，查询到未被缓存的数据时，就会发生穿透。\n * 互联网业务的数据访问模型一般是遵循“二八”原则的，即 20% 的数据为热点数据，80% 的数据是非热点不被常访问的数据。\n\n现在既然我们的缓存容量有限，然后 20% 的数据为热点数据，也就是说，我们可以利用有限的容量去缓存那 20% 的数据，其实就是可以保护我们的后端系统的，至于80%非热点不常用的数据发生穿透了，是我们能够接受的。\n\n那究竟什么的缓存穿透会影响到我们的系统呢？是大量的穿透请求超过了我们后端系统的承受范围，比如恶意的穿透攻击，这样的穿透就很有可能把我们的系统给干崩溃。接下来，我们就来基于相关应用场景来解决这种缓存穿透。\n\n\n# 缓存穿透如何解决\n\n在我们app的在线搜索相关系统里面，有个产品product 1 并没有在数据库中进行存储，现在通过cache aside pattern 策略（缓存读写策略，开发必备）查这个product 1 。\n\n那查询一个数据库中本身就没有的数据后面会怎样呢？依照cache aside 策略，读取时，首先会读取缓存，没读到数据就会穿透到读数据库，现在数据库也没有，也就没有数据写回缓存。那么，再来个请求依然如此，更多的请求来还是一样，这样的缓存就没意义了。\n\n通过上面场景我们可以看到，这样的系统面临非正常的穿透是会崩溃掉的，那我们该怎么去解决呢？一般我们对此有两种方案，都是有用的：\n\n * 设置空值\n * 布隆过滤器\n\n\n# 设置空值\n\n通过上面场景我们知道，当有大量恶意的穿透请求到数据库，就会给我们系统带来灾难。\n\n所以，当我们请求数据中没有数据或者因为代码bug带来的异常造成的数据为空，这个时候我们就可以回写一个空值null到缓存中。同时，我们还要给这个null值设置过期时间，因为这个空值不具有实际业务性，而且还占用空间。\n\n可见设置空值是可以阻挡大量穿透请求的，但是如果有大量的获取并不存在数据的穿透请求的话例如恶意攻击，则会浪费缓存空间，如果这种null值过量的话，还会淘汰掉本身缓存存在的数据，这就会使我们的缓存命中率下降。\n\n**生产建议，**在使用设置空值方案时，我们要做好监控，预防缓存空间被过多null值占领造成的缓存空间浪费，如果这种数据量太大，就不再建议使用，那就使用另一种方案，即布隆过滤器。\n\n\n# 布隆过滤器\n\n生产建议：\n\n * 采用多个hash 算法计算hash 值，这样可以减少误判的几率。\n * 布隆过滤器会消耗一定内存空间，根据业务场景进行评估需要多大内存，最后依据公司资源以及成本，看是否能够接受。\n\n\n# 接口限流\n\n根据用户或者 ip 对接口进行限流，对于异常频繁的访问行为，还可以采取黑名单机制，例如将异常 ip 列入黑名单。\n\n后面提到的缓存击穿和雪崩都可以配合接口限流来解决，毕竟这些问题的关键都是有很多请求落到了数据库上造成数据库压力过大。",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"缓存击穿",frontmatter:{title:"缓存击穿",date:"2024-09-14T16:50:56.000Z",permalink:"/pages/1d96b2/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/03.%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF.html",relativePath:"03.经典场景设计/01.热门场景设计/03.缓存击穿.md",key:"v-4c0a6dfc",path:"/pages/1d96b2/",headers:[{level:2,title:"前言：什么是缓存击穿",slug:"前言-什么是缓存击穿",normalizedTitle:"前言：什么是缓存击穿",charIndex:2},{level:2,title:"有哪些解决办法",slug:"有哪些解决办法",normalizedTitle:"有哪些解决办法",charIndex:209},{level:2,title:"双检锁解决缓存击穿",slug:"双检锁解决缓存击穿",normalizedTitle:"双检锁解决缓存击穿",charIndex:367}],headersStr:"前言：什么是缓存击穿 有哪些解决办法 双检锁解决缓存击穿",content:'# 前言：什么是缓存击穿\n\n缓存击穿中，请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期） 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。\n\n\n\n举个例子：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力\n\n\n# 有哪些解决办法\n\n 1. 永不过期（不推荐）：设置热点数据永不过期或者过期时间比较长。\n 2. 提前预热（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。\n 3. 加锁（看情况）：在缓存失效后，通过设置互斥锁确保只有一个请求去查询数据库并更新缓存。\n\n\n# 双检锁解决缓存击穿\n\n> 单例模式的一种实现，双重检测，其中的一层检测是为了提高效率。由于项目中采用了多线程，所以在第一个线程没有从缓存中获取到数据之后，有可能其他线程已经完成了读取数据库写入缓存的操作，也就是说，第一个线程再次得到时间片的时候，就没有必要访问数据库获取数据了。第二层检测是为了避免额外的访库操作。\n\npublic  Student getStudentById(Integer id) {\n    redisTemplate.setKeySerializer(new StringRedisSerializer());\n    //查询缓存\n    Student student = (Student) redisTemplate.opsForValue().get("studentKey");\n    //判断缓存是否为空\n    if (null == student) {\n\n        //双重检测锁实现\n        synchronized (this) {\n\n            student = (Student) redisTemplate.opsForValue().get("studentKey");\n\n            if (null == student) {\n                System.out.println("查询了数据库......");\n                //查询数据库\n                student = studentMapper.selectByPrimaryKey(id);\n                //放入缓存\n                redisTemplate.opsForValue().set("studentKey", student);\n            }\n        }\n    } else {\n        System.out.println("查询了缓存......");\n    }\n    return student;\n}\n',normalizedContent:'# 前言：什么是缓存击穿\n\n缓存击穿中，请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期） 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。\n\n\n\n举个例子：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力\n\n\n# 有哪些解决办法\n\n 1. 永不过期（不推荐）：设置热点数据永不过期或者过期时间比较长。\n 2. 提前预热（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。\n 3. 加锁（看情况）：在缓存失效后，通过设置互斥锁确保只有一个请求去查询数据库并更新缓存。\n\n\n# 双检锁解决缓存击穿\n\n> 单例模式的一种实现，双重检测，其中的一层检测是为了提高效率。由于项目中采用了多线程，所以在第一个线程没有从缓存中获取到数据之后，有可能其他线程已经完成了读取数据库写入缓存的操作，也就是说，第一个线程再次得到时间片的时候，就没有必要访问数据库获取数据了。第二层检测是为了避免额外的访库操作。\n\npublic  student getstudentbyid(integer id) {\n    redistemplate.setkeyserializer(new stringredisserializer());\n    //查询缓存\n    student student = (student) redistemplate.opsforvalue().get("studentkey");\n    //判断缓存是否为空\n    if (null == student) {\n\n        //双重检测锁实现\n        synchronized (this) {\n\n            student = (student) redistemplate.opsforvalue().get("studentkey");\n\n            if (null == student) {\n                system.out.println("查询了数据库......");\n                //查询数据库\n                student = studentmapper.selectbyprimarykey(id);\n                //放入缓存\n                redistemplate.opsforvalue().set("studentkey", student);\n            }\n        }\n    } else {\n        system.out.println("查询了缓存......");\n    }\n    return student;\n}\n',charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"超卖",frontmatter:{title:"超卖",date:"2024-09-14T22:14:25.000Z",permalink:"/pages/8a57f2/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/06.%E8%B6%85%E5%8D%96.html",relativePath:"03.经典场景设计/01.热门场景设计/06.超卖.md",key:"v-cb82a926",path:"/pages/8a57f2/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"实现方案",slug:"实现方案",normalizedTitle:"实现方案",charIndex:96},{level:3,title:"数据库扣减库存",slug:"数据库扣减库存",normalizedTitle:"数据库扣减库存",charIndex:105},{level:3,title:"redis扣减库存",slug:"redis扣减库存",normalizedTitle:"redis扣减库存",charIndex:764},{level:3,title:"lua脚本扣减库存",slug:"lua脚本扣减库存",normalizedTitle:"lua脚本扣减库存",charIndex:2141},{level:3,title:"redis decr + 分布式锁",slug:"redis-decr-分布式锁",normalizedTitle:"redis decr + 分布式锁",charIndex:2879},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:3513}],headersStr:"前言 实现方案 数据库扣减库存 redis扣减库存 lua脚本扣减库存 redis decr + 分布式锁 参考文献",content:'# 前言\n\n超卖问题，简单来说就是卖出的商品数量超出库存数\n\n一般是难点在于秒杀场景下的超卖\n\necho 觉得 在秒杀场景下这个库存是可以不用回退的，因为本就是瞬时的，回退也没有意义\n\n\n# 实现方案\n\n\n# 数据库扣减库存\n\nupdate product set stock=stock-1 where id=123;\n\n\n这种写法对于扣减库存是没有问题的，但如何控制库存不足的情况下，不让用户操作呢？\n\n这就需要在update之前，先查一下库存是否足够了。\n\n伪代码如下：\n\nint stock = mapper.getStockById(123);\nif(stock > 0) {\n  int count = mapper.updateStock(123);\n  if(count > 0) {\n    addOrder(123);\n  }\n}\n\n\n大家有没有发现这段代码的问题？\n\n没错，查询操作和更新操作不是原子性的，会导致在并发的场景下，出现库存超卖的情况。\n\n有人可能会说，这样好办，加把锁，不就搞定了，比如使用synchronized关键字。\n\n确实，可以，但是性能不够好。\n\n还有更优雅的处理方案，即基于数据库的乐观锁，这样会少一次数据库查询，而且能够天然的保证数据操作的原子性。\n\n只需将上面的sql稍微调整一下：\n\nupdate product set stock=stock-1 where id=product and stock > 0;\n\n\n在sql最后加上：stock > 0，就能保证不会出现超卖的情况。\n\n但需要频繁访问数据库，我们都知道数据库连接是非常昂贵的资源。在高并发的场景下，可能会造成系统雪崩。而且，容易出现多个请求，同时竞争行锁的情况，造成相互等待，从而出现死锁的问题。\n\n\n# redis扣减库存\n\nredis的incr方法是原子性的，可以用该方法扣减库存。\n\nboolean exist = redisClient.query(productId,userId);\nif(exist) {\n\treturn -1;\n}\nint stock = redisClient.queryStock(productId);\nif(stock <=0) {\n\treturn 0;\n}\nredisClient.incrby(productId, -1);\nredisClient.add(productId,userId);\nreturn 1;\n\n\n代码流程如下：\n\n 1. 先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。\n 2. 查询库存，如果库存小于等于0，则直接返回0，表示库存不足。\n 3. 如果库存充足，则扣减库存，然后将本次秒杀记录保存起来。然后返回1，表示成功。\n\n估计很多小伙伴，一开始都会按这样的思路写代码。但如果仔细想想会发现，这段代码有问题。\n\n有什么问题呢？\n\n如果在高并发下，有多个请求同时查询库存，当时都大于0。由于查询库存和更新库存非原则操作，则会出现库存为负数的情况，即库存超卖。\n\n当然有人可能会说，加个synchronized不就解决问题？\n\n调整后代码如下：\n\nboolean exist = redisClient.query(productId,userId);\nif(exist) {\n\treturn -1;\n}\nsynchronized(this) {\nint stock = redisClient.queryStock(productId);\nif(stock <=0) {\n\treturn 0;\n}\nredisClient.incrby(productId, -1);\nredisClient.add(productId,userId);\n}\n\nreturn 1;\n\n\n加synchronized确实能解决库存为负数问题，但是这样会导致接口性能急剧下降，每次查询都需要竞争同一把锁，显然不太合理。\n\n为了解决上面的问题，代码优化如下：\n\nboolean exist = redisClient.query(productId,userId);\nif(exist) {\n  return -1;\n}\nif(redisClient.incrby(productId, -1)<0) {\n  return 0;\n}\nredisClient.add(productId,userId);\nreturn 1;\n\n\n该代码主要流程如下：\n\n 1. 先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。\n 2. 扣减库存，判断返回值是否小于0，如果小于0，则直接返回0，表示库存不足。\n 3. 如果扣减库存后，返回值大于或等于0，则将本次秒杀记录保存起来。然后返回1，表示成功。\n\n该方案咋一看，好像没问题。\n\n但如果在高并发场景中，有多个请求同时扣减库存，大多数请求的incrby操作之后，结果都会小于0。\n\n虽说，库存出现负数，不会出现超卖的问题。但由于这里是预减库存，如果负数值负的太多的话，后面万一要回退库存时，就会导致库存不准。\n\n那么，有没有更好的方案呢？\n\n\n# lua脚本扣减库存\n\n我们都知道lua脚本，是能够保证原子性的，它跟redis一起配合使用，能够完美解决上面的问题。\n\nlua脚本有段非常经典的代码：\n\n  StringBuilder lua = new StringBuilder();\n  lua.append("if (redis.call(\'exists\', KEYS[1]) == 1) then");\n  lua.append("    local stock = tonumber(redis.call(\'get\', KEYS[1]));");\n  lua.append("    if (stock == -1) then");\n  lua.append("        return 1;");\n  lua.append("    end;");\n  lua.append("    if (stock > 0) then");\n  lua.append("        redis.call(\'incrby\', KEYS[1], -1);");\n  lua.append("        return stock;");\n  lua.append("    end;");\n  lua.append("    return 0;");\n  lua.append("end;");\n  lua.append("return -1;");\n\n\n该代码的主要流程如下：\n\n 1. 先判断商品id是否存在，如果不存在则直接返回。\n 2. 获取该商品id的库存，判断库存如果是-1，则直接返回，表示不限制库存。\n 3. 如果库存大于0，则扣减库存。\n 4. 如果库存等于0，是直接返回，表示库存不足。\n\n\n# redis decr + 分布式锁\n\n\n\n先用 decr 去扣减库存，然后用分布式锁，锁住当前库存，防止库存回退现象的发生\n\n 1. 在 redis 集群模式下【以我们的场景为例】，incr 请求操作也可能在请求时发生网络抖动超时返回。这个时候incr有可能成功，也有可能失败。可能是请求超时，也可能是请求完的应答超时。那么incr 的值可能就不准。【实际使用中10万次，可能会有10万零1和不足10万】，那么为了这样一个临界状态的可靠性，所以添加 setNx 加锁只有成功和失败。\n 2. setNx 因为是非独占锁，所以key不存在释放。setNx 的key 可以过期时间可以优化为活动的有效期时间为结束。—— 而独占锁，其实你永远也不好把握释放时间，因为秒杀都是瞬态的，释放的晚了活动用户都走了，释放的早了，流程可能还没处理完。\n 3. 对于 setNx 可能还有些时候，集群主从切换，或者活动出问题的时候恢复。如果恢复的 incr 值多了，那么有 setNx 锁拦截后，会更加可靠。\n 4. 关于库存恢复，一般这类抽奖都是瞬态的，且redis集群非常稳定。所以很少有需要恢复库存，如果需要恢复库存，那么是把失败的秒杀incr对应的值的key，加入到待消费队列中。等整体库存消耗后，开始消耗队列库存。\n 5. 这里的锁的颗粒度在于一个用户一个锁的key，所以没有个人释放再需要被让别人抢占的需要，因为这不是独占锁。所以锁的key可以设置活动结束后释放。\n\n\n# 参考文献\n\n面试必考：秒杀系统如何设计？-腾讯云开发者社区-腾讯云 (tencent.com)',normalizedContent:'# 前言\n\n超卖问题，简单来说就是卖出的商品数量超出库存数\n\n一般是难点在于秒杀场景下的超卖\n\necho 觉得 在秒杀场景下这个库存是可以不用回退的，因为本就是瞬时的，回退也没有意义\n\n\n# 实现方案\n\n\n# 数据库扣减库存\n\nupdate product set stock=stock-1 where id=123;\n\n\n这种写法对于扣减库存是没有问题的，但如何控制库存不足的情况下，不让用户操作呢？\n\n这就需要在update之前，先查一下库存是否足够了。\n\n伪代码如下：\n\nint stock = mapper.getstockbyid(123);\nif(stock > 0) {\n  int count = mapper.updatestock(123);\n  if(count > 0) {\n    addorder(123);\n  }\n}\n\n\n大家有没有发现这段代码的问题？\n\n没错，查询操作和更新操作不是原子性的，会导致在并发的场景下，出现库存超卖的情况。\n\n有人可能会说，这样好办，加把锁，不就搞定了，比如使用synchronized关键字。\n\n确实，可以，但是性能不够好。\n\n还有更优雅的处理方案，即基于数据库的乐观锁，这样会少一次数据库查询，而且能够天然的保证数据操作的原子性。\n\n只需将上面的sql稍微调整一下：\n\nupdate product set stock=stock-1 where id=product and stock > 0;\n\n\n在sql最后加上：stock > 0，就能保证不会出现超卖的情况。\n\n但需要频繁访问数据库，我们都知道数据库连接是非常昂贵的资源。在高并发的场景下，可能会造成系统雪崩。而且，容易出现多个请求，同时竞争行锁的情况，造成相互等待，从而出现死锁的问题。\n\n\n# redis扣减库存\n\nredis的incr方法是原子性的，可以用该方法扣减库存。\n\nboolean exist = redisclient.query(productid,userid);\nif(exist) {\n\treturn -1;\n}\nint stock = redisclient.querystock(productid);\nif(stock <=0) {\n\treturn 0;\n}\nredisclient.incrby(productid, -1);\nredisclient.add(productid,userid);\nreturn 1;\n\n\n代码流程如下：\n\n 1. 先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。\n 2. 查询库存，如果库存小于等于0，则直接返回0，表示库存不足。\n 3. 如果库存充足，则扣减库存，然后将本次秒杀记录保存起来。然后返回1，表示成功。\n\n估计很多小伙伴，一开始都会按这样的思路写代码。但如果仔细想想会发现，这段代码有问题。\n\n有什么问题呢？\n\n如果在高并发下，有多个请求同时查询库存，当时都大于0。由于查询库存和更新库存非原则操作，则会出现库存为负数的情况，即库存超卖。\n\n当然有人可能会说，加个synchronized不就解决问题？\n\n调整后代码如下：\n\nboolean exist = redisclient.query(productid,userid);\nif(exist) {\n\treturn -1;\n}\nsynchronized(this) {\nint stock = redisclient.querystock(productid);\nif(stock <=0) {\n\treturn 0;\n}\nredisclient.incrby(productid, -1);\nredisclient.add(productid,userid);\n}\n\nreturn 1;\n\n\n加synchronized确实能解决库存为负数问题，但是这样会导致接口性能急剧下降，每次查询都需要竞争同一把锁，显然不太合理。\n\n为了解决上面的问题，代码优化如下：\n\nboolean exist = redisclient.query(productid,userid);\nif(exist) {\n  return -1;\n}\nif(redisclient.incrby(productid, -1)<0) {\n  return 0;\n}\nredisclient.add(productid,userid);\nreturn 1;\n\n\n该代码主要流程如下：\n\n 1. 先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。\n 2. 扣减库存，判断返回值是否小于0，如果小于0，则直接返回0，表示库存不足。\n 3. 如果扣减库存后，返回值大于或等于0，则将本次秒杀记录保存起来。然后返回1，表示成功。\n\n该方案咋一看，好像没问题。\n\n但如果在高并发场景中，有多个请求同时扣减库存，大多数请求的incrby操作之后，结果都会小于0。\n\n虽说，库存出现负数，不会出现超卖的问题。但由于这里是预减库存，如果负数值负的太多的话，后面万一要回退库存时，就会导致库存不准。\n\n那么，有没有更好的方案呢？\n\n\n# lua脚本扣减库存\n\n我们都知道lua脚本，是能够保证原子性的，它跟redis一起配合使用，能够完美解决上面的问题。\n\nlua脚本有段非常经典的代码：\n\n  stringbuilder lua = new stringbuilder();\n  lua.append("if (redis.call(\'exists\', keys[1]) == 1) then");\n  lua.append("    local stock = tonumber(redis.call(\'get\', keys[1]));");\n  lua.append("    if (stock == -1) then");\n  lua.append("        return 1;");\n  lua.append("    end;");\n  lua.append("    if (stock > 0) then");\n  lua.append("        redis.call(\'incrby\', keys[1], -1);");\n  lua.append("        return stock;");\n  lua.append("    end;");\n  lua.append("    return 0;");\n  lua.append("end;");\n  lua.append("return -1;");\n\n\n该代码的主要流程如下：\n\n 1. 先判断商品id是否存在，如果不存在则直接返回。\n 2. 获取该商品id的库存，判断库存如果是-1，则直接返回，表示不限制库存。\n 3. 如果库存大于0，则扣减库存。\n 4. 如果库存等于0，是直接返回，表示库存不足。\n\n\n# redis decr + 分布式锁\n\n\n\n先用 decr 去扣减库存，然后用分布式锁，锁住当前库存，防止库存回退现象的发生\n\n 1. 在 redis 集群模式下【以我们的场景为例】，incr 请求操作也可能在请求时发生网络抖动超时返回。这个时候incr有可能成功，也有可能失败。可能是请求超时，也可能是请求完的应答超时。那么incr 的值可能就不准。【实际使用中10万次，可能会有10万零1和不足10万】，那么为了这样一个临界状态的可靠性，所以添加 setnx 加锁只有成功和失败。\n 2. setnx 因为是非独占锁，所以key不存在释放。setnx 的key 可以过期时间可以优化为活动的有效期时间为结束。—— 而独占锁，其实你永远也不好把握释放时间，因为秒杀都是瞬态的，释放的晚了活动用户都走了，释放的早了，流程可能还没处理完。\n 3. 对于 setnx 可能还有些时候，集群主从切换，或者活动出问题的时候恢复。如果恢复的 incr 值多了，那么有 setnx 锁拦截后，会更加可靠。\n 4. 关于库存恢复，一般这类抽奖都是瞬态的，且redis集群非常稳定。所以很少有需要恢复库存，如果需要恢复库存，那么是把失败的秒杀incr对应的值的key，加入到待消费队列中。等整体库存消耗后，开始消耗队列库存。\n 5. 这里的锁的颗粒度在于一个用户一个锁的key，所以没有个人释放再需要被让别人抢占的需要，因为这不是独占锁。所以锁的key可以设置活动结束后释放。\n\n\n# 参考文献\n\n面试必考：秒杀系统如何设计？-腾讯云开发者社区-腾讯云 (tencent.com)',charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"多级缓存",frontmatter:{title:"多级缓存",date:"2024-09-14T16:52:24.000Z",permalink:"/pages/51aa8b/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/07.%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98.html",relativePath:"03.经典场景设计/01.热门场景设计/07.多级缓存.md",key:"v-31813d8e",path:"/pages/51aa8b/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"超时&重试",frontmatter:{title:"超时&重试",date:"2024-09-14T16:52:35.000Z",permalink:"/pages/0dfb49/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/08.%E8%B6%85%E6%97%B6&%E9%87%8D%E8%AF%95.html",relativePath:"03.经典场景设计/01.热门场景设计/08.超时&重试.md",key:"v-08ebe39c",path:"/pages/0dfb49/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:35},{level:3,title:"重试的风险",slug:"重试的风险",normalizedTitle:"重试的风险",charIndex:147},{level:3,title:"重试的使用成本",slug:"重试的使用成本",normalizedTitle:"重试的使用成本",charIndex:754},{level:2,title:"重试治理",slug:"重试治理",normalizedTitle:"重试治理",charIndex:1089},{level:3,title:"动态配置",slug:"动态配置",normalizedTitle:"动态配置",charIndex:1191},{level:3,title:"退避策略",slug:"退避策略",normalizedTitle:"退避策略",charIndex:1835},{level:3,title:"防止 retry storm",slug:"防止-retry-storm",normalizedTitle:"防止 retry storm",charIndex:2122},{level:4,title:"限制单点重试",slug:"限制单点重试",normalizedTitle:"限制单点重试",charIndex:2176},{level:4,title:"限制链路重试",slug:"限制链路重试",normalizedTitle:"限制链路重试",charIndex:2562},{level:4,title:"超时处理",slug:"超时处理",normalizedTitle:"超时处理",charIndex:3355},{level:4,title:"超时场景优化",slug:"超时场景优化",normalizedTitle:"超时场景优化",charIndex:4118},{level:4,title:"结合 DDL",slug:"结合-ddl",normalizedTitle:"结合 ddl",charIndex:5186},{level:4,title:"实际的链路放大效应",slug:"实际的链路放大效应",normalizedTitle:"实际的链路放大效应",charIndex:5645},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:6011},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:6196}],headersStr:"前言 重试的风险 重试的使用成本 重试治理 动态配置 退避策略 防止 retry storm 限制单点重试 限制链路重试 超时处理 超时场景优化 结合 DDL 实际的链路放大效应 总结 参考文献",content:"下述是引用字节某大佬的一篇文章，讲的是如何在微服务中进行重试\n\n\n# 前言\n\n在微服务架构中，一个大系统被拆分成多个小服务，小服务之间大量 RPC 调用，经常可能因为网络抖动等原因导致 RPC 调用失败，这时候使用重试机制可以提高请求的最终成功率，减少故障影响，让系统运行更稳定。\n\n\n\n\n# 重试的风险\n\n重试能够提高服务稳定性，但是一般情况下大家都不会轻易去重试，或者说不敢重试，主要是因为重试有放大故障的风险。\n\n首先，重试会加大直接下游的负载。如下图，假设 A 服务调用 B 服务，重试次数设置为 r（包括首次请求），当 B 高负载时很可能调用不成功，这时 A 调用失败重试 B ，B 服务的被调用量快速增大，最坏情况下可能放大到 r 倍，不仅不能请求成功，还可能导致 B 的负载继续升高，甚至直接打挂。\n\n\n\n更可怕的是，重试还会存在链路放大的效应，结合下图说明一下：\n\n\n\n假设现在场景是 Backend A 调用 Backend B，Backend B 调用 DB Frontend，均设置重试次数为 3 。如果 Backend B 调用 DB Frontend，请求 3 次都失败了，这时 Backend B 会给 Backend A 返回失败。但是 Backend A 也有重试的逻辑，Backend A 重试 Backend B 三次，每一次 Backend B 都会请求 DB Frontend 3 次，这样算起来，DB Frontend 就会被请求了 9 次，实际是指数级扩大。假设正常访问量是 n，链路一共有 m 层，每层重试次数为 r，则最后一层受到的访问量最大，为 n * r ^ (m - 1) 。这种指数放大的效应很可怕，可能导致链路上多层都被打挂，整个系统雪崩。\n\n\n# 重试的使用成本\n\n另外使用重试的成本也比较高。之前在字节跳动的内部框架和服务治理平台中都没有支持重试，在一些很需要重试的业务场景下（比如调用一些第三方业务经常失败），业务方可能用简单 for 循环来实现，基本不会考虑重试的放大效应，这样很不安全，公司内部出现过多次因为重试而导致的事故，且出事故的时候还需要修改代码上线才能关闭重试，导致事故恢复也不迅速。\n\n另外也有一些业务使用开源的重试组件，这些组件通常会考虑对直接下游的保护，但不会考虑链路级别的重试放大，另外需要业务方修改 RPC 调用代码才能使用，对业务代码入侵较多，而且也是静态配置，需要修改配置时都必须重新上线。\n\n基于以上的背景，为了让业务方能够灵活安全的使用重试，我们字节跳动直播中台团队设计和实现了一个重试治理组件，具有以下优点：\n\n 1. 能够在链路级别防重试风暴。\n\n 2. 保证易用性，业务接入成本小。\n\n 3. 具有灵活性，能够动态调整配置。\n\n下面介绍具体的实现方案。\n\n\n# 重试治理\n\n\n# 动态配置\n\n如何让业务方简单接入是首先要解决的问题。如果还是普通组件库的方式，依旧免不了要大量入侵用户代码，且很难动态调整。\n\n字节跳动的 Golang 开发框架支持中间件 (Milddleware) 模式，可以注册多个自定义 Middleware 并依次递归调用，通常是用于完成打印日志、上报监控等非业务逻辑，能够有效将业务和非业务代码功能进行解耦。因此我们决定使用 Middleware 的方式来实现重试功能，定义一个 Middleware 并在内部实现对 RPC 的重复调用，把重试的配置信息用字节跳动的分布式配置存储中心存储，这样 Middleware 中能够读取配置中心的配置并进行重试，对用户来说不需要修改调用 RPC 的代码，而只需要在服务中引入一个全局的 Middleware 即可。\n\n如下面的整体架构图所示，我们提供配置的网页和后台，用户能够在专门进行服务治理的页面上很方便的对 RPC 进行配置修改并自动生效，内部的实现逻辑对用户透明，对业务代码无入侵。\n\n\n\n配置的维度按照字节跳动的 RPC 调用特点，选定 [调用方服务，调用方集群，被调用服务， 被调用方法] 为一个元组，按照元组来进行配置。Middleware 中封装了读取配置的方法，在 RPC 调用的时候会自动读取并生效。\n\n这种 Middleware 的方式能够让业务方很容易接入，相对于之前普通组件库的方式要方便很多，并且一次接入以后就具有动态配置的能力，可能很方便地调整或者关闭重试配置。\n\n\n# 退避策略\n\n确定了接入方式以后就可以开始实现重试组件的具体功能，一个重试组件所包含的基本功能中，除了重试次数和总延时这样的基础配置外，还需要有退避策略。\n\n对于一些暂时性的错误，如网络抖动等，可能立即重试还是会失败，通常等待一小会儿再重试的话成功率会较高，并且也可能打散上游重试的时间，较少因为同时都重试而导致的下游瞬间流量高峰。决定等待多久之后再重试的方法叫做退避策略，我们实现了常见的退避策略，如：\n\n * 线性退避：每次等待固定时间后重试。\n\n * 随机退避：在一定范围内随机等待一个时间后重试。\n\n * 指数退避：连续重试时，每次等待时间都是前一次的倍数。\n\n\n# 防止 retry storm\n\n如何安全重试，防止 retry storm 是我们面临的最大的难题。\n\n# 限制单点重试\n\n首先要在单点进行限制，一个服务不能不受限制的重试下游，很容易造成下游被打挂。除了限制用户设定的重试次数上限外，更重要的是限制重试请求的成功率。\n\n实现的方案很简单，基于断路器的思想，限制 请求失败/请求成功 的比率，给重试增加熔断功能。我们采用了常见的滑动窗口的方法来实现，如下图，内存中为每一类 RPC 调用维护一个滑动窗口，比如窗口分 10 个 bucket ，每个 bucket 里面记录了 1s 内 RPC 的请求结果数据（成功、失败）。新的一秒到来时，生成新的 bucket ，并淘汰最早的一个 bucket ，只维持 10s 的数据。在新请求这个 RPC 失败时，根据前 10s 内的 失败/成功 是否超过阈值来判断是否可以重试。默认阈值是 0.1 ，即下游最多承受 1.1 倍的 QPS ，用户可以根据需要自行调整熔断开关和阈值。\n\n\n\n# 限制链路重试\n\n前面说过在多级链路中如果每层都配置重试可能导致调用量指数级扩大，虽然有了重试熔断之后，重试不再是指数增长(每一单节点重试扩大限制了 1.1 倍)，但还是会随着链路的级数增长而扩大调用次数，因此还是需要从链路层面来考虑重试的安全性。\n\n链路层面的防重试风暴的核心是限制每层都发生重试，理想情况下只有最下一层发生重试。Google SRE 中指出了 Google 内部使用特殊错误码的方式来实现：\n\n * 统一约定一个特殊的 status code ，它表示：调用失败，但别重试。\n\n * 任何一级重试失败后，生成该 status code 并返回给上层。\n\n * 上层收到该 status code 后停止对这个下游的重试，并将错误码再传给自己的上层。\n\n这种方式理想情况下只有最下一层发生重试，它的上游收到错误码后都不会重试，链路整体放大倍数也就是 r 倍(单层的重试次数)。但是这种策略依赖于业务方传递错误码，对业务代码有一定入侵，而且通常业务方的代码差异很大，调用 RPC 的方式和场景也各不相同，需要业务方配合进行大量改造，很可能因为漏改等原因导致没有把从下游拿到的错误码传递给上游。\n\n好在字节跳动内部用的 RPC 协议中有扩展字段，我们在 Middleware 中做了很多尝试，封装了错误码处理和传递的逻辑，在 RPC 的 Response 扩展字段中传递错误码标识 nomore_retry ，它告诉上游不要再重试了。Middleware 完成错误码的生成、识别、传递等整个生命周期的管理，不需要业务方修改本身的 RPC 逻辑，错误码的方案对业务来说是透明的。\n\n\n\n在链路中，推进每层都接入重试组件，这样每一层都可以通过识别这个标志位来停止重试，并逐层往上传递，上层也都停止重试，做到链路层面的防护，达到“只有最靠近错误发生的那一层才重试”的效果。\n\n# 超时处理\n\n在测试错误码上传的方案时，我们发现超时的情况可能导致传递错误码的方案失效。\n\n对于 A -> B -> C 的场景，假设 B -> C 超时，B 重试请求 C ，这时候很可能 A -> B 也超时了，所以 A 没有拿到 B 返回的错误码，而是也会重试 B , 这个时候虽然 B 重试 C 且生成了重试失败的错误码，但是却不能再传递给 A 。这种情况下，A 还是会重试 B ，如果链路中每一层都超时，那么还是会出现链路指数扩大的效应。\n\n因此为了处理这种情况，除了下游传递重试错误标志以外，我们还实现了“对重试请求不重试”的方案。\n\n对于重试的请求，我们在 Request 中打上一个特殊的 retry flag ，在上面 A -> B -> C 的链路，当 B 收到 A 的请求时会先读取这个 flag 判断这个请求是不是重试请求，如果是，那它调用 C 即使失败也不会重试；否则调用 C 失败后会重试 C 。同时 B 也会把这个 retry flag 下传，它发出的请求也会有这个标志，它的下游也不会再对这个请求重试。\n\n\n\n这样即使 A 因为超时而拿不到 B 的返回，对 B 发出重试请求后，B 能感知到并且不会对 C 重试，这样 A 最多请求 r 次，B 最多请求 r + r - 1，如果后面还有更下层次的话，C 最多请求 r + r + r - 2 次， 第 i 层最多请求 i * r - (i-1) 次，最坏情况下是倍数增长，不是指数增长了。加上实际还有重试熔断的限制，增长的幅度要小很多。\n\n通过重试熔断来限制单点的放大倍数，通过重试错误标志链路回传的方式来保证只有最下层发生重试，又通过重试请求 flag 链路下传的方式来保证对重试请求不重试，多种控制策略结合，可以有效地较少重试放大效应。\n\n# 超时场景优化\n\n分布式系统中，RPC 请求的结果有三种状态：成功、失败、超时，其中最难处理的就是超时的情况。但是超时往往又是最经常发生的那一个，我们统计了字节跳动直播业务线上一些重要服务的 RPC 错误分布，发现占比最高的就是超时错误，怕什么偏来什么。\n\n在超时重试的场景中，虽然给重试请求添加 retry flag 能防止指数扩大，但是却不能提高请求成功率。如下图，假如 A 和 B 的超时时间都是 1000ms ，当 C 负载很高导致 B 访问 C 超时，这时 B 会重试 C ，但是时间已经超过了 1000ms ，时间 A 这里也超时了并且断开了和 B 的连接，所以 B 这次重试 C 不管是否成功都是无用功，从 A 的视角看，本次请求已经失败了。\n\n\n\n这种情况的本质原因是因为链路上的超时时间设置得不合理，上游和下游的超时时间设置的一样，甚至上游的超时时间比下游还要短。在实际情况中业务一般都没有专门配置过 RPC 的超时时间，所以可能上下游都是默认的超时，时长是一样的。为了应对这种情况，我们需要有一个机制来优化超时情况下的稳定性，并减少无用的重试。\n\n如下图，正常重试的场景是等拿到 Resp1 (或者拿到超时结果) 后再发起第二次请求，整体耗时是 t1 + t2 。我们分析下，service A 在发出去 Req1 之后可能等待很长的时间，比如 1s ，但是这个请求的 pct99 或者 pct999 可能通常只有 100ms 以内，如果超过了 100ms ，有很大概率是这次访问最终会超时，能不能不要傻等，而是提前重试呢？\n\n\n\n基于这种思想，我们引入并实现了 Backup Requests 的方案。如下图，我们预先设定一个阈值 t3（比超时时间小，通常建议是 RPC 请求延时的 pct99 ），当 Req1 发出去后超过 t3 时间都没有返回，那我们直接发起重试请求 Req2 ，这样相当于同时有两个请求运行。然后等待请求返回，只要 Resp1 或者 Resp2 任意一个返回成功的结果，就可以立即结束这次请求，这样整体的耗时就是 t4 ，它表示从第一个请求发出到第一个成功结果返回之间的时间，相比于等待超时后再发出请求，这种机制能大大减少整体延时。\n\n\n\n实际上 Backup Requests 是一种用访问量来换成功率 (或者说低延时) 的思想，当然我们会控制它的访问量增大比率，在发起重试之前，会为第一次的请求记录一次失败，并检查当前失败率是否超过了熔断阈值，这样整体的访问比率还是会在控制之内。\n\n# 结合 DDL\n\nBackup Requests 的思路能在缩短整体请求延时的同时减少一部分的无效请求，但不是所有业务场景下都适合配置 Backup Requests ，因此我们又结合了 DDL 来控制无效重试。\n\nDDL 是“ Deadline Request 调用链超时”的简称，我们知道 TCP/IP 协议中的 TTL 用于判断数据包在网络中的时间是否太长而应被丢弃，DDL 与之类似，它是一种全链路式的调用超时，可以用来判断当前的 RPC 请求是否还需要继续下去。如下图，字节跳动的基础团队已经实现了 DDL 功能，在 RPC 请求调用链中会带上超时时间，并且每经过一层就减去该层处理的时间，如果剩下的时间已经小于等于 0 ，则可以不需要再请求下游，直接返回失败即可。\n\n\n\nDDL 的方式能有效减少对下游的无效调用，我们在重试治理中也结合了 DDL 的数据，在每一次发起重试前都会判断 DDL 的剩余值是否还大于 0 ，如果已经不满足条件了，那也就没必要对下游重试，这样能做到最大限度的减少无用的重试。\n\n# 实际的链路放大效应\n\n之前说的链路指数放大是理想情况下的分析，实际的情况要复杂很多，因为有很多影响因素：\n\n策略         说明\n重试熔断       请求失败 / 成功 > 0.1 时停止重试\n链路上传错误标志   下层重试失败后上传错误标志，上层不再重试\n链路下传重试标志   重试请求特殊标记，下层对重试请求不会重试\nDDL        当剩余时间不够时不再发起重试请求\n框架熔断       微服务框架本身熔断、过载保护等机制也会影响重试效果\n\n各种因素综合下来，最终实际方法情况不是一个简单的计算公式能说明，我们构造了多层调用链路，在线上实际测试和记录了在不同错误类型、不同错误率的情况下使用重试治理组件的效果，发现接入重试治理组件后能够在链路层面有效的控制重试放大倍数，大幅减少重试导致系统雪崩的概率。\n\n\n# 总结\n\n如上所述，基于服务治理的思想我们开发了重试治理的功能，支持动态配置，接入方式基本无需入侵业务代码，并使用多种策略结合的方式在链路层面控制重试放大效应，兼顾易用性、灵活性、安全性，在字节跳动内部已经有包括直播在内的很多服务接入使用并上线验证，对提高服务本身稳定性有良好的效果。目前方案已经被验证并在字节跳动直播等业务推广，后续将为更多的字节跳动业务服务。\n\n\n# 参考文献\n\n如何优雅地重试 (qq.com)",normalizedContent:"下述是引用字节某大佬的一篇文章，讲的是如何在微服务中进行重试\n\n\n# 前言\n\n在微服务架构中，一个大系统被拆分成多个小服务，小服务之间大量 rpc 调用，经常可能因为网络抖动等原因导致 rpc 调用失败，这时候使用重试机制可以提高请求的最终成功率，减少故障影响，让系统运行更稳定。\n\n\n\n\n# 重试的风险\n\n重试能够提高服务稳定性，但是一般情况下大家都不会轻易去重试，或者说不敢重试，主要是因为重试有放大故障的风险。\n\n首先，重试会加大直接下游的负载。如下图，假设 a 服务调用 b 服务，重试次数设置为 r（包括首次请求），当 b 高负载时很可能调用不成功，这时 a 调用失败重试 b ，b 服务的被调用量快速增大，最坏情况下可能放大到 r 倍，不仅不能请求成功，还可能导致 b 的负载继续升高，甚至直接打挂。\n\n\n\n更可怕的是，重试还会存在链路放大的效应，结合下图说明一下：\n\n\n\n假设现在场景是 backend a 调用 backend b，backend b 调用 db frontend，均设置重试次数为 3 。如果 backend b 调用 db frontend，请求 3 次都失败了，这时 backend b 会给 backend a 返回失败。但是 backend a 也有重试的逻辑，backend a 重试 backend b 三次，每一次 backend b 都会请求 db frontend 3 次，这样算起来，db frontend 就会被请求了 9 次，实际是指数级扩大。假设正常访问量是 n，链路一共有 m 层，每层重试次数为 r，则最后一层受到的访问量最大，为 n * r ^ (m - 1) 。这种指数放大的效应很可怕，可能导致链路上多层都被打挂，整个系统雪崩。\n\n\n# 重试的使用成本\n\n另外使用重试的成本也比较高。之前在字节跳动的内部框架和服务治理平台中都没有支持重试，在一些很需要重试的业务场景下（比如调用一些第三方业务经常失败），业务方可能用简单 for 循环来实现，基本不会考虑重试的放大效应，这样很不安全，公司内部出现过多次因为重试而导致的事故，且出事故的时候还需要修改代码上线才能关闭重试，导致事故恢复也不迅速。\n\n另外也有一些业务使用开源的重试组件，这些组件通常会考虑对直接下游的保护，但不会考虑链路级别的重试放大，另外需要业务方修改 rpc 调用代码才能使用，对业务代码入侵较多，而且也是静态配置，需要修改配置时都必须重新上线。\n\n基于以上的背景，为了让业务方能够灵活安全的使用重试，我们字节跳动直播中台团队设计和实现了一个重试治理组件，具有以下优点：\n\n 1. 能够在链路级别防重试风暴。\n\n 2. 保证易用性，业务接入成本小。\n\n 3. 具有灵活性，能够动态调整配置。\n\n下面介绍具体的实现方案。\n\n\n# 重试治理\n\n\n# 动态配置\n\n如何让业务方简单接入是首先要解决的问题。如果还是普通组件库的方式，依旧免不了要大量入侵用户代码，且很难动态调整。\n\n字节跳动的 golang 开发框架支持中间件 (milddleware) 模式，可以注册多个自定义 middleware 并依次递归调用，通常是用于完成打印日志、上报监控等非业务逻辑，能够有效将业务和非业务代码功能进行解耦。因此我们决定使用 middleware 的方式来实现重试功能，定义一个 middleware 并在内部实现对 rpc 的重复调用，把重试的配置信息用字节跳动的分布式配置存储中心存储，这样 middleware 中能够读取配置中心的配置并进行重试，对用户来说不需要修改调用 rpc 的代码，而只需要在服务中引入一个全局的 middleware 即可。\n\n如下面的整体架构图所示，我们提供配置的网页和后台，用户能够在专门进行服务治理的页面上很方便的对 rpc 进行配置修改并自动生效，内部的实现逻辑对用户透明，对业务代码无入侵。\n\n\n\n配置的维度按照字节跳动的 rpc 调用特点，选定 [调用方服务，调用方集群，被调用服务， 被调用方法] 为一个元组，按照元组来进行配置。middleware 中封装了读取配置的方法，在 rpc 调用的时候会自动读取并生效。\n\n这种 middleware 的方式能够让业务方很容易接入，相对于之前普通组件库的方式要方便很多，并且一次接入以后就具有动态配置的能力，可能很方便地调整或者关闭重试配置。\n\n\n# 退避策略\n\n确定了接入方式以后就可以开始实现重试组件的具体功能，一个重试组件所包含的基本功能中，除了重试次数和总延时这样的基础配置外，还需要有退避策略。\n\n对于一些暂时性的错误，如网络抖动等，可能立即重试还是会失败，通常等待一小会儿再重试的话成功率会较高，并且也可能打散上游重试的时间，较少因为同时都重试而导致的下游瞬间流量高峰。决定等待多久之后再重试的方法叫做退避策略，我们实现了常见的退避策略，如：\n\n * 线性退避：每次等待固定时间后重试。\n\n * 随机退避：在一定范围内随机等待一个时间后重试。\n\n * 指数退避：连续重试时，每次等待时间都是前一次的倍数。\n\n\n# 防止 retry storm\n\n如何安全重试，防止 retry storm 是我们面临的最大的难题。\n\n# 限制单点重试\n\n首先要在单点进行限制，一个服务不能不受限制的重试下游，很容易造成下游被打挂。除了限制用户设定的重试次数上限外，更重要的是限制重试请求的成功率。\n\n实现的方案很简单，基于断路器的思想，限制 请求失败/请求成功 的比率，给重试增加熔断功能。我们采用了常见的滑动窗口的方法来实现，如下图，内存中为每一类 rpc 调用维护一个滑动窗口，比如窗口分 10 个 bucket ，每个 bucket 里面记录了 1s 内 rpc 的请求结果数据（成功、失败）。新的一秒到来时，生成新的 bucket ，并淘汰最早的一个 bucket ，只维持 10s 的数据。在新请求这个 rpc 失败时，根据前 10s 内的 失败/成功 是否超过阈值来判断是否可以重试。默认阈值是 0.1 ，即下游最多承受 1.1 倍的 qps ，用户可以根据需要自行调整熔断开关和阈值。\n\n\n\n# 限制链路重试\n\n前面说过在多级链路中如果每层都配置重试可能导致调用量指数级扩大，虽然有了重试熔断之后，重试不再是指数增长(每一单节点重试扩大限制了 1.1 倍)，但还是会随着链路的级数增长而扩大调用次数，因此还是需要从链路层面来考虑重试的安全性。\n\n链路层面的防重试风暴的核心是限制每层都发生重试，理想情况下只有最下一层发生重试。google sre 中指出了 google 内部使用特殊错误码的方式来实现：\n\n * 统一约定一个特殊的 status code ，它表示：调用失败，但别重试。\n\n * 任何一级重试失败后，生成该 status code 并返回给上层。\n\n * 上层收到该 status code 后停止对这个下游的重试，并将错误码再传给自己的上层。\n\n这种方式理想情况下只有最下一层发生重试，它的上游收到错误码后都不会重试，链路整体放大倍数也就是 r 倍(单层的重试次数)。但是这种策略依赖于业务方传递错误码，对业务代码有一定入侵，而且通常业务方的代码差异很大，调用 rpc 的方式和场景也各不相同，需要业务方配合进行大量改造，很可能因为漏改等原因导致没有把从下游拿到的错误码传递给上游。\n\n好在字节跳动内部用的 rpc 协议中有扩展字段，我们在 middleware 中做了很多尝试，封装了错误码处理和传递的逻辑，在 rpc 的 response 扩展字段中传递错误码标识 nomore_retry ，它告诉上游不要再重试了。middleware 完成错误码的生成、识别、传递等整个生命周期的管理，不需要业务方修改本身的 rpc 逻辑，错误码的方案对业务来说是透明的。\n\n\n\n在链路中，推进每层都接入重试组件，这样每一层都可以通过识别这个标志位来停止重试，并逐层往上传递，上层也都停止重试，做到链路层面的防护，达到“只有最靠近错误发生的那一层才重试”的效果。\n\n# 超时处理\n\n在测试错误码上传的方案时，我们发现超时的情况可能导致传递错误码的方案失效。\n\n对于 a -> b -> c 的场景，假设 b -> c 超时，b 重试请求 c ，这时候很可能 a -> b 也超时了，所以 a 没有拿到 b 返回的错误码，而是也会重试 b , 这个时候虽然 b 重试 c 且生成了重试失败的错误码，但是却不能再传递给 a 。这种情况下，a 还是会重试 b ，如果链路中每一层都超时，那么还是会出现链路指数扩大的效应。\n\n因此为了处理这种情况，除了下游传递重试错误标志以外，我们还实现了“对重试请求不重试”的方案。\n\n对于重试的请求，我们在 request 中打上一个特殊的 retry flag ，在上面 a -> b -> c 的链路，当 b 收到 a 的请求时会先读取这个 flag 判断这个请求是不是重试请求，如果是，那它调用 c 即使失败也不会重试；否则调用 c 失败后会重试 c 。同时 b 也会把这个 retry flag 下传，它发出的请求也会有这个标志，它的下游也不会再对这个请求重试。\n\n\n\n这样即使 a 因为超时而拿不到 b 的返回，对 b 发出重试请求后，b 能感知到并且不会对 c 重试，这样 a 最多请求 r 次，b 最多请求 r + r - 1，如果后面还有更下层次的话，c 最多请求 r + r + r - 2 次， 第 i 层最多请求 i * r - (i-1) 次，最坏情况下是倍数增长，不是指数增长了。加上实际还有重试熔断的限制，增长的幅度要小很多。\n\n通过重试熔断来限制单点的放大倍数，通过重试错误标志链路回传的方式来保证只有最下层发生重试，又通过重试请求 flag 链路下传的方式来保证对重试请求不重试，多种控制策略结合，可以有效地较少重试放大效应。\n\n# 超时场景优化\n\n分布式系统中，rpc 请求的结果有三种状态：成功、失败、超时，其中最难处理的就是超时的情况。但是超时往往又是最经常发生的那一个，我们统计了字节跳动直播业务线上一些重要服务的 rpc 错误分布，发现占比最高的就是超时错误，怕什么偏来什么。\n\n在超时重试的场景中，虽然给重试请求添加 retry flag 能防止指数扩大，但是却不能提高请求成功率。如下图，假如 a 和 b 的超时时间都是 1000ms ，当 c 负载很高导致 b 访问 c 超时，这时 b 会重试 c ，但是时间已经超过了 1000ms ，时间 a 这里也超时了并且断开了和 b 的连接，所以 b 这次重试 c 不管是否成功都是无用功，从 a 的视角看，本次请求已经失败了。\n\n\n\n这种情况的本质原因是因为链路上的超时时间设置得不合理，上游和下游的超时时间设置的一样，甚至上游的超时时间比下游还要短。在实际情况中业务一般都没有专门配置过 rpc 的超时时间，所以可能上下游都是默认的超时，时长是一样的。为了应对这种情况，我们需要有一个机制来优化超时情况下的稳定性，并减少无用的重试。\n\n如下图，正常重试的场景是等拿到 resp1 (或者拿到超时结果) 后再发起第二次请求，整体耗时是 t1 + t2 。我们分析下，service a 在发出去 req1 之后可能等待很长的时间，比如 1s ，但是这个请求的 pct99 或者 pct999 可能通常只有 100ms 以内，如果超过了 100ms ，有很大概率是这次访问最终会超时，能不能不要傻等，而是提前重试呢？\n\n\n\n基于这种思想，我们引入并实现了 backup requests 的方案。如下图，我们预先设定一个阈值 t3（比超时时间小，通常建议是 rpc 请求延时的 pct99 ），当 req1 发出去后超过 t3 时间都没有返回，那我们直接发起重试请求 req2 ，这样相当于同时有两个请求运行。然后等待请求返回，只要 resp1 或者 resp2 任意一个返回成功的结果，就可以立即结束这次请求，这样整体的耗时就是 t4 ，它表示从第一个请求发出到第一个成功结果返回之间的时间，相比于等待超时后再发出请求，这种机制能大大减少整体延时。\n\n\n\n实际上 backup requests 是一种用访问量来换成功率 (或者说低延时) 的思想，当然我们会控制它的访问量增大比率，在发起重试之前，会为第一次的请求记录一次失败，并检查当前失败率是否超过了熔断阈值，这样整体的访问比率还是会在控制之内。\n\n# 结合 ddl\n\nbackup requests 的思路能在缩短整体请求延时的同时减少一部分的无效请求，但不是所有业务场景下都适合配置 backup requests ，因此我们又结合了 ddl 来控制无效重试。\n\nddl 是“ deadline request 调用链超时”的简称，我们知道 tcp/ip 协议中的 ttl 用于判断数据包在网络中的时间是否太长而应被丢弃，ddl 与之类似，它是一种全链路式的调用超时，可以用来判断当前的 rpc 请求是否还需要继续下去。如下图，字节跳动的基础团队已经实现了 ddl 功能，在 rpc 请求调用链中会带上超时时间，并且每经过一层就减去该层处理的时间，如果剩下的时间已经小于等于 0 ，则可以不需要再请求下游，直接返回失败即可。\n\n\n\nddl 的方式能有效减少对下游的无效调用，我们在重试治理中也结合了 ddl 的数据，在每一次发起重试前都会判断 ddl 的剩余值是否还大于 0 ，如果已经不满足条件了，那也就没必要对下游重试，这样能做到最大限度的减少无用的重试。\n\n# 实际的链路放大效应\n\n之前说的链路指数放大是理想情况下的分析，实际的情况要复杂很多，因为有很多影响因素：\n\n策略         说明\n重试熔断       请求失败 / 成功 > 0.1 时停止重试\n链路上传错误标志   下层重试失败后上传错误标志，上层不再重试\n链路下传重试标志   重试请求特殊标记，下层对重试请求不会重试\nddl        当剩余时间不够时不再发起重试请求\n框架熔断       微服务框架本身熔断、过载保护等机制也会影响重试效果\n\n各种因素综合下来，最终实际方法情况不是一个简单的计算公式能说明，我们构造了多层调用链路，在线上实际测试和记录了在不同错误类型、不同错误率的情况下使用重试治理组件的效果，发现接入重试治理组件后能够在链路层面有效的控制重试放大倍数，大幅减少重试导致系统雪崩的概率。\n\n\n# 总结\n\n如上所述，基于服务治理的思想我们开发了重试治理的功能，支持动态配置，接入方式基本无需入侵业务代码，并使用多种策略结合的方式在链路层面控制重试放大效应，兼顾易用性、灵活性、安全性，在字节跳动内部已经有包括直播在内的很多服务接入使用并上线验证，对提高服务本身稳定性有良好的效果。目前方案已经被验证并在字节跳动直播等业务推广，后续将为更多的字节跳动业务服务。\n\n\n# 参考文献\n\n如何优雅地重试 (qq.com)",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"幂等&防重",frontmatter:{title:"幂等&防重",date:"2024-09-14T16:52:57.000Z",permalink:"/pages/4fc8cb/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/09.%E5%B9%82%E7%AD%89&%E9%98%B2%E9%87%8D.html",relativePath:"03.经典场景设计/01.热门场景设计/09.幂等&防重.md",key:"v-293e6008",path:"/pages/4fc8cb/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"1. insert 前先 select",slug:"_1-insert-前先-select",normalizedTitle:"1. insert 前先 select",charIndex:653},{level:2,title:"2. 加悲观锁",slug:"_2-加悲观锁",normalizedTitle:"2. 加悲观锁",charIndex:881},{level:2,title:"3. 加乐观锁",slug:"_3-加乐观锁",normalizedTitle:"3. 加乐观锁",charIndex:1715},{level:2,title:"4. 加唯一索引",slug:"_4-加唯一索引",normalizedTitle:"4. 加唯一索引",charIndex:2528},{level:2,title:"5. 建防重表",slug:"_5-建防重表",normalizedTitle:"5. 建防重表",charIndex:3040},{level:2,title:"6. 根据状态机",slug:"_6-根据状态机",normalizedTitle:"6. 根据状态机",charIndex:3397},{level:2,title:"7. 加分布式锁",slug:"_7-加分布式锁",normalizedTitle:"7. 加分布式锁",charIndex:3982},{level:2,title:"8. 获取token",slug:"_8-获取token",normalizedTitle:"8. 获取token",charIndex:4516},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:4950},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:5048}],headersStr:"前言 1. insert 前先 select 2. 加悲观锁 3. 加乐观锁 4. 加唯一索引 5. 建防重表 6. 根据状态机 7. 加分布式锁 8. 获取token 总结 参考文献",content:"# 前言\n\n接口幂等性问题，对于开发人员来说，是一个跟语言无关的公共问题。本文分享了一些解决这类问题非常实用的办法，绝大部分内容我在项目中实践过的，给有需要的小伙伴一个参考。\n\n不知道你有没有遇到过这些场景：\n\n 1. 有时我们在填写某些form表单时，保存按钮不小心快速点了两次，表中竟然产生了两条重复的数据，只是id不一样。\n 2. 我们在项目中为了解决接口超时问题，通常会引入了重试机制。第一次请求接口超时了，请求方没能及时获取返回结果（此时有可能已经成功了），为了避免返回错误的结果（这种情况不可能直接返回失败吧？），于是会对该请求重试几次，这样也会产生重复的数据。\n 3. mq消费者在读取消息时，有时候会读取到重复消息（至于什么原因这里先不说，有兴趣的小伙伴，可以找我私聊），如果处理不好，也会产生重复的数据。\n\n没错，这些都是幂等性问题。\n\n接口幂等性是指用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。\n\n这类问题多发于接口的：\n\n * insert操作，这种情况下多次请求，可能会产生重复数据。\n * update操作，如果只是单纯的更新数据，比如：update user set status=1 where id=1，是没有问题的。如果还有计算，比如：update user set status=status+1 where id=1，这种情况下多次请求，可能会导致数据错误。\n\n那么我们要如何保证接口幂等性？本文将会告诉你答案。\n\n\n# 1. insert 前先 select\n\n通常情况下，在保存数据的接口中，我们为了防止产生重复数据，一般会在insert前，先根据name或code字段select一下数据。如果该数据已存在，则执行update操作，如果不存在，才执行 insert操作。\n\n\n\n该方案可能是我们平时在防止产生重复数据时，使用最多的方案。但是该方案不适用于并发场景，在并发场景中，要配合其他方案一起使用，否则同样会产生重复数据。我在这里提一下，是为了避免大家踩坑。\n\n\n# 2. 加悲观锁\n\n在支付场景中，用户A的账号余额有150元，想转出100元，正常情况下用户A的余额只剩50元。一般情况下，sql是这样的：\n\nupdate user amount = amount-100 where id=123;\n\n\n如果出现多次相同的请求，可能会导致用户A的余额变成负数。这种情况，用户A来可能要哭了。于此同时，系统开发人员可能也要哭了，因为这是很严重的系统bug。\n\n为了解决这个问题，可以加悲观锁，将用户A的那行数据锁住，在同一时刻只允许一个请求获得锁，更新数据，其他的请求则等待。\n\n通常情况下通过如下sql锁住单行数据：\n\nselect * from user id=123 for update;\n\n\n具体流程如下：\n\n\n\n具体步骤：\n\n 1. 多个请求同时根据id查询用户信息。\n 2. 判断余额是否不足100，如果余额不足，则直接返回余额不足。\n 3. 如果余额充足，则通过for update再次查询用户信息，并且尝试获取锁。\n 4. 只有第一个请求能获取到行锁，其余没有获取锁的请求，则等待下一次获取锁的机会。\n 5. 第一个请求获取到锁之后，判断余额是否不足100，如果余额足够，则进行update操作。\n 6. 如果余额不足，说明是重复请求，则直接返回成功。\n\n> 需要特别注意的是：如果使用的是mysql数据库，存储引擎必须用innodb，因为它才支持事务。此外，这里id字段一定要是主键或者唯一索引，不然会锁住整张表。\n\n悲观锁需要在同一个事务操作过程中锁住一行数据，如果事务耗时比较长，会造成大量的请求等待，影响接口性能。此外，每次请求接口很难保证都有相同的返回值，所以不适合幂等性设计场景，但是在防重场景中是可以的使用的。在这里顺便说一下，防重设计 和 幂等设计，其实是有区别的。防重设计主要为了避免产生重复数据，对接口返回没有太多要求。而幂等设计除了避免产生重复数据之外，还要求每次请求都返回一样的结果。\n\n\n# 3. 加乐观锁\n\n既然悲观锁有性能问题，为了提升接口性能，我们可以使用乐观锁。需要在表中增加一个timestamp或者version字段，这里以version字段为例。\n\n在更新数据之前先查询一下数据：\n\nselect id,amount,version from user id=123;\n\n\n如果数据存在，假设查到的version等于1，再使用id和version字段作为查询条件更新数据：\n\nupdate user set amount=amount+100,version=version+1\nwhere id=123 and version=1;\n\n\n更新数据的同时version+1，然后判断本次update操作的影响行数，如果大于0，则说明本次更新成功，如果等于0，则说明本次更新没有让数据变更。\n\n由于第一次请求version等于1是可以成功的，操作成功后version变成2了。这时如果并发的请求过来，再执行相同的sql：\n\nupdate user set amount=amount+100,version=version+1\nwhere id=123 and version=1;\n\n\n该update操作不会真正更新数据，最终sql的执行结果影响行数是0，因为version已经变成2了，where中的version=1肯定无法满足条件。但为了保证接口幂等性，接口可以直接返回成功，因为version值已经修改了，那么前面必定已经成功过一次，后面都是重复的请求。\n\n具体流程如下：\n\n\n\n具体步骤：\n\n 1. 先根据id查询用户信息，包含version字段\n 2. 根据id和version字段值作为where条件的参数，更新用户信息，同时version+1\n 3. 判断操作影响行数，如果影响1行，则说明是一次请求，可以做其他数据操作。\n 4. 如果影响0行，说明是重复请求，则直接返回成功。\n\n\n# 4. 加唯一索引\n\n绝大数情况下，为了防止重复数据的产生，我们都会在表中加唯一索引，这是一个非常简单，并且有效的方案。\n\nalter table `order` add UNIQUE KEY `un_code` (`code`);\n\n\n加了唯一索引之后，第一次请求数据可以插入成功。但后面的相同请求，插入数据时会报Duplicate entry '002' for key 'order.un_code异常，表示唯一索引有冲突。\n\n虽说抛异常对数据来说没有影响，不会造成错误数据。但是为了保证接口幂等性，我们需要对该异常进行捕获，然后返回成功。\n\n如果是java程序需要捕获：DuplicateKeyException异常，如果使用了spring框架还需要捕获：MySQLIntegrityConstraintViolationException异常。\n\n具体流程图如下：\n\n\n\n具体步骤：\n\n 1. 用户通过浏览器发起请求，服务端收集数据。\n 2. 将该数据插入mysql\n 3. 判断是否执行成功，如果成功，则操作其他数据（可能还有其他的业务逻辑）。\n 4. 如果执行失败，捕获唯一索引冲突异常，直接返回成功。\n\n\n# 5. 建防重表\n\n有时候表中并非所有的场景都不允许产生重复的数据，只有某些特定场景才不允许。这时候，直接在表中加唯一索引，显然是不太合适的。\n\n针对这种情况，我们可以通过建防重表来解决问题。\n\n该表可以只包含两个字段：id 和 唯一索引，唯一索引可以是多个字段比如：name、code等组合起来的唯一标识，例如：susan_0001。\n\n具体流程图如下：\n\n\n\n具体步骤：\n\n 1. 用户通过浏览器发起请求，服务端收集数据。\n 2. 将该数据插入mysql防重表\n 3. 判断是否执行成功，如果成功，则做mysql其他的数据操作（可能还有其他的业务逻辑）。\n 4. 如果执行失败，捕获唯一索引冲突异常，直接返回成功。\n\n> 需要特别注意的是：防重表和业务表必须在同一个数据库中，并且操作要在同一个事务中。\n\n\n# 6. 根据状态机\n\n很多时候业务表是有状态的，比如订单表中有：1-下单、2-已支付、3-完成、4-撤销等状态。如果这些状态的值是有规律的，按照业务节点正好是从小到大，我们就能通过它来保证接口的幂等性。\n\n假如id=123的订单状态是已支付，现在要变成完成状态。\n\nupdate `order` set status=3 where id=123 and status=2;\n\n\n第一次请求时，该订单的状态是已支付，值是2，所以该update语句可以正常更新数据，sql执行结果的影响行数是1，订单状态变成了3。\n\n后面有相同的请求过来，再执行相同的sql时，由于订单状态变成了3，再用status=2作为条件，无法查询出需要更新的数据，所以最终sql执行结果的影响行数是0，即不会真正的更新数据。但为了保证接口幂等性，影响行数是0时，接口也可以直接返回成功。\n\n具体流程图如下：\n\n\n\n具体步骤：\n\n 1. 用户通过浏览器发起请求，服务端收集数据。\n 2. 根据id和当前状态作为条件，更新成下一个状态\n 3. 判断操作影响行数，如果影响了1行，说明当前操作成功，可以进行其他数据操作。\n 4. 如果影响了0行，说明是重复请求，直接返回成功。\n\n> 主要特别注意的是，该方案仅限于要更新的表有状态字段，并且刚好要更新状态字段的这种特殊情况，并非所有场景都适用。\n\n\n# 7. 加分布式锁\n\n其实前面介绍过的加唯一索引或者加防重表，本质是使用了数据库的分布式锁，也属于分布式锁的一种。但由于数据库分布式锁的性能不太好，我们可以改用：redis或zookeeper。\n\n鉴于现在很多公司分布式配置中心改用apollo或nacos，已经很少用zookeeper了，我们以redis为例介绍分布式锁。\n\n目前主要有三种方式实现redis的分布式锁：\n\n 1. setNx命令\n 2. set命令\n 3. Redission框架\n\n每种方案各有利弊，具体实现细节我就不说了，有兴趣的朋友可以加我微信找我私聊。\n\n具体流程图如下：\n\n\n\n具体步骤：\n\n 1. 用户通过浏览器发起请求，服务端会收集数据，并且生成订单号code作为唯一业务字段。\n 2. 使用redis的set命令，将该订单code设置到redis中，同时设置超时时间。\n 3. 判断是否设置成功，如果设置成功，说明是第一次请求，则进行数据操作。\n 4. 如果设置失败，说明是重复请求，则直接返回成功。\n\n> 需要特别注意的是：分布式锁一定要设置一个合理的过期时间，如果设置过短，无法有效的防止重复请求。如果设置过长，可能会浪费redis的存储空间，需要根据实际业务情况而定。\n\n\n# 8. 获取token\n\n除了上述方案之外，还有最后一种使用token的方案。该方案跟之前的所有方案都有点不一样，需要两次请求才能完成一次业务操作。\n\n 1. 第一次请求获取token\n 2. 第二次请求带着这个token，完成业务操作。\n\n具体流程图如下：\n\n第一步，先获取token。\n\n\n\n第二步，做具体业务操作。\n\n\n\n具体步骤：\n\n 1. 用户访问页面时，浏览器自动发起获取token请求。\n 2. 服务端生成token，保存到redis中，然后返回给浏览器。\n 3. 用户通过浏览器发起请求时，携带该token。\n 4. 在redis中查询该token是否存在，如果不存在，说明是第一次请求，做则后续的数据操作。\n 5. 如果存在，说明是重复请求，则直接返回成功。\n 6. 在redis中token会在过期时间之后，被自动删除。\n\n以上方案是针对幂等设计的。\n\n如果是防重设计，流程图要改改：\n\n\n\n> 需要特别注意的是：token必须是全局唯一的\n\n\n# 总结\n\n 1. insert 前先 select\n 2. 加悲观锁\n 3. 加乐观锁\n 4. 加唯一索引\n 5. 建防重表\n 6. 根据状态机\n 7. 加分布式锁\n 8. 获取token\n\n\n# 参考文献\n\n高并发下如何保证接口的幂等性？ - 苏三说技术 - 博客园 (cnblogs.com)",normalizedContent:"# 前言\n\n接口幂等性问题，对于开发人员来说，是一个跟语言无关的公共问题。本文分享了一些解决这类问题非常实用的办法，绝大部分内容我在项目中实践过的，给有需要的小伙伴一个参考。\n\n不知道你有没有遇到过这些场景：\n\n 1. 有时我们在填写某些form表单时，保存按钮不小心快速点了两次，表中竟然产生了两条重复的数据，只是id不一样。\n 2. 我们在项目中为了解决接口超时问题，通常会引入了重试机制。第一次请求接口超时了，请求方没能及时获取返回结果（此时有可能已经成功了），为了避免返回错误的结果（这种情况不可能直接返回失败吧？），于是会对该请求重试几次，这样也会产生重复的数据。\n 3. mq消费者在读取消息时，有时候会读取到重复消息（至于什么原因这里先不说，有兴趣的小伙伴，可以找我私聊），如果处理不好，也会产生重复的数据。\n\n没错，这些都是幂等性问题。\n\n接口幂等性是指用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。\n\n这类问题多发于接口的：\n\n * insert操作，这种情况下多次请求，可能会产生重复数据。\n * update操作，如果只是单纯的更新数据，比如：update user set status=1 where id=1，是没有问题的。如果还有计算，比如：update user set status=status+1 where id=1，这种情况下多次请求，可能会导致数据错误。\n\n那么我们要如何保证接口幂等性？本文将会告诉你答案。\n\n\n# 1. insert 前先 select\n\n通常情况下，在保存数据的接口中，我们为了防止产生重复数据，一般会在insert前，先根据name或code字段select一下数据。如果该数据已存在，则执行update操作，如果不存在，才执行 insert操作。\n\n\n\n该方案可能是我们平时在防止产生重复数据时，使用最多的方案。但是该方案不适用于并发场景，在并发场景中，要配合其他方案一起使用，否则同样会产生重复数据。我在这里提一下，是为了避免大家踩坑。\n\n\n# 2. 加悲观锁\n\n在支付场景中，用户a的账号余额有150元，想转出100元，正常情况下用户a的余额只剩50元。一般情况下，sql是这样的：\n\nupdate user amount = amount-100 where id=123;\n\n\n如果出现多次相同的请求，可能会导致用户a的余额变成负数。这种情况，用户a来可能要哭了。于此同时，系统开发人员可能也要哭了，因为这是很严重的系统bug。\n\n为了解决这个问题，可以加悲观锁，将用户a的那行数据锁住，在同一时刻只允许一个请求获得锁，更新数据，其他的请求则等待。\n\n通常情况下通过如下sql锁住单行数据：\n\nselect * from user id=123 for update;\n\n\n具体流程如下：\n\n\n\n具体步骤：\n\n 1. 多个请求同时根据id查询用户信息。\n 2. 判断余额是否不足100，如果余额不足，则直接返回余额不足。\n 3. 如果余额充足，则通过for update再次查询用户信息，并且尝试获取锁。\n 4. 只有第一个请求能获取到行锁，其余没有获取锁的请求，则等待下一次获取锁的机会。\n 5. 第一个请求获取到锁之后，判断余额是否不足100，如果余额足够，则进行update操作。\n 6. 如果余额不足，说明是重复请求，则直接返回成功。\n\n> 需要特别注意的是：如果使用的是mysql数据库，存储引擎必须用innodb，因为它才支持事务。此外，这里id字段一定要是主键或者唯一索引，不然会锁住整张表。\n\n悲观锁需要在同一个事务操作过程中锁住一行数据，如果事务耗时比较长，会造成大量的请求等待，影响接口性能。此外，每次请求接口很难保证都有相同的返回值，所以不适合幂等性设计场景，但是在防重场景中是可以的使用的。在这里顺便说一下，防重设计 和 幂等设计，其实是有区别的。防重设计主要为了避免产生重复数据，对接口返回没有太多要求。而幂等设计除了避免产生重复数据之外，还要求每次请求都返回一样的结果。\n\n\n# 3. 加乐观锁\n\n既然悲观锁有性能问题，为了提升接口性能，我们可以使用乐观锁。需要在表中增加一个timestamp或者version字段，这里以version字段为例。\n\n在更新数据之前先查询一下数据：\n\nselect id,amount,version from user id=123;\n\n\n如果数据存在，假设查到的version等于1，再使用id和version字段作为查询条件更新数据：\n\nupdate user set amount=amount+100,version=version+1\nwhere id=123 and version=1;\n\n\n更新数据的同时version+1，然后判断本次update操作的影响行数，如果大于0，则说明本次更新成功，如果等于0，则说明本次更新没有让数据变更。\n\n由于第一次请求version等于1是可以成功的，操作成功后version变成2了。这时如果并发的请求过来，再执行相同的sql：\n\nupdate user set amount=amount+100,version=version+1\nwhere id=123 and version=1;\n\n\n该update操作不会真正更新数据，最终sql的执行结果影响行数是0，因为version已经变成2了，where中的version=1肯定无法满足条件。但为了保证接口幂等性，接口可以直接返回成功，因为version值已经修改了，那么前面必定已经成功过一次，后面都是重复的请求。\n\n具体流程如下：\n\n\n\n具体步骤：\n\n 1. 先根据id查询用户信息，包含version字段\n 2. 根据id和version字段值作为where条件的参数，更新用户信息，同时version+1\n 3. 判断操作影响行数，如果影响1行，则说明是一次请求，可以做其他数据操作。\n 4. 如果影响0行，说明是重复请求，则直接返回成功。\n\n\n# 4. 加唯一索引\n\n绝大数情况下，为了防止重复数据的产生，我们都会在表中加唯一索引，这是一个非常简单，并且有效的方案。\n\nalter table `order` add unique key `un_code` (`code`);\n\n\n加了唯一索引之后，第一次请求数据可以插入成功。但后面的相同请求，插入数据时会报duplicate entry '002' for key 'order.un_code异常，表示唯一索引有冲突。\n\n虽说抛异常对数据来说没有影响，不会造成错误数据。但是为了保证接口幂等性，我们需要对该异常进行捕获，然后返回成功。\n\n如果是java程序需要捕获：duplicatekeyexception异常，如果使用了spring框架还需要捕获：mysqlintegrityconstraintviolationexception异常。\n\n具体流程图如下：\n\n\n\n具体步骤：\n\n 1. 用户通过浏览器发起请求，服务端收集数据。\n 2. 将该数据插入mysql\n 3. 判断是否执行成功，如果成功，则操作其他数据（可能还有其他的业务逻辑）。\n 4. 如果执行失败，捕获唯一索引冲突异常，直接返回成功。\n\n\n# 5. 建防重表\n\n有时候表中并非所有的场景都不允许产生重复的数据，只有某些特定场景才不允许。这时候，直接在表中加唯一索引，显然是不太合适的。\n\n针对这种情况，我们可以通过建防重表来解决问题。\n\n该表可以只包含两个字段：id 和 唯一索引，唯一索引可以是多个字段比如：name、code等组合起来的唯一标识，例如：susan_0001。\n\n具体流程图如下：\n\n\n\n具体步骤：\n\n 1. 用户通过浏览器发起请求，服务端收集数据。\n 2. 将该数据插入mysql防重表\n 3. 判断是否执行成功，如果成功，则做mysql其他的数据操作（可能还有其他的业务逻辑）。\n 4. 如果执行失败，捕获唯一索引冲突异常，直接返回成功。\n\n> 需要特别注意的是：防重表和业务表必须在同一个数据库中，并且操作要在同一个事务中。\n\n\n# 6. 根据状态机\n\n很多时候业务表是有状态的，比如订单表中有：1-下单、2-已支付、3-完成、4-撤销等状态。如果这些状态的值是有规律的，按照业务节点正好是从小到大，我们就能通过它来保证接口的幂等性。\n\n假如id=123的订单状态是已支付，现在要变成完成状态。\n\nupdate `order` set status=3 where id=123 and status=2;\n\n\n第一次请求时，该订单的状态是已支付，值是2，所以该update语句可以正常更新数据，sql执行结果的影响行数是1，订单状态变成了3。\n\n后面有相同的请求过来，再执行相同的sql时，由于订单状态变成了3，再用status=2作为条件，无法查询出需要更新的数据，所以最终sql执行结果的影响行数是0，即不会真正的更新数据。但为了保证接口幂等性，影响行数是0时，接口也可以直接返回成功。\n\n具体流程图如下：\n\n\n\n具体步骤：\n\n 1. 用户通过浏览器发起请求，服务端收集数据。\n 2. 根据id和当前状态作为条件，更新成下一个状态\n 3. 判断操作影响行数，如果影响了1行，说明当前操作成功，可以进行其他数据操作。\n 4. 如果影响了0行，说明是重复请求，直接返回成功。\n\n> 主要特别注意的是，该方案仅限于要更新的表有状态字段，并且刚好要更新状态字段的这种特殊情况，并非所有场景都适用。\n\n\n# 7. 加分布式锁\n\n其实前面介绍过的加唯一索引或者加防重表，本质是使用了数据库的分布式锁，也属于分布式锁的一种。但由于数据库分布式锁的性能不太好，我们可以改用：redis或zookeeper。\n\n鉴于现在很多公司分布式配置中心改用apollo或nacos，已经很少用zookeeper了，我们以redis为例介绍分布式锁。\n\n目前主要有三种方式实现redis的分布式锁：\n\n 1. setnx命令\n 2. set命令\n 3. redission框架\n\n每种方案各有利弊，具体实现细节我就不说了，有兴趣的朋友可以加我微信找我私聊。\n\n具体流程图如下：\n\n\n\n具体步骤：\n\n 1. 用户通过浏览器发起请求，服务端会收集数据，并且生成订单号code作为唯一业务字段。\n 2. 使用redis的set命令，将该订单code设置到redis中，同时设置超时时间。\n 3. 判断是否设置成功，如果设置成功，说明是第一次请求，则进行数据操作。\n 4. 如果设置失败，说明是重复请求，则直接返回成功。\n\n> 需要特别注意的是：分布式锁一定要设置一个合理的过期时间，如果设置过短，无法有效的防止重复请求。如果设置过长，可能会浪费redis的存储空间，需要根据实际业务情况而定。\n\n\n# 8. 获取token\n\n除了上述方案之外，还有最后一种使用token的方案。该方案跟之前的所有方案都有点不一样，需要两次请求才能完成一次业务操作。\n\n 1. 第一次请求获取token\n 2. 第二次请求带着这个token，完成业务操作。\n\n具体流程图如下：\n\n第一步，先获取token。\n\n\n\n第二步，做具体业务操作。\n\n\n\n具体步骤：\n\n 1. 用户访问页面时，浏览器自动发起获取token请求。\n 2. 服务端生成token，保存到redis中，然后返回给浏览器。\n 3. 用户通过浏览器发起请求时，携带该token。\n 4. 在redis中查询该token是否存在，如果不存在，说明是第一次请求，做则后续的数据操作。\n 5. 如果存在，说明是重复请求，则直接返回成功。\n 6. 在redis中token会在过期时间之后，被自动删除。\n\n以上方案是针对幂等设计的。\n\n如果是防重设计，流程图要改改：\n\n\n\n> 需要特别注意的是：token必须是全局唯一的\n\n\n# 总结\n\n 1. insert 前先 select\n 2. 加悲观锁\n 3. 加乐观锁\n 4. 加唯一索引\n 5. 建防重表\n 6. 根据状态机\n 7. 加分布式锁\n 8. 获取token\n\n\n# 参考文献\n\n高并发下如何保证接口的幂等性？ - 苏三说技术 - 博客园 (cnblogs.com)",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"任务补偿",frontmatter:{title:"任务补偿",date:"2024-09-14T16:51:13.000Z",permalink:"/pages/24abe0/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/04.%E4%BB%BB%E5%8A%A1%E8%A1%A5%E5%81%BF.html",relativePath:"03.经典场景设计/01.热门场景设计/04.任务补偿.md",key:"v-bc60cd96",path:"/pages/24abe0/",headers:[{level:2,title:"前言：补偿机制的意义？",slug:"前言-补偿机制的意义",normalizedTitle:"前言：补偿机制的意义？",charIndex:2},{level:2,title:"补偿 该怎么做？",slug:"补偿-该怎么做",normalizedTitle:"补偿 该怎么做？",charIndex:726},{level:3,title:"回滚",slug:"回滚",normalizedTitle:"回滚",charIndex:771},{level:3,title:"重试",slug:"重试",normalizedTitle:"重试",charIndex:318},{level:2,title:"重试 的最佳实践",slug:"重试-的最佳实践",normalizedTitle:"重试 的最佳实践",charIndex:3585},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:4108},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:4244}],headersStr:"前言：补偿机制的意义？ 补偿 该怎么做？ 回滚 重试 重试 的最佳实践 总结 参考文献",content:"# 前言：补偿机制的意义？\n\n以电商的购物场景为例：\n\n客户端 ----\x3e购物车微服务 ----\x3e订单微服务 ----\x3e 支付微服务。\n\n这种调用链非常普遍。\n\n那么为什么需要考虑补偿机制呢？\n\n正如之前几篇文章所说，一次跨机器的通信可能会经过DNS 服务，网卡、交换机、路由器、负载均衡等设备，这些设备都不一定是一直稳定的，在数据传输的整个过程中，只要任意一个环节出错，都会导致问题的产生。\n\n而在分布式场景中，一个完整的业务又是由多次跨机器通信组成的，所以产生问题的概率成倍数增加。\n\n但是，这些问题并不完全代表真正的系统无法处理请求，所以我们应当尽可能的自动消化掉这些异常。\n\n可能你会问，之前也看到过「补偿」和「事务补偿」或者「重试」，它们之间的关系是什么？\n\n你其实可以不用太纠结这些名字，从目的来说都是一样的。就是一旦某个操作发生了异常，如何通过内部机制将这个异常产生的「不一致」状态消除掉。\n\n> 在 echo 看来，不管用什么方式，只要通过额外的方式解决了问题都可以理解为是「补偿」，所以「事务补偿」和「重试」都是「补偿」的子集。前者是一个逆向操作，而后者则是一个正向操作。\n\n只是从结果来看，两者的意义不同。「事务补偿」意味着“放弃”，当前操作必然会失败。\n\n事务补偿\n\n\n\n「重试」则还有处理成功的机会。这两种方式分别适用于不同的场景。\n\n重试\n\n\n\n因为「补偿」已经是一个额外流程了，既然能够走这个额外流程，说明时效性并不是第一考虑的因素，所以做补偿的核心要点是：宁可慢，不可错。\n\n因此，不要草率的就确定了补偿的实施方案，需要谨慎的评估。虽说错误无法100%避免，但是抱着这样的一个心态或多或少可以减少一些错误的发生。\n\n\n# 补偿 该怎么做？\n\n做「补偿」的主流方式就前面提到的「事务补偿」和「重试」，以下会被称作「回滚」和「重试」。\n\n我们先来聊聊「回滚」。相比「重试」，它逻辑上更简单一些。\n\n\n# 回滚\n\necho 将回滚分为2种模式，一种叫「显式回滚」（调用逆向接口），一种叫「隐式回滚」（无需调用逆向接口）。\n\n最常见的就是「显式回滚」。这个方案无非就是做2个事情：\n\n首先要确定失败的步骤和状态，从而确定需要回滚的范围。一个业务的流程，往往在设计之初就制定好了，所以确定回滚的范围比较容易。但这里唯一需要注意的一点就是：如果在一个业务处理中涉及到的服务并不是都提供了「回滚接口」，那么在编排服务时应该把提供「回滚接口」的服务放在前面，这样当后面的工作服务错误时还有机会「回滚」。\n\n其次要能提供「回滚」操作使用到的业务数据。「回滚」时提供的数据越多，越有益于程序的健壮性。因为程序可以在收到「回滚」操作的时候可以做业务的检查，比如检查账户是否相等，金额是否一致等等。\n\n由于这个中间状态的数据结构和数据大小并不固定，所以echo建议你在实现这点的时候可以将相关的数据序列化成一个json，然后存放到一个nosql类型的存储中。\n\n「隐式回滚」相对来说运用场景比较少。它意味着这个回滚动作你不需要进行额外处理，下游服务内部有类似“预占”并且“超时失效”的机制的。例如：\n\n电商场景中，会将订单中的商品先预占库存，等待用户在 15 分钟内支付。如果没有收到用户的支付，则释放库存。\n\n下面聊聊可以有很多玩法，也更容易陷入坑里的「重试」。\n\n\n# 重试\n\n「重试」最大的好处在于，业务系统可以不需要提供「逆向接口」，这是一个对长期开发成本特别大的利好，毕竟业务是天天在变的。所以，在可能的情况下，应该优先考虑使用「重试」。\n\n不过，相比「回滚」来说「重试」的适用场景更少一些，所以我们第一步首先要判断，当前场景是否适合「重试」。比如：\n\n * 下游系统返回「请求超时」、「被限流中」等临时状态的时候，我们可以考虑重试\n * 而如果是返回“余额不足”、“无权限”等明确无法继续的业务性错误的时候就不需要重试了\n * 一些中间件或者rpc框架中返回Http503、404等没有何时恢复的预期的时候，也不需要重试\n\n如果确定要进行「重试」，我们还需要选定一个合适的「重试策略」。主流的「重试策略」主要是以下几种。\n\n策略1.立即重试。有时故障是候暂时性，可能是因网络数据包冲突或硬件组件流量高峰等事件造成的。在此情况下，适合立即重试操作。不过，立即重试次数不应超过一次，如果立即重试失败，应改用其它的策略。\n\n策略2.固定间隔。应用程序每次尝试的间隔时间相同。 这个好理解，例如，固定每 3 秒重试操作。（以下所有示例代码中的具体的数字仅供参考。）\n\n策略1和策略2多用于前端系统的交互式操作中。\n\n策略3.增量间隔。每一次的重试间隔时间增量递增。比如，第一次0秒、第二次3秒、第三次6秒，9、12、15这样。\n\nreturn (retryCount - 1) * incrementInterval;\n\n\n使得失败次数越多的重试请求优先级排到越后面，给新进入的重试请求让道。\n\n策略4.指数间隔。每一次的重试间隔呈指数级增加。和增量间隔“殊途同归”，都是想让失败次数越多的重试请求优先级排到越后面，只不过这个方案的增长幅度更大一些。\n\nreturn 2 ^ retryCount;\n\n\n策略5.全抖动。在递增的基础上，增加随机性（可以把其中的指数增长部分替换成增量增长。）。适用于将某一时刻集中产生的大量重试请求进行压力分散的场景。\n\nreturn random(0 , 2 ^ retryCount);\n\n\n策略6.等抖动。在「指数间隔」和「全抖动」之间寻求一个中庸的方案，降低随机性的作用。适用场景和「全抖动」一样。\n\nvar baseNum = 2 ^ retryCount;return baseNum + random(0 , baseNum);\n\n\n3、4、5、6策略的表现情况大致是这样。(x轴为重试次数)\n\n\n\n为什么说「重试」有坑呢？\n\n正如前面聊到的那样，出于对开发成本考虑，你在做「重试」的时候可能是复用的常规调用的接口。那么此时就不得不提一个「幂等性」问题。\n\n如果实现「重试」选用的技术方案不能100%确保不会重复发起重试，那么「幂等性」问题是一个必须要考虑的问题。哪怕技术方案可以确保100%不会重复发起重试，出于对意外情况的考量，尽量也考虑一下「幂等性」问题。\n\n**幂等性：**不管对程序发起几次重复调用，程序表现的状态（所有相关的数据变化）与调用一次的结果是一致的话，就是保证了幂等性。\n\n这意味着可以根据需要重复或重试操作，而不会导致意外的影响。对于非幂等操作，算法可能必须跟踪操作是否已经执行。\n\n所以，一旦某个功能支持「重试」，那么整个链路上的接口都需要考虑幂等性问题，不能因为服务的多次调用而导致业务数据的累计增加或减少。\n\n满足「幂等性」其实就是需要想办法识别重复的请求，并且将其过滤掉。思路就是：\n\n 1. 给每个请求定义一个唯一标识。\n 2. 在进行「重试」的时候判断这个请求是否已经被执行或者正在被执行，如果是则抛弃该请求。\n\n**第1点，**我们可以使用一个全局唯一id生成器或者生成服务（可以扩展阅读，分布式系统中的必备良药 —— 全局唯一单据号生成）。 或者简单粗暴一些，使用官方类库自带的Guid、uuid之类的也行。\n\n然后通过rpc框架在发起调用的客户端中，对每个请求增加一个唯一标识的字段进行赋值。\n\n**第2点，**我们可以在服务端通过Aop的方式切入到实际的处理逻辑代码之前和之后，一起配合做验证。\n\n\n\n大致的代码思路如下。\n\n【方法执行前】if(isExistLog(requestId)){  //1.判断请求是否已被接收过。  对应序号3\n    var lastResult = getLastResult();  //2.获取用于判断之前的请求是否已经处理完成。  对应序号4\n    if(lastResult == null){  \n        var result = waitResult();  //挂起等待处理完成\n        return result;\n    }\n    else{\n        return lastResult;\n    }  \n}\nelse{\n    log(requestId);  //3.记录该请求已接收\n}\n\n//do something..【方法执行后】\n\nlogResult(requestId, result);  //4.将结果也更新一下。\n\n\n如果「补偿」这个工作是通过MQ来进行的话，这事就可以直接在对接MQ所封装的SDK中做。在生产端赋值全局唯一标识，在消费端通过唯一标识消重。\n\n\n# 重试 的最佳实践\n\n再聊一些 echo 积累的最佳实践吧，都是针对「重试」的，的确这也是工作中最常用的方案。\n\n「重试」特别适合在高负载情况下被「降级」，当然也应当受到「限流」和「熔断」机制的影响。当「重试」的“矛”与「限流」和「熔断」的“盾”搭配使用，效果才是最好。\n\n需要衡量增加补偿机制的投入产出比。一些不是很重要的问题时，应该「快速失败」而不是「重试」。\n\n过度积极的重试策略（例如间隔太短或重试次数过多）会对下游服务造成不利影响，这点一定要注意。\n\n一定要给「重试」制定一个终止策略。\n\n当回滚的过程很困难或代价很大的情况下，可以接受很长的间隔及大量的重试次数，DDD中经常被提到的「saga」模式其实也是这样的思路。不过，前提是不会因为保留或锁定稀缺资源而阻止其他操作（比如1、2、3、4、5几个串行操作。由于2一直没处理完成导致3、4、5没法继续进行）。\n\n可以离线的事务一致性维护机制\n\n 1. 第一步：在线业务生成可疑记录\n 2. 第二步：离线服务诊断可疑记录，生成故障记录\n 3. 第三步：离线服务尝试对故障记录进行智能修复（补偿或重试）\n 4. 第四步：对于无法修复，或者修复过程失败的记录发出告警，交由人工处理。\n\n\n# 总结\n\n这篇我们先聊了下做「补偿」的意义，以及做补偿的2个方式「回滚」和「重试」的实现思路。\n\n然后，提醒你要注意「重试」的时候需要考虑幂等性问题，并且z哥也给出了一个解决思路。\n\n最后，分享了几个 echo 总结的针对「重试」的最佳实践。\n\n希望对你有所帮助。\n\n\n# 参考文献\n\n99%的人都能看懂的分布式系统「补偿」机制 - 知乎 (zhihu.com)",normalizedContent:"# 前言：补偿机制的意义？\n\n以电商的购物场景为例：\n\n客户端 ----\x3e购物车微服务 ----\x3e订单微服务 ----\x3e 支付微服务。\n\n这种调用链非常普遍。\n\n那么为什么需要考虑补偿机制呢？\n\n正如之前几篇文章所说，一次跨机器的通信可能会经过dns 服务，网卡、交换机、路由器、负载均衡等设备，这些设备都不一定是一直稳定的，在数据传输的整个过程中，只要任意一个环节出错，都会导致问题的产生。\n\n而在分布式场景中，一个完整的业务又是由多次跨机器通信组成的，所以产生问题的概率成倍数增加。\n\n但是，这些问题并不完全代表真正的系统无法处理请求，所以我们应当尽可能的自动消化掉这些异常。\n\n可能你会问，之前也看到过「补偿」和「事务补偿」或者「重试」，它们之间的关系是什么？\n\n你其实可以不用太纠结这些名字，从目的来说都是一样的。就是一旦某个操作发生了异常，如何通过内部机制将这个异常产生的「不一致」状态消除掉。\n\n> 在 echo 看来，不管用什么方式，只要通过额外的方式解决了问题都可以理解为是「补偿」，所以「事务补偿」和「重试」都是「补偿」的子集。前者是一个逆向操作，而后者则是一个正向操作。\n\n只是从结果来看，两者的意义不同。「事务补偿」意味着“放弃”，当前操作必然会失败。\n\n事务补偿\n\n\n\n「重试」则还有处理成功的机会。这两种方式分别适用于不同的场景。\n\n重试\n\n\n\n因为「补偿」已经是一个额外流程了，既然能够走这个额外流程，说明时效性并不是第一考虑的因素，所以做补偿的核心要点是：宁可慢，不可错。\n\n因此，不要草率的就确定了补偿的实施方案，需要谨慎的评估。虽说错误无法100%避免，但是抱着这样的一个心态或多或少可以减少一些错误的发生。\n\n\n# 补偿 该怎么做？\n\n做「补偿」的主流方式就前面提到的「事务补偿」和「重试」，以下会被称作「回滚」和「重试」。\n\n我们先来聊聊「回滚」。相比「重试」，它逻辑上更简单一些。\n\n\n# 回滚\n\necho 将回滚分为2种模式，一种叫「显式回滚」（调用逆向接口），一种叫「隐式回滚」（无需调用逆向接口）。\n\n最常见的就是「显式回滚」。这个方案无非就是做2个事情：\n\n首先要确定失败的步骤和状态，从而确定需要回滚的范围。一个业务的流程，往往在设计之初就制定好了，所以确定回滚的范围比较容易。但这里唯一需要注意的一点就是：如果在一个业务处理中涉及到的服务并不是都提供了「回滚接口」，那么在编排服务时应该把提供「回滚接口」的服务放在前面，这样当后面的工作服务错误时还有机会「回滚」。\n\n其次要能提供「回滚」操作使用到的业务数据。「回滚」时提供的数据越多，越有益于程序的健壮性。因为程序可以在收到「回滚」操作的时候可以做业务的检查，比如检查账户是否相等，金额是否一致等等。\n\n由于这个中间状态的数据结构和数据大小并不固定，所以echo建议你在实现这点的时候可以将相关的数据序列化成一个json，然后存放到一个nosql类型的存储中。\n\n「隐式回滚」相对来说运用场景比较少。它意味着这个回滚动作你不需要进行额外处理，下游服务内部有类似“预占”并且“超时失效”的机制的。例如：\n\n电商场景中，会将订单中的商品先预占库存，等待用户在 15 分钟内支付。如果没有收到用户的支付，则释放库存。\n\n下面聊聊可以有很多玩法，也更容易陷入坑里的「重试」。\n\n\n# 重试\n\n「重试」最大的好处在于，业务系统可以不需要提供「逆向接口」，这是一个对长期开发成本特别大的利好，毕竟业务是天天在变的。所以，在可能的情况下，应该优先考虑使用「重试」。\n\n不过，相比「回滚」来说「重试」的适用场景更少一些，所以我们第一步首先要判断，当前场景是否适合「重试」。比如：\n\n * 下游系统返回「请求超时」、「被限流中」等临时状态的时候，我们可以考虑重试\n * 而如果是返回“余额不足”、“无权限”等明确无法继续的业务性错误的时候就不需要重试了\n * 一些中间件或者rpc框架中返回http503、404等没有何时恢复的预期的时候，也不需要重试\n\n如果确定要进行「重试」，我们还需要选定一个合适的「重试策略」。主流的「重试策略」主要是以下几种。\n\n策略1.立即重试。有时故障是候暂时性，可能是因网络数据包冲突或硬件组件流量高峰等事件造成的。在此情况下，适合立即重试操作。不过，立即重试次数不应超过一次，如果立即重试失败，应改用其它的策略。\n\n策略2.固定间隔。应用程序每次尝试的间隔时间相同。 这个好理解，例如，固定每 3 秒重试操作。（以下所有示例代码中的具体的数字仅供参考。）\n\n策略1和策略2多用于前端系统的交互式操作中。\n\n策略3.增量间隔。每一次的重试间隔时间增量递增。比如，第一次0秒、第二次3秒、第三次6秒，9、12、15这样。\n\nreturn (retrycount - 1) * incrementinterval;\n\n\n使得失败次数越多的重试请求优先级排到越后面，给新进入的重试请求让道。\n\n策略4.指数间隔。每一次的重试间隔呈指数级增加。和增量间隔“殊途同归”，都是想让失败次数越多的重试请求优先级排到越后面，只不过这个方案的增长幅度更大一些。\n\nreturn 2 ^ retrycount;\n\n\n策略5.全抖动。在递增的基础上，增加随机性（可以把其中的指数增长部分替换成增量增长。）。适用于将某一时刻集中产生的大量重试请求进行压力分散的场景。\n\nreturn random(0 , 2 ^ retrycount);\n\n\n策略6.等抖动。在「指数间隔」和「全抖动」之间寻求一个中庸的方案，降低随机性的作用。适用场景和「全抖动」一样。\n\nvar basenum = 2 ^ retrycount;return basenum + random(0 , basenum);\n\n\n3、4、5、6策略的表现情况大致是这样。(x轴为重试次数)\n\n\n\n为什么说「重试」有坑呢？\n\n正如前面聊到的那样，出于对开发成本考虑，你在做「重试」的时候可能是复用的常规调用的接口。那么此时就不得不提一个「幂等性」问题。\n\n如果实现「重试」选用的技术方案不能100%确保不会重复发起重试，那么「幂等性」问题是一个必须要考虑的问题。哪怕技术方案可以确保100%不会重复发起重试，出于对意外情况的考量，尽量也考虑一下「幂等性」问题。\n\n**幂等性：**不管对程序发起几次重复调用，程序表现的状态（所有相关的数据变化）与调用一次的结果是一致的话，就是保证了幂等性。\n\n这意味着可以根据需要重复或重试操作，而不会导致意外的影响。对于非幂等操作，算法可能必须跟踪操作是否已经执行。\n\n所以，一旦某个功能支持「重试」，那么整个链路上的接口都需要考虑幂等性问题，不能因为服务的多次调用而导致业务数据的累计增加或减少。\n\n满足「幂等性」其实就是需要想办法识别重复的请求，并且将其过滤掉。思路就是：\n\n 1. 给每个请求定义一个唯一标识。\n 2. 在进行「重试」的时候判断这个请求是否已经被执行或者正在被执行，如果是则抛弃该请求。\n\n**第1点，**我们可以使用一个全局唯一id生成器或者生成服务（可以扩展阅读，分布式系统中的必备良药 —— 全局唯一单据号生成）。 或者简单粗暴一些，使用官方类库自带的guid、uuid之类的也行。\n\n然后通过rpc框架在发起调用的客户端中，对每个请求增加一个唯一标识的字段进行赋值。\n\n**第2点，**我们可以在服务端通过aop的方式切入到实际的处理逻辑代码之前和之后，一起配合做验证。\n\n\n\n大致的代码思路如下。\n\n【方法执行前】if(isexistlog(requestid)){  //1.判断请求是否已被接收过。  对应序号3\n    var lastresult = getlastresult();  //2.获取用于判断之前的请求是否已经处理完成。  对应序号4\n    if(lastresult == null){  \n        var result = waitresult();  //挂起等待处理完成\n        return result;\n    }\n    else{\n        return lastresult;\n    }  \n}\nelse{\n    log(requestid);  //3.记录该请求已接收\n}\n\n//do something..【方法执行后】\n\nlogresult(requestid, result);  //4.将结果也更新一下。\n\n\n如果「补偿」这个工作是通过mq来进行的话，这事就可以直接在对接mq所封装的sdk中做。在生产端赋值全局唯一标识，在消费端通过唯一标识消重。\n\n\n# 重试 的最佳实践\n\n再聊一些 echo 积累的最佳实践吧，都是针对「重试」的，的确这也是工作中最常用的方案。\n\n「重试」特别适合在高负载情况下被「降级」，当然也应当受到「限流」和「熔断」机制的影响。当「重试」的“矛”与「限流」和「熔断」的“盾”搭配使用，效果才是最好。\n\n需要衡量增加补偿机制的投入产出比。一些不是很重要的问题时，应该「快速失败」而不是「重试」。\n\n过度积极的重试策略（例如间隔太短或重试次数过多）会对下游服务造成不利影响，这点一定要注意。\n\n一定要给「重试」制定一个终止策略。\n\n当回滚的过程很困难或代价很大的情况下，可以接受很长的间隔及大量的重试次数，ddd中经常被提到的「saga」模式其实也是这样的思路。不过，前提是不会因为保留或锁定稀缺资源而阻止其他操作（比如1、2、3、4、5几个串行操作。由于2一直没处理完成导致3、4、5没法继续进行）。\n\n可以离线的事务一致性维护机制\n\n 1. 第一步：在线业务生成可疑记录\n 2. 第二步：离线服务诊断可疑记录，生成故障记录\n 3. 第三步：离线服务尝试对故障记录进行智能修复（补偿或重试）\n 4. 第四步：对于无法修复，或者修复过程失败的记录发出告警，交由人工处理。\n\n\n# 总结\n\n这篇我们先聊了下做「补偿」的意义，以及做补偿的2个方式「回滚」和「重试」的实现思路。\n\n然后，提醒你要注意「重试」的时候需要考虑幂等性问题，并且z哥也给出了一个解决思路。\n\n最后，分享了几个 echo 总结的针对「重试」的最佳实践。\n\n希望对你有所帮助。\n\n\n# 参考文献\n\n99%的人都能看懂的分布式系统「补偿」机制 - 知乎 (zhihu.com)",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"海量数据计数",frontmatter:{title:"海量数据计数",date:"2024-09-14T16:52:01.000Z",permalink:"/pages/f3295f/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/10.%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E8%AE%A1%E6%95%B0.html",relativePath:"03.经典场景设计/01.热门场景设计/10.海量数据计数.md",key:"v-025c760c",path:"/pages/f3295f/",headers:[{level:2,title:"引子",slug:"引子",normalizedTitle:"引子",charIndex:2},{level:2,title:"计数在业务上的特点",slug:"计数在业务上的特点",normalizedTitle:"计数在业务上的特点",charIndex:410},{level:2,title:"支撑高并发的计数系统要如何设计",slug:"支撑高并发的计数系统要如何设计",normalizedTitle:"支撑高并发的计数系统要如何设计",charIndex:808},{level:2,title:"如何降低计数系统的存储成本",slug:"如何降低计数系统的存储成本",normalizedTitle:"如何降低计数系统的存储成本",charIndex:2153},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:4116}],headersStr:"引子 计数在业务上的特点 支撑高并发的计数系统要如何设计 如何降低计数系统的存储成本 总结",content:"# 引子\n\n在地铁上，你也许会经常刷微博、点赞热搜，如果有抽奖活动，再转 发一波，而这些与微博息息相关的数据，其实就是微博场景下的计数数据，细说起来，它主要有几类\n\n * 微博的评论数、点赞数、转发数、浏览数、表态数等等；\n * 用户的粉丝数、关注数、发布微博数、私信数等等。\n\n微博维度的计数代表了这条微博受欢迎的程度，用户维度的数据（尤其是粉丝数），代表了这个用户的影响力，因此大家会普遍看重这些计数信息。并且在很多场景下，我们都需要查询计数数据（比如首页信息流页面、个人主页面），计数数据访问量巨大，所以需要设计计数系统维护它\n\n但在设计计数系统时，不少人会出现性能不高、存储成本很大的问题，比如，把计数与微博数据存储在一起，这样每次更新计数的时候都需要锁住这一行记录，降低了写入的并发。在我看来，之所以出现这些问题，还是因为你对计数系统的设计和优化不甚了解，所以要想解决痛点，你有必要形成完备的设计方案\n\n\n# 计数在业务上的特点\n\n * 数据量巨大，微博系统中微博条目的数量早已经超过了千亿级别，仅仅计算 微博的转发、评论、点赞、浏览等核心计数，其数据量级就已经在几千亿的级别。更何 况微博条目的数量还在不断高速地增长，并且随着微博业务越来越复杂，微博维度的计数种类也可能会持续扩展（比如说增加了表态数），因此，仅仅是微博维度上的计数量 级就已经过了万亿级别。除此之外，微博的用户量级已经超过了 10 亿，用户维度的计数 量级相比微博维度来说虽然相差很大，但是也达到了百亿级别。那么如何存储这些过万 亿级别的数字，对我们来说就是一大挑战\n * 访问量大，对于性能的要求高。微博的日活用户超过 2 亿，月活用户接近 5 亿，核心服 务（比如首页信息流）访问量级到达每秒几十万次，计数系统的访问量级也超过了每秒 百万级别，而且在性能方面，它要求要毫秒级别返回结果\n * 对于可用性、数字的准确性要求高\n\n\n# 支撑高并发的计数系统要如何设计\n\n刚开始设计计数系统的时候，微博的流量还没有现在这么夸张，我们本着 KISS（Keep It Simple and Stupid）原则，尽量将系统设计的简单易维护，所以，我们使用 MySQL 存储计数的数据，因为它是我们最熟悉的，团队在运维上经验也会比较丰富。举个具体的例子。\n\nselect repost_count, comment_count, praise_count, view_count from t_weibo_count\n\n\n随着微博的不断壮大，之前的计数系统面临了很多的问题和挑战。\n\n比如微博用户量和发布的微博量增加迅猛，计数存储数据量级也飞速增长，而 MySQL 数据库单表的存储量级达到几千万的时候，性能上就会有损耗。所以我们考虑使用分库分表的 方式分散数据量，提升读取计数的性能。\n\n我们用“weibo_id”作为分区键，在选择分库分表的方式时，考虑了下面两种\n\n * 一种方式是选择一种哈希算法对 weibo_id 计算哈希值，然后依据这个哈希值计算出需 要存储到哪一个库哪一张表中\n * 另一种方式是按照 weibo_id 生成的时间来做分库分表，我们在第 10 讲谈到发号器的时候曾经提到，ID 的生成最好带有业务意义的字段，比如生成 ID 的时间戳\n\n分表的时候，可以先依据发号器的算法反解出时间戳，然后按照时间戳来做分库分表， 比如，一天一张表或者一个月一张表等等。\n\n因为越是最近发布的微博，计数数据的访问量就越大，所以虽然我考虑了两种方案，但是按照时间来分库分表会造成数据访问的不均匀，最后用了哈希的方式来做分库分表。\n\n\n\n与此同时，计数的访问量级也有质的飞越。在微博最初的版本中，首页信息流里面是不展示 计数数据的，那么使用 MySQL 也可以承受当时读取计数的访问量。但是后来在首页信息流中也要展示转发、评论和点赞等计数数据了。而信息流的访问量巨大，仅仅靠数据库已经 完全不能承担如此高的并发量了。于是我们考虑使用 Redis 来加速读请求，通过部署多个从节点来提升可用性和性能，并且通过 Hash 的方式对数据做分片，也基本上可以保证计数的读取性能。然而，这种数据库 + 缓存的方式有一个弊端：无法保证数据的一致性，比如，如果数据库写入成功而缓存更新失败，就会导致数据的不一致，影响计数的准确性。所以，我们完全抛弃了 MySQL，全面使用 Redis 来作为计数的存储组\n\n\n\n除了考虑计数的读取性能之外，由于热门微博的计数变化频率相当快，也需要考虑如何提升 计数的写入性能。比如，每次在转发一条微博的时候，都需要增加这条微博的转发数，那么 如果明星发布结婚、离婚的微博，瞬时就可能会产生几万甚至几十万的转发。如果是你的话，要如何降低写压力呢？\n\n你可能已经想到用消息队列来削峰填谷了，也就是说，我们在转发微博的时候向消息队列写 入一条消息，然后在消息处理程序中给这条微博的转发计数加 1。这里需要注意的一点， 我们可以通过批量处理消息的方式进一步减小 Redis 的写压力，比如像下面这样连续更改 三次转发数（我用 SQL 来表示来方便你理解）：\n\n\n\n这个时候，你可以把它们合并成一次更新：\n\n\n\n\n# 如何降低计数系统的存储成本\n\n讲到这里，我其实已经告诉你一个支撑高并发查询请求的计数系统是如何实现的了。但是在微博的场景下，计数的量级是万亿的级别，这也给我们提了更高的要求，就是如何在有限的存储成本下实现对于全量计数数据的存取。\n\n你知道，Redis 是使用内存来存储信息，相比于使用磁盘存储数据的 MySQL 来说，存储的成本不可同日而语，比如一台服务器磁盘可以挂载到 2 个 T，但是内存可能只有 128G，这样磁盘的存储空间就是内存的 16 倍。而 Redis 基于通用性的考虑，对于内存的使用比较粗 放，存在大量的指针以及额外数据结构的开销，如果要存储一个 KV 类型的计数信息，Key 是 8 字节 Long 类型的 weibo_id，Value 是 4 字节 int 类型的转发数，存储在 Redis 中之后会占用超过 70 个字节的空间，空间的浪费是巨大的。如果你面临这个问题，要如何优化呢\n\n我建议你先对原生 Redis 做一些改造，采用新的数据结构和数据类型来存储计数数据。我 在改造时，主要涉及了两点\n\n * 一是原生的 Redis 在存储 Key 时是按照字符串类型来存储的，比如一个 8 字节的 Long 类型的数据，需要 8（sdshdr 数据结构长度）+ 19（8 字节数字的长度）+1（’\\0’） =28 个字节，如果我们使用 Long 类型来存储就只需要 8 个字节，会节省 20 个字节的 空间；\n * 二是去除了原生 Redis 中多余的指针，如果要存储一个 KV 信息就只需要 8（weibo_id）+4（转发数）=12 个字节，相比之前有很大的改进。\n\n同时，我们也会使用一个大的数组来存储计数信息，存储的位置是基于 weibo_id 的哈希值来计算出来的，具体的算法像下面展示的这样：\n\n插入时:\nh1 = hash1(weibo_id) // 根据微博 ID 计算 Hash\nh2 = hash2(weibo_id) // 根据微博 ID 计算另一个 Hash，用以解决前一个 Hash 算法带来的冲突\nfor s in 0,1000\n\tpos = (h1 + h2*s) % tsize // 如果发生冲突，就多算几次 Hash2\n\t\tif(isempty(pos) || isdelete(pos))\n\t\t\tt[ pos ] = item  // 写入数组\n查询时:\nfor s in 0,1000\n\tpos = (h1 + h2*s) % tsize  // 依照插入数据时候的逻辑，计算出存储在数组中的位置\n\t\tif(!isempty(pos) && t[pos]==weibo_id)\n\t\t\treturn t[pos]\nreturn 0 \n删除时:\ninsert(FFFF) // 插入一个特殊的标\n\n\n在对原生的 Redis 做了改造之后，你还需要进一步考虑如何节省内存的使用。比如，微博的计数有转发数、评论数、浏览数、点赞数等等，如果每一个计数都需要存储 weibo_id， 那么总共就需要 8（weibo_id）*4（4 个微博 ID）+4（转发数） + 4（评论数） + 4（点 赞数） + 4（浏览数）= 48 字节。但是我们可以把相同微博 ID 的计数存储在一起，这样就只需要记录一个微博 ID，省掉了多余的三个微博 ID 的存储开销，存储空间就进一步减少 了。\n\n不过，即使经过上面的优化，由于计数的量级实在是太过巨大，并且还在以极快的速度增 长，所以如果我们以全内存的方式来存储计数信息，就需要使用非常多的机器来支撑。\n\n冷热分离\n\n然而微博计数的数据具有明显的热点属性：越是最近的微博越是会被访问到，时间上久远的微博被访问的几率很小。所以为了尽量减少服务器的使用，我们考虑给计数服务增加 SSD 磁盘，然后将时间上比较久远的数据 dump 到磁盘上，内存中只保留最近的数据。当我们要读取冷数据的时候，使用单独的 I/O 线程异步地将冷数据从 SSD 磁盘中加载到一块儿单 独的 Cold Cache 中\n\n\n\n在经过了上面这些优化之后，我们的计数服务就可以支撑高并发大数据量的考验，无论是在 性能上、成本上和可用性上都能够达到业务的需求了。\n\n总的来说，我用微博设计计数系统的例子，并不是仅仅告诉你计数系统是如何做的，而是想 告诉你在做系统设计的时候需要了解自己系统目前的痛点是什么，然后再针对痛点来做细致 的优化。比如，微博计数系统的痛点是存储的成本，那么我们后期做的事情很多都是围绕着 如何使用有限的服务器存储全量的计数数据，即使是对开源组件（Redis）做深度的定制会 带来很大的运维成本，也只能被认为是为了实现计数系统而必须要做的权衡。\n\n\n# 总结\n\n 1. 数据库 + 缓存的方案是计数系统的初级阶段，完全可以支撑中小访问量和存储量的存储 服务。如果你的项目还处在初级阶段，量级还不是很大，那么你一开始可以考虑使用这 种方案。\n 2. 通过对原生 Redis 组件的改造，我们可以极大地减小存储数据的内存开销。\n 3. 使用 SSD+ 内存的方案可以最终解决存储计数数据的成本问题。这个方式适用于冷热数 据明显的场景，你在使用时需要考虑如何将内存中的数据做换入换出",normalizedContent:"# 引子\n\n在地铁上，你也许会经常刷微博、点赞热搜，如果有抽奖活动，再转 发一波，而这些与微博息息相关的数据，其实就是微博场景下的计数数据，细说起来，它主要有几类\n\n * 微博的评论数、点赞数、转发数、浏览数、表态数等等；\n * 用户的粉丝数、关注数、发布微博数、私信数等等。\n\n微博维度的计数代表了这条微博受欢迎的程度，用户维度的数据（尤其是粉丝数），代表了这个用户的影响力，因此大家会普遍看重这些计数信息。并且在很多场景下，我们都需要查询计数数据（比如首页信息流页面、个人主页面），计数数据访问量巨大，所以需要设计计数系统维护它\n\n但在设计计数系统时，不少人会出现性能不高、存储成本很大的问题，比如，把计数与微博数据存储在一起，这样每次更新计数的时候都需要锁住这一行记录，降低了写入的并发。在我看来，之所以出现这些问题，还是因为你对计数系统的设计和优化不甚了解，所以要想解决痛点，你有必要形成完备的设计方案\n\n\n# 计数在业务上的特点\n\n * 数据量巨大，微博系统中微博条目的数量早已经超过了千亿级别，仅仅计算 微博的转发、评论、点赞、浏览等核心计数，其数据量级就已经在几千亿的级别。更何 况微博条目的数量还在不断高速地增长，并且随着微博业务越来越复杂，微博维度的计数种类也可能会持续扩展（比如说增加了表态数），因此，仅仅是微博维度上的计数量 级就已经过了万亿级别。除此之外，微博的用户量级已经超过了 10 亿，用户维度的计数 量级相比微博维度来说虽然相差很大，但是也达到了百亿级别。那么如何存储这些过万 亿级别的数字，对我们来说就是一大挑战\n * 访问量大，对于性能的要求高。微博的日活用户超过 2 亿，月活用户接近 5 亿，核心服 务（比如首页信息流）访问量级到达每秒几十万次，计数系统的访问量级也超过了每秒 百万级别，而且在性能方面，它要求要毫秒级别返回结果\n * 对于可用性、数字的准确性要求高\n\n\n# 支撑高并发的计数系统要如何设计\n\n刚开始设计计数系统的时候，微博的流量还没有现在这么夸张，我们本着 kiss（keep it simple and stupid）原则，尽量将系统设计的简单易维护，所以，我们使用 mysql 存储计数的数据，因为它是我们最熟悉的，团队在运维上经验也会比较丰富。举个具体的例子。\n\nselect repost_count, comment_count, praise_count, view_count from t_weibo_count\n\n\n随着微博的不断壮大，之前的计数系统面临了很多的问题和挑战。\n\n比如微博用户量和发布的微博量增加迅猛，计数存储数据量级也飞速增长，而 mysql 数据库单表的存储量级达到几千万的时候，性能上就会有损耗。所以我们考虑使用分库分表的 方式分散数据量，提升读取计数的性能。\n\n我们用“weibo_id”作为分区键，在选择分库分表的方式时，考虑了下面两种\n\n * 一种方式是选择一种哈希算法对 weibo_id 计算哈希值，然后依据这个哈希值计算出需 要存储到哪一个库哪一张表中\n * 另一种方式是按照 weibo_id 生成的时间来做分库分表，我们在第 10 讲谈到发号器的时候曾经提到，id 的生成最好带有业务意义的字段，比如生成 id 的时间戳\n\n分表的时候，可以先依据发号器的算法反解出时间戳，然后按照时间戳来做分库分表， 比如，一天一张表或者一个月一张表等等。\n\n因为越是最近发布的微博，计数数据的访问量就越大，所以虽然我考虑了两种方案，但是按照时间来分库分表会造成数据访问的不均匀，最后用了哈希的方式来做分库分表。\n\n\n\n与此同时，计数的访问量级也有质的飞越。在微博最初的版本中，首页信息流里面是不展示 计数数据的，那么使用 mysql 也可以承受当时读取计数的访问量。但是后来在首页信息流中也要展示转发、评论和点赞等计数数据了。而信息流的访问量巨大，仅仅靠数据库已经 完全不能承担如此高的并发量了。于是我们考虑使用 redis 来加速读请求，通过部署多个从节点来提升可用性和性能，并且通过 hash 的方式对数据做分片，也基本上可以保证计数的读取性能。然而，这种数据库 + 缓存的方式有一个弊端：无法保证数据的一致性，比如，如果数据库写入成功而缓存更新失败，就会导致数据的不一致，影响计数的准确性。所以，我们完全抛弃了 mysql，全面使用 redis 来作为计数的存储组\n\n\n\n除了考虑计数的读取性能之外，由于热门微博的计数变化频率相当快，也需要考虑如何提升 计数的写入性能。比如，每次在转发一条微博的时候，都需要增加这条微博的转发数，那么 如果明星发布结婚、离婚的微博，瞬时就可能会产生几万甚至几十万的转发。如果是你的话，要如何降低写压力呢？\n\n你可能已经想到用消息队列来削峰填谷了，也就是说，我们在转发微博的时候向消息队列写 入一条消息，然后在消息处理程序中给这条微博的转发计数加 1。这里需要注意的一点， 我们可以通过批量处理消息的方式进一步减小 redis 的写压力，比如像下面这样连续更改 三次转发数（我用 sql 来表示来方便你理解）：\n\n\n\n这个时候，你可以把它们合并成一次更新：\n\n\n\n\n# 如何降低计数系统的存储成本\n\n讲到这里，我其实已经告诉你一个支撑高并发查询请求的计数系统是如何实现的了。但是在微博的场景下，计数的量级是万亿的级别，这也给我们提了更高的要求，就是如何在有限的存储成本下实现对于全量计数数据的存取。\n\n你知道，redis 是使用内存来存储信息，相比于使用磁盘存储数据的 mysql 来说，存储的成本不可同日而语，比如一台服务器磁盘可以挂载到 2 个 t，但是内存可能只有 128g，这样磁盘的存储空间就是内存的 16 倍。而 redis 基于通用性的考虑，对于内存的使用比较粗 放，存在大量的指针以及额外数据结构的开销，如果要存储一个 kv 类型的计数信息，key 是 8 字节 long 类型的 weibo_id，value 是 4 字节 int 类型的转发数，存储在 redis 中之后会占用超过 70 个字节的空间，空间的浪费是巨大的。如果你面临这个问题，要如何优化呢\n\n我建议你先对原生 redis 做一些改造，采用新的数据结构和数据类型来存储计数数据。我 在改造时，主要涉及了两点\n\n * 一是原生的 redis 在存储 key 时是按照字符串类型来存储的，比如一个 8 字节的 long 类型的数据，需要 8（sdshdr 数据结构长度）+ 19（8 字节数字的长度）+1（’\\0’） =28 个字节，如果我们使用 long 类型来存储就只需要 8 个字节，会节省 20 个字节的 空间；\n * 二是去除了原生 redis 中多余的指针，如果要存储一个 kv 信息就只需要 8（weibo_id）+4（转发数）=12 个字节，相比之前有很大的改进。\n\n同时，我们也会使用一个大的数组来存储计数信息，存储的位置是基于 weibo_id 的哈希值来计算出来的，具体的算法像下面展示的这样：\n\n插入时:\nh1 = hash1(weibo_id) // 根据微博 id 计算 hash\nh2 = hash2(weibo_id) // 根据微博 id 计算另一个 hash，用以解决前一个 hash 算法带来的冲突\nfor s in 0,1000\n\tpos = (h1 + h2*s) % tsize // 如果发生冲突，就多算几次 hash2\n\t\tif(isempty(pos) || isdelete(pos))\n\t\t\tt[ pos ] = item  // 写入数组\n查询时:\nfor s in 0,1000\n\tpos = (h1 + h2*s) % tsize  // 依照插入数据时候的逻辑，计算出存储在数组中的位置\n\t\tif(!isempty(pos) && t[pos]==weibo_id)\n\t\t\treturn t[pos]\nreturn 0 \n删除时:\ninsert(ffff) // 插入一个特殊的标\n\n\n在对原生的 redis 做了改造之后，你还需要进一步考虑如何节省内存的使用。比如，微博的计数有转发数、评论数、浏览数、点赞数等等，如果每一个计数都需要存储 weibo_id， 那么总共就需要 8（weibo_id）*4（4 个微博 id）+4（转发数） + 4（评论数） + 4（点 赞数） + 4（浏览数）= 48 字节。但是我们可以把相同微博 id 的计数存储在一起，这样就只需要记录一个微博 id，省掉了多余的三个微博 id 的存储开销，存储空间就进一步减少 了。\n\n不过，即使经过上面的优化，由于计数的量级实在是太过巨大，并且还在以极快的速度增 长，所以如果我们以全内存的方式来存储计数信息，就需要使用非常多的机器来支撑。\n\n冷热分离\n\n然而微博计数的数据具有明显的热点属性：越是最近的微博越是会被访问到，时间上久远的微博被访问的几率很小。所以为了尽量减少服务器的使用，我们考虑给计数服务增加 ssd 磁盘，然后将时间上比较久远的数据 dump 到磁盘上，内存中只保留最近的数据。当我们要读取冷数据的时候，使用单独的 i/o 线程异步地将冷数据从 ssd 磁盘中加载到一块儿单 独的 cold cache 中\n\n\n\n在经过了上面这些优化之后，我们的计数服务就可以支撑高并发大数据量的考验，无论是在 性能上、成本上和可用性上都能够达到业务的需求了。\n\n总的来说，我用微博设计计数系统的例子，并不是仅仅告诉你计数系统是如何做的，而是想 告诉你在做系统设计的时候需要了解自己系统目前的痛点是什么，然后再针对痛点来做细致 的优化。比如，微博计数系统的痛点是存储的成本，那么我们后期做的事情很多都是围绕着 如何使用有限的服务器存储全量的计数数据，即使是对开源组件（redis）做深度的定制会 带来很大的运维成本，也只能被认为是为了实现计数系统而必须要做的权衡。\n\n\n# 总结\n\n 1. 数据库 + 缓存的方案是计数系统的初级阶段，完全可以支撑中小访问量和存储量的存储 服务。如果你的项目还处在初级阶段，量级还不是很大，那么你一开始可以考虑使用这 种方案。\n 2. 通过对原生 redis 组件的改造，我们可以极大地减小存储数据的内存开销。\n 3. 使用 ssd+ 内存的方案可以最终解决存储计数数据的成本问题。这个方式适用于冷热数 据明显的场景，你在使用时需要考虑如何将内存中的数据做换入换出",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"消息未读数系统",frontmatter:{title:"消息未读数系统",date:"2024-09-14T23:57:17.000Z",permalink:"/pages/6b9d68/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/11.%E6%B6%88%E6%81%AF%E6%9C%AA%E8%AF%BB%E6%95%B0%E7%B3%BB%E7%BB%9F.html",relativePath:"03.经典场景设计/01.热门场景设计/11.消息未读数系统.md",key:"v-ded3b0dc",path:"/pages/6b9d68/",headers:[{level:2,title:"引子",slug:"引子",normalizedTitle:"引子",charIndex:2},{level:2,title:"系统通知的未读数要如何设计",slug:"系统通知的未读数要如何设计",normalizedTitle:"系统通知的未读数要如何设计",charIndex:242},{level:2,title:"如何为信息流的未读数设计方案",slug:"如何为信息流的未读数设计方案",normalizedTitle:"如何为信息流的未读数设计方案",charIndex:2043},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:3457}],headersStr:"引子 系统通知的未读数要如何设计 如何为信息流的未读数设计方案 总结",content:"# 引子\n\n未读数也是系统中一个常见的模块，以微博系统为例，你可看到有多个未读计数的场景，\n\n比如：\n\n * 当有人 @你、评论你、给你的博文点赞或者给你发送私信的时候，你会收到相应的未读提醒；\n * 在早期的微博版本中有系统通知的功能，也就是系统会给全部用户发送消息，通知用户有新的版本或者有一些好玩的运营活动，如果用户没有看，系统就会给他展示有多少条未读的提醒。\n * 我们在浏览信息流的时候，如果长时间没有刷新页面，那么信息流上方就会提示你在这段时间有多少条信息没有看\n\n\n# 系统通知的未读数要如何设计\n\n来看具体的例子。假如你的系统中只有 A、B、C 三个用户，那么你可以在通用计数系统中 增加一块儿内存区域，并且以用户 ID 为 Key 来存储这三个用户的未读通知数据，当系统发 送一个新的通知时，我们会循环给每一个用户的未读数加 1，这个处理逻辑的伪代码就像下 面这样\n\nList<Long> userIds = getAllUserIds();\n    for(Long id : userIds) {\n    incrUnreadCount(id);\n}\n\n\n但随着系统中的用户越来越多，这个方案存在两个致命的问题\n\n * 首先，获取全量用户就是一个比较耗时的操作，相当于对用户库做一次全表的扫描，这不仅会对数据库造成很大的压力，而且查询全量用户数据的响应时间是很长的，对于在线业务来说是难以接受的。如果你的用户库已经做了分库分表，那么就要扫描所有的库表，响应时间就更长了。不过有一个折中的方法， 那就是在发送系统通知之前，先从线下的数据仓库中 获取全量的用户 ID，并且存储在一个本地的文件中，然后再轮询所有的用户 ID，给这些用 户增加未读计数。\n   * 这似乎是一个可行的技术方案，然而它给所有人增加未读计数，会消耗非常长的时间。你计 算一下，假如你的系统中有一个亿的用户，给一个用户增加未读数需要消耗 1ms，那么给 所有人都增加未读计数就需要 100000000 * 1 /1000 = 100000 秒，也就是超过一天的时 间；即使你启动 100 个线程并发的设置，也需要十几分钟的时间才能完成，而用户很难接 受这么长的延迟时间。\n * 另外，使用这种方式需要给系统中的每一个用户都记一个未读数的值，而在系统中，活跃用 户只是很少的一部分，大部分的用户是不活跃的，甚至从来没有打开过系统通知，为这些用 户记录未读数显然是一种浪费。\n\n通过上面的内容，你可以知道为什么我们不能用通用计数系统实现系统通知未读数了吧？那正确的做法是什么呢\n\n要知道，系统通知实际上是存储在一个大的列表中的，这个列表对所有用户共享，也就是所有人看到的都是同一份系统通知的数据。不过不同的人最近看到的消息不同，所以每个人会有不同的未读数。因此，你可以记录一下在这个列表中每个人看过最后一条消息的 ID，然 后统计这个 ID 之后有多少条消息，这就是未读数了\n\n\n\n上述就是 timeline 模型\n\n这个方案在实现时有这样几个关键点：\n\n * 用户访问系统通知页面需要设置未读数为 0，我们需要将用户最近看过的通知 ID 设置为最新的一条系统通知 ID\n * 如果最近看过的通知 ID 为空，则认为是一个新的用户，返回未读数为 0；\n * 对于非活跃用户，比如最近一个月都没有登录和使用过系统的用户，可以把用户最近看过的通知 ID 清空，节省内存空间。\n\n这是一种比较通用的方案，即节省内存，又能尽量减少获取未读数的延迟。\n\n这个方案适用 的另一个业务场景是全量用户打点的场景，比如像下面这张微博截图中的红点\n\n\n\n这个红点和系统通知类似，也是一种通知全量用户的手段，如果逐个通知用户，延迟也是无法接受的。因此你可以采用和系统通知类似的方案。\n\n首先，我们为每一个用户存储一个时间戳，代表最近点过这个红点的时间，用户点了红点， 就把这个时间戳设置为当前时间；然后，我们也记录一个全局的时间戳，这个时间戳标识最新的一次打点时间，如果你在后台操作给全体用户打点，就更新这个时间戳为当前时间。而 我们在判断是否需要展示红点时，只需要判断用户的时间戳和全局时间戳的大小，如果用户时间戳小于全局时间戳，代表在用户最后一次点击红点之后又有新的红点推送，那么就要展 示红点，反之，就不展示红点了。\n\n\n\n这两个场景的共性是全部用户共享一份有限的存储数据，每个人只记录自己在这份存储中的 偏移量，就可以得到未读数了。\n\n你可以看到，系统消息未读的实现方案不是很复杂，它通过设计避免了操作全量数据未读数，如果你的系统中有这种打红点的需求，那我建议你可以结合实际工作灵活使用上述方案。\n\n最后一个需求关注的是微博信息流的未读数，在现在的社交系统中，关注关系已经成为标配的功能，而基于关注关系的信息流也是一种非常重要的信息聚合方式，因此，如何设计信息流的未读数系统就成了你必须面对的一个问题。\n\n\n# 如何为信息流的未读数设计方案\n\n信息流的未读数之所以复杂主要有这样几点原因\n\n首先，微博的信息流是基于关注关系的，未读数也是基于关注关系的，就是说，你关注的人发布了新的微博，那么你作为粉丝未读数就要增加 1。\n\n如果微博用户都是像我这样只有几百粉丝的“小透明”就简单了，你发微博的时候系统给你粉丝的未读数增加 1 不 是什么难事儿。但是对于一些动辄几千万甚至上亿粉丝的微博大 V 就麻烦了，增加未读 数可能需要几个小时。假设你是杨幂的粉丝，想了解她实时发布的博文，那么如果当她 发布博文几个小时之后，你才收到提醒，这显然是不能接受的。所以未读数的延迟是你在设计方案时首先要考虑的内容。\n\n其次，信息流未读数请求量极大、并发极高，这是因为接口是客户端轮询请求的，不是用户触发的。\n\n也就是说，用户即使打开微博客户端什么都不做，这个接口也会被请求到。在几年前，请求未读数接口的量级就已经接近每秒 50 万次，这几年随着微博量级的增长，请求量也变得更高。而作为微博的非核心接口，我们不太可能使用大量的机器来抗未读数请求，因此，如何使用有限的资源来支撑如此高的流量是这个方案的难点。 最后，它不像系统通知那样有共享的存储，因为每个人关注的人不同，信息流的列表也就不同，所以也就没办法采用系统通知未读数的方案。\n\n那要如何设计能够承接每秒几十万次请求的信息流未读数系统呢？你可以这样做：\n\n首先，在通用计数器中记录每一个用户发布的博文数； 然后在 Redis 或者 Memcached 中记录一个人所有关注人的博文数快照，当用户点击未读消息重置未读数为 0 时，将他关注所有人的博文数刷新到快照中； 这样，他关注所有人的博文总数减去快照中的博文总数就是他的信息流未读数。\n\n\n\n假如用户 A，像上图这样关注了用户 B、C、D，其中 B 发布的博文数是 10，C 发布的博 文数是 8，D 发布的博文数是 14，而在用户 A 最近一次查看未读消息时，记录在快照中的 这三个用户的博文数分别是 6、7、12，因此用户 A 的未读数就是（10-6）+（8-7）+（14-12）=7。\n\n这个方案设计简单，并且是全内存操作，性能足够好，能够支撑比较高的并发，事实上微博团队仅仅用 16 台普通的服务器就支撑了每秒接近 50 万次的请求，这就足以证明这个方案的性能有多出色，因此，它完全能够满足信息流未读数的需求。\n\n当然了这个方案也有一些缺陷，比如说快照中需要存储关注关系，如果关注关系变更的时候 更新不及时，那么就会造成未读数不准确；快照采用的是全缓存存储，如果缓存满了就会剔 除一些数据，那么被剔除用户的未读数就变为 0 了。但是好在用户对于未读数的准确度要求不高（未读 10 条还是 11 条，其实用户有时候看不出来），因此，这些缺陷也是可以接受的\n\n通过分享未读数系统设计这个案例，我想给你一些建议：\n\n 1. 缓存是提升系统性能和抵抗大并发量的神器，像是微博信息流未读数这么大的量级我们 仅仅使用十几台服务器就可以支撑，这全都是缓存的功劳；\n 2. 要围绕系统设计的关键困难点想解决办法，就像我们解决系统通知未读数的延迟问题一 样；\n 3. 合理分析业务场景，明确哪些是可以权衡的，哪些是不行的，会对你的系统设计增益良多，比如对于长久不登录用户，我们就会记录未读数为 0，通过这样的权衡，可以极大 地减少内存的占用，减少成本。\n\n\n# 总结\n\n 1. 评论未读、@未读、赞未读等一对一关系的未读数可以使用上节课讲到的通用计数方案来解决；\n 2. 在系统通知未读、全量用户打点等存在有限的共享存储的场景下，可以通过记录用户上次操作的时间或者偏移量，来实现未读方案；\n 3. 最后，信息流未读方案最为复杂，采用的是记录用户博文数快照的方式",normalizedContent:"# 引子\n\n未读数也是系统中一个常见的模块，以微博系统为例，你可看到有多个未读计数的场景，\n\n比如：\n\n * 当有人 @你、评论你、给你的博文点赞或者给你发送私信的时候，你会收到相应的未读提醒；\n * 在早期的微博版本中有系统通知的功能，也就是系统会给全部用户发送消息，通知用户有新的版本或者有一些好玩的运营活动，如果用户没有看，系统就会给他展示有多少条未读的提醒。\n * 我们在浏览信息流的时候，如果长时间没有刷新页面，那么信息流上方就会提示你在这段时间有多少条信息没有看\n\n\n# 系统通知的未读数要如何设计\n\n来看具体的例子。假如你的系统中只有 a、b、c 三个用户，那么你可以在通用计数系统中 增加一块儿内存区域，并且以用户 id 为 key 来存储这三个用户的未读通知数据，当系统发 送一个新的通知时，我们会循环给每一个用户的未读数加 1，这个处理逻辑的伪代码就像下 面这样\n\nlist<long> userids = getalluserids();\n    for(long id : userids) {\n    incrunreadcount(id);\n}\n\n\n但随着系统中的用户越来越多，这个方案存在两个致命的问题\n\n * 首先，获取全量用户就是一个比较耗时的操作，相当于对用户库做一次全表的扫描，这不仅会对数据库造成很大的压力，而且查询全量用户数据的响应时间是很长的，对于在线业务来说是难以接受的。如果你的用户库已经做了分库分表，那么就要扫描所有的库表，响应时间就更长了。不过有一个折中的方法， 那就是在发送系统通知之前，先从线下的数据仓库中 获取全量的用户 id，并且存储在一个本地的文件中，然后再轮询所有的用户 id，给这些用 户增加未读计数。\n   * 这似乎是一个可行的技术方案，然而它给所有人增加未读计数，会消耗非常长的时间。你计 算一下，假如你的系统中有一个亿的用户，给一个用户增加未读数需要消耗 1ms，那么给 所有人都增加未读计数就需要 100000000 * 1 /1000 = 100000 秒，也就是超过一天的时 间；即使你启动 100 个线程并发的设置，也需要十几分钟的时间才能完成，而用户很难接 受这么长的延迟时间。\n * 另外，使用这种方式需要给系统中的每一个用户都记一个未读数的值，而在系统中，活跃用 户只是很少的一部分，大部分的用户是不活跃的，甚至从来没有打开过系统通知，为这些用 户记录未读数显然是一种浪费。\n\n通过上面的内容，你可以知道为什么我们不能用通用计数系统实现系统通知未读数了吧？那正确的做法是什么呢\n\n要知道，系统通知实际上是存储在一个大的列表中的，这个列表对所有用户共享，也就是所有人看到的都是同一份系统通知的数据。不过不同的人最近看到的消息不同，所以每个人会有不同的未读数。因此，你可以记录一下在这个列表中每个人看过最后一条消息的 id，然 后统计这个 id 之后有多少条消息，这就是未读数了\n\n\n\n上述就是 timeline 模型\n\n这个方案在实现时有这样几个关键点：\n\n * 用户访问系统通知页面需要设置未读数为 0，我们需要将用户最近看过的通知 id 设置为最新的一条系统通知 id\n * 如果最近看过的通知 id 为空，则认为是一个新的用户，返回未读数为 0；\n * 对于非活跃用户，比如最近一个月都没有登录和使用过系统的用户，可以把用户最近看过的通知 id 清空，节省内存空间。\n\n这是一种比较通用的方案，即节省内存，又能尽量减少获取未读数的延迟。\n\n这个方案适用 的另一个业务场景是全量用户打点的场景，比如像下面这张微博截图中的红点\n\n\n\n这个红点和系统通知类似，也是一种通知全量用户的手段，如果逐个通知用户，延迟也是无法接受的。因此你可以采用和系统通知类似的方案。\n\n首先，我们为每一个用户存储一个时间戳，代表最近点过这个红点的时间，用户点了红点， 就把这个时间戳设置为当前时间；然后，我们也记录一个全局的时间戳，这个时间戳标识最新的一次打点时间，如果你在后台操作给全体用户打点，就更新这个时间戳为当前时间。而 我们在判断是否需要展示红点时，只需要判断用户的时间戳和全局时间戳的大小，如果用户时间戳小于全局时间戳，代表在用户最后一次点击红点之后又有新的红点推送，那么就要展 示红点，反之，就不展示红点了。\n\n\n\n这两个场景的共性是全部用户共享一份有限的存储数据，每个人只记录自己在这份存储中的 偏移量，就可以得到未读数了。\n\n你可以看到，系统消息未读的实现方案不是很复杂，它通过设计避免了操作全量数据未读数，如果你的系统中有这种打红点的需求，那我建议你可以结合实际工作灵活使用上述方案。\n\n最后一个需求关注的是微博信息流的未读数，在现在的社交系统中，关注关系已经成为标配的功能，而基于关注关系的信息流也是一种非常重要的信息聚合方式，因此，如何设计信息流的未读数系统就成了你必须面对的一个问题。\n\n\n# 如何为信息流的未读数设计方案\n\n信息流的未读数之所以复杂主要有这样几点原因\n\n首先，微博的信息流是基于关注关系的，未读数也是基于关注关系的，就是说，你关注的人发布了新的微博，那么你作为粉丝未读数就要增加 1。\n\n如果微博用户都是像我这样只有几百粉丝的“小透明”就简单了，你发微博的时候系统给你粉丝的未读数增加 1 不 是什么难事儿。但是对于一些动辄几千万甚至上亿粉丝的微博大 v 就麻烦了，增加未读 数可能需要几个小时。假设你是杨幂的粉丝，想了解她实时发布的博文，那么如果当她 发布博文几个小时之后，你才收到提醒，这显然是不能接受的。所以未读数的延迟是你在设计方案时首先要考虑的内容。\n\n其次，信息流未读数请求量极大、并发极高，这是因为接口是客户端轮询请求的，不是用户触发的。\n\n也就是说，用户即使打开微博客户端什么都不做，这个接口也会被请求到。在几年前，请求未读数接口的量级就已经接近每秒 50 万次，这几年随着微博量级的增长，请求量也变得更高。而作为微博的非核心接口，我们不太可能使用大量的机器来抗未读数请求，因此，如何使用有限的资源来支撑如此高的流量是这个方案的难点。 最后，它不像系统通知那样有共享的存储，因为每个人关注的人不同，信息流的列表也就不同，所以也就没办法采用系统通知未读数的方案。\n\n那要如何设计能够承接每秒几十万次请求的信息流未读数系统呢？你可以这样做：\n\n首先，在通用计数器中记录每一个用户发布的博文数； 然后在 redis 或者 memcached 中记录一个人所有关注人的博文数快照，当用户点击未读消息重置未读数为 0 时，将他关注所有人的博文数刷新到快照中； 这样，他关注所有人的博文总数减去快照中的博文总数就是他的信息流未读数。\n\n\n\n假如用户 a，像上图这样关注了用户 b、c、d，其中 b 发布的博文数是 10，c 发布的博 文数是 8，d 发布的博文数是 14，而在用户 a 最近一次查看未读消息时，记录在快照中的 这三个用户的博文数分别是 6、7、12，因此用户 a 的未读数就是（10-6）+（8-7）+（14-12）=7。\n\n这个方案设计简单，并且是全内存操作，性能足够好，能够支撑比较高的并发，事实上微博团队仅仅用 16 台普通的服务器就支撑了每秒接近 50 万次的请求，这就足以证明这个方案的性能有多出色，因此，它完全能够满足信息流未读数的需求。\n\n当然了这个方案也有一些缺陷，比如说快照中需要存储关注关系，如果关注关系变更的时候 更新不及时，那么就会造成未读数不准确；快照采用的是全缓存存储，如果缓存满了就会剔 除一些数据，那么被剔除用户的未读数就变为 0 了。但是好在用户对于未读数的准确度要求不高（未读 10 条还是 11 条，其实用户有时候看不出来），因此，这些缺陷也是可以接受的\n\n通过分享未读数系统设计这个案例，我想给你一些建议：\n\n 1. 缓存是提升系统性能和抵抗大并发量的神器，像是微博信息流未读数这么大的量级我们 仅仅使用十几台服务器就可以支撑，这全都是缓存的功劳；\n 2. 要围绕系统设计的关键困难点想解决办法，就像我们解决系统通知未读数的延迟问题一 样；\n 3. 合理分析业务场景，明确哪些是可以权衡的，哪些是不行的，会对你的系统设计增益良多，比如对于长久不登录用户，我们就会记录未读数为 0，通过这样的权衡，可以极大 地减少内存的占用，减少成本。\n\n\n# 总结\n\n 1. 评论未读、@未读、赞未读等一对一关系的未读数可以使用上节课讲到的通用计数方案来解决；\n 2. 在系统通知未读、全量用户打点等存在有限的共享存储的场景下，可以通过记录用户上次操作的时间或者偏移量，来实现未读方案；\n 3. 最后，信息流未读方案最为复杂，采用的是记录用户博文数快照的方式",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"分布式缓存",frontmatter:{title:"分布式缓存",date:"2024-09-14T02:09:39.000Z",permalink:"/pages/84cb49/"},regularPath:"/04.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/01.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98.html",relativePath:"04.设计基础设施/01.设计基础设施/01.分布式缓存.md",key:"v-415197ac",path:"/pages/84cb49/",headers:[{level:2,title:"需求",slug:"需求",normalizedTitle:"需求",charIndex:2},{level:2,title:"前置知识",slug:"前置知识",normalizedTitle:"前置知识",charIndex:124},{level:2,title:"渐进式设计",slug:"渐进式设计",normalizedTitle:"渐进式设计",charIndex:251},{level:3,title:"本地缓存",slug:"本地缓存",normalizedTitle:"本地缓存",charIndex:261},{level:3,title:"分布式缓存",slug:"分布式缓存",normalizedTitle:"分布式缓存",charIndex:272},{level:4,title:"认识分布式缓存",slug:"认识分布式缓存",normalizedTitle:"认识分布式缓存",charIndex:281},{level:4,title:"如何选择缓存节点？",slug:"如何选择缓存节点",normalizedTitle:"如何选择缓存节点？",charIndex:294},{level:4,title:"缓存客户端是什么？",slug:"缓存客户端是什么",normalizedTitle:"缓存客户端是什么？",charIndex:311},{level:4,title:"获取缓存节点列表",slug:"获取缓存节点列表",normalizedTitle:"获取缓存节点列表",charIndex:332},{level:2,title:"非功能设计",slug:"非功能设计",normalizedTitle:"非功能设计",charIndex:383},{level:3,title:"高可用",slug:"高可用",normalizedTitle:"高可用",charIndex:74},{level:3,title:"高可靠",slug:"高可靠",normalizedTitle:"高可靠",charIndex:403},{level:2,title:"还有什么重要的",slug:"还有什么重要的",normalizedTitle:"还有什么重要的",charIndex:482},{level:3,title:"一致性",slug:"一致性",normalizedTitle:"一致性",charIndex:149},{level:3,title:"数据过期",slug:"数据过期",normalizedTitle:"数据过期",charIndex:221},{level:3,title:"数据淘汰策略",slug:"数据淘汰策略",normalizedTitle:"数据淘汰策略",charIndex:533},{level:3,title:"本地缓存+远程缓存",slug:"本地缓存-远程缓存",normalizedTitle:"本地缓存+远程缓存",charIndex:544},{level:3,title:"安全",slug:"安全",normalizedTitle:"安全",charIndex:234},{level:3,title:"监控和日志",slug:"监控和日志",normalizedTitle:"监控和日志",charIndex:238},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:575}],headersStr:"需求 前置知识 渐进式设计 本地缓存 分布式缓存 认识分布式缓存 如何选择缓存节点？ 缓存客户端是什么？ 获取缓存节点列表 非功能设计 高可用 高可靠 还有什么重要的 一致性 数据过期 数据淘汰策略 本地缓存+远程缓存 安全 监控和日志 总结",content:"# 需求\n\n功能性\n\n * put(key,value)\n * get(key)\n\n非功能性\n\n * 高扩展（随着数据和请求的增加轻松扩展）\n * 高可用（硬件/网络故障下仍然可用）\n * 高性能（put和get的高性能！）\n * 持久化\n\n\n# 前置知识\n\n * LRU 算法\n\n * 哈希取模与一致性哈希算法\n\n * 专用缓存集群与共存缓存\n\n * 缓存客户端\n\n * 静态与动态缓存服务器列表配置\n\n * 主从复制\n\n * 缓存一致性、数据过期、本地和远程缓存、安全性、监控和日志记录。\n\n\n# 渐进式设计\n\n\n# 本地缓存\n\n\n\n\n# 分布式缓存\n\n# 认识分布式缓存\n\n\n\n# 如何选择缓存节点？\n\n\n\n\n\n# 缓存客户端是什么？\n\n\n\n * 客户端如何获取缓存节点列表？\n * 当扩容或缩容时，缓存节点列表如何更新？\n\n# 获取缓存节点列表\n\n\n\n\n# 非功能设计\n\n\n# 高可用\n\n\n\n\n# 高可靠\n\n * 数据异步复制到replica\n * 数据同步复制到replica\n * 数据同步复制到所有replica然后返回？\n\n我们需要权衡！\n\n\n# 还有什么重要的\n\n\n# 一致性\n\n引入同步复制，确保所有缓存节点的视图一致\n\n\n# 数据过期\n\n\n# 数据淘汰策略\n\n\n# 本地缓存+远程缓存\n\n\n# 安全\n\n\n# 监控和日志\n\n\n# 总结\n\n",normalizedContent:"# 需求\n\n功能性\n\n * put(key,value)\n * get(key)\n\n非功能性\n\n * 高扩展（随着数据和请求的增加轻松扩展）\n * 高可用（硬件/网络故障下仍然可用）\n * 高性能（put和get的高性能！）\n * 持久化\n\n\n# 前置知识\n\n * lru 算法\n\n * 哈希取模与一致性哈希算法\n\n * 专用缓存集群与共存缓存\n\n * 缓存客户端\n\n * 静态与动态缓存服务器列表配置\n\n * 主从复制\n\n * 缓存一致性、数据过期、本地和远程缓存、安全性、监控和日志记录。\n\n\n# 渐进式设计\n\n\n# 本地缓存\n\n\n\n\n# 分布式缓存\n\n# 认识分布式缓存\n\n\n\n# 如何选择缓存节点？\n\n\n\n\n\n# 缓存客户端是什么？\n\n\n\n * 客户端如何获取缓存节点列表？\n * 当扩容或缩容时，缓存节点列表如何更新？\n\n# 获取缓存节点列表\n\n\n\n\n# 非功能设计\n\n\n# 高可用\n\n\n\n\n# 高可靠\n\n * 数据异步复制到replica\n * 数据同步复制到replica\n * 数据同步复制到所有replica然后返回？\n\n我们需要权衡！\n\n\n# 还有什么重要的\n\n\n# 一致性\n\n引入同步复制，确保所有缓存节点的视图一致\n\n\n# 数据过期\n\n\n# 数据淘汰策略\n\n\n# 本地缓存+远程缓存\n\n\n# 安全\n\n\n# 监控和日志\n\n\n# 总结\n\n",charsets:{cjk:!0},lastUpdated:"2024/09/14, 20:19:06",lastUpdatedTimestamp:1726345146e3},{title:"限流器",frontmatter:{title:"限流器",date:"2024-09-14T02:09:39.000Z",permalink:"/pages/57d5a5/"},regularPath:"/04.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/01.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/02.%E9%99%90%E6%B5%81%E5%99%A8.html",relativePath:"04.设计基础设施/01.设计基础设施/02.限流器.md",key:"v-2432b466",path:"/pages/57d5a5/",headers:[{level:2,title:"概述",slug:"概述",normalizedTitle:"概述",charIndex:2},{level:2,title:"需求",slug:"需求",normalizedTitle:"需求",charIndex:190},{level:2,title:"前置知识",slug:"前置知识",normalizedTitle:"前置知识",charIndex:299},{level:2,title:"组件架构",slug:"组件架构",normalizedTitle:"组件架构",charIndex:438},{level:2,title:"接口和类",slug:"接口和类",normalizedTitle:"接口和类",charIndex:449},{level:2,title:"消息广播",slug:"消息广播",normalizedTitle:"消息广播",charIndex:355},{level:2,title:"如何集成",slug:"如何集成",normalizedTitle:"如何集成",charIndex:471},{level:2,title:"答疑解惑",slug:"答疑解惑",normalizedTitle:"答疑解惑",charIndex:482},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:753}],headersStr:"概述 需求 前置知识 组件架构 接口和类 消息广播 如何集成 答疑解惑 总结",content:"# 概述\n\n\n\n * 我们需要编写一个可扩展以处理高负载的软件吗？\n\n * 负载均衡器中已经实现了最大连接数和服务端点上的最大线程数呢。我们还需要节流吗？\n\n * * 这种机制是不加区别的，有些操作快，有些操作慢，负载均衡器不了解每个操作的成本，如果我们想对某个操作实现特定的限流，负载均衡器就不好使了\n\n * 我们如何单独控制每个主机呢？\n\n * * 主机间相互通信！\n\n\n# 需求\n\n功能性\n\n * allowRequest(request)\n\n非功能性\n\n * 低延迟（尽快做出决定）\n * 准确性（尽可能准确）\n * 可扩展（支持集群中任意数量的主机）\n * 高可用\n * 高可靠\n\n\n# 前置知识\n\n * 令牌桶算法\n * 速率限制解决方案的面向对象设计\n * 负载均衡器最大连接数，自动扩展\n * 消息广播：全网状网络拓扑、gossip 通信、分布式缓存、协调服务\n * 通信协议：TCP、UDP\n * 嵌入式速率限制器与守护进程\n * 存储桶管理、同步\n\n\n# 组件架构\n\n\n\n\n# 接口和类\n\n\n\n\n# 消息广播\n\n\n\n\n# 如何集成\n\n\n\n\n# 答疑解惑\n\n * 我的服务非常受欢迎，有数百万用户。这是否意味着内存中存储了数百万个桶？\n\n * * 可以瞬间增加很多桶，但是当桶没用的时候，可以删除桶\n\n * 有哪些失败的场景？\n\n * * 守护线程失败\n   * 网络分区，无法传播消息，每个主机将允许更多的请求\n\n * 我们是否需要一个自动配置管理服务？\n\n * 我有点担心同步问题。这不是瓶颈吗？\n\n * * 原则上来说 我们要重视并发安全\n   * 但是我们没有必要实现，会对性能造成影响\n\n * 当客户的请求被拒绝时，他们应该做什么？\n\n * * 重试（指数退避、抖动）\n\n\n# 总结\n\n",normalizedContent:"# 概述\n\n\n\n * 我们需要编写一个可扩展以处理高负载的软件吗？\n\n * 负载均衡器中已经实现了最大连接数和服务端点上的最大线程数呢。我们还需要节流吗？\n\n * * 这种机制是不加区别的，有些操作快，有些操作慢，负载均衡器不了解每个操作的成本，如果我们想对某个操作实现特定的限流，负载均衡器就不好使了\n\n * 我们如何单独控制每个主机呢？\n\n * * 主机间相互通信！\n\n\n# 需求\n\n功能性\n\n * allowrequest(request)\n\n非功能性\n\n * 低延迟（尽快做出决定）\n * 准确性（尽可能准确）\n * 可扩展（支持集群中任意数量的主机）\n * 高可用\n * 高可靠\n\n\n# 前置知识\n\n * 令牌桶算法\n * 速率限制解决方案的面向对象设计\n * 负载均衡器最大连接数，自动扩展\n * 消息广播：全网状网络拓扑、gossip 通信、分布式缓存、协调服务\n * 通信协议：tcp、udp\n * 嵌入式速率限制器与守护进程\n * 存储桶管理、同步\n\n\n# 组件架构\n\n\n\n\n# 接口和类\n\n\n\n\n# 消息广播\n\n\n\n\n# 如何集成\n\n\n\n\n# 答疑解惑\n\n * 我的服务非常受欢迎，有数百万用户。这是否意味着内存中存储了数百万个桶？\n\n * * 可以瞬间增加很多桶，但是当桶没用的时候，可以删除桶\n\n * 有哪些失败的场景？\n\n * * 守护线程失败\n   * 网络分区，无法传播消息，每个主机将允许更多的请求\n\n * 我们是否需要一个自动配置管理服务？\n\n * 我有点担心同步问题。这不是瓶颈吗？\n\n * * 原则上来说 我们要重视并发安全\n   * 但是我们没有必要实现，会对性能造成影响\n\n * 当客户的请求被拒绝时，他们应该做什么？\n\n * * 重试（指数退避、抖动）\n\n\n# 总结\n\n",charsets:{cjk:!0},lastUpdated:"2024/09/14, 20:19:06",lastUpdatedTimestamp:1726345146e3},{title:"秒杀",frontmatter:{title:"秒杀",date:"2024-09-14T16:51:28.000Z",permalink:"/pages/a72629/"},regularPath:"/03.%E7%BB%8F%E5%85%B8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/01.%E7%83%AD%E9%97%A8%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/05.%E7%A7%92%E6%9D%80.html",relativePath:"03.经典场景设计/01.热门场景设计/05.秒杀.md",key:"v-b8b11d74",path:"/pages/a72629/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"秒杀会有哪些问题",slug:"秒杀会有哪些问题",normalizedTitle:"秒杀会有哪些问题",charIndex:21},{level:2,title:"解决方案",slug:"解决方案",normalizedTitle:"解决方案",charIndex:1438},{level:3,title:"前端",slug:"前端",normalizedTitle:"前端",charIndex:1447},{level:3,title:"Nginx",slug:"nginx",normalizedTitle:"nginx",charIndex:2626},{level:3,title:"风控",slug:"风控",normalizedTitle:"风控",charIndex:2613},{level:3,title:"后端",slug:"后端",normalizedTitle:"后端",charIndex:1535},{level:3,title:"数据库",slug:"数据库",normalizedTitle:"数据库",charIndex:1180},{level:3,title:"分布式事务",slug:"分布式事务",normalizedTitle:"分布式事务",charIndex:4905},{level:3,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:5198},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:5347}],headersStr:"前言 秒杀会有哪些问题 解决方案 前端 Nginx 风控 后端 数据库 分布式事务 总结 参考文献",content:"# 前言\n\n秒杀系统的架构图\n\n\n\n\n# 秒杀会有哪些问题\n\n高并发\n\n是的高并发这个是我们想都不用想的一个点，一瞬间这么多人进来这不是高并发什么时候是呢？\n\n是吧，秒杀的特点就是这样时间极短、 瞬间用户量大。\n\n正常的店铺营销都是用极低的价格配合上短信、APP的精准推送，吸引特别多的用户来参与这场秒杀，爽了商家苦了开发呀。\n\n秒杀大家都知道如果真的营销到位，价格诱人，几十万的流量我觉得完全不是问题，那单机的Redis我感觉3-4W的QPS还是能顶得住的，但是再高了就没办法了，那这个数据随便搞个热销商品的秒杀可能都不止了。\n\n大量的请求进来，我们需要考虑的点就很多了，缓存雪崩，缓存击穿，缓存穿透这些我之前提到的点都是有可能发生的，出现问题打挂DB那就很难受了，活动失败用户体验差，活动人气没了，最后背锅的还是开发\n\n超卖\n\n但凡是个秒杀，都怕超卖，如果卖的是尿不湿还好，要是换成100个MacBook Pro，商家的预算经费卖100个可以赚点还可以造势，结果你写错程序多卖出去200个，你不发货用户投诉你，平台封你店，你发货就血亏，你怎么办？\n\n那最后只能杀个开发祭天解气了，秒杀的价格本来就低了，基本上都是不怎么赚钱的，超卖了就恐怖了呀，所以超卖也是很关键的一个点。\n\n恶意请求\n\n你这么低的价格，假如我抢到了，我转手卖掉我不是血赚？就算我不卖我也不亏啊，那用户知道，你知道，别的别有用心的人（黑客、黄牛…）肯定也知道的。\n\n那简单啊，我知道你什么时候抢，我搞个几十台机器搞点脚本，我也模拟出来十几万个人左右的请求，那我是不是意味着我基本上有80%的成功率了。\n\n真实情况可能远远不止，因为机器请求的速度比人的手速往往快太多了，在贵州的敖丙我每年回家抢高铁票都是秒光的，我也不知道有没有黄牛的功劳，我要Diss你，黄牛。杰伦演唱会门票抢不到，我也Diss你。\n\nTip：科普下，小道消息了解到的，黄牛的抢票系统，比国内很多小公司的系统还吊很多，架构设计都是顶级的，我用顶配的服务加上顶配的架构设计，你还想看演唱会？还想回家？\n\n不过不用黄牛我回家都难，我们云贵川跟我一样要回家过年的仔太多了555！\n\n链接暴露\n\n前面几个问题大家可能都很好理解，一看到这个有的小伙伴可能会比较疑惑，啥是链接暴露呀？\n\n相信是个开发同学都对这个画面一点都不陌生吧，懂点行的仔都可以打开谷歌的开发者模式，然后看看你的网页代码，有的就有URL，但是我写VUE的时候是事件触发然后去调用文件里面的接口看源码看不到，但是我可以点击一下查看你的请求地址啊，不过你好像可以对按钮在秒杀前置灰。\n\n不管怎么样子都有危险，撇开外面的所有的东西你都挡住了，你卖这个东西实在便宜得过分，有诱惑力，你能保证开发不动心？开发知道地址，在秒杀的时候自己提前请求。。。（开发：怎么TM又是我）\n\n数据库\n\n每秒上万甚至十几万的QPS（每秒请求数）直接打到数据库，基本上都要把库打挂掉，而且你服务不单单是做秒杀的还涉及其他的业务，你没做降级、限流、熔断啥的，别的一起挂，小公司的话可能全站崩溃404。\n\n反正不管你秒杀怎么挂，你别把别的搞挂了对吧，搞挂了就不是杀一个程序员能搞定的。\n\n程序员：我TM好难啊！\n\n问题都列出来了，那怎么设计，怎么解决这些问题就是接下去要考虑的了，我们对症下药。\n\n我会从我设计的秒杀系统从上到下去给大家介绍我们正常电商秒杀系统在每一层做了些什么，每一层存在的问题，难点等。\n\n\n# 解决方案\n\n\n# 前端\n\n秒杀系统普遍都是商城网页、H5、APP、小程序这几项。\n\n在前端这一层其实我们可以做的事情有很多，如果用node去做，甚至能直接处理掉整个秒杀，但是node其实应该属于后端，所以我不讨论node Service了。\n\n资源静态化\n\n秒杀一般都是特定的商品还有页面模板，现在一般都是前后端分离的，页面一般都是不会经过后端的，但是前端也要自己的服务器啊，那就把能提前放入cdn服务器的东西都放进去，反正把所有能提升效率的步骤都做一下，减少真正秒杀时候服务器的压力。\n\n秒杀链接加盐\n\n我们上面说了链接要是提前暴露出去可能有人直接访问url就提前秒杀了，那又有小伙伴要说了我做个时间的校验就好了呀，那我告诉你，知道链接的地址比起页面人工点击的还是有很大优势。\n\n我知道url了，那我通过程序不断获取最新的北京时间，可以达到毫秒级别的，我就在00毫秒的时候请求，我敢说绝对比你人工点的成功率大太多了，而且我可以一毫秒发送N次请求，搞不好你卖100个产品我全拿了。\n\n那这种情况怎么避免？把URL动态化，就连写代码的人都不知道，你就通过MD5之类的摘要算法加密随机的字符串去做url，然后通过前端代码获取url后台校验才能通过。\n\n这个只能防止一部分没耐心继续破解下去的黑客，有耐心的人研究出来还是能破解，在电商场景存在很多这样的羊毛党，那怎么做呢？后面我会说。\n\n限流\n\n限流这里我觉得应该分为前端限流和后端限流。\n\n物理控制\n\n大家有没有发现没到秒杀前，一般按钮都是置灰的，只有时间到了，才能点击。\n\n这是因为怕大家在时间快到的最后几秒秒疯狂请求服务器，然后还没到秒杀的时候基本上服务器就挂了。\n\n这个时候就需要前端的配合，定时去请求你的后端服务器，获取最新的北京时间，到时间点再给按钮可用状态。\n\n按钮可以点击之后也得给他置灰几秒，不然他一样在开始之后一直点的。\n\n你敢说你们秒杀的时候不是这样的？\n\n前端限流：这个很简单，一般秒杀不会让你一直点的，一般都是点击一下或者两下然后几秒之后才可以继续点击，这也是保护服务器的一种手段。\n\n后端限流：秒杀的时候肯定是涉及到后续的订单生成和支付等操作，但是都只是成功的幸运儿才会走到那一步，那一旦100个产品卖光了，return了一个false，前端直接秒杀结束，然后你后端也关闭后续无效请求的介入了。\n\nTip：真正的限流还会有限流组件的加入例如：阿里的Sentinel、Hystrix等。我这里就不展开了，就说一下物理的限流。\n\n我们卖1000件商品，请求有10W，我们不需要把十万都放进来，你可以放1W请求进来，然后再进行操作，因为秒杀对于用户本身就是黑盒的，所以你怎么做的他们是没感知的，至于为啥放1W进来，而不是刚好1000，是因为会丢掉一些薅羊毛的用户，至于怎么判断，后面的风控阶段我会说。\n\n\n# Nginx\n\nNginx大家想必都不陌生了吧，这玩意是高性能的web服务器，并发也随便顶几万不是梦，但是我们的Tomcat只能顶几百的并发呀，那简单呀负载均衡嘛，一台服务几百，那就多搞点，在秒杀的时候多租点流量机。\n\nTip：据我所知国内某大厂就是在去年春节活动期间租光了亚洲所有的服务器，小公司也很喜欢在双十一期间买流量机来顶住压力。\n\n恶意请求拦截也需要用到它，一般单个用户请求次数太夸张，不像人为的请求在网关那一层就得拦截掉了，不然请求多了他抢不抢得到是一回事，服务器压力上去了，可能占用网络带宽或者把服务器打崩、缓存击穿等等\n\n\n# 风控\n\n我可以明确的告诉大家，前面的所有措施还是拦不住很多羊毛党，因为他们是专业的团队，他们可以注册很多账号来薅你的羊毛，而且不用机器请求，就用群控，操作几乎跟真实用户一模一样。\n\n那怎么办，是不是无解了？\n\n这个时候就需要风控同学的介入了，在请求到达后端之前，风控可以根据账号行为分析出这个账号机器人的概率大不大，我现在负责公司的某些特殊系统，每个用户的行为都是会送到我们大数据团队进行分析处理，给你打上对应标签的。\n\n那黑客其实也有办法：养号\n\n他们去黑市买真实用户有过很多记录的账号，买到了还不闲着，帮他们去购物啥的，让系统无法识别他们是黑号还是真实用户的号。\n\n怎么办？\n\n通杀！是的没有办法，只能通杀了，通杀的意思就是，我们通过风管分析出来这个用户是真实用户的概率没有其他用户概率大，那就认为他是机器了，丢弃他的请求。\n\n之前的限流我们放进来10000个请求，但是我们真正的库存只有1000个，那我们就算出最有可能是真实用户的1000人进行秒杀，丢弃其他请求，因为秒杀本来就是黑盒操作的，用户层面是无感知的，这样设计能让真实的用户买到东西，还可以减少自己被薅羊毛的概率。\n\n风控可以说是流量进入的最后一道门槛了，所以很多公司的风控是很强的，蚂蚁金服的风控大家如果了解过就知道了，你的资金在支付宝被盗了，他们是能做到全款补偿是有原因的。\n\n\n# 后端\n\n服务单一职责\n\n设计个能抗住高并发的系统，我觉得还是得单一职责。\n\n什么意思呢，大家都知道现在设计都是微服务的设计思想，然后再用分布式的部署方式。\n\n也就是我们下单是有个订单服务，用户登录管理等有个用户服务等等，那为啥我们不给秒杀也开个服务，我们把秒杀的代码业务逻辑放一起。\n\n单一职责的好处就是就算秒杀没抗住，秒杀库崩了，服务挂了，也不会影响到其他的服务。（高可用）\n\nRedis 集群\n\n之前不是说单机的Redis顶不住嘛，那简单多找几个兄弟啊，秒杀本来就是读多写少，那你们是不是瞬间想起来我之前跟你们提到过的，Redis集群，主从同步、读写分离，我们还搞点哨兵，开启持久化直接无敌高可用！\n\n库存预热\n\n秒杀的本质，就是对库存的抢夺，每个秒杀的用户来你都去数据库查询库存校验库存，然后扣减库存，撇开性能因数，你不觉得这样好繁琐，对业务开发人员都不友好，而且数据库顶不住啊。\n\n我们都知道数据库顶不住但是他的兄弟非关系型的数据库Redis能顶啊！\n\n那不简单了，我们要开始秒杀前你通过定时任务或者运维同学提前把商品的库存加载到Redis中去，让整个流程都在Redis里面去做，然后等秒杀介绍了，再异步的去修改库存就好了。\n\n但是用了Redis就有一个问题了，我们上面说了我们采用主从，就是我们会去读取库存然后再判断然后有库存才去减库存，正常情况没问题，但是高并发的情况问题就很大了。\n\n**多品几遍！！！**就比如现在库存只剩下1个了，我们高并发嘛，4个服务器一起查询了发现都是还有1个，那大家都觉得是自己抢到了，就都去扣库存，那结果就变成了-3，是的只有一个是真的抢到了，别的都是超卖的。咋办？\n\n事务\n\nRedis本身是支持事务的，而且他有很多原子命令的，大家也可以用LUA，还可以用他的管道，乐观锁他也知支持。\n\n限流&降级&熔断&隔离\n\n这个为啥要做呢，不怕一万就怕万一，万一你真的顶不住了，限流，顶不住就挡一部分出去但是不能说不行，降级，降级了还是被打挂了，熔断，至少不要影响别的系统，隔离，你本身就独立的，但是你会调用其他的系统嘛，你快不行了你别拖累兄弟们啊。\n\n消息队列（削峰填谷）\n\n一说到这个名词，很多小伙伴就知道了，对的MQ，你买东西少了你直接100个请求改库我觉得没问题，但是万一秒杀一万个，10万个呢？服务器挂了，程序员又要背锅的。\n\n秒杀就是这种瞬间流量很高，但是平时又没有流量的场景，那消息队列完全契合这样的场景了呀，削峰填谷。\n\n\n\nTip：可能小伙伴说我们业务达不到这个量级，没必要。但是我想说我们写代码，就不应该写出有逻辑漏洞的代码，至少以后公司体量上去了，别人一看居然不用改代码，一看代码作者是xxx？有点东西！\n\n你可以把它放消息队列，然后一点点消费去改库存就好了嘛，不过单个商品其实一次修改就够了，我这里说的是某个点多个商品一起秒杀的场景，像极了双十一零点。\n\n\n# 数据库\n\n数据库用MySQL只要连接池设置合理一般问题是不大的，不过一般大公司不缺钱而且秒杀这样的活动十分频繁，我之前所在的公司就是这样秒杀特卖这样的场景一直都是不间断的。\n\n单独给秒杀建立一个数据库，为秒杀服务，表的设计也是竟可能的简单点，现在的互联网架构部署都是分库的。\n\n至于表就看大家怎么设计了，该设置索引的地方还是要设置索引的，建完后记得用explain看看SQL的执行计划。（不了解的小伙伴也没事，MySQL章节去康康）\n\n\n# 分布式事务\n\n这为啥我不放在后端而放到最后来讲呢？\n\n因为上面的任何一步都是可能出错的，而且我们是在不同的服务里面出错的，那就涉及分布式事务了，但是分布式事务大家想的是一定要成功什么的那就不对了，还是那句话，几个请求丢了就丢了，要保证时效和服务的可用可靠。\n\n所以TCC和最终一致性其实不是很适合，TCC开发成本很大，所有接口都要写三次，因为涉及TCC的三个阶段。\n\n最终一致性基本上都是靠轮训的操作去保证一个操作一定成功，那时效性就大打折扣了。\n\n大家觉得不那么可靠的**两段式（2PC）和三段式（3PC）**就派上用场了，他们不一定能保证数据最终一致，但是效率上还算ok。\n\n\n# 总结\n\n到这里我想我已经基本上把该考虑的点还有对应的解决方案也都说了一下，不知道还有没有没考虑到的，但是就算没考虑到我想我这个设计，应该也能撑住一个完整的秒杀流程。\n\n最后大家再看看这个秒杀系统或许会有新的感悟，是不是一个系统真的没有大家想的那么简单，而且我还是有漏掉的细节，这是一定的。\n\n\n# 参考文献\n\n面试了十个应届生九个都是秒杀系统，你确定你们那是秒杀？_小公司的qps只有几十-CSDN博客",normalizedContent:"# 前言\n\n秒杀系统的架构图\n\n\n\n\n# 秒杀会有哪些问题\n\n高并发\n\n是的高并发这个是我们想都不用想的一个点，一瞬间这么多人进来这不是高并发什么时候是呢？\n\n是吧，秒杀的特点就是这样时间极短、 瞬间用户量大。\n\n正常的店铺营销都是用极低的价格配合上短信、app的精准推送，吸引特别多的用户来参与这场秒杀，爽了商家苦了开发呀。\n\n秒杀大家都知道如果真的营销到位，价格诱人，几十万的流量我觉得完全不是问题，那单机的redis我感觉3-4w的qps还是能顶得住的，但是再高了就没办法了，那这个数据随便搞个热销商品的秒杀可能都不止了。\n\n大量的请求进来，我们需要考虑的点就很多了，缓存雪崩，缓存击穿，缓存穿透这些我之前提到的点都是有可能发生的，出现问题打挂db那就很难受了，活动失败用户体验差，活动人气没了，最后背锅的还是开发\n\n超卖\n\n但凡是个秒杀，都怕超卖，如果卖的是尿不湿还好，要是换成100个macbook pro，商家的预算经费卖100个可以赚点还可以造势，结果你写错程序多卖出去200个，你不发货用户投诉你，平台封你店，你发货就血亏，你怎么办？\n\n那最后只能杀个开发祭天解气了，秒杀的价格本来就低了，基本上都是不怎么赚钱的，超卖了就恐怖了呀，所以超卖也是很关键的一个点。\n\n恶意请求\n\n你这么低的价格，假如我抢到了，我转手卖掉我不是血赚？就算我不卖我也不亏啊，那用户知道，你知道，别的别有用心的人（黑客、黄牛…）肯定也知道的。\n\n那简单啊，我知道你什么时候抢，我搞个几十台机器搞点脚本，我也模拟出来十几万个人左右的请求，那我是不是意味着我基本上有80%的成功率了。\n\n真实情况可能远远不止，因为机器请求的速度比人的手速往往快太多了，在贵州的敖丙我每年回家抢高铁票都是秒光的，我也不知道有没有黄牛的功劳，我要diss你，黄牛。杰伦演唱会门票抢不到，我也diss你。\n\ntip：科普下，小道消息了解到的，黄牛的抢票系统，比国内很多小公司的系统还吊很多，架构设计都是顶级的，我用顶配的服务加上顶配的架构设计，你还想看演唱会？还想回家？\n\n不过不用黄牛我回家都难，我们云贵川跟我一样要回家过年的仔太多了555！\n\n链接暴露\n\n前面几个问题大家可能都很好理解，一看到这个有的小伙伴可能会比较疑惑，啥是链接暴露呀？\n\n相信是个开发同学都对这个画面一点都不陌生吧，懂点行的仔都可以打开谷歌的开发者模式，然后看看你的网页代码，有的就有url，但是我写vue的时候是事件触发然后去调用文件里面的接口看源码看不到，但是我可以点击一下查看你的请求地址啊，不过你好像可以对按钮在秒杀前置灰。\n\n不管怎么样子都有危险，撇开外面的所有的东西你都挡住了，你卖这个东西实在便宜得过分，有诱惑力，你能保证开发不动心？开发知道地址，在秒杀的时候自己提前请求。。。（开发：怎么tm又是我）\n\n数据库\n\n每秒上万甚至十几万的qps（每秒请求数）直接打到数据库，基本上都要把库打挂掉，而且你服务不单单是做秒杀的还涉及其他的业务，你没做降级、限流、熔断啥的，别的一起挂，小公司的话可能全站崩溃404。\n\n反正不管你秒杀怎么挂，你别把别的搞挂了对吧，搞挂了就不是杀一个程序员能搞定的。\n\n程序员：我tm好难啊！\n\n问题都列出来了，那怎么设计，怎么解决这些问题就是接下去要考虑的了，我们对症下药。\n\n我会从我设计的秒杀系统从上到下去给大家介绍我们正常电商秒杀系统在每一层做了些什么，每一层存在的问题，难点等。\n\n\n# 解决方案\n\n\n# 前端\n\n秒杀系统普遍都是商城网页、h5、app、小程序这几项。\n\n在前端这一层其实我们可以做的事情有很多，如果用node去做，甚至能直接处理掉整个秒杀，但是node其实应该属于后端，所以我不讨论node service了。\n\n资源静态化\n\n秒杀一般都是特定的商品还有页面模板，现在一般都是前后端分离的，页面一般都是不会经过后端的，但是前端也要自己的服务器啊，那就把能提前放入cdn服务器的东西都放进去，反正把所有能提升效率的步骤都做一下，减少真正秒杀时候服务器的压力。\n\n秒杀链接加盐\n\n我们上面说了链接要是提前暴露出去可能有人直接访问url就提前秒杀了，那又有小伙伴要说了我做个时间的校验就好了呀，那我告诉你，知道链接的地址比起页面人工点击的还是有很大优势。\n\n我知道url了，那我通过程序不断获取最新的北京时间，可以达到毫秒级别的，我就在00毫秒的时候请求，我敢说绝对比你人工点的成功率大太多了，而且我可以一毫秒发送n次请求，搞不好你卖100个产品我全拿了。\n\n那这种情况怎么避免？把url动态化，就连写代码的人都不知道，你就通过md5之类的摘要算法加密随机的字符串去做url，然后通过前端代码获取url后台校验才能通过。\n\n这个只能防止一部分没耐心继续破解下去的黑客，有耐心的人研究出来还是能破解，在电商场景存在很多这样的羊毛党，那怎么做呢？后面我会说。\n\n限流\n\n限流这里我觉得应该分为前端限流和后端限流。\n\n物理控制\n\n大家有没有发现没到秒杀前，一般按钮都是置灰的，只有时间到了，才能点击。\n\n这是因为怕大家在时间快到的最后几秒秒疯狂请求服务器，然后还没到秒杀的时候基本上服务器就挂了。\n\n这个时候就需要前端的配合，定时去请求你的后端服务器，获取最新的北京时间，到时间点再给按钮可用状态。\n\n按钮可以点击之后也得给他置灰几秒，不然他一样在开始之后一直点的。\n\n你敢说你们秒杀的时候不是这样的？\n\n前端限流：这个很简单，一般秒杀不会让你一直点的，一般都是点击一下或者两下然后几秒之后才可以继续点击，这也是保护服务器的一种手段。\n\n后端限流：秒杀的时候肯定是涉及到后续的订单生成和支付等操作，但是都只是成功的幸运儿才会走到那一步，那一旦100个产品卖光了，return了一个false，前端直接秒杀结束，然后你后端也关闭后续无效请求的介入了。\n\ntip：真正的限流还会有限流组件的加入例如：阿里的sentinel、hystrix等。我这里就不展开了，就说一下物理的限流。\n\n我们卖1000件商品，请求有10w，我们不需要把十万都放进来，你可以放1w请求进来，然后再进行操作，因为秒杀对于用户本身就是黑盒的，所以你怎么做的他们是没感知的，至于为啥放1w进来，而不是刚好1000，是因为会丢掉一些薅羊毛的用户，至于怎么判断，后面的风控阶段我会说。\n\n\n# nginx\n\nnginx大家想必都不陌生了吧，这玩意是高性能的web服务器，并发也随便顶几万不是梦，但是我们的tomcat只能顶几百的并发呀，那简单呀负载均衡嘛，一台服务几百，那就多搞点，在秒杀的时候多租点流量机。\n\ntip：据我所知国内某大厂就是在去年春节活动期间租光了亚洲所有的服务器，小公司也很喜欢在双十一期间买流量机来顶住压力。\n\n恶意请求拦截也需要用到它，一般单个用户请求次数太夸张，不像人为的请求在网关那一层就得拦截掉了，不然请求多了他抢不抢得到是一回事，服务器压力上去了，可能占用网络带宽或者把服务器打崩、缓存击穿等等\n\n\n# 风控\n\n我可以明确的告诉大家，前面的所有措施还是拦不住很多羊毛党，因为他们是专业的团队，他们可以注册很多账号来薅你的羊毛，而且不用机器请求，就用群控，操作几乎跟真实用户一模一样。\n\n那怎么办，是不是无解了？\n\n这个时候就需要风控同学的介入了，在请求到达后端之前，风控可以根据账号行为分析出这个账号机器人的概率大不大，我现在负责公司的某些特殊系统，每个用户的行为都是会送到我们大数据团队进行分析处理，给你打上对应标签的。\n\n那黑客其实也有办法：养号\n\n他们去黑市买真实用户有过很多记录的账号，买到了还不闲着，帮他们去购物啥的，让系统无法识别他们是黑号还是真实用户的号。\n\n怎么办？\n\n通杀！是的没有办法，只能通杀了，通杀的意思就是，我们通过风管分析出来这个用户是真实用户的概率没有其他用户概率大，那就认为他是机器了，丢弃他的请求。\n\n之前的限流我们放进来10000个请求，但是我们真正的库存只有1000个，那我们就算出最有可能是真实用户的1000人进行秒杀，丢弃其他请求，因为秒杀本来就是黑盒操作的，用户层面是无感知的，这样设计能让真实的用户买到东西，还可以减少自己被薅羊毛的概率。\n\n风控可以说是流量进入的最后一道门槛了，所以很多公司的风控是很强的，蚂蚁金服的风控大家如果了解过就知道了，你的资金在支付宝被盗了，他们是能做到全款补偿是有原因的。\n\n\n# 后端\n\n服务单一职责\n\n设计个能抗住高并发的系统，我觉得还是得单一职责。\n\n什么意思呢，大家都知道现在设计都是微服务的设计思想，然后再用分布式的部署方式。\n\n也就是我们下单是有个订单服务，用户登录管理等有个用户服务等等，那为啥我们不给秒杀也开个服务，我们把秒杀的代码业务逻辑放一起。\n\n单一职责的好处就是就算秒杀没抗住，秒杀库崩了，服务挂了，也不会影响到其他的服务。（高可用）\n\nredis 集群\n\n之前不是说单机的redis顶不住嘛，那简单多找几个兄弟啊，秒杀本来就是读多写少，那你们是不是瞬间想起来我之前跟你们提到过的，redis集群，主从同步、读写分离，我们还搞点哨兵，开启持久化直接无敌高可用！\n\n库存预热\n\n秒杀的本质，就是对库存的抢夺，每个秒杀的用户来你都去数据库查询库存校验库存，然后扣减库存，撇开性能因数，你不觉得这样好繁琐，对业务开发人员都不友好，而且数据库顶不住啊。\n\n我们都知道数据库顶不住但是他的兄弟非关系型的数据库redis能顶啊！\n\n那不简单了，我们要开始秒杀前你通过定时任务或者运维同学提前把商品的库存加载到redis中去，让整个流程都在redis里面去做，然后等秒杀介绍了，再异步的去修改库存就好了。\n\n但是用了redis就有一个问题了，我们上面说了我们采用主从，就是我们会去读取库存然后再判断然后有库存才去减库存，正常情况没问题，但是高并发的情况问题就很大了。\n\n**多品几遍！！！**就比如现在库存只剩下1个了，我们高并发嘛，4个服务器一起查询了发现都是还有1个，那大家都觉得是自己抢到了，就都去扣库存，那结果就变成了-3，是的只有一个是真的抢到了，别的都是超卖的。咋办？\n\n事务\n\nredis本身是支持事务的，而且他有很多原子命令的，大家也可以用lua，还可以用他的管道，乐观锁他也知支持。\n\n限流&降级&熔断&隔离\n\n这个为啥要做呢，不怕一万就怕万一，万一你真的顶不住了，限流，顶不住就挡一部分出去但是不能说不行，降级，降级了还是被打挂了，熔断，至少不要影响别的系统，隔离，你本身就独立的，但是你会调用其他的系统嘛，你快不行了你别拖累兄弟们啊。\n\n消息队列（削峰填谷）\n\n一说到这个名词，很多小伙伴就知道了，对的mq，你买东西少了你直接100个请求改库我觉得没问题，但是万一秒杀一万个，10万个呢？服务器挂了，程序员又要背锅的。\n\n秒杀就是这种瞬间流量很高，但是平时又没有流量的场景，那消息队列完全契合这样的场景了呀，削峰填谷。\n\n\n\ntip：可能小伙伴说我们业务达不到这个量级，没必要。但是我想说我们写代码，就不应该写出有逻辑漏洞的代码，至少以后公司体量上去了，别人一看居然不用改代码，一看代码作者是xxx？有点东西！\n\n你可以把它放消息队列，然后一点点消费去改库存就好了嘛，不过单个商品其实一次修改就够了，我这里说的是某个点多个商品一起秒杀的场景，像极了双十一零点。\n\n\n# 数据库\n\n数据库用mysql只要连接池设置合理一般问题是不大的，不过一般大公司不缺钱而且秒杀这样的活动十分频繁，我之前所在的公司就是这样秒杀特卖这样的场景一直都是不间断的。\n\n单独给秒杀建立一个数据库，为秒杀服务，表的设计也是竟可能的简单点，现在的互联网架构部署都是分库的。\n\n至于表就看大家怎么设计了，该设置索引的地方还是要设置索引的，建完后记得用explain看看sql的执行计划。（不了解的小伙伴也没事，mysql章节去康康）\n\n\n# 分布式事务\n\n这为啥我不放在后端而放到最后来讲呢？\n\n因为上面的任何一步都是可能出错的，而且我们是在不同的服务里面出错的，那就涉及分布式事务了，但是分布式事务大家想的是一定要成功什么的那就不对了，还是那句话，几个请求丢了就丢了，要保证时效和服务的可用可靠。\n\n所以tcc和最终一致性其实不是很适合，tcc开发成本很大，所有接口都要写三次，因为涉及tcc的三个阶段。\n\n最终一致性基本上都是靠轮训的操作去保证一个操作一定成功，那时效性就大打折扣了。\n\n大家觉得不那么可靠的**两段式（2pc）和三段式（3pc）**就派上用场了，他们不一定能保证数据最终一致，但是效率上还算ok。\n\n\n# 总结\n\n到这里我想我已经基本上把该考虑的点还有对应的解决方案也都说了一下，不知道还有没有没考虑到的，但是就算没考虑到我想我这个设计，应该也能撑住一个完整的秒杀流程。\n\n最后大家再看看这个秒杀系统或许会有新的感悟，是不是一个系统真的没有大家想的那么简单，而且我还是有漏掉的细节，这是一定的。\n\n\n# 参考文献\n\n面试了十个应届生九个都是秒杀系统，你确定你们那是秒杀？_小公司的qps只有几十-csdn博客",charsets:{cjk:!0},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"热点探查（Top k）",frontmatter:{title:"热点探查（Top k）",date:"2024-09-14T03:52:03.000Z",permalink:"/pages/5dcb6b/"},regularPath:"/04.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/01.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/03.%E7%83%AD%E7%82%B9%E6%8E%A2%E6%9F%A5%EF%BC%88Top%20k%EF%BC%89.html",relativePath:"04.设计基础设施/01.设计基础设施/03.热点探查（Top k）.md",key:"v-04b7b9e3",path:"/pages/5dcb6b/",headers:[{level:2,title:"概述",slug:"概述",normalizedTitle:"概述",charIndex:2},{level:2,title:"前置知识",slug:"前置知识",normalizedTitle:"前置知识",charIndex:313},{level:2,title:"需求",slug:"需求",normalizedTitle:"需求",charIndex:373},{level:2,title:"渐进设计",slug:"渐进设计",normalizedTitle:"渐进设计",charIndex:600},{level:3,title:"哈希表+单主机",slug:"哈希表-单主机",normalizedTitle:"哈希表+单主机",charIndex:609},{level:3,title:"哈希表+多主机",slug:"哈希表-多主机",normalizedTitle:"哈希表+多主机",charIndex:739},{level:3,title:"哈希表+多主机+分区",slug:"哈希表-多主机-分区",normalizedTitle:"哈希表+多主机+分区",charIndex:830},{level:3,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:959},{level:2,title:"高层架构",slug:"高层架构",normalizedTitle:"高层架构",charIndex:1630},{level:2,title:"客户端检索数据",slug:"客户端检索数据",normalizedTitle:"客户端检索数据",charIndex:2400},{level:2,title:"解答疑惑",slug:"解答疑惑",normalizedTitle:"解答疑惑",charIndex:2485},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:5033}],headersStr:"概述 前置知识 需求 渐进设计 哈希表+单主机 哈希表+多主机 哈希表+多主机+分区 总结 高层架构 客户端检索数据 解答疑惑 参考资料",content:"# 概述\n\nTop k 问题解决方案的各种应用（Google/Twitter/YouTube 趋势、热门产品、波动性股票、DDoS 攻击预防）。\n\n在这样的规模下，数据库或分布式缓存不是一个选项。我们可能正在处理 1M RPS。如果我们使用 DB 来跟踪视图计数，首先写入/更新会非常慢，然后找到前 K 项需要扫描整个数据集。\n\n也许 MapReduce 可以提供帮助。但这还不够。我们需要尽可能接近实时地返回重磅统计数据。\n\n例如：\n\n * Calculate top 100 list for last\n * 1 min, 5 min, 15 mins, 60 mins etc.\n\n这使得这个问题成为流处理问题\n\n\n# 前置知识\n\nMapReduce\n\nCount-min sketch\n\n数据聚合原理\n\n合并 N 个排序列表问题\n\n\n# 需求\n\n功能\n\n * topK(k,startTime,endTime)\n\n非功能\n\n * 高扩展（随着数据量的增加而扩展：视频、推文、帖子等）\n * 高可用性（在硬件/网络故障中幸存，没有 SPOF）\n * 高性能（返回前100名列表需要几十毫秒，考虑到性能要求，这暗示了最终列表应该预先计算，我们应该避免在调用 top K API 时进行繁重的计算。）\n * 准确性（例如，通过使用数据采样，我们可能不会计算每个元素，而只计算一小部分事件）\n\n\n# 渐进设计\n\n\n# 哈希表+单主机\n\n * 在 hashmap 中保留传入事件列表的计数\n\n * * 按频率对 hashmap 中的条目列表进行排序，并返回前 K 个元素。时间 O(nLogN)\n   * 将元素放在大小为 K 的堆上。时间复杂度O(nLogK)\n\n\n\n\n\n\n# 哈希表+多主机\n\n * 如果您将所有 youtube 视频 ID 存储在您作为主机的内存中，内存将是一个问题\n\n\n\n虽然增加了吞吐量，但是有内存瓶颈，hash 表会越来越大\n\n\n# 哈希表+多主机+分区\n\n * 我们不会将所有哈希表数据从所有主机发送到存储主机。相反，我们会在每个主机上单独计算 topK 列表，最后我们需要在存储主机上合并这些排序的列表。\n\n\n\n数据分区可以不将所有数据存储到一个主机上，减少了每个主机内存的压力\n\n\n# 总结\n\n问题\n\n * 我们认为数据集是无界的，这就是为什么我们能够考虑将其划分为多个块。但流数据没有界限。它不断涌现。在这种情况下，处理器主机只能在一段时间内继续积累数据，在此之前它将耗尽内存。比如 1 分钟。\n\n * * 我们将 1 min 数据刷新到存储主机\n   * 存储主机存储每分钟的热点列表\n   * 我们故意丢失了有关非 topK 元素的所有信息。我们负担不起在内存中存储每个视频的信息。\n   * 但是，如果我们想找到过去 1 小时或过去 1 天的 topK，我们如何使用 60 个 1 分钟 list 来构建它呢。鉴于当前的方法，没有解决此问题的正确方法。要找到当天的 topK，我们需要全天的完整数据集。\n   * 需求冲突，保留完整的 1 天数据（以满足需求）或丢失它以负担存储。让我们把所有数据存储在磁盘上，因为它无法放入内存，并使用批处理框架来做 topK 列表。Map Reduce 架构将发挥作用\n\n * 每次引入数据分区时，我们都必须考虑数据复制，以便将每个分区的副本存储在多个节点上。我们需要考虑在集群中添加/删除新节点时重新平衡。我们需要处理热分区。\n\n解决方案\n\n在进入上面讨论的方法之前，让我们想一想是否有一个简单的解决方案来解决 topK 问题？\n\n权衡利弊权衡利弊，所有的选择，不过是权衡利弊罢了\n\n我们需要在此过程中做出牺牲。准确性就是牺牲\n\n我们要合理利用数据结构，这将帮助我们使用固定大小的内存计算 topK，但结果可能不是 100% 准确\n\nCount-Min Sketch！\n\n\n\n\n# 高层架构\n\n\n\n * API Gateway：连接到视频内容交付系统，该系统将提供视频请求\n\n * * 对于我们的用例，我们对 API 网关的 1 个功能感兴趣，即日志生成，其中记录对 API 的每次调用。通常这些日志用于监控、日志记录和审计。我们将使用这些日志来计算每个视频的观看次数。我们可能有一个后台进程，它从日志中读取数据，进行一些初始聚合并发送数据进行进一步处理。\n   * 为 API 网关服务上的缓冲区分配内存，读取日志行，并构建频率计数哈希表。此缓冲区的大小应有限，当缓冲区已满时，将刷新数据。如果缓冲区在某个时间段内未满，我们可以根据时间段进行 flush。\n   * 其他选项可以是动态聚合数据，而不写入日志文件。或者完全跳过 API 网关端的数据聚合，并将有关每个事件（正在查看的视频）的信息进一步发送以进行处理。评估每个选项的优缺点。\n   * 我们可以通过以紧凑的二进制格式（例如 Apache Avro）序列化数据来节省网络 IO 利用率，并让 CPU 付出代价。所有这些注意事项都取决于 API 网关主机上可用的资源，即内存、CPU、网络和磁盘 IO。\n\n * distributed messaging system：初始聚合数据将发送到分布式消息传递系统，如 Apache Kafka。\n\n * Fast path and Slow path\n\n * * 在 Fast path 中，我们将大致计算 topK hitter 的结果。结果将在几秒钟内提供。\n   * 在 slow path 中，我们将精确计算 topK hitter 的结果。几分钟/几小时内即可获得结果。\n   * 根据系统对系统时序的限制（是否需要近实时结果，或者延迟是否可以接受以实现精度），您应该选择任一路径。\n\n\n\n\n\n\n\n\n# 客户端检索数据\n\n\n\n合并 2 个不同的结果集来回答 API 调用并不准确，但这是一种权衡。您无法在任何时间聚合数据。您必须了解确切需要的东西，并据此进行构建。\n\n\n# 解答疑惑\n\n * 我们是否可以使用哈希映射，但每隔几秒钟将其内容（转换为堆后）刷新到存储中，而不是使用 CMS？\n\n * * 对于小规模，使用哈希映射是完全可以的。当规模增长时，哈希映射可能会变得太大（使用大量内存）。为了防止这种情况，我们可以对数据进行分区，以便只有所有数据的子集进入 Fast Processor 服务主机。但它使架构复杂化。CMS 的美妙之处在于它消耗有限的（定义的）内存，并且无需对数据进行分区。CMS 的缺点是它大约计算数字。权衡，权衡......\n\n * 我们如何将 count-min sketch 和 heap 存储到数据库中？如何设计 table 架构？\n\n * * Heap 只是一个一维数组。CMS 是一个二维数组。这意味着两者都可以很容易地序列化为字节数组。使用语言原生序列化 API 或备受推崇的序列化框架（Protobufs、Thrift、Avro）。我们可以将它们以这种形式存储在数据库中。\n\n * 虽然 CMS 是为了节省内存，但我们还有 n log k 时间来获得前 k，对吧？\n\n * * 是的。它是 O(nlogk)（用于堆）+ O(klogk)（用于对最终列表进行排序）。N 通常比 k 大得多。所以，O(nlogk) 是主导的。\n\n * 如果 CMS 只用于 1 min 计数，为什么我们不直接使用哈希表来计数呢？毕竟，数据集的大小不会无限增长。\n\n * * 对于中小规模，哈希表解决方案可能效果很好。但请记住，如果我们尝试创建一个需要为许多不同场景查找前 K 个列表的服务，则可能会有很多这样的哈希表，并且它不会很好地扩展。例如，最常喜欢/不喜欢的视频、观看次数最多（基于时间）的视频、评论次数最多的视频、视频打开期间异常数量最多的前 K 名等。类似的统计数据可以按渠道级别、每个国家/地区等进行计算。长话短说，我们可能需要使用我们的服务来计算许多不同的前 K 名列表\n\n * 如何合并两个 1 小时的 top k 列表，以获得 2 小时的 top k？\n\n * * 我们需要对相同标识符的值求和。换句话说，我们会汇总两个列表中相同视频的观看次数。并获取合并列表的前 K （通过排序或使用 Heap）。 [不过，这不一定是 100% 准确的结果]\n\n * 当存在您提到的不同情况时，CMS 如何工作......最赞/最不喜欢的视频。我们需要构建多个 CMS 吗？我们是否需要为每个类别指定哈希值？无论哪种方式，它们都需要更多的内存，就像哈希表一样。\n\n * * 正确。我们需要特定的 CMS 来计算不同的事件类型：视频观看次数、喜欢、不喜欢、提交评论等。\n\n * 关于慢路径，我对数据分区器感到困惑。我们是否可以删除第一个 Distribute Messaging System 和 data partitioner？API 网关将根据其分区直接向第二个 Distribute Messaging System 发送消息。例如，API 网关会将所有 B 消息发送到分区 1，将所有 A 消息发送到分区 2，将所有 C 消息发送到分区 3。为什么我们需要第一个 Distribute Messaging System 和data partitioner？如果我们使用 Kalfa 作为 Distribute Messaging System，我们可以只为一组消息类型创建一个主题。\n\n * * 在大规模（例如 YouTube 规模）的情况下，API Gateway 集群将处理大量请求。我假设这些是数千甚至数万台 CPU 密集型计算机。主要目标是提供视频内容并尽可能少地做 “其他” 事情。在这样的机器上，我们通常希望避免任何繁重的聚合或逻辑。我们能做的最简单的事情是将每个视频观看请求批处理在一起。我的意思是根本不做任何聚合。创建包含如下内容的单个消息：{A = 1， B = 1， C = 1}，并将其发送以进行进一步处理。在您提到的选项中，我们仍然需要在 API Gateway 端进行聚合。由于规模很大，我们无法承受每个视频观看请求向第二个 DMS 发送一条消息的后果。我的意思是我们不能有三条消息，比如：{A = 1}、{B = 1}、{C = 1}。如视频中所述，我们希望在每个下一个阶段降低请求率。\n\n * 我有一个关于快速路径的问题，似乎您将聚合后的 CMS 存储在存储系统中，但这足以计算前 k 个吗？我觉得我们需要有一个网站列表，并在某个地方维护一个大小为 k 的堆，以找出前 k 个。\n\n * * 你是对的。我们始终保留两种数据结构：一个 count-min sketch 和一个 Fast Processor 中的堆。我们使用 count-min sketch 进行计数，而 heap 存储前 k 个列表。在 Storage 服务中，我们也可以同时保留两者或仅保留堆。但是 heap 始终存在。\n\n * 所以总的来说，我们仍然需要存储 keys。。。Count-min Sketch 无需单独维护 Key 的计数，从而有助于节省成本...当必须找到前 k 个元素时，必须遍历每个键并使用 count-min sketch 来找到前 k 个元素......这种理解准确吗？\n\n * * 我们需要存储 keys ，但只需要存储其中的 K（或更多）。并非全部。\n   * 当每个 key 到来时，我们执行以下操作：\n * * * 将其添加到 count-min 草图中。\n     * 从 count-min 草图中获取密钥计数。\n     * 检查当前 key 是否在堆中。如果它出现在堆中，我们在那里更新它的 count 值。如果它不存在于堆中，我们检查堆是否已满。如果未满，我们将此键添加到堆中。如果 heap 已满，则检查最小 heap 元素并将其值与当前 key count 值进行比较。此时，我们可以删除最小元素并添加当前键（如果当前键计数 > 最小元素值）。\n * * 这样我们只保留预定义数量的 key。这保证了我们永远不会超过内存，因为 count-min sketch 和堆的大小都是有限的\n\n\n# 参考资料\n\nhttps://www.youtube.com/watch?v=kx-XDoPjoHw",normalizedContent:"# 概述\n\ntop k 问题解决方案的各种应用（google/twitter/youtube 趋势、热门产品、波动性股票、ddos 攻击预防）。\n\n在这样的规模下，数据库或分布式缓存不是一个选项。我们可能正在处理 1m rps。如果我们使用 db 来跟踪视图计数，首先写入/更新会非常慢，然后找到前 k 项需要扫描整个数据集。\n\n也许 mapreduce 可以提供帮助。但这还不够。我们需要尽可能接近实时地返回重磅统计数据。\n\n例如：\n\n * calculate top 100 list for last\n * 1 min, 5 min, 15 mins, 60 mins etc.\n\n这使得这个问题成为流处理问题\n\n\n# 前置知识\n\nmapreduce\n\ncount-min sketch\n\n数据聚合原理\n\n合并 n 个排序列表问题\n\n\n# 需求\n\n功能\n\n * topk(k,starttime,endtime)\n\n非功能\n\n * 高扩展（随着数据量的增加而扩展：视频、推文、帖子等）\n * 高可用性（在硬件/网络故障中幸存，没有 spof）\n * 高性能（返回前100名列表需要几十毫秒，考虑到性能要求，这暗示了最终列表应该预先计算，我们应该避免在调用 top k api 时进行繁重的计算。）\n * 准确性（例如，通过使用数据采样，我们可能不会计算每个元素，而只计算一小部分事件）\n\n\n# 渐进设计\n\n\n# 哈希表+单主机\n\n * 在 hashmap 中保留传入事件列表的计数\n\n * * 按频率对 hashmap 中的条目列表进行排序，并返回前 k 个元素。时间 o(nlogn)\n   * 将元素放在大小为 k 的堆上。时间复杂度o(nlogk)\n\n\n\n\n\n\n# 哈希表+多主机\n\n * 如果您将所有 youtube 视频 id 存储在您作为主机的内存中，内存将是一个问题\n\n\n\n虽然增加了吞吐量，但是有内存瓶颈，hash 表会越来越大\n\n\n# 哈希表+多主机+分区\n\n * 我们不会将所有哈希表数据从所有主机发送到存储主机。相反，我们会在每个主机上单独计算 topk 列表，最后我们需要在存储主机上合并这些排序的列表。\n\n\n\n数据分区可以不将所有数据存储到一个主机上，减少了每个主机内存的压力\n\n\n# 总结\n\n问题\n\n * 我们认为数据集是无界的，这就是为什么我们能够考虑将其划分为多个块。但流数据没有界限。它不断涌现。在这种情况下，处理器主机只能在一段时间内继续积累数据，在此之前它将耗尽内存。比如 1 分钟。\n\n * * 我们将 1 min 数据刷新到存储主机\n   * 存储主机存储每分钟的热点列表\n   * 我们故意丢失了有关非 topk 元素的所有信息。我们负担不起在内存中存储每个视频的信息。\n   * 但是，如果我们想找到过去 1 小时或过去 1 天的 topk，我们如何使用 60 个 1 分钟 list 来构建它呢。鉴于当前的方法，没有解决此问题的正确方法。要找到当天的 topk，我们需要全天的完整数据集。\n   * 需求冲突，保留完整的 1 天数据（以满足需求）或丢失它以负担存储。让我们把所有数据存储在磁盘上，因为它无法放入内存，并使用批处理框架来做 topk 列表。map reduce 架构将发挥作用\n\n * 每次引入数据分区时，我们都必须考虑数据复制，以便将每个分区的副本存储在多个节点上。我们需要考虑在集群中添加/删除新节点时重新平衡。我们需要处理热分区。\n\n解决方案\n\n在进入上面讨论的方法之前，让我们想一想是否有一个简单的解决方案来解决 topk 问题？\n\n权衡利弊权衡利弊，所有的选择，不过是权衡利弊罢了\n\n我们需要在此过程中做出牺牲。准确性就是牺牲\n\n我们要合理利用数据结构，这将帮助我们使用固定大小的内存计算 topk，但结果可能不是 100% 准确\n\ncount-min sketch！\n\n\n\n\n# 高层架构\n\n\n\n * api gateway：连接到视频内容交付系统，该系统将提供视频请求\n\n * * 对于我们的用例，我们对 api 网关的 1 个功能感兴趣，即日志生成，其中记录对 api 的每次调用。通常这些日志用于监控、日志记录和审计。我们将使用这些日志来计算每个视频的观看次数。我们可能有一个后台进程，它从日志中读取数据，进行一些初始聚合并发送数据进行进一步处理。\n   * 为 api 网关服务上的缓冲区分配内存，读取日志行，并构建频率计数哈希表。此缓冲区的大小应有限，当缓冲区已满时，将刷新数据。如果缓冲区在某个时间段内未满，我们可以根据时间段进行 flush。\n   * 其他选项可以是动态聚合数据，而不写入日志文件。或者完全跳过 api 网关端的数据聚合，并将有关每个事件（正在查看的视频）的信息进一步发送以进行处理。评估每个选项的优缺点。\n   * 我们可以通过以紧凑的二进制格式（例如 apache avro）序列化数据来节省网络 io 利用率，并让 cpu 付出代价。所有这些注意事项都取决于 api 网关主机上可用的资源，即内存、cpu、网络和磁盘 io。\n\n * distributed messaging system：初始聚合数据将发送到分布式消息传递系统，如 apache kafka。\n\n * fast path and slow path\n\n * * 在 fast path 中，我们将大致计算 topk hitter 的结果。结果将在几秒钟内提供。\n   * 在 slow path 中，我们将精确计算 topk hitter 的结果。几分钟/几小时内即可获得结果。\n   * 根据系统对系统时序的限制（是否需要近实时结果，或者延迟是否可以接受以实现精度），您应该选择任一路径。\n\n\n\n\n\n\n\n\n# 客户端检索数据\n\n\n\n合并 2 个不同的结果集来回答 api 调用并不准确，但这是一种权衡。您无法在任何时间聚合数据。您必须了解确切需要的东西，并据此进行构建。\n\n\n# 解答疑惑\n\n * 我们是否可以使用哈希映射，但每隔几秒钟将其内容（转换为堆后）刷新到存储中，而不是使用 cms？\n\n * * 对于小规模，使用哈希映射是完全可以的。当规模增长时，哈希映射可能会变得太大（使用大量内存）。为了防止这种情况，我们可以对数据进行分区，以便只有所有数据的子集进入 fast processor 服务主机。但它使架构复杂化。cms 的美妙之处在于它消耗有限的（定义的）内存，并且无需对数据进行分区。cms 的缺点是它大约计算数字。权衡，权衡......\n\n * 我们如何将 count-min sketch 和 heap 存储到数据库中？如何设计 table 架构？\n\n * * heap 只是一个一维数组。cms 是一个二维数组。这意味着两者都可以很容易地序列化为字节数组。使用语言原生序列化 api 或备受推崇的序列化框架（protobufs、thrift、avro）。我们可以将它们以这种形式存储在数据库中。\n\n * 虽然 cms 是为了节省内存，但我们还有 n log k 时间来获得前 k，对吧？\n\n * * 是的。它是 o(nlogk)（用于堆）+ o(klogk)（用于对最终列表进行排序）。n 通常比 k 大得多。所以，o(nlogk) 是主导的。\n\n * 如果 cms 只用于 1 min 计数，为什么我们不直接使用哈希表来计数呢？毕竟，数据集的大小不会无限增长。\n\n * * 对于中小规模，哈希表解决方案可能效果很好。但请记住，如果我们尝试创建一个需要为许多不同场景查找前 k 个列表的服务，则可能会有很多这样的哈希表，并且它不会很好地扩展。例如，最常喜欢/不喜欢的视频、观看次数最多（基于时间）的视频、评论次数最多的视频、视频打开期间异常数量最多的前 k 名等。类似的统计数据可以按渠道级别、每个国家/地区等进行计算。长话短说，我们可能需要使用我们的服务来计算许多不同的前 k 名列表\n\n * 如何合并两个 1 小时的 top k 列表，以获得 2 小时的 top k？\n\n * * 我们需要对相同标识符的值求和。换句话说，我们会汇总两个列表中相同视频的观看次数。并获取合并列表的前 k （通过排序或使用 heap）。 [不过，这不一定是 100% 准确的结果]\n\n * 当存在您提到的不同情况时，cms 如何工作......最赞/最不喜欢的视频。我们需要构建多个 cms 吗？我们是否需要为每个类别指定哈希值？无论哪种方式，它们都需要更多的内存，就像哈希表一样。\n\n * * 正确。我们需要特定的 cms 来计算不同的事件类型：视频观看次数、喜欢、不喜欢、提交评论等。\n\n * 关于慢路径，我对数据分区器感到困惑。我们是否可以删除第一个 distribute messaging system 和 data partitioner？api 网关将根据其分区直接向第二个 distribute messaging system 发送消息。例如，api 网关会将所有 b 消息发送到分区 1，将所有 a 消息发送到分区 2，将所有 c 消息发送到分区 3。为什么我们需要第一个 distribute messaging system 和data partitioner？如果我们使用 kalfa 作为 distribute messaging system，我们可以只为一组消息类型创建一个主题。\n\n * * 在大规模（例如 youtube 规模）的情况下，api gateway 集群将处理大量请求。我假设这些是数千甚至数万台 cpu 密集型计算机。主要目标是提供视频内容并尽可能少地做 “其他” 事情。在这样的机器上，我们通常希望避免任何繁重的聚合或逻辑。我们能做的最简单的事情是将每个视频观看请求批处理在一起。我的意思是根本不做任何聚合。创建包含如下内容的单个消息：{a = 1， b = 1， c = 1}，并将其发送以进行进一步处理。在您提到的选项中，我们仍然需要在 api gateway 端进行聚合。由于规模很大，我们无法承受每个视频观看请求向第二个 dms 发送一条消息的后果。我的意思是我们不能有三条消息，比如：{a = 1}、{b = 1}、{c = 1}。如视频中所述，我们希望在每个下一个阶段降低请求率。\n\n * 我有一个关于快速路径的问题，似乎您将聚合后的 cms 存储在存储系统中，但这足以计算前 k 个吗？我觉得我们需要有一个网站列表，并在某个地方维护一个大小为 k 的堆，以找出前 k 个。\n\n * * 你是对的。我们始终保留两种数据结构：一个 count-min sketch 和一个 fast processor 中的堆。我们使用 count-min sketch 进行计数，而 heap 存储前 k 个列表。在 storage 服务中，我们也可以同时保留两者或仅保留堆。但是 heap 始终存在。\n\n * 所以总的来说，我们仍然需要存储 keys。。。count-min sketch 无需单独维护 key 的计数，从而有助于节省成本...当必须找到前 k 个元素时，必须遍历每个键并使用 count-min sketch 来找到前 k 个元素......这种理解准确吗？\n\n * * 我们需要存储 keys ，但只需要存储其中的 k（或更多）。并非全部。\n   * 当每个 key 到来时，我们执行以下操作：\n * * * 将其添加到 count-min 草图中。\n     * 从 count-min 草图中获取密钥计数。\n     * 检查当前 key 是否在堆中。如果它出现在堆中，我们在那里更新它的 count 值。如果它不存在于堆中，我们检查堆是否已满。如果未满，我们将此键添加到堆中。如果 heap 已满，则检查最小 heap 元素并将其值与当前 key count 值进行比较。此时，我们可以删除最小元素并添加当前键（如果当前键计数 > 最小元素值）。\n * * 这样我们只保留预定义数量的 key。这保证了我们永远不会超过内存，因为 count-min sketch 和堆的大小都是有限的\n\n\n# 参考资料\n\nhttps://www.youtube.com/watch?v=kx-xdopjohw",charsets:{cjk:!0},lastUpdated:"2024/09/14, 20:19:06",lastUpdatedTimestamp:1726345146e3},{title:"消息队列",frontmatter:{title:"消息队列",date:"2024-09-14T16:43:00.000Z",permalink:"/pages/567090/"},regularPath:"/04.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/01.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/04.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.html",relativePath:"04.设计基础设施/01.设计基础设施/04.消息队列.md",key:"v-6d729576",path:"/pages/567090/",headers:[{level:2,title:"概述",slug:"概述",normalizedTitle:"概述",charIndex:2},{level:2,title:"需求",slug:"需求",normalizedTitle:"需求",charIndex:11},{level:2,title:"高层抽象",slug:"高层抽象",normalizedTitle:"高层抽象",charIndex:78},{level:2,title:"虚拟IP和负载均衡",slug:"虚拟ip和负载均衡",normalizedTitle:"虚拟ip和负载均衡",charIndex:89},{level:2,title:"前端服务",slug:"前端服务",normalizedTitle:"前端服务",charIndex:105},{level:2,title:"元数据服务",slug:"元数据服务",normalizedTitle:"元数据服务",charIndex:116},{level:2,title:"后端服务",slug:"后端服务",normalizedTitle:"后端服务",charIndex:128},{level:2,title:"还有什么重要的？",slug:"还有什么重要的",normalizedTitle:"还有什么重要的？",charIndex:145},{level:3,title:"队列的创建与删除",slug:"队列的创建与删除",normalizedTitle:"队列的创建与删除",charIndex:160},{level:3,title:"消息的删除",slug:"消息的删除",normalizedTitle:"消息的删除",charIndex:173},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:183}],headersStr:"概述 需求 高层抽象 虚拟IP和负载均衡 前端服务 元数据服务 后端服务 还有什么重要的？ 队列的创建与删除 消息的删除 总结",content:"# 概述\n\n\n\n\n# 需求\n\n功能性\n\n * sendMessage(messageBody)\n * receiveMessage()\n\n非功能性\n\n\n# 高层抽象\n\n\n\n\n# 虚拟IP和负载均衡\n\n\n\n\n# 前端服务\n\n\n\n\n# 元数据服务\n\n\n\n\n# 后端服务\n\n\n\n\n\n\n\n\n\n\n# 还有什么重要的？\n\n\n\n\n# 队列的创建与删除\n\n\n# 消息的删除\n\n\n# 总结\n\n",normalizedContent:"# 概述\n\n\n\n\n# 需求\n\n功能性\n\n * sendmessage(messagebody)\n * receivemessage()\n\n非功能性\n\n\n# 高层抽象\n\n\n\n\n# 虚拟ip和负载均衡\n\n\n\n\n# 前端服务\n\n\n\n\n# 元数据服务\n\n\n\n\n# 后端服务\n\n\n\n\n\n\n\n\n\n\n# 还有什么重要的？\n\n\n\n\n# 队列的创建与删除\n\n\n# 消息的删除\n\n\n# 总结\n\n",charsets:{cjk:!0},lastUpdated:"2024/09/14, 20:19:06",lastUpdatedTimestamp:1726345146e3},{title:"动态线程池",frontmatter:{title:"动态线程池",date:"2024-09-14T23:28:32.000Z",permalink:"/pages/d81a42/"},regularPath:"/04.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/01.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/06.%E5%8A%A8%E6%80%81%E7%BA%BF%E7%A8%8B%E6%B1%A0.html",relativePath:"04.设计基础设施/01.设计基础设施/06.动态线程池.md",key:"v-352bf426",path:"/pages/d81a42/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2024/09/14, 20:19:06",lastUpdatedTimestamp:1726345146e3},{title:"服务通知",frontmatter:{title:"服务通知",date:"2024-09-14T16:43:28.000Z",permalink:"/pages/8416e6/"},regularPath:"/04.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/01.%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/05.%E8%AE%A2%E9%98%85%E5%8F%91%E5%B8%83.html",relativePath:"04.设计基础设施/01.设计基础设施/05.订阅发布.md",key:"v-5dd3d42a",path:"/pages/8416e6/",headers:[{level:2,title:"需求",slug:"需求",normalizedTitle:"需求",charIndex:2},{level:2,title:"高层架构",slug:"高层架构",normalizedTitle:"高层架构",charIndex:142},{level:2,title:"客户端主机",slug:"客户端主机",normalizedTitle:"客户端主机",charIndex:153}],headersStr:"需求 高层架构 客户端主机",content:"# 需求\n\n功能性\n\n * createTopic(topicname)\n * publish(topicName,message)\n * subscribe(topicName,endpoint)\n\n非功能性\n\n * 高可扩展性\n * 高可用性\n * 高性能\n * 持久性\n\n\n# 高层架构\n\n\n\n\n# 客户端主机",normalizedContent:"# 需求\n\n功能性\n\n * createtopic(topicname)\n * publish(topicname,message)\n * subscribe(topicname,endpoint)\n\n非功能性\n\n * 高可扩展性\n * 高可用性\n * 高性能\n * 持久性\n\n\n# 高层架构\n\n\n\n\n# 客户端主机",charsets:{cjk:!0},lastUpdated:"2024/09/14, 20:19:06",lastUpdatedTimestamp:1726345146e3},{title:"碎碎念",frontmatter:{title:"碎碎念",date:"2024-09-15T01:18:31.000Z",permalink:"/pages/52ebd8/"},regularPath:"/06.%E6%88%91%E7%9A%84%E5%8A%A8%E6%80%81/01.%E7%A2%8E%E7%A2%8E%E5%BF%B5.html",relativePath:"06.我的动态/01.碎碎念.md",key:"v-1c3f7e81",path:"/pages/52ebd8/",headers:[{level:2,title:"如何写好一篇文档",slug:"如何写好一篇文档",normalizedTitle:"如何写好一篇文档",charIndex:2},{level:2,title:"如何拥有持续输出的能力",slug:"如何拥有持续输出的能力",normalizedTitle:"如何拥有持续输出的能力",charIndex:241}],headersStr:"如何写好一篇文档 如何拥有持续输出的能力",content:"# 如何写好一篇文档\n\n 1. 总分总结构\n 2. 多用图片 数据 代码块 引用文献\n 3. 排版简约 避免一段文字超过 8 行 尽量有主句\n 4. 每发一篇文章之前，至少要看 5 篇类似的优质文章做调研，如果找不到，就别发了\n 5. 要有自己的特色，我认为我要在文章中多穿插问答题，以及多插入自己的见解，例如：echo 认为 xxx\n 6. 把每一个栏目做好做精致，切勿急于求成，把观众留下\n 7. 每一篇文章末尾都要搜集相关问答\n 8. 在开篇设置悬念是一个很好的办法\n\n\n# 如何拥有持续输出的能力\n\n 1. 对每一个栏目有一个总的理解，然后对该栏目需要发布哪些内容有个抽象的理解，然后对每一个抽象去做调研\n 2. 多看优质文章，学习他们的思路与表达方式\n 3. 学习英语，外网也有很多优质的文章\n 4. 写好自己的每一篇文章，每一篇文章都要做到最优",normalizedContent:"# 如何写好一篇文档\n\n 1. 总分总结构\n 2. 多用图片 数据 代码块 引用文献\n 3. 排版简约 避免一段文字超过 8 行 尽量有主句\n 4. 每发一篇文章之前，至少要看 5 篇类似的优质文章做调研，如果找不到，就别发了\n 5. 要有自己的特色，我认为我要在文章中多穿插问答题，以及多插入自己的见解，例如：echo 认为 xxx\n 6. 把每一个栏目做好做精致，切勿急于求成，把观众留下\n 7. 每一篇文章末尾都要搜集相关问答\n 8. 在开篇设置悬念是一个很好的办法\n\n\n# 如何拥有持续输出的能力\n\n 1. 对每一个栏目有一个总的理解，然后对该栏目需要发布哪些内容有个抽象的理解，然后对每一个抽象去做调研\n 2. 多看优质文章，学习他们的思路与表达方式\n 3. 学习英语，外网也有很多优质的文章\n 4. 写好自己的每一篇文章，每一篇文章都要做到最优",charsets:{cjk:!0},lastUpdated:"2024/09/14, 19:13:27",lastUpdatedTimestamp:1726341207e3},{title:"第一步：一般性原则",frontmatter:{title:"第一步：一般性原则",date:"2024-09-15T11:11:46.000Z",permalink:"/pages/bd2edd/"},regularPath:"/08.%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/01.%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/01.%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E4%B8%80%E8%88%AC%E6%80%A7%E5%8E%9F%E5%88%99.html",relativePath:"08.学习路线/01.学习路线/01.第一步：一般性原则.md",key:"v-03654e78",path:"/pages/bd2edd/",headers:[{level:4,title:"可扩展性",slug:"可扩展性",normalizedTitle:"可扩展性",charIndex:52},{level:4,title:"性能与可扩展性",slug:"性能与可扩展性",normalizedTitle:"性能与可扩展性",charIndex:263},{level:4,title:"延迟与吞吐量",slug:"延迟与吞吐量",normalizedTitle:"延迟与吞吐量",charIndex:274},{level:4,title:"可用性与一致性",slug:"可用性与一致性",normalizedTitle:"可用性与一致性",charIndex:284},{level:4,title:"一致性模式",slug:"一致性模式",normalizedTitle:"一致性模式",charIndex:892},{level:4,title:"可用性模式",slug:"可用性模式",normalizedTitle:"可用性模式",charIndex:1377}],headersStr:"可扩展性 性能与可扩展性 延迟与吞吐量 可用性与一致性 一致性模式 可用性模式",content:"不熟悉系统设计？\n\n首先，你需要对一般性原则有一个基本的认识，知道它们是什么，怎样使用以及利弊。\n\n# 可扩展性\n\n哈佛大学可扩展性讲座\n\n * 主题涵盖\n   * 垂直扩展（Vertical scaling）\n   * 水平扩展（Horizontal scaling）\n   * 缓存\n   * 负载均衡\n   * 数据库复制\n   * 数据库分区\n * 可扩展性\n   * 主题涵盖\n     * Clones\n     * 数据库\n     * 缓存\n     * 异步\n\n接下来，我们将看看高阶的权衡和取舍:\n\n * 性能与可扩展性\n * 延迟与吞吐量\n * 可用性与一致性\n\n记住每个方面都面临取舍和权衡。\n\n然后，我们将深入更具体的主题，如 DNS、CDN 和负载均衡器。\n\n# 性能与可扩展性\n\n如果服务性能的增长与资源的增加是成比例的，服务就是可扩展的。通常，提高性能意味着服务于更多的工作单元，另一方面，当数据集增长时，同样也可以处理更大的工作单位。\n\n另一个角度来看待性能与可扩展性:\n\n * 如果你的系统有性能问题，对于单个用户来说是缓慢的。\n * 如果你的系统有可扩展性问题，单个用户较快但在高负载下会变慢。\n\n来源及延伸阅读\n\n * 简单谈谈可扩展性\n * 可扩展性，可用性，稳定性和模式\n\n# 延迟与吞吐量\n\n延迟是执行操作或运算结果所花费的时间。\n\n吞吐量是单位时间内（执行）此类操作或运算的数量。\n\n通常，你应该以可接受级延迟下最大化吞吐量为目标。\n\n来源及延伸阅读\n\n * 理解延迟与吞吐量\n\n# 可用性与一致性\n\n * CAP 理论\n   * 在一个分布式计算系统中，只能同时满足下列的两点:\n     * 一致性 ─ 每次访问都能获得最新数据但可能会收到错误响应\n     * 可用性 ─ 每次访问都能收到非错响应，但不保证获取到最新数据\n     * 分区容错性 ─ 在任意分区网络故障的情况下系统仍能继续运行\n * Base 理论\n\n来源及延伸阅读\n\n * 再看 CAP 理论\n * 通俗易懂地介绍 CAP 理论\n * CAP FAQ\n\n# 一致性模式\n\n有同一份数据的多份副本，我们面临着怎样同步它们的选择，以便让客户端有一致的显示数据。回想 CAP 理论中的一致性定义 ─ 每次访问都能获得最新数据但可能会收到错误响应\n\n * 弱一致性\n   * 在写入之后，访问可能看到，也可能看不到（写入数据）。尽力优化之让其能访问最新数据。\n   * 这种方式可以 memcached 等系统中看到。弱一致性在 VoIP，视频聊天和实时多人游戏等真实用例中表现不错。打个比方，如果你在通话中丢失信号几秒钟时间，当重新连接时你是听不到这几秒钟所说的话的。\n * 最终一致性\n   * 在写入后，访问最终能看到写入数据（通常在数毫秒内）。数据被异步复制。\n   * DNS 和 email 等系统使用的是此种方式。最终一致性在高可用性系统中效果不错。\n * 强一致性\n   * 在写入后，访问立即可见。数据被同步复制。\n   * 文件系统和关系型数据库（RDBMS）中使用的是此种方式。强一致性在需要记录的系统中运作良好。\n\n来源及延伸阅读\n\n * Transactions across data centers\n\n# 可用性模式\n\n有两种支持高可用性的模式: 故障切换（fail-over）和复制（replication）。\n\n * 故障切换\n   * 工作到备用切换（Active-passive）\n     * 关于工作到备用的故障切换流程是，工作服务器发送周期信号给待机中的备用服务器。如果周期信号中断，备用服务器切换成工作服务器的 IP 地址并恢复服务。\n     * 宕机时间取决于备用服务器处于“热”待机状态还是需要从“冷”待机状态进行启动。只有工作服务器处理流量。\n     * 工作到备用的故障切换也被称为主从切换。\n   * 双工作切换（Active-active）\n     * 在双工作切换中，双方都在管控流量，在它们之间分散负载。\n     * 如果是外网服务器，DNS 将需要对两方都了解。如果是内网服务器，应用程序逻辑将需要对两方都了解。\n     * 双工作切换也可以称为主主切换。\n   * 缺陷：故障切换\n     * 故障切换需要添加额外硬件并增加复杂性。\n     * 如果新写入数据在能被复制到备用系统之前，工作系统出现了故障，则有可能会丢失数据。\n * 复制\n   * 主 ─ 从复制\n   * 主 ─ 主复制\n\n这个主题进一步探讨了数据库部分:\n\n * 主 ─ 从复制\n * 主 ─ 主复制",normalizedContent:"不熟悉系统设计？\n\n首先，你需要对一般性原则有一个基本的认识，知道它们是什么，怎样使用以及利弊。\n\n# 可扩展性\n\n哈佛大学可扩展性讲座\n\n * 主题涵盖\n   * 垂直扩展（vertical scaling）\n   * 水平扩展（horizontal scaling）\n   * 缓存\n   * 负载均衡\n   * 数据库复制\n   * 数据库分区\n * 可扩展性\n   * 主题涵盖\n     * clones\n     * 数据库\n     * 缓存\n     * 异步\n\n接下来，我们将看看高阶的权衡和取舍:\n\n * 性能与可扩展性\n * 延迟与吞吐量\n * 可用性与一致性\n\n记住每个方面都面临取舍和权衡。\n\n然后，我们将深入更具体的主题，如 dns、cdn 和负载均衡器。\n\n# 性能与可扩展性\n\n如果服务性能的增长与资源的增加是成比例的，服务就是可扩展的。通常，提高性能意味着服务于更多的工作单元，另一方面，当数据集增长时，同样也可以处理更大的工作单位。\n\n另一个角度来看待性能与可扩展性:\n\n * 如果你的系统有性能问题，对于单个用户来说是缓慢的。\n * 如果你的系统有可扩展性问题，单个用户较快但在高负载下会变慢。\n\n来源及延伸阅读\n\n * 简单谈谈可扩展性\n * 可扩展性，可用性，稳定性和模式\n\n# 延迟与吞吐量\n\n延迟是执行操作或运算结果所花费的时间。\n\n吞吐量是单位时间内（执行）此类操作或运算的数量。\n\n通常，你应该以可接受级延迟下最大化吞吐量为目标。\n\n来源及延伸阅读\n\n * 理解延迟与吞吐量\n\n# 可用性与一致性\n\n * cap 理论\n   * 在一个分布式计算系统中，只能同时满足下列的两点:\n     * 一致性 ─ 每次访问都能获得最新数据但可能会收到错误响应\n     * 可用性 ─ 每次访问都能收到非错响应，但不保证获取到最新数据\n     * 分区容错性 ─ 在任意分区网络故障的情况下系统仍能继续运行\n * base 理论\n\n来源及延伸阅读\n\n * 再看 cap 理论\n * 通俗易懂地介绍 cap 理论\n * cap faq\n\n# 一致性模式\n\n有同一份数据的多份副本，我们面临着怎样同步它们的选择，以便让客户端有一致的显示数据。回想 cap 理论中的一致性定义 ─ 每次访问都能获得最新数据但可能会收到错误响应\n\n * 弱一致性\n   * 在写入之后，访问可能看到，也可能看不到（写入数据）。尽力优化之让其能访问最新数据。\n   * 这种方式可以 memcached 等系统中看到。弱一致性在 voip，视频聊天和实时多人游戏等真实用例中表现不错。打个比方，如果你在通话中丢失信号几秒钟时间，当重新连接时你是听不到这几秒钟所说的话的。\n * 最终一致性\n   * 在写入后，访问最终能看到写入数据（通常在数毫秒内）。数据被异步复制。\n   * dns 和 email 等系统使用的是此种方式。最终一致性在高可用性系统中效果不错。\n * 强一致性\n   * 在写入后，访问立即可见。数据被同步复制。\n   * 文件系统和关系型数据库（rdbms）中使用的是此种方式。强一致性在需要记录的系统中运作良好。\n\n来源及延伸阅读\n\n * transactions across data centers\n\n# 可用性模式\n\n有两种支持高可用性的模式: 故障切换（fail-over）和复制（replication）。\n\n * 故障切换\n   * 工作到备用切换（active-passive）\n     * 关于工作到备用的故障切换流程是，工作服务器发送周期信号给待机中的备用服务器。如果周期信号中断，备用服务器切换成工作服务器的 ip 地址并恢复服务。\n     * 宕机时间取决于备用服务器处于“热”待机状态还是需要从“冷”待机状态进行启动。只有工作服务器处理流量。\n     * 工作到备用的故障切换也被称为主从切换。\n   * 双工作切换（active-active）\n     * 在双工作切换中，双方都在管控流量，在它们之间分散负载。\n     * 如果是外网服务器，dns 将需要对两方都了解。如果是内网服务器，应用程序逻辑将需要对两方都了解。\n     * 双工作切换也可以称为主主切换。\n   * 缺陷：故障切换\n     * 故障切换需要添加额外硬件并增加复杂性。\n     * 如果新写入数据在能被复制到备用系统之前，工作系统出现了故障，则有可能会丢失数据。\n * 复制\n   * 主 ─ 从复制\n   * 主 ─ 主复制\n\n这个主题进一步探讨了数据库部分:\n\n * 主 ─ 从复制\n * 主 ─ 主复制",charsets:{cjk:!0},lastUpdated:"2024/09/15, 03:15:07",lastUpdatedTimestamp:1726370107e3},{title:"第二步：核心组件",frontmatter:{title:"第二步：核心组件",date:"2024-09-15T11:12:01.000Z",permalink:"/pages/c64895/"},regularPath:"/08.%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/01.%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/02.%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6.html",relativePath:"08.学习路线/01.学习路线/02.第二步：核心组件.md",key:"v-52fa84a6",path:"/pages/c64895/",headers:[{level:3,title:"域名系统",slug:"域名系统",normalizedTitle:"域名系统",charIndex:2},{level:4,title:"缺陷:DNS",slug:"缺陷-dns",normalizedTitle:"缺陷:dns",charIndex:519},{level:4,title:"来源及延伸阅读",slug:"来源及延伸阅读",normalizedTitle:"来源及延伸阅读",charIndex:674},{level:3,title:"内容分发网络（CDN）",slug:"内容分发网络-cdn",normalizedTitle:"内容分发网络（cdn）",charIndex:724},{level:4,title:"CDN 推送（push）",slug:"cdn-推送-push",normalizedTitle:"cdn 推送（push）",charIndex:942},{level:4,title:"CDN 拉取（pull）",slug:"cdn-拉取-pull",normalizedTitle:"cdn 拉取（pull）",charIndex:1068},{level:4,title:"缺陷：CDN",slug:"缺陷-cdn",normalizedTitle:"缺陷：cdn",charIndex:1298},{level:4,title:"来源及延伸阅读",slug:"来源及延伸阅读-2",normalizedTitle:"来源及延伸阅读",charIndex:674},{level:3,title:"负载均衡器",slug:"负载均衡器",normalizedTitle:"负载均衡器",charIndex:1472},{level:4,title:"四层负载均衡",slug:"四层负载均衡",normalizedTitle:"四层负载均衡",charIndex:1910},{level:4,title:"七层负载均衡器",slug:"七层负载均衡器",normalizedTitle:"七层负载均衡器",charIndex:2043},{level:4,title:"水平扩展",slug:"水平扩展",normalizedTitle:"水平扩展",charIndex:2254},{level:4,title:"缺陷：水平扩展",slug:"缺陷-水平扩展",normalizedTitle:"缺陷：水平扩展",charIndex:2356},{level:4,title:"缺陷：负载均衡器",slug:"缺陷-负载均衡器",normalizedTitle:"缺陷：负载均衡器",charIndex:2535},{level:4,title:"来源及延伸阅读",slug:"来源及延伸阅读-3",normalizedTitle:"来源及延伸阅读",charIndex:674},{level:3,title:"反向代理（web 服务器）",slug:"反向代理-web-服务器",normalizedTitle:"反向代理（web 服务器）",charIndex:2749}],headersStr:"域名系统 缺陷:DNS 来源及延伸阅读 内容分发网络（CDN） CDN 推送（push） CDN 拉取（pull） 缺陷：CDN 来源及延伸阅读 负载均衡器 四层负载均衡 七层负载均衡器 水平扩展 缺陷：水平扩展 缺陷：负载均衡器 来源及延伸阅读 反向代理（web 服务器）",content:"# 域名系统\n\n\n\n域名系统是把 www.example.com 等域名转换成 IP 地址。\n\n域名系统是分层次的，一些 DNS 服务器位于顶层。当查询（域名） IP 时，路由或 ISP 提供连接 DNS 服务器的信息。较底层的 DNS 服务器缓存映射，它可能会因为 DNS 传播延时而失效。DNS 结果可以缓存在浏览器或操作系统中一段时间，时间长短取决于存活时间 TTL。\n\n * NS 记录（域名服务） ─ 指定解析域名或子域名的 DNS 服务器。\n * MX 记录（邮件交换） ─ 指定接收信息的邮件服务器。\n * A 记录（地址） ─ 指定域名对应的 IP 地址记录。\n * CNAME（规范） ─ 一个域名映射到另一个域名或 CNAME 记录（ example.com 指向 www.example.com ）或映射到一个 A 记录。\n\nCloudFlare 和 Route 53 等平台提供管理 DNS 的功能。某些 DNS 服务通过集中方式来路由流量:\n\n * 加权轮询调度\n   * 防止流量进入维护中的服务器\n   * 在不同大小集群间负载均衡\n   * A/B 测试\n * 基于延迟路由\n * 基于地理位置路由\n\n# 缺陷:DNS\n\n * 虽说缓存可以减轻 DNS 延迟，但连接 DNS 服务器还是带来了轻微的延迟。\n * 虽然它们通常由政府，网络服务提供商和大公司管理，但 DNS 服务管理仍可能是复杂的。\n * DNS 服务最近遭受 DDoS 攻击，阻止不知道 Twitter IP 地址的用户访问 Twitter。\n\n# 来源及延伸阅读\n\n * DNS 架构\n * Wikipedia\n * 关于 DNS 的文章\n\n\n# 内容分发网络（CDN）\n\n\n\n内容分发网络（CDN）是一个全球性的代理服务器分布式网络，它从靠近用户的位置提供内容。通常，HTML/CSS/JS，图片和视频等静态内容由 CDN 提供，虽然亚马逊 CloudFront 等也支持动态内容。CDN 的 DNS 解析会告知客户端连接哪台服务器。\n\n将内容存储在 CDN 上可以从两个方面来提供性能:\n\n * 从靠近用户的数据中心提供资源\n * 通过 CDN 你的服务器不必真的处理请求\n\n# CDN 推送（push）\n\n当你服务器上内容发生变动时，推送 CDN 接受新内容。直接推送给 CDN 并重写 URL 地址以指向你的内容的 CDN 地址。你可以配置内容到期时间及何时更新。内容只有在更改或新增是才推送，流量最小化，但储存最大化。\n\n# CDN 拉取（pull）\n\nCDN 拉取是当第一个用户请求该资源时，从服务器上拉取资源。你将内容留在自己的服务器上并重写 URL 指向 CDN 地址。直到内容被缓存在 CDN 上为止，这样请求只会更慢，\n\n存活时间（TTL）决定缓存多久时间。CDN 拉取方式最小化 CDN 上的储存空间，但如果过期文件并在实际更改之前被拉取，则会导致冗余的流量。\n\n高流量站点使用 CDN 拉取效果不错，因为只有最近请求的内容保存在 CDN 中，流量才能更平衡地分散。\n\n# 缺陷：CDN\n\n * CDN 成本可能因流量而异，可能在权衡之后你将不会使用 CDN。\n * 如果在 TTL 过期之前更新内容，CDN 缓存内容可能会过时。\n * CDN 需要更改静态内容的 URL 地址以指向 CDN。\n\n# 来源及延伸阅读\n\n * 全球性内容分发网络\n * CDN 拉取和 CDN 推送的区别\n * Wikipedia\n\n\n# 负载均衡器\n\n\n\n负载均衡器将传入的请求分发到应用服务器和数据库等计算资源。无论哪种情况，负载均衡器将从计算资源来的响应返回给恰当的客户端。负载均衡器的效用在于:\n\n * 防止请求进入不好的服务器\n * 防止资源过载\n * 帮助消除单一的故障点\n\n负载均衡器可以通过硬件（昂贵）或 HAProxy 等软件来实现。 增加的好处包括:\n\n * SSL 终结\n   \n   ─ 解密传入的请求并加密服务器响应，这样的话后端服务器就不必再执行这些潜在高消耗运算了。\n   \n   * 不需要再每台服务器上安装 X.509 证书。\n\n * Session 留存 ─ 如果 Web 应用程序不追踪会话，发出 cookie 并将特定客户端的请求路由到同一实例。\n\n通常会设置采用工作 ─ 备用 或 双工作 模式的多个负载均衡器，以免发生故障。\n\n负载均衡器能基于多种方式来路由流量:\n\n * 随机\n * 最少负载\n * Session/cookie\n * 轮询调度或加权轮询调度算法\n * 四层负载均衡\n * 七层负载均衡\n\n# 四层负载均衡\n\n四层负载均衡根据监看传输层的信息来决定如何分发请求。通常，这会涉及来源，目标 IP 地址和请求头中的端口，但不包括数据包（报文）内容。四层负载均衡执行网络地址转换（NAT）来向上游服务器转发网络数据包。\n\n# 七层负载均衡器\n\n七层负载均衡器根据监控应用层来决定怎样分发请求。这会涉及请求头的内容，消息和 cookie。七层负载均衡器终结网络流量，读取消息，做出负载均衡判定，然后传送给特定服务器。比如，一个七层负载均衡器能直接将视频流量连接到托管视频的服务器，同时将更敏感的用户账单流量引导到安全性更强的服务器。\n\n以损失灵活性为代价，四层负载均衡比七层负载均衡花费更少时间和计算资源，虽然这对现代商用硬件的性能影响甚微。\n\n# 水平扩展\n\n负载均衡器还能帮助水平扩展，提高性能和可用性。使用商业硬件的性价比更高，并且比在单台硬件上垂直扩展更贵的硬件具有更高的可用性。相比招聘特定企业系统人才，招聘商业硬件方面的人才更加容易。\n\n# 缺陷：水平扩展\n\n * 水平扩展引入了复杂度并涉及服务器复制\n   * 服务器应该是无状态的:它们也不该包含像 session 或资料图片等与用户关联的数据。\n   * session 可以集中存储在数据库或持久化缓存（Redis、Memcached）的数据存储区中。\n * 缓存和数据库等下游服务器需要随着上游服务器进行扩展，以处理更多的并发连接。\n\n# 缺陷：负载均衡器\n\n * 如果没有足够的资源配置或配置错误，负载均衡器会变成一个性能瓶颈。\n * 引入负载均衡器以帮助消除单点故障但导致了额外的复杂性。\n * 单个负载均衡器会导致单点故障，但配置多个负载均衡器会进一步增加复杂性。\n\n# 来源及延伸阅读\n\n * NGINX 架构\n * HAProxy 架构指南\n * 可扩展性\n * Wikipedia\n * 四层负载平衡\n * 七层负载平衡\n * ELB 监听器配置\n\n\n# 反向代理（web 服务器）\n\n",normalizedContent:"# 域名系统\n\n\n\n域名系统是把 www.example.com 等域名转换成 ip 地址。\n\n域名系统是分层次的，一些 dns 服务器位于顶层。当查询（域名） ip 时，路由或 isp 提供连接 dns 服务器的信息。较底层的 dns 服务器缓存映射，它可能会因为 dns 传播延时而失效。dns 结果可以缓存在浏览器或操作系统中一段时间，时间长短取决于存活时间 ttl。\n\n * ns 记录（域名服务） ─ 指定解析域名或子域名的 dns 服务器。\n * mx 记录（邮件交换） ─ 指定接收信息的邮件服务器。\n * a 记录（地址） ─ 指定域名对应的 ip 地址记录。\n * cname（规范） ─ 一个域名映射到另一个域名或 cname 记录（ example.com 指向 www.example.com ）或映射到一个 a 记录。\n\ncloudflare 和 route 53 等平台提供管理 dns 的功能。某些 dns 服务通过集中方式来路由流量:\n\n * 加权轮询调度\n   * 防止流量进入维护中的服务器\n   * 在不同大小集群间负载均衡\n   * a/b 测试\n * 基于延迟路由\n * 基于地理位置路由\n\n# 缺陷:dns\n\n * 虽说缓存可以减轻 dns 延迟，但连接 dns 服务器还是带来了轻微的延迟。\n * 虽然它们通常由政府，网络服务提供商和大公司管理，但 dns 服务管理仍可能是复杂的。\n * dns 服务最近遭受 ddos 攻击，阻止不知道 twitter ip 地址的用户访问 twitter。\n\n# 来源及延伸阅读\n\n * dns 架构\n * wikipedia\n * 关于 dns 的文章\n\n\n# 内容分发网络（cdn）\n\n\n\n内容分发网络（cdn）是一个全球性的代理服务器分布式网络，它从靠近用户的位置提供内容。通常，html/css/js，图片和视频等静态内容由 cdn 提供，虽然亚马逊 cloudfront 等也支持动态内容。cdn 的 dns 解析会告知客户端连接哪台服务器。\n\n将内容存储在 cdn 上可以从两个方面来提供性能:\n\n * 从靠近用户的数据中心提供资源\n * 通过 cdn 你的服务器不必真的处理请求\n\n# cdn 推送（push）\n\n当你服务器上内容发生变动时，推送 cdn 接受新内容。直接推送给 cdn 并重写 url 地址以指向你的内容的 cdn 地址。你可以配置内容到期时间及何时更新。内容只有在更改或新增是才推送，流量最小化，但储存最大化。\n\n# cdn 拉取（pull）\n\ncdn 拉取是当第一个用户请求该资源时，从服务器上拉取资源。你将内容留在自己的服务器上并重写 url 指向 cdn 地址。直到内容被缓存在 cdn 上为止，这样请求只会更慢，\n\n存活时间（ttl）决定缓存多久时间。cdn 拉取方式最小化 cdn 上的储存空间，但如果过期文件并在实际更改之前被拉取，则会导致冗余的流量。\n\n高流量站点使用 cdn 拉取效果不错，因为只有最近请求的内容保存在 cdn 中，流量才能更平衡地分散。\n\n# 缺陷：cdn\n\n * cdn 成本可能因流量而异，可能在权衡之后你将不会使用 cdn。\n * 如果在 ttl 过期之前更新内容，cdn 缓存内容可能会过时。\n * cdn 需要更改静态内容的 url 地址以指向 cdn。\n\n# 来源及延伸阅读\n\n * 全球性内容分发网络\n * cdn 拉取和 cdn 推送的区别\n * wikipedia\n\n\n# 负载均衡器\n\n\n\n负载均衡器将传入的请求分发到应用服务器和数据库等计算资源。无论哪种情况，负载均衡器将从计算资源来的响应返回给恰当的客户端。负载均衡器的效用在于:\n\n * 防止请求进入不好的服务器\n * 防止资源过载\n * 帮助消除单一的故障点\n\n负载均衡器可以通过硬件（昂贵）或 haproxy 等软件来实现。 增加的好处包括:\n\n * ssl 终结\n   \n   ─ 解密传入的请求并加密服务器响应，这样的话后端服务器就不必再执行这些潜在高消耗运算了。\n   \n   * 不需要再每台服务器上安装 x.509 证书。\n\n * session 留存 ─ 如果 web 应用程序不追踪会话，发出 cookie 并将特定客户端的请求路由到同一实例。\n\n通常会设置采用工作 ─ 备用 或 双工作 模式的多个负载均衡器，以免发生故障。\n\n负载均衡器能基于多种方式来路由流量:\n\n * 随机\n * 最少负载\n * session/cookie\n * 轮询调度或加权轮询调度算法\n * 四层负载均衡\n * 七层负载均衡\n\n# 四层负载均衡\n\n四层负载均衡根据监看传输层的信息来决定如何分发请求。通常，这会涉及来源，目标 ip 地址和请求头中的端口，但不包括数据包（报文）内容。四层负载均衡执行网络地址转换（nat）来向上游服务器转发网络数据包。\n\n# 七层负载均衡器\n\n七层负载均衡器根据监控应用层来决定怎样分发请求。这会涉及请求头的内容，消息和 cookie。七层负载均衡器终结网络流量，读取消息，做出负载均衡判定，然后传送给特定服务器。比如，一个七层负载均衡器能直接将视频流量连接到托管视频的服务器，同时将更敏感的用户账单流量引导到安全性更强的服务器。\n\n以损失灵活性为代价，四层负载均衡比七层负载均衡花费更少时间和计算资源，虽然这对现代商用硬件的性能影响甚微。\n\n# 水平扩展\n\n负载均衡器还能帮助水平扩展，提高性能和可用性。使用商业硬件的性价比更高，并且比在单台硬件上垂直扩展更贵的硬件具有更高的可用性。相比招聘特定企业系统人才，招聘商业硬件方面的人才更加容易。\n\n# 缺陷：水平扩展\n\n * 水平扩展引入了复杂度并涉及服务器复制\n   * 服务器应该是无状态的:它们也不该包含像 session 或资料图片等与用户关联的数据。\n   * session 可以集中存储在数据库或持久化缓存（redis、memcached）的数据存储区中。\n * 缓存和数据库等下游服务器需要随着上游服务器进行扩展，以处理更多的并发连接。\n\n# 缺陷：负载均衡器\n\n * 如果没有足够的资源配置或配置错误，负载均衡器会变成一个性能瓶颈。\n * 引入负载均衡器以帮助消除单点故障但导致了额外的复杂性。\n * 单个负载均衡器会导致单点故障，但配置多个负载均衡器会进一步增加复杂性。\n\n# 来源及延伸阅读\n\n * nginx 架构\n * haproxy 架构指南\n * 可扩展性\n * wikipedia\n * 四层负载平衡\n * 七层负载平衡\n * elb 监听器配置\n\n\n# 反向代理（web 服务器）\n\n",charsets:{cjk:!0},lastUpdated:"2024/09/15, 03:15:07",lastUpdatedTimestamp:1726370107e3},{title:"博客文章",frontmatter:{archivesPage:!0,title:"博客文章",permalink:"/blog/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-61d0fb85",path:"/blog/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2024/09/13, 19:57:43",lastUpdatedTimestamp:1726257463e3},{title:"第三步：核心系统",frontmatter:{title:"第三步：核心系统",date:"2024-09-15T11:12:53.000Z",permalink:"/pages/b97db9/"},regularPath:"/08.%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/01.%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/03.%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E6%A0%B8%E5%BF%83%E7%B3%BB%E7%BB%9F.html",relativePath:"08.学习路线/01.学习路线/03.第三步：核心系统.md",key:"v-7604068d",path:"/pages/b97db9/",headers:[{level:3,title:"应用层",slug:"应用层",normalizedTitle:"应用层",charIndex:2},{level:4,title:"微服务",slug:"微服务",normalizedTitle:"微服务",charIndex:157},{level:4,title:"服务发现",slug:"服务发现",normalizedTitle:"服务发现",charIndex:298},{level:4,title:"不利之处：应用层",slug:"不利之处-应用层",normalizedTitle:"不利之处：应用层",charIndex:465},{level:4,title:"来源及延伸阅读",slug:"来源及延伸阅读",normalizedTitle:"来源及延伸阅读",charIndex:548},{level:3,title:"数据库",slug:"数据库",normalizedTitle:"数据库",charIndex:631},{level:4,title:"关系型数据库管理系统（RDBMS）",slug:"关系型数据库管理系统-rdbms",normalizedTitle:"关系型数据库管理系统（rdbms）",charIndex:640},{level:4,title:"NoSQL",slug:"nosql",normalizedTitle:"nosql",charIndex:2747},{level:4,title:"SQL 还是 NoSQL",slug:"sql-还是-nosql",normalizedTitle:"sql 还是 nosql",charIndex:3008},{level:3,title:"缓存",slug:"缓存",normalizedTitle:"缓存",charIndex:1421},{level:3,title:"异步",slug:"异步",normalizedTitle:"异步",charIndex:149},{level:3,title:"通讯",slug:"通讯",normalizedTitle:"通讯",charIndex:231},{level:3,title:"安全",slug:"安全",normalizedTitle:"安全",charIndex:5394},{level:2,title:"附录",slug:"附录",normalizedTitle:"附录",charIndex:5578},{level:3,title:"其它的系统设计面试题",slug:"其它的系统设计面试题",normalizedTitle:"其它的系统设计面试题",charIndex:5585},{level:3,title:"真实架构",slug:"真实架构",normalizedTitle:"真实架构",charIndex:6788},{level:3,title:"公司的系统架构",slug:"公司的系统架构",normalizedTitle:"公司的系统架构",charIndex:8502},{level:3,title:"公司工程博客",slug:"公司工程博客",normalizedTitle:"公司工程博客",charIndex:9566},{level:4,title:"来源及延伸阅读",slug:"来源及延伸阅读-2",normalizedTitle:"来源及延伸阅读",charIndex:548},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:10622}],headersStr:"应用层 微服务 服务发现 不利之处：应用层 来源及延伸阅读 数据库 关系型数据库管理系统（RDBMS） NoSQL SQL 还是 NoSQL 缓存 异步 通讯 安全 附录 其它的系统设计面试题 真实架构 公司的系统架构 公司工程博客 来源及延伸阅读 参考文献",content:"# 应用层\n\n\n\n将 Web 服务层与应用层（也被称作平台层）分离，可以独立缩放和配置这两层。添加新的 API 只需要添加应用服务器，而不必添加额外的 web 服务器。\n\n单一职责原则提倡小型的，自治的服务共同合作。小团队通过提供小型的服务，可以更激进地计划增长。\n\n应用层中的工作进程也有可以实现异步化。\n\n# 微服务\n\n与此讨论相关的话题是 微服务，可以被描述为一系列可以独立部署的小型的，模块化服务。每个服务运行在一个独立的线程中，通过明确定义的轻量级机制通讯，共同实现业务目标。1\n\n例如，Pinterest 可能有这些微服务： 用户资料、关注者、Feed 流、搜索、照片上传等。\n\n# 服务发现\n\n像 Consul，Etcd 和 Zookeeper 这样的系统可以通过追踪注册名、地址、端口等信息来帮助服务互相发现对方。Health checks 可以帮助确认服务的完整性和是否经常使用一个 HTTP 路径。Consul 和 Etcd 都有一个内建的 key-value 存储 用来存储配置信息和其他的共享信息。\n\n# 不利之处：应用层\n\n * 添加由多个松耦合服务组成的应用层，从架构、运营、流程等层面来讲将非常不同（相对于单体系统）。\n * 微服务会增加部署和运营的复杂度。\n\n# 来源及延伸阅读\n\n * 可缩放系统构架介绍\n * 破解系统设计面试\n * 面向服务架构\n * Zookeeper 介绍\n * 构建微服务，你所需要知道的一切\n\n\n# 数据库\n\n\n\n# 关系型数据库管理系统（RDBMS）\n\n * 主从复制\n   \n   * 主库同时负责读取和写入操作，并复制写入到一个或多个从库中，从库只负责读操作。树状形式的从库再将写入复制到更多的从库中去。如果主库离线，系统可以以只读模式运行，直到某个从库被提升为主库或有新的主库出现。\n   * 缺点\n     * 将从库提升为主库需要额外的逻辑\n     * 参考不利之处：复制中，主从复制和主主复制共同的问题。\n\n * 主主复制\n   \n   * 两个主库都负责读操作和写操作，写入操作时互相协调。如果其中一个主库挂机，系统可以继续读取和写入。\n   * 缺点：\n     * 你需要添加负载均衡器或者在应用逻辑中做改动，来确定写入哪一个数据库。\n     * 多数主-主系统要么不能保证一致性（违反 ACID），要么因为同步产生了写入延迟。\n     * 随着更多写入节点的加入和延迟的提高，如何解决冲突显得越发重要。\n     * 参考不利之处：复制中，主从复制和主主复制共同的问题\n\n * 不利之处：复制\n   \n   * 如果主库在将新写入的数据复制到其他节点前挂掉，则有数据丢失的可能。\n   * 写入会被重放到负责读取操作的副本。副本可能因为过多写操作阻塞住，导致读取功能异常。\n   * 读取从库越多，需要复制的写入数据就越多，导致更严重的复制延迟。\n   * 在某些数据库系统中，写入主库的操作可以用多个线程并行写入，但读取副本只支持单线程顺序地写入。\n   * 复制意味着更多的硬件和额外的复杂度。\n\n * 联合\n   \n   * 联合（或按功能划分）将数据库按对应功能分割。例如，你可以有三个数据库：论坛、用户和产品，而不仅是一个单体数据库，从而减少每个数据库的读取和写入流量，减少复制延迟。较小的数据库意味着更多适合放入内存的数据，进而意味着更高的缓存命中几率。没有只能串行写入的中心化主库，你可以并行写入，提高负载能力。\n   * 缺点\n     * 如果你的数据库模式需要大量的功能和数据表，联合的效率并不好。\n     * 你需要更新应用程序的逻辑来确定要读取和写入哪个数据库。\n     * 用 server link 从两个库联结数据更复杂。\n     * 联合需要更多的硬件和额外的复杂度。\n\n * 分片\n   \n   * 分片将数据分配在不同的数据库上，使得每个数据库仅管理整个数据集的一个子集。以用户数据库为例，随着用户数量的增加，越来越多的分片会被添加到集群中。\n     \n     类似联合的优点，分片可以减少读取和写入流量，减少复制并提高缓存命中率。也减少了索引，通常意味着查询更快，性能更好。如果一个分片出问题，其他的仍能运行，你可以使用某种形式的冗余来防止数据丢失。类似联合，没有只能串行写入的中心化主库，你可以并行写入，提高负载能力。\n     \n     常见的做法是用户姓氏的首字母或者用户的地理位置来分隔用户表。\n   \n   * 缺点\n     \n     * 你需要修改应用程序的逻辑来实现分片，这会带来复杂的 SQL 查询。\n     * 分片不合理可能导致数据负载不均衡。例如，被频繁访问的用户数据会导致其所在分片的负载相对其他分片高。\n       * 再平衡会引入额外的复杂度。基于一致性哈希的分片算法可以减少这种情况。\n     * 联结多个分片的数据操作更复杂。\n     * 分片需要更多的硬件和额外的复杂度。\n\n * 非规范化\n   \n   * 非规范化试图以写入性能为代价来换取读取性能。在多个表中冗余数据副本，以避免高成本的联结操作。一些关系型数据库，比如 PostgreSQL 和 Oracle 支持物化视图，可以处理冗余信息存储和保证冗余副本一致。\n     \n     当数据使用诸如联合和分片等技术被分割，进一步提高了处理跨数据中心的联结操作复杂度。非规范化可以规避这种复杂的联结操作。\n     \n     在多数系统中，读取操作的频率远高于写入操作，比例可达到 100:1，甚至 1000:1。需要复杂的数据库联结的读取操作成本非常高，在磁盘操作上消耗了大量时间。\n   \n   * 缺点\n     \n     * 数据会冗余。\n     * 约束可以帮助冗余的信息副本保持同步，但这样会增加数据库设计的复杂度。\n     * 非规范化的数据库在高写入负载下性能可能比规范化的数据库差。\n\n * SQL 调优\n   \n   * SQL 调优是一个范围很广的话题，有很多相关的书可以作为参考。\n     \n     利用基准测试和性能分析来模拟和发现系统瓶颈很重要。\n     \n     * 基准测试 - 用 ab 等工具模拟高负载情况。\n     * 性能分析 - 通过启用如慢查询日志等工具来辅助追踪性能问题。\n     \n     基准测试和性能分析可能会指引你到以下优化方案。\n   \n   * 使用正确的索引\n   \n   * 避免高成本的联结操作\n   \n   * 分割数据表\n   \n   * 调优查询缓存\n\n# NoSQL\n\nNoSQL 是键-值数据库、文档型数据库、列型数据库或图数据库的统称。数据库是非规范化的，表联结大多在应用程序代码中完成。大多数 NoSQL 无法实现真正符合 ACID 的事务，支持最终一致。\n\nBASE 通常被用于描述 NoSQL 数据库的特性。相比 CAP 理论，BASE 强调可用性超过一致性。\n\n * 基本可用 - 系统保证可用性。\n * 软状态 - 即使没有输入，系统状态也可能随着时间变化。\n * 最终一致性 - 经过一段时间之后，系统最终会变一致，因为系统在此期间没有收到任何输入。\n\n除了在 SQL 还是 NoSQL 之间做选择，了解哪种类型的 NoSQL 数据库最适合你的用例也是非常有帮助的。我们将在下一节中快速了解下 键-值存储、文档型存储、列型存储和图存储数据库。\n\n键-值存储\n\n> 抽象模型：哈希表\n\n键-值存储通常可以实现 O(1) 时间读写，用内存或 SSD 存储数据。数据存储可以按字典顺序维护键，从而实现键的高效检索。键-值存储可以用于存储元数据。\n\n键-值存储性能很高，通常用于存储简单数据模型或频繁修改的数据，如存放在内存中的缓存。键-值存储提供的操作有限，如果需要更多操作，复杂度将转嫁到应用程序层面。\n\n键-值存储是如文档存储，在某些情况下，甚至是图存储等更复杂的存储系统的基础。\n\n文档类型存储\n\n> 抽象模型：将文档作为值的键-值存储\n\n文档类型存储以文档（XML、JSON、二进制文件等）为中心，文档存储了指定对象的全部信息。文档存储根据文档自身的内部结构提供 API 或查询语句来实现查询。请注意，许多键-值存储数据库有用值存储元数据的特性，这也模糊了这两种存储类型的界限。\n\n基于底层实现，文档可以根据集合、标签、元数据或者文件夹组织。尽管不同文档可以被组织在一起或者分成一组，但相互之间可能具有完全不同的字段。\n\nMongoDB 和 CouchDB 等一些文档类型存储还提供了类似 SQL 语言的查询语句来实现复杂查询。DynamoDB 同时支持键-值存储和文档类型存储。\n\n文档类型存储具备高度的灵活性，常用于处理偶尔变化的数据。\n\n图数据库\n\n在图数据库中，一个节点对应一条记录，一个弧对应两个节点之间的关系。图数据库被优化用于表示外键繁多的复杂关系或多对多关系。\n\n图数据库为存储复杂关系的数据模型，如社交网络，提供了很高的性能。它们相对较新，尚未广泛应用，查找开发工具或者资源相对较难。许多图只能通过 REST API 访问。\n\n# SQL 还是 NoSQL\n\n选取 SQL 的原因:\n\n * 结构化数据\n * 严格的模式\n * 关系型数据\n * 需要复杂的联结操作\n * 事务\n * 清晰的扩展模式\n * 既有资源更丰富：开发者、社区、代码库、工具等\n * 通过索引进行查询非常快\n\n选取 NoSQL 的原因：\n\n * 半结构化数据\n * 动态或灵活的模式\n * 非关系型数据\n * 不需要复杂的联结操作\n * 存储 TB （甚至 PB）级别的数据\n * 高数据密集的工作负载\n * IOPS 高吞吐量\n\n适合 NoSQL 的示例数据：\n\n * 埋点数据和日志数据\n * 排行榜或者得分数据\n * 临时数据，如购物车\n * 频繁访问的（“热”）表\n * 元数据／查找表\n\n\n# 缓存\n\n缓存可以提高页面加载速度，并可以减少服务器和数据库的负载。在这个模型中，分发器先查看请求之前是否被响应过，如果有则将之前的结果直接返回，来省掉真正的处理。\n\n数据库分片均匀分布的读取是最好的。但是热门数据会让读取分布不均匀，这样就会造成瓶颈，如果在数据库前加个缓存，就会抹平不均匀的负载和突发流量对数据库的影响。\n\n缓存类型\n\n * 客户端缓存\n * CDN 缓存\n * Web 服务器缓存（Nginx）\n * 数据库缓存\n * 应用缓存（Redis）\n\n缓存相关\n\n * 数据库查询级别的缓存\n * 对象级别的缓存\n * 缓存的模式：https://javaguide.cn/database/redis/3-commonly-used-cache-read-and-write-strategies.html\n\n\n# 异步\n\n\n\n异步工作流有助于减少那些原本顺序执行的请求时间。它们可以通过提前进行一些耗时的工作来帮助减少请求时间，比如定期汇总数据。\n\n * 消息队列：\n   \n   * 消息队列接收，保留和传递消息。如果按顺序执行操作太慢的话，你可以使用有以下工作流的消息队列：\n     \n     * 应用程序将作业发布到队列，然后通知用户作业状态\n     * 一个 worker 从队列中取出该作业，对其进行处理，然后显示该作业完成\n     \n     不去阻塞用户操作，作业在后台处理。在此期间，客户端可能会进行一些处理使得看上去像是任务已经完成了。例如，如果要发送一条推文，推文可能会马上出现在你的时间线上，但是可能需要一些时间才能将你的推文推送到你的所有关注者那里去。\n     \n     Redis 是一个令人满意的简单的消息代理，但是消息有可能会丢失。\n     \n     RabbitMQ 很受欢迎但是要求你适应「AMQP」协议并且管理你自己的节点。\n     \n     Amazon SQS 是被托管的，但可能具有高延迟，并且消息可能会被传送两次。\n\n * 任务队列\n   \n   * 任务队列接收任务及其相关数据，运行它们，然后传递其结果。 它们可以支持调度，并可用于在后台运行计算密集型作业。\n\n * 背压\n   \n   * 如果队列开始明显增长，那么队列大小可能会超过内存大小，导致高速缓存未命中，磁盘读取，甚至性能更慢。背压可以通过限制队列大小来帮助我们，从而为队列中的作业保持高吞吐率和良好的响应时间。一旦队列填满，客户端将得到服务器忙或者 HTTP 503 状态码，以便稍后重试。客户端可以在稍后时间重试该请求，也许是指数退避。\n\n * 异步的缺点\n   \n   * 简单的计算和实时工作流等用例可能更适用于同步操作，因为引入队列可能会增加延迟和复杂性。\n\n\n# 通讯\n\n * 超文本传输协议（HTTP）\n * 传输控制协议（TCP）\n * 用户数据报协议（UDP）\n * 远程过程调用协议（RPC）\n * 表述性状态转移（REST）\n * RPC 与 REST 比较\n\n\n# 安全\n\n这一部分需要更多内容。一起来吧！\n\n安全是一个宽泛的话题。除非你有相当的经验、安全方面背景或者正在申请的职位要求安全知识，你不需要了解安全基础知识以外的内容：\n\n * 在运输和等待过程中加密\n * 对所有的用户输入和从用户那里发来的参数进行处理以防止 XSS 和 SQL 注入。\n * 使用参数化的查询来防止 SQL 注入。\n * 使用最小权限原则。\n\n\n# 附录\n\n\n# 其它的系统设计面试题\n\n常见的系统设计面试问题，给出了如何解决的方案链接\n\n问题                        引用\n设计类似于 Dropbox 的文件同步服务     youtube.com\n设计类似于 Google 的搜索引擎        queue.acm.orgstackexchange.comardendertat.comstanford.edu\n设计类似于 Google 的可扩展网络爬虫     quora.com\n设计 Google 文档              code.google.comneil.fraser.name\n设计类似 Redis 的键值存储          slideshare.net\n设计类似 Memcached 的缓存系统      slideshare.net\n设计类似亚马逊的推荐系统              hulu.comijcai13.org\n设计类似 Bitly 的短链接系统         n00tc0d3r.blogspot.com\n设计类似 WhatsApp 的聊天应用       highscalability.com\n设计类似 Instagram 的图片分享系统    highscalability.comhighscalability.com\n设计 Facebook 的新闻推荐方法       quora.comquora.comslideshare.net\n设计 Facebook 的时间线系统        facebook.comhighscalability.com\n设计 Facebook 的聊天系统         erlang-factory.comfacebook.com\n设计类似 Facebook 的图表搜索系统     facebook.comfacebook.comfacebook.com\n设计类似 CloudFlare 的内容传递网络   cmu.edu\n设计类似 Twitter 的热门话题系统      michael-noll.comsnikolov .wordpress.com\n设计一个随机 ID 生成系统            blog.twitter.comgithub.com\n返回一定时间段内次数前 k 高的请求        ucsb.eduwpi.edu\n设计一个数据源于多个数据中心的服务系统       highscalability.com\n设计一个多人网络卡牌游戏              indieflashblog.combuildnewgames.com\n设计一个垃圾回收系统                stuffwithstuff.comwashington.edu\n添加更多的系统设计问题               贡献\n\n\n# 真实架构\n\n关于现实中真实的系统是怎么设计的文章。\n\nSource: Twitter timelines at scale\n\n不要专注于以下文章的细节，专注于以下方面：\n\n * 发现这些文章中的共同的原则、技术和模式。\n * 学习每个组件解决哪些问题，什么情况下使用，什么情况下不适用\n * 复习学过的文章\n\n类型                系统                                      引用\nData processing   MapReduce - Google 的分布式数据处理             research.google.com\nData processing   Spark - Databricks 的分布式数据处理             slideshare.net\nData processing   Storm - Twitter 的分布式数据处理                slideshare.net\n                                                          \nData store        Bigtable - Google 的列式数据库                harvard.edu\nData store        HBase - Bigtable 的开源实现                  slideshare.net\nData store        Cassandra - Facebook 的列式数据库             slideshare.net\nData store        DynamoDB - Amazon 的文档数据库                harvard.edu\nData store        MongoDB - 文档数据库                         slideshare.net\nData store        Spanner - Google 的全球分布数据库               research.google.com\nData store        Memcached - 分布式内存缓存系统                   slideshare.net\nData store        Redis - 能够持久化及具有值类型的分布式内存缓存系统           slideshare.net\n                                                          \nFile system       Google File System (GFS) - 分布式文件系统      research.google.com\nFile system       Hadoop File System (HDFS) - GFS 的开源实现   apache.org\n                                                          \nMisc              Chubby - Google 的分布式系统的低耦合锁服务           research.google.com\nMisc              Dapper - 分布式系统跟踪基础设施                    research.google.com\nMisc              Kafka - LinkedIn 的发布订阅消息系统              slideshare.net\nMisc              Zookeeper - 集中的基础架构和协调服务                slideshare.net\n                  添加更多                                    贡献\n\n\n# 公司的系统架构\n\nCOMPANY          REFERENCE(S)\nAmazon           Amazon 的架构\nCinchcast        每天产生 1500 小时的音频\nDataSift         每秒实时挖掘 120000 条 tweet\nDropBox          我们如何缩放 Dropbox\nESPN             每秒操作 100000 次\nGoogle           Google 的架构\nInstagram        1400 万用户，达到兆级别的照片存储是什么在驱动 Instagram\nJustin.tv        Justin.Tv 的直播广播架构\nFacebook         Facebook 的可扩展 memcachedTAO: Facebook 社交图的分布式数据存储Facebook\n                 的图片存储\nFlickr           Flickr 的架构\nMailbox          在 6 周内从 0 到 100 万用户\nPinterest        从零到每月数十亿的浏览量1800 万访问用户，10 倍增长，12 名员工\nPlayfish         月用户量 5000 万并在不断增长\nPlentyOfFish     PlentyOfFish 的架构\nSalesforce       他们每天如何处理 13 亿笔交易\nStack Overflow   Stack Overflow 的架构\nTripAdvisor      40M 访问者，200M 页面浏览量，30TB 数据\nTumblr           每月 150 亿的浏览量\nTwitter          Making Twitter 10000 percent faster每天使用 MySQL 存储 2.5 亿条\n                 tweet150M 活跃用户，300K QPS，22 MB/S 的防火墙可扩展时间表Twitter\n                 的大小数据Twitter 的行为：规模超过 1 亿用户\nUber             Uber 如何扩展自己的实时化市场\nWhatsApp         Facebook 用 190 亿美元购买 WhatsApp 的架构\nYouTube          YouTube 的可扩展性YouTube 的架构\n\n\n# 公司工程博客\n\n你即将面试的公司的架构\n\n你面对的问题可能就来自于同样领域\n\n * Airbnb Engineering\n * Atlassian Developers\n * Autodesk Engineering\n * AWS Blog\n * Bitly Engineering Blog\n * Box Blogs\n * Cloudera Developer Blog\n * Dropbox Tech Blog\n * Engineering at Quora\n * Ebay Tech Blog\n * Evernote Tech Blog\n * Etsy Code as Craft\n * Facebook Engineering\n * Flickr Code\n * Foursquare Engineering Blog\n * GitHub Engineering Blog\n * Google Research Blog\n * Groupon Engineering Blog\n * Heroku Engineering Blog\n * Hubspot Engineering Blog\n * High Scalability\n * Instagram Engineering\n * Intel Software Blog\n * Jane Street Tech Blog\n * LinkedIn Engineering\n * Microsoft Engineering\n * Microsoft Python Engineering\n * Netflix Tech Blog\n * Paypal Developer Blog\n * Pinterest Engineering Blog\n * Quora Engineering\n * Reddit Blog\n * Salesforce Engineering Blog\n * Slack Engineering Blog\n * Spotify Labs\n * Twilio Engineering Blog\n * Twitter Engineering\n * Uber Engineering Blog\n * Yahoo Engineering Blog\n * Yelp Engineering Blog\n * Zynga Engineering Blog\n\n# 来源及延伸阅读\n\n * kilimchoi/engineering-blogs\n\n\n# 参考文献\n\n * 原文地址：github.com/donnemartin/system-design-primer\n * 译文出自：掘金翻译计划",normalizedContent:"# 应用层\n\n\n\n将 web 服务层与应用层（也被称作平台层）分离，可以独立缩放和配置这两层。添加新的 api 只需要添加应用服务器，而不必添加额外的 web 服务器。\n\n单一职责原则提倡小型的，自治的服务共同合作。小团队通过提供小型的服务，可以更激进地计划增长。\n\n应用层中的工作进程也有可以实现异步化。\n\n# 微服务\n\n与此讨论相关的话题是 微服务，可以被描述为一系列可以独立部署的小型的，模块化服务。每个服务运行在一个独立的线程中，通过明确定义的轻量级机制通讯，共同实现业务目标。1\n\n例如，pinterest 可能有这些微服务： 用户资料、关注者、feed 流、搜索、照片上传等。\n\n# 服务发现\n\n像 consul，etcd 和 zookeeper 这样的系统可以通过追踪注册名、地址、端口等信息来帮助服务互相发现对方。health checks 可以帮助确认服务的完整性和是否经常使用一个 http 路径。consul 和 etcd 都有一个内建的 key-value 存储 用来存储配置信息和其他的共享信息。\n\n# 不利之处：应用层\n\n * 添加由多个松耦合服务组成的应用层，从架构、运营、流程等层面来讲将非常不同（相对于单体系统）。\n * 微服务会增加部署和运营的复杂度。\n\n# 来源及延伸阅读\n\n * 可缩放系统构架介绍\n * 破解系统设计面试\n * 面向服务架构\n * zookeeper 介绍\n * 构建微服务，你所需要知道的一切\n\n\n# 数据库\n\n\n\n# 关系型数据库管理系统（rdbms）\n\n * 主从复制\n   \n   * 主库同时负责读取和写入操作，并复制写入到一个或多个从库中，从库只负责读操作。树状形式的从库再将写入复制到更多的从库中去。如果主库离线，系统可以以只读模式运行，直到某个从库被提升为主库或有新的主库出现。\n   * 缺点\n     * 将从库提升为主库需要额外的逻辑\n     * 参考不利之处：复制中，主从复制和主主复制共同的问题。\n\n * 主主复制\n   \n   * 两个主库都负责读操作和写操作，写入操作时互相协调。如果其中一个主库挂机，系统可以继续读取和写入。\n   * 缺点：\n     * 你需要添加负载均衡器或者在应用逻辑中做改动，来确定写入哪一个数据库。\n     * 多数主-主系统要么不能保证一致性（违反 acid），要么因为同步产生了写入延迟。\n     * 随着更多写入节点的加入和延迟的提高，如何解决冲突显得越发重要。\n     * 参考不利之处：复制中，主从复制和主主复制共同的问题\n\n * 不利之处：复制\n   \n   * 如果主库在将新写入的数据复制到其他节点前挂掉，则有数据丢失的可能。\n   * 写入会被重放到负责读取操作的副本。副本可能因为过多写操作阻塞住，导致读取功能异常。\n   * 读取从库越多，需要复制的写入数据就越多，导致更严重的复制延迟。\n   * 在某些数据库系统中，写入主库的操作可以用多个线程并行写入，但读取副本只支持单线程顺序地写入。\n   * 复制意味着更多的硬件和额外的复杂度。\n\n * 联合\n   \n   * 联合（或按功能划分）将数据库按对应功能分割。例如，你可以有三个数据库：论坛、用户和产品，而不仅是一个单体数据库，从而减少每个数据库的读取和写入流量，减少复制延迟。较小的数据库意味着更多适合放入内存的数据，进而意味着更高的缓存命中几率。没有只能串行写入的中心化主库，你可以并行写入，提高负载能力。\n   * 缺点\n     * 如果你的数据库模式需要大量的功能和数据表，联合的效率并不好。\n     * 你需要更新应用程序的逻辑来确定要读取和写入哪个数据库。\n     * 用 server link 从两个库联结数据更复杂。\n     * 联合需要更多的硬件和额外的复杂度。\n\n * 分片\n   \n   * 分片将数据分配在不同的数据库上，使得每个数据库仅管理整个数据集的一个子集。以用户数据库为例，随着用户数量的增加，越来越多的分片会被添加到集群中。\n     \n     类似联合的优点，分片可以减少读取和写入流量，减少复制并提高缓存命中率。也减少了索引，通常意味着查询更快，性能更好。如果一个分片出问题，其他的仍能运行，你可以使用某种形式的冗余来防止数据丢失。类似联合，没有只能串行写入的中心化主库，你可以并行写入，提高负载能力。\n     \n     常见的做法是用户姓氏的首字母或者用户的地理位置来分隔用户表。\n   \n   * 缺点\n     \n     * 你需要修改应用程序的逻辑来实现分片，这会带来复杂的 sql 查询。\n     * 分片不合理可能导致数据负载不均衡。例如，被频繁访问的用户数据会导致其所在分片的负载相对其他分片高。\n       * 再平衡会引入额外的复杂度。基于一致性哈希的分片算法可以减少这种情况。\n     * 联结多个分片的数据操作更复杂。\n     * 分片需要更多的硬件和额外的复杂度。\n\n * 非规范化\n   \n   * 非规范化试图以写入性能为代价来换取读取性能。在多个表中冗余数据副本，以避免高成本的联结操作。一些关系型数据库，比如 postgresql 和 oracle 支持物化视图，可以处理冗余信息存储和保证冗余副本一致。\n     \n     当数据使用诸如联合和分片等技术被分割，进一步提高了处理跨数据中心的联结操作复杂度。非规范化可以规避这种复杂的联结操作。\n     \n     在多数系统中，读取操作的频率远高于写入操作，比例可达到 100:1，甚至 1000:1。需要复杂的数据库联结的读取操作成本非常高，在磁盘操作上消耗了大量时间。\n   \n   * 缺点\n     \n     * 数据会冗余。\n     * 约束可以帮助冗余的信息副本保持同步，但这样会增加数据库设计的复杂度。\n     * 非规范化的数据库在高写入负载下性能可能比规范化的数据库差。\n\n * sql 调优\n   \n   * sql 调优是一个范围很广的话题，有很多相关的书可以作为参考。\n     \n     利用基准测试和性能分析来模拟和发现系统瓶颈很重要。\n     \n     * 基准测试 - 用 ab 等工具模拟高负载情况。\n     * 性能分析 - 通过启用如慢查询日志等工具来辅助追踪性能问题。\n     \n     基准测试和性能分析可能会指引你到以下优化方案。\n   \n   * 使用正确的索引\n   \n   * 避免高成本的联结操作\n   \n   * 分割数据表\n   \n   * 调优查询缓存\n\n# nosql\n\nnosql 是键-值数据库、文档型数据库、列型数据库或图数据库的统称。数据库是非规范化的，表联结大多在应用程序代码中完成。大多数 nosql 无法实现真正符合 acid 的事务，支持最终一致。\n\nbase 通常被用于描述 nosql 数据库的特性。相比 cap 理论，base 强调可用性超过一致性。\n\n * 基本可用 - 系统保证可用性。\n * 软状态 - 即使没有输入，系统状态也可能随着时间变化。\n * 最终一致性 - 经过一段时间之后，系统最终会变一致，因为系统在此期间没有收到任何输入。\n\n除了在 sql 还是 nosql 之间做选择，了解哪种类型的 nosql 数据库最适合你的用例也是非常有帮助的。我们将在下一节中快速了解下 键-值存储、文档型存储、列型存储和图存储数据库。\n\n键-值存储\n\n> 抽象模型：哈希表\n\n键-值存储通常可以实现 o(1) 时间读写，用内存或 ssd 存储数据。数据存储可以按字典顺序维护键，从而实现键的高效检索。键-值存储可以用于存储元数据。\n\n键-值存储性能很高，通常用于存储简单数据模型或频繁修改的数据，如存放在内存中的缓存。键-值存储提供的操作有限，如果需要更多操作，复杂度将转嫁到应用程序层面。\n\n键-值存储是如文档存储，在某些情况下，甚至是图存储等更复杂的存储系统的基础。\n\n文档类型存储\n\n> 抽象模型：将文档作为值的键-值存储\n\n文档类型存储以文档（xml、json、二进制文件等）为中心，文档存储了指定对象的全部信息。文档存储根据文档自身的内部结构提供 api 或查询语句来实现查询。请注意，许多键-值存储数据库有用值存储元数据的特性，这也模糊了这两种存储类型的界限。\n\n基于底层实现，文档可以根据集合、标签、元数据或者文件夹组织。尽管不同文档可以被组织在一起或者分成一组，但相互之间可能具有完全不同的字段。\n\nmongodb 和 couchdb 等一些文档类型存储还提供了类似 sql 语言的查询语句来实现复杂查询。dynamodb 同时支持键-值存储和文档类型存储。\n\n文档类型存储具备高度的灵活性，常用于处理偶尔变化的数据。\n\n图数据库\n\n在图数据库中，一个节点对应一条记录，一个弧对应两个节点之间的关系。图数据库被优化用于表示外键繁多的复杂关系或多对多关系。\n\n图数据库为存储复杂关系的数据模型，如社交网络，提供了很高的性能。它们相对较新，尚未广泛应用，查找开发工具或者资源相对较难。许多图只能通过 rest api 访问。\n\n# sql 还是 nosql\n\n选取 sql 的原因:\n\n * 结构化数据\n * 严格的模式\n * 关系型数据\n * 需要复杂的联结操作\n * 事务\n * 清晰的扩展模式\n * 既有资源更丰富：开发者、社区、代码库、工具等\n * 通过索引进行查询非常快\n\n选取 nosql 的原因：\n\n * 半结构化数据\n * 动态或灵活的模式\n * 非关系型数据\n * 不需要复杂的联结操作\n * 存储 tb （甚至 pb）级别的数据\n * 高数据密集的工作负载\n * iops 高吞吐量\n\n适合 nosql 的示例数据：\n\n * 埋点数据和日志数据\n * 排行榜或者得分数据\n * 临时数据，如购物车\n * 频繁访问的（“热”）表\n * 元数据／查找表\n\n\n# 缓存\n\n缓存可以提高页面加载速度，并可以减少服务器和数据库的负载。在这个模型中，分发器先查看请求之前是否被响应过，如果有则将之前的结果直接返回，来省掉真正的处理。\n\n数据库分片均匀分布的读取是最好的。但是热门数据会让读取分布不均匀，这样就会造成瓶颈，如果在数据库前加个缓存，就会抹平不均匀的负载和突发流量对数据库的影响。\n\n缓存类型\n\n * 客户端缓存\n * cdn 缓存\n * web 服务器缓存（nginx）\n * 数据库缓存\n * 应用缓存（redis）\n\n缓存相关\n\n * 数据库查询级别的缓存\n * 对象级别的缓存\n * 缓存的模式：https://javaguide.cn/database/redis/3-commonly-used-cache-read-and-write-strategies.html\n\n\n# 异步\n\n\n\n异步工作流有助于减少那些原本顺序执行的请求时间。它们可以通过提前进行一些耗时的工作来帮助减少请求时间，比如定期汇总数据。\n\n * 消息队列：\n   \n   * 消息队列接收，保留和传递消息。如果按顺序执行操作太慢的话，你可以使用有以下工作流的消息队列：\n     \n     * 应用程序将作业发布到队列，然后通知用户作业状态\n     * 一个 worker 从队列中取出该作业，对其进行处理，然后显示该作业完成\n     \n     不去阻塞用户操作，作业在后台处理。在此期间，客户端可能会进行一些处理使得看上去像是任务已经完成了。例如，如果要发送一条推文，推文可能会马上出现在你的时间线上，但是可能需要一些时间才能将你的推文推送到你的所有关注者那里去。\n     \n     redis 是一个令人满意的简单的消息代理，但是消息有可能会丢失。\n     \n     rabbitmq 很受欢迎但是要求你适应「amqp」协议并且管理你自己的节点。\n     \n     amazon sqs 是被托管的，但可能具有高延迟，并且消息可能会被传送两次。\n\n * 任务队列\n   \n   * 任务队列接收任务及其相关数据，运行它们，然后传递其结果。 它们可以支持调度，并可用于在后台运行计算密集型作业。\n\n * 背压\n   \n   * 如果队列开始明显增长，那么队列大小可能会超过内存大小，导致高速缓存未命中，磁盘读取，甚至性能更慢。背压可以通过限制队列大小来帮助我们，从而为队列中的作业保持高吞吐率和良好的响应时间。一旦队列填满，客户端将得到服务器忙或者 http 503 状态码，以便稍后重试。客户端可以在稍后时间重试该请求，也许是指数退避。\n\n * 异步的缺点\n   \n   * 简单的计算和实时工作流等用例可能更适用于同步操作，因为引入队列可能会增加延迟和复杂性。\n\n\n# 通讯\n\n * 超文本传输协议（http）\n * 传输控制协议（tcp）\n * 用户数据报协议（udp）\n * 远程过程调用协议（rpc）\n * 表述性状态转移（rest）\n * rpc 与 rest 比较\n\n\n# 安全\n\n这一部分需要更多内容。一起来吧！\n\n安全是一个宽泛的话题。除非你有相当的经验、安全方面背景或者正在申请的职位要求安全知识，你不需要了解安全基础知识以外的内容：\n\n * 在运输和等待过程中加密\n * 对所有的用户输入和从用户那里发来的参数进行处理以防止 xss 和 sql 注入。\n * 使用参数化的查询来防止 sql 注入。\n * 使用最小权限原则。\n\n\n# 附录\n\n\n# 其它的系统设计面试题\n\n常见的系统设计面试问题，给出了如何解决的方案链接\n\n问题                        引用\n设计类似于 dropbox 的文件同步服务     youtube.com\n设计类似于 google 的搜索引擎        queue.acm.orgstackexchange.comardendertat.comstanford.edu\n设计类似于 google 的可扩展网络爬虫     quora.com\n设计 google 文档              code.google.comneil.fraser.name\n设计类似 redis 的键值存储          slideshare.net\n设计类似 memcached 的缓存系统      slideshare.net\n设计类似亚马逊的推荐系统              hulu.comijcai13.org\n设计类似 bitly 的短链接系统         n00tc0d3r.blogspot.com\n设计类似 whatsapp 的聊天应用       highscalability.com\n设计类似 instagram 的图片分享系统    highscalability.comhighscalability.com\n设计 facebook 的新闻推荐方法       quora.comquora.comslideshare.net\n设计 facebook 的时间线系统        facebook.comhighscalability.com\n设计 facebook 的聊天系统         erlang-factory.comfacebook.com\n设计类似 facebook 的图表搜索系统     facebook.comfacebook.comfacebook.com\n设计类似 cloudflare 的内容传递网络   cmu.edu\n设计类似 twitter 的热门话题系统      michael-noll.comsnikolov .wordpress.com\n设计一个随机 id 生成系统            blog.twitter.comgithub.com\n返回一定时间段内次数前 k 高的请求        ucsb.eduwpi.edu\n设计一个数据源于多个数据中心的服务系统       highscalability.com\n设计一个多人网络卡牌游戏              indieflashblog.combuildnewgames.com\n设计一个垃圾回收系统                stuffwithstuff.comwashington.edu\n添加更多的系统设计问题               贡献\n\n\n# 真实架构\n\n关于现实中真实的系统是怎么设计的文章。\n\nsource: twitter timelines at scale\n\n不要专注于以下文章的细节，专注于以下方面：\n\n * 发现这些文章中的共同的原则、技术和模式。\n * 学习每个组件解决哪些问题，什么情况下使用，什么情况下不适用\n * 复习学过的文章\n\n类型                系统                                      引用\ndata processing   mapreduce - google 的分布式数据处理             research.google.com\ndata processing   spark - databricks 的分布式数据处理             slideshare.net\ndata processing   storm - twitter 的分布式数据处理                slideshare.net\n                                                          \ndata store        bigtable - google 的列式数据库                harvard.edu\ndata store        hbase - bigtable 的开源实现                  slideshare.net\ndata store        cassandra - facebook 的列式数据库             slideshare.net\ndata store        dynamodb - amazon 的文档数据库                harvard.edu\ndata store        mongodb - 文档数据库                         slideshare.net\ndata store        spanner - google 的全球分布数据库               research.google.com\ndata store        memcached - 分布式内存缓存系统                   slideshare.net\ndata store        redis - 能够持久化及具有值类型的分布式内存缓存系统           slideshare.net\n                                                          \nfile system       google file system (gfs) - 分布式文件系统      research.google.com\nfile system       hadoop file system (hdfs) - gfs 的开源实现   apache.org\n                                                          \nmisc              chubby - google 的分布式系统的低耦合锁服务           research.google.com\nmisc              dapper - 分布式系统跟踪基础设施                    research.google.com\nmisc              kafka - linkedin 的发布订阅消息系统              slideshare.net\nmisc              zookeeper - 集中的基础架构和协调服务                slideshare.net\n                  添加更多                                    贡献\n\n\n# 公司的系统架构\n\ncompany          reference(s)\namazon           amazon 的架构\ncinchcast        每天产生 1500 小时的音频\ndatasift         每秒实时挖掘 120000 条 tweet\ndropbox          我们如何缩放 dropbox\nespn             每秒操作 100000 次\ngoogle           google 的架构\ninstagram        1400 万用户，达到兆级别的照片存储是什么在驱动 instagram\njustin.tv        justin.tv 的直播广播架构\nfacebook         facebook 的可扩展 memcachedtao: facebook 社交图的分布式数据存储facebook\n                 的图片存储\nflickr           flickr 的架构\nmailbox          在 6 周内从 0 到 100 万用户\npinterest        从零到每月数十亿的浏览量1800 万访问用户，10 倍增长，12 名员工\nplayfish         月用户量 5000 万并在不断增长\nplentyoffish     plentyoffish 的架构\nsalesforce       他们每天如何处理 13 亿笔交易\nstack overflow   stack overflow 的架构\ntripadvisor      40m 访问者，200m 页面浏览量，30tb 数据\ntumblr           每月 150 亿的浏览量\ntwitter          making twitter 10000 percent faster每天使用 mysql 存储 2.5 亿条\n                 tweet150m 活跃用户，300k qps，22 mb/s 的防火墙可扩展时间表twitter\n                 的大小数据twitter 的行为：规模超过 1 亿用户\nuber             uber 如何扩展自己的实时化市场\nwhatsapp         facebook 用 190 亿美元购买 whatsapp 的架构\nyoutube          youtube 的可扩展性youtube 的架构\n\n\n# 公司工程博客\n\n你即将面试的公司的架构\n\n你面对的问题可能就来自于同样领域\n\n * airbnb engineering\n * atlassian developers\n * autodesk engineering\n * aws blog\n * bitly engineering blog\n * box blogs\n * cloudera developer blog\n * dropbox tech blog\n * engineering at quora\n * ebay tech blog\n * evernote tech blog\n * etsy code as craft\n * facebook engineering\n * flickr code\n * foursquare engineering blog\n * github engineering blog\n * google research blog\n * groupon engineering blog\n * heroku engineering blog\n * hubspot engineering blog\n * high scalability\n * instagram engineering\n * intel software blog\n * jane street tech blog\n * linkedin engineering\n * microsoft engineering\n * microsoft python engineering\n * netflix tech blog\n * paypal developer blog\n * pinterest engineering blog\n * quora engineering\n * reddit blog\n * salesforce engineering blog\n * slack engineering blog\n * spotify labs\n * twilio engineering blog\n * twitter engineering\n * uber engineering blog\n * yahoo engineering blog\n * yelp engineering blog\n * zynga engineering blog\n\n# 来源及延伸阅读\n\n * kilimchoi/engineering-blogs\n\n\n# 参考文献\n\n * 原文地址：github.com/donnemartin/system-design-primer\n * 译文出自：掘金翻译计划",charsets:{cjk:!0},lastUpdated:"2024/09/15, 03:15:07",lastUpdatedTimestamp:1726370107e3},{title:"Redis 架构概述",frontmatter:{title:"Redis 架构概述",date:"2024-09-15T01:36:53.000Z",permalink:"/pages/264b06/"},regularPath:"/09.%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E9%89%B4%E8%B5%8F/01.Redis/01.Redis%20%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0.html",relativePath:"09.系统设计鉴赏/01.Redis/01.Redis 架构概述.md",key:"v-5c2bcd3a",path:"/pages/264b06/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2024/09/14, 17:38:31",lastUpdatedTimestamp:1726335511e3},{title:"首页",frontmatter:{home:!0,title:"首页",heroImage:"/img/hero.png",heroText:"Echo 系统设计之美",tagline:"🚀将系统设计技能提升到一个新水平所需的一切🚀",actionText:"开始使用 →",actionLink:"/pages/3c1db5/",bannerBg:"none",features:[{title:"设计基础设施",details:"你可以跟随我一起去设计后端核心基础设施，并深入了解其原理"},{title:"设计热门应用",details:"你可以跟随我一起去设计当下最热门的应用，并深入了解其原理"},{title:"系统设计算法",details:"你可以在这里充分了解我们后端开发所必备的系统设计算法，算法是必需品"},{title:"设计理论",details:"对系统设计的相关概念理论进行详细讲解，良药苦口"},{title:"问答归档",details:"对系统设计的常见问题进行汇总、归档，定期对所有常见问题进行归档"},{title:"学习路线",details:"记录一些比较优质的学习方法与路线，别走弯路"}],postList:"none"},regularPath:"/",relativePath:"index.md",key:"v-a11d1cc4",path:"/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2024/09/13, 19:57:43",lastUpdatedTimestamp:1726257463e3}],themeConfig:{pageButton:!1,nav:[{text:"首页",link:"/"},{text:"学习路线",link:"/pages/bd2edd/"},{text:"系统设计算法",link:"/pages/fccd91/"},{text:"设计基础设施",link:"/pages/84cb49/"},{text:"系统设计鉴赏",link:"/pages/264b06/"},{text:"设计热门应用",link:"/pages/a95d7d/"},{text:"经典场景设计",link:"/pages/def08a/"},{text:"问答归档",link:"/pages/92b2ee/"},{text:"我的动态",link:"/pages/52ebd8/"}],sidebarDepth:2,logo:"/img/logo.png",repo:"echo-lxy/echo-system-design",searchMaxSuggestions:10,lastUpdated:"上次更新",docsDir:"docs",editLinks:!0,editLinkText:"编辑",sidebar:{"/01.系统设计算法/":[{title:"系统设计算法",collapsable:!1,children:[["01.系统设计算法/01.布隆过滤.md","布隆过滤","/pages/fccd91/"],["01.系统设计算法/02.一致性哈希.md","一致性哈希","/pages/1e28a2/"],["01.系统设计算法/03.Count-Min Sketch.md","Count-Min Sketch","/pages/8624c5"],["01.系统设计算法/04.LRU.md","LRU","/pages/87589a"],["01.系统设计算法/05.LFU.md","LFU","/pages/7d22be/"],["01.系统设计算法/06.渐进式 hash.md","渐进式 hash","/pages/2d43d1/"],["01.系统设计算法/10.时间轮.md","时间轮","/pages/44dcc2/"]]}],catalogue:{},"/02.设计热门应用/":[{title:"社交类",collapsable:!1,children:[["01.社交类/01.设计 微信.md","设计 微信","/pages/a95d7d/"],["01.社交类/02.设计Twitter.md","设计Twitter","/pages/90ad66/"]]}],"/03.经典场景设计/":[{title:"热门场景设计",collapsable:!1,children:[["01.热门场景设计/01.双写一致性.md","双写一致性","/pages/def08a/"],["01.热门场景设计/02.缓存穿透.md","缓存穿透","/pages/1e9e8e/"],["01.热门场景设计/03.缓存击穿.md","缓存击穿","/pages/1d96b2/"],["01.热门场景设计/04.任务补偿.md","任务补偿","/pages/24abe0/"],["01.热门场景设计/05.秒杀.md","秒杀","/pages/a72629/"],["01.热门场景设计/06.超卖.md","超卖","/pages/8a57f2/"],["01.热门场景设计/07.多级缓存.md","多级缓存","/pages/51aa8b/"],["01.热门场景设计/08.超时&重试.md","超时&重试","/pages/0dfb49/"],["01.热门场景设计/09.幂等&防重.md","幂等&防重","/pages/4fc8cb/"],["01.热门场景设计/10.海量数据计数.md","海量数据计数","/pages/f3295f/"],["01.热门场景设计/11.消息未读数系统.md","消息未读数系统","/pages/6b9d68/"]]}],"/04.设计基础设施/":[{title:"设计基础设施",collapsable:!1,children:[["01.设计基础设施/01.分布式缓存.md","分布式缓存","/pages/84cb49/"],["01.设计基础设施/02.限流器.md","限流器","/pages/57d5a5/"],["01.设计基础设施/03.热点探查（Top k）.md","热点探查（Top k）","/pages/5dcb6b/"],["01.设计基础设施/04.消息队列.md","消息队列","/pages/567090/"],["01.设计基础设施/05.订阅发布.md","服务通知","/pages/8416e6/"],["01.设计基础设施/06.动态线程池.md","动态线程池","/pages/d81a42/"]]}],"/06.我的动态/":[["01.碎碎念.md","碎碎念","/pages/52ebd8/"]],"/08.学习路线/":[{title:"学习路线",collapsable:!1,children:[["01.学习路线/01.第一步：一般性原则.md","第一步：一般性原则","/pages/bd2edd/"],["01.学习路线/02.第二步：核心组件.md","第二步：核心组件","/pages/c64895/"],["01.学习路线/03.第三步：核心系统.md","第三步：核心系统","/pages/b97db9/"]]}],"/09.系统设计鉴赏/":[{title:"Redis",collapsable:!1,children:[["01.Redis/01.Redis 架构概述.md","Redis 架构概述","/pages/264b06/"]]}]},updateBar:{showToArticle:!1},pageStyle:"line",category:!1,tag:!1,author:{name:"echo",href:"https://gitee.com/brother-one"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:lixinyang2002@163.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/echo-lxy"},{iconClass:"icon-erji",title:"听音乐",link:"https://music.163.com/#/playlist?id=755597173"}]},footer:{createYear:2024,copyrightInfo:"Xinyang Li | MIT License"},htmlModules:{pageT:'\n    <div class="wwads-cn wwads-horizontal page-wwads" data-id="136"></div>\n    <style>\n      .page-wwads{\n        width:100%!important;\n        min-height: 0;\n        margin: 0;\n      }\n      .page-wwads .wwads-img img{\n        width:80px!important;\n      }\n      .page-wwads .wwads-poweredby{\n        width: 40px;\n        position: absolute;\n        right: 25px;\n        bottom: 3px;\n      }\n      .wwads-content .wwads-text, .page-wwads .wwads-text{\n        height: 100%;\n        padding-top: 5px;\n        display: block;\n      }\n  </style>\n  '}}};var Ll=t(95),Sl=t(96),Rl=t(11);var Il={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:r}}=n;return!(e||!1===t||!0===r)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,r=e.frontmatter.sticky;return t&&r?t==r?Object(Rl.a)(n,e):t-r:t&&!r?-1:!t&&r?1:Object(Rl.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(Rl.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let r=0,i=n.length;r<i;r++){const{frontmatter:{categories:i,tags:o}}=n[r];"array"===Object(Rl.n)(i)&&i.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[r]))}),"array"===Object(Rl.n)(o)&&o.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[r]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Wt.component(Ll.default),Wt.component(Sl.default);function zl(n){return n.toString().padStart(2,"0")}t(245);Wt.component("Badge",()=>Promise.all([t.e(0),t.e(3)]).then(t.bind(null,369))),Wt.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,95))),Wt.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,96)));t(246);var Bl=[({Vue:n,options:e,router:t,siteData:r,isServer:i})=>{i||t.afterEach(()=>{var n;n=function(){setTimeout((function(){void 0===window._AdBlockInit&&function(){const n=document.getElementsByClassName("wwads-cn"),e=document.querySelector(".wwads-content");n[0]&&!e&&(n[0].innerHTML=h)}()}),3e3)},"complete"===document.readyState||"interactive"===document.readyState?setTimeout(n,1):document.addEventListener("DOMContentLoaded",n),setTimeout(()=>{const n=document.querySelector(".page-wwads");if(!n)return;const e=n.querySelector(".wwads-hide");e&&(e.onclick=()=>{n.style.display="none"}),"none"===n.style.display&&(n.style.display="flex")},900)})},({Vue:n,options:e,router:t,siteData:r})=>{r.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${zl(n.getUTCMonth()+1)}-${zl(n.getUTCDate())} ${zl(n.getUTCHours())}:${zl(n.getUTCMinutes())}:${zl(n.getUTCSeconds())}`}(e)),t?n.author=t:r.themeConfig.author&&(n.author=r.themeConfig.author)}),n.mixin(Il)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({router:n})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var n=document.createElement("script");n.src="https://hm.baidu.com/hm.js?01293bffa6c3962016c08ba685c79d78";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(n,e)}(),n.afterEach((function(n){_hmt.push(["_trackPageview",n.fullPath])})))}],Ol=[];class jl extends class{constructor(){this.store=new Wt({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){Wt.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign(jl.prototype,{getPageAsyncComponent:ls,getLayoutAsyncComponent:cs,getAsyncComponent:us,getVueComponent:ds});var Ul={install(n){const e=new jl;n.$vuepress=e,n.prototype.$vuepress=e}};function Pl(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var Dl={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return ps("pageKey",e),Wt.component(e)||Wt.component(e,ls(e)),Wt.component(e)?n(e):n("")}},Ml={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},Nl={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Fl=(t(247),t(248),Object(Is.a)(Nl,(function(){var n=this._self._c;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),$l={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};Wt.config.productionTip=!1,Wt.use(Va),Wt.use(Ul),Wt.mixin(function(n,e,t=Wt){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const r=new(n(t.$vuepress.$get("siteData"))),i=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),o={};return Object.keys(i).reduce((n,e)=>(e.startsWith("$")&&(n[e]=i[e].get),n),o),{computed:o}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const r in n)"/"===r?t=n[r]:0===this.$page.path.indexOf(r)&&(e=n[r]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},Cl)),Wt.component("Content",Dl),Wt.component("ContentSlotsDistributor",Ml),Wt.component("OutboundLink",Fl),Wt.component("ClientOnly",$l),Wt.component("Layout",cs("Layout")),Wt.component("NotFound",cs("NotFound")),Wt.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.9",hash:"f796ffd"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:Cl.routerBase||Cl.base,t=new Va({base:e,mode:"history",fallback:!1,routes:Al,scrollBehavior:(n,e,t)=>t||(n.hash?!Wt.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,r)=>{if(Pl(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";Pl(n,t)?r(t):r()}else r();else{const t=e.path+"/",i=e.path+".html";Pl(n,i)?r(i):Pl(n,t)?r(t):r()}})}(t);const r={};try{await Promise.all(Bl.filter(n=>"function"==typeof n).map(e=>e({Vue:Wt,options:r,router:t,siteData:Cl,isServer:n})))}catch(n){console.error(n)}return{app:new Wt(Object.assign(r,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Ol.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);